	.att_syntax
	.text
	.p2align	5
	.globl	_mayo2_crypto_sign_open
	.globl	mayo2_crypto_sign_open
_mayo2_crypto_sign_open:
mayo2_crypto_sign_open:
	movq	%rsp, %rax
	leaq	-216232(%rsp), %rsp
	andq	$-8, %rsp
	movq	%rbx, 216176(%rsp)
	movq	%rbp, 216184(%rsp)
	movq	%r12, 216192(%rsp)
	movq	%r13, 216200(%rsp)
	movq	%r14, 216208(%rsp)
	movq	%r15, 216216(%rsp)
	movq	%rax, 216224(%rsp)
	movb	(%rdi), %al
	movb	%al, 215680(%rsp)
	movb	1(%rdi), %al
	movb	%al, 215681(%rsp)
	movb	2(%rdi), %al
	movb	%al, 215682(%rsp)
	movb	3(%rdi), %al
	movb	%al, 215683(%rsp)
	movb	4(%rdi), %al
	movb	%al, 215684(%rsp)
	movb	5(%rdi), %al
	movb	%al, 215685(%rsp)
	movb	6(%rdi), %al
	movb	%al, 215686(%rsp)
	movb	7(%rdi), %al
	movb	%al, 215687(%rsp)
	movb	8(%rdi), %al
	movb	%al, 215688(%rsp)
	movb	9(%rdi), %al
	movb	%al, 215689(%rsp)
	movb	10(%rdi), %al
	movb	%al, 215690(%rsp)
	movb	11(%rdi), %al
	movb	%al, 215691(%rsp)
	movb	12(%rdi), %al
	movb	%al, 215692(%rsp)
	movb	13(%rdi), %al
	movb	%al, 215693(%rsp)
	movb	14(%rdi), %al
	movb	%al, 215694(%rsp)
	movb	15(%rdi), %al
	movb	%al, 215695(%rsp)
	movb	16(%rdi), %al
	movb	%al, 215696(%rsp)
	movb	17(%rdi), %al
	movb	%al, 215697(%rsp)
	movb	18(%rdi), %al
	movb	%al, 215698(%rsp)
	movb	19(%rdi), %al
	movb	%al, 215699(%rsp)
	movb	20(%rdi), %al
	movb	%al, 215700(%rsp)
	movb	21(%rdi), %al
	movb	%al, 215701(%rsp)
	movb	22(%rdi), %al
	movb	%al, 215702(%rsp)
	movb	23(%rdi), %al
	movb	%al, 215703(%rsp)
	movb	24(%rdi), %al
	movb	%al, 215704(%rsp)
	movb	25(%rdi), %al
	movb	%al, 215705(%rsp)
	movb	26(%rdi), %al
	movb	%al, 215706(%rsp)
	movb	27(%rdi), %al
	movb	%al, 215707(%rsp)
	movb	28(%rdi), %al
	movb	%al, 215708(%rsp)
	movb	29(%rdi), %al
	movb	%al, 215709(%rsp)
	movb	30(%rdi), %al
	movb	%al, 215710(%rsp)
	movb	31(%rdi), %al
	movb	%al, 215711(%rsp)
	movb	32(%rdi), %al
	movb	%al, 215712(%rsp)
	movb	33(%rdi), %al
	movb	%al, 215713(%rsp)
	movb	34(%rdi), %al
	movb	%al, 215714(%rsp)
	movb	35(%rdi), %al
	movb	%al, 215715(%rsp)
	movb	36(%rdi), %al
	movb	%al, 215716(%rsp)
	movb	37(%rdi), %al
	movb	%al, 215717(%rsp)
	movb	38(%rdi), %al
	movb	%al, 215718(%rsp)
	movb	39(%rdi), %al
	movb	%al, 215719(%rsp)
	movb	40(%rdi), %al
	movb	%al, 215720(%rsp)
	movb	41(%rdi), %al
	movb	%al, 215721(%rsp)
	movb	42(%rdi), %al
	movb	%al, 215722(%rsp)
	movb	43(%rdi), %al
	movb	%al, 215723(%rsp)
	movb	44(%rdi), %al
	movb	%al, 215724(%rsp)
	movb	45(%rdi), %al
	movb	%al, 215725(%rsp)
	movb	46(%rdi), %al
	movb	%al, 215726(%rsp)
	movb	47(%rdi), %al
	movb	%al, 215727(%rsp)
	movb	48(%rdi), %al
	movb	%al, 215728(%rsp)
	movb	49(%rdi), %al
	movb	%al, 215729(%rsp)
	movb	50(%rdi), %al
	movb	%al, 215730(%rsp)
	movb	51(%rdi), %al
	movb	%al, 215731(%rsp)
	movb	52(%rdi), %al
	movb	%al, 215732(%rsp)
	movb	53(%rdi), %al
	movb	%al, 215733(%rsp)
	movb	54(%rdi), %al
	movb	%al, 215734(%rsp)
	movb	55(%rdi), %al
	movb	%al, 215735(%rsp)
	movb	56(%rdi), %al
	movb	%al, 215736(%rsp)
	movb	57(%rdi), %al
	movb	%al, 215737(%rsp)
	movb	58(%rdi), %al
	movb	%al, 215738(%rsp)
	movb	59(%rdi), %al
	movb	%al, 215739(%rsp)
	movb	60(%rdi), %al
	movb	%al, 215740(%rsp)
	movb	61(%rdi), %al
	movb	%al, 215741(%rsp)
	movb	62(%rdi), %al
	movb	%al, 215742(%rsp)
	movb	63(%rdi), %al
	movb	%al, 215743(%rsp)
	movb	64(%rdi), %al
	movb	%al, 215744(%rsp)
	movb	65(%rdi), %al
	movb	%al, 215745(%rsp)
	movb	66(%rdi), %al
	movb	%al, 215746(%rsp)
	movb	67(%rdi), %al
	movb	%al, 215747(%rsp)
	movb	68(%rdi), %al
	movb	%al, 215748(%rsp)
	movb	69(%rdi), %al
	movb	%al, 215749(%rsp)
	movb	70(%rdi), %al
	movb	%al, 215750(%rsp)
	movb	71(%rdi), %al
	movb	%al, 215751(%rsp)
	movb	72(%rdi), %al
	movb	%al, 215752(%rsp)
	movb	73(%rdi), %al
	movb	%al, 215753(%rsp)
	movb	74(%rdi), %al
	movb	%al, 215754(%rsp)
	movb	75(%rdi), %al
	movb	%al, 215755(%rsp)
	movb	76(%rdi), %al
	movb	%al, 215756(%rsp)
	movb	77(%rdi), %al
	movb	%al, 215757(%rsp)
	movb	78(%rdi), %al
	movb	%al, 215758(%rsp)
	movb	79(%rdi), %al
	movb	%al, 215759(%rsp)
	movb	80(%rdi), %al
	movb	%al, 215760(%rsp)
	movb	81(%rdi), %al
	movb	%al, 215761(%rsp)
	movb	82(%rdi), %al
	movb	%al, 215762(%rsp)
	movb	83(%rdi), %al
	movb	%al, 215763(%rsp)
	movb	84(%rdi), %al
	movb	%al, 215764(%rsp)
	movb	85(%rdi), %al
	movb	%al, 215765(%rsp)
	movb	86(%rdi), %al
	movb	%al, 215766(%rsp)
	movb	87(%rdi), %al
	movb	%al, 215767(%rsp)
	movb	88(%rdi), %al
	movb	%al, 215768(%rsp)
	movb	89(%rdi), %al
	movb	%al, 215769(%rsp)
	movb	90(%rdi), %al
	movb	%al, 215770(%rsp)
	movb	91(%rdi), %al
	movb	%al, 215771(%rsp)
	movb	92(%rdi), %al
	movb	%al, 215772(%rsp)
	movb	93(%rdi), %al
	movb	%al, 215773(%rsp)
	movb	94(%rdi), %al
	movb	%al, 215774(%rsp)
	movb	95(%rdi), %al
	movb	%al, 215775(%rsp)
	movb	96(%rdi), %al
	movb	%al, 215776(%rsp)
	movb	97(%rdi), %al
	movb	%al, 215777(%rsp)
	movb	98(%rdi), %al
	movb	%al, 215778(%rsp)
	movb	99(%rdi), %al
	movb	%al, 215779(%rsp)
	movb	100(%rdi), %al
	movb	%al, 215780(%rsp)
	movb	101(%rdi), %al
	movb	%al, 215781(%rsp)
	movb	102(%rdi), %al
	movb	%al, 215782(%rsp)
	movb	103(%rdi), %al
	movb	%al, 215783(%rsp)
	movb	104(%rdi), %al
	movb	%al, 215784(%rsp)
	movb	105(%rdi), %al
	movb	%al, 215785(%rsp)
	movb	106(%rdi), %al
	movb	%al, 215786(%rsp)
	movb	107(%rdi), %al
	movb	%al, 215787(%rsp)
	movb	108(%rdi), %al
	movb	%al, 215788(%rsp)
	movb	109(%rdi), %al
	movb	%al, 215789(%rsp)
	movb	110(%rdi), %al
	movb	%al, 215790(%rsp)
	movb	111(%rdi), %al
	movb	%al, 215791(%rsp)
	movb	112(%rdi), %al
	movb	%al, 215792(%rsp)
	movb	113(%rdi), %al
	movb	%al, 215793(%rsp)
	movb	114(%rdi), %al
	movb	%al, 215794(%rsp)
	movb	115(%rdi), %al
	movb	%al, 215795(%rsp)
	movb	116(%rdi), %al
	movb	%al, 215796(%rsp)
	movb	117(%rdi), %al
	movb	%al, 215797(%rsp)
	movb	118(%rdi), %al
	movb	%al, 215798(%rsp)
	movb	119(%rdi), %al
	movb	%al, 215799(%rsp)
	movb	120(%rdi), %al
	movb	%al, 215800(%rsp)
	movb	121(%rdi), %al
	movb	%al, 215801(%rsp)
	movb	122(%rdi), %al
	movb	%al, 215802(%rsp)
	movb	123(%rdi), %al
	movb	%al, 215803(%rsp)
	movb	124(%rdi), %al
	movb	%al, 215804(%rsp)
	movb	125(%rdi), %al
	movb	%al, 215805(%rsp)
	movb	126(%rdi), %al
	movb	%al, 215806(%rsp)
	movb	127(%rdi), %al
	movb	%al, 215807(%rsp)
	movb	128(%rdi), %al
	movb	%al, 215808(%rsp)
	movb	129(%rdi), %al
	movb	%al, 215809(%rsp)
	movb	130(%rdi), %al
	movb	%al, 215810(%rsp)
	movb	131(%rdi), %al
	movb	%al, 215811(%rsp)
	movb	132(%rdi), %al
	movb	%al, 215812(%rsp)
	movb	133(%rdi), %al
	movb	%al, 215813(%rsp)
	movb	134(%rdi), %al
	movb	%al, 215814(%rsp)
	movb	135(%rdi), %al
	movb	%al, 215815(%rsp)
	movb	136(%rdi), %al
	movb	%al, 215816(%rsp)
	movb	137(%rdi), %al
	movb	%al, 215817(%rsp)
	movb	138(%rdi), %al
	movb	%al, 215818(%rsp)
	movb	139(%rdi), %al
	movb	%al, 215819(%rsp)
	movb	140(%rdi), %al
	movb	%al, 215820(%rsp)
	movb	141(%rdi), %al
	movb	%al, 215821(%rsp)
	movb	142(%rdi), %al
	movb	%al, 215822(%rsp)
	movb	143(%rdi), %al
	movb	%al, 215823(%rsp)
	movb	144(%rdi), %al
	movb	%al, 215824(%rsp)
	movb	145(%rdi), %al
	movb	%al, 215825(%rsp)
	movb	146(%rdi), %al
	movb	%al, 215826(%rsp)
	movb	147(%rdi), %al
	movb	%al, 215827(%rsp)
	movb	148(%rdi), %al
	movb	%al, 215828(%rsp)
	movb	149(%rdi), %al
	movb	%al, 215829(%rsp)
	movb	150(%rdi), %al
	movb	%al, 215830(%rsp)
	movb	151(%rdi), %al
	movb	%al, 215831(%rsp)
	movb	152(%rdi), %al
	movb	%al, 215832(%rsp)
	movb	153(%rdi), %al
	movb	%al, 215833(%rsp)
	movb	154(%rdi), %al
	movb	%al, 215834(%rsp)
	movb	155(%rdi), %al
	movb	%al, 215835(%rsp)
	movb	156(%rdi), %al
	movb	%al, 215836(%rsp)
	movb	157(%rdi), %al
	movb	%al, 215837(%rsp)
	movb	158(%rdi), %al
	movb	%al, 215838(%rsp)
	movb	159(%rdi), %al
	movb	%al, 215839(%rsp)
	movb	160(%rdi), %al
	movb	%al, 215840(%rsp)
	movb	161(%rdi), %al
	movb	%al, 215841(%rsp)
	movb	162(%rdi), %al
	movb	%al, 215842(%rsp)
	movb	163(%rdi), %al
	movb	%al, 215843(%rsp)
	movb	164(%rdi), %al
	movb	%al, 215844(%rsp)
	movb	165(%rdi), %al
	movb	%al, 215845(%rsp)
	movb	166(%rdi), %al
	movb	%al, 215846(%rsp)
	movb	167(%rdi), %al
	movb	%al, 215847(%rsp)
	movb	168(%rdi), %al
	movb	%al, 215848(%rsp)
	movb	169(%rdi), %al
	movb	%al, 215849(%rsp)
	movb	170(%rdi), %al
	movb	%al, 215850(%rsp)
	movb	171(%rdi), %al
	movb	%al, 215851(%rsp)
	movb	172(%rdi), %al
	movb	%al, 215852(%rsp)
	movb	173(%rdi), %al
	movb	%al, 215853(%rsp)
	movb	174(%rdi), %al
	movb	%al, 215854(%rsp)
	movb	175(%rdi), %al
	movb	%al, 215855(%rsp)
	movb	176(%rdi), %al
	movb	%al, 215856(%rsp)
	movb	177(%rdi), %al
	movb	%al, 215857(%rsp)
	movb	178(%rdi), %al
	movb	%al, 215858(%rsp)
	movb	179(%rdi), %al
	movb	%al, 215859(%rsp)
	leaq	24(%rsp), %rax
	movb	$31, %r8b
	movq	$136, %r9
	movq	%rsi, %rdi
	movq	%r9, %rsi
	leaq	-240(%rsp), %rsp
	call	L_keccak1600_32_x$1
Lmayo2_crypto_sign_open$92:
	leaq	240(%rsp), %rsp
	movq	(%rcx), %rax
	movq	%rax, 944(%rsp)
	movq	8(%rcx), %rax
	movq	%rax, 952(%rsp)
	movq	16(%rcx), %rax
	movq	%rax, 960(%rsp)
	movq	24(%rcx), %rax
	movq	%rax, 968(%rsp)
	movq	32(%rcx), %rax
	movq	%rax, 976(%rsp)
	movq	40(%rcx), %rax
	movq	%rax, 984(%rsp)
	movq	48(%rcx), %rax
	movq	%rax, 992(%rsp)
	movq	56(%rcx), %rax
	movq	%rax, 1000(%rsp)
	movq	64(%rcx), %rax
	movq	%rax, 1008(%rsp)
	movq	72(%rcx), %rax
	movq	%rax, 1016(%rsp)
	movq	80(%rcx), %rax
	movq	%rax, 1024(%rsp)
	movq	88(%rcx), %rax
	movq	%rax, 1032(%rsp)
	movq	96(%rcx), %rax
	movq	%rax, 1040(%rsp)
	movq	104(%rcx), %rax
	movq	%rax, 1048(%rsp)
	movq	112(%rcx), %rax
	movq	%rax, 1056(%rsp)
	movq	120(%rcx), %rax
	movq	%rax, 1064(%rsp)
	movq	128(%rcx), %rax
	movq	%rax, 1072(%rsp)
	movq	136(%rcx), %rax
	movq	%rax, 1080(%rsp)
	movq	144(%rcx), %rax
	movq	%rax, 1088(%rsp)
	movq	152(%rcx), %rax
	movq	%rax, 1096(%rsp)
	movq	160(%rcx), %rax
	movq	%rax, 1104(%rsp)
	movq	168(%rcx), %rax
	movq	%rax, 1112(%rsp)
	movq	176(%rcx), %rax
	movq	%rax, 1120(%rsp)
	movq	184(%rcx), %rax
	movq	%rax, 1128(%rsp)
	movq	192(%rcx), %rax
	movq	%rax, 1136(%rsp)
	movq	200(%rcx), %rax
	movq	%rax, 1144(%rsp)
	movq	208(%rcx), %rax
	movq	%rax, 1152(%rsp)
	movq	216(%rcx), %rax
	movq	%rax, 1160(%rsp)
	movq	224(%rcx), %rax
	movq	%rax, 1168(%rsp)
	movq	232(%rcx), %rax
	movq	%rax, 1176(%rsp)
	movq	240(%rcx), %rax
	movq	%rax, 1184(%rsp)
	movq	248(%rcx), %rax
	movq	%rax, 1192(%rsp)
	movq	256(%rcx), %rax
	movq	%rax, 1200(%rsp)
	movq	264(%rcx), %rax
	movq	%rax, 1208(%rsp)
	movq	272(%rcx), %rax
	movq	%rax, 1216(%rsp)
	movq	280(%rcx), %rax
	movq	%rax, 1224(%rsp)
	movq	288(%rcx), %rax
	movq	%rax, 1232(%rsp)
	movq	296(%rcx), %rax
	movq	%rax, 1240(%rsp)
	movq	304(%rcx), %rax
	movq	%rax, 1248(%rsp)
	movq	312(%rcx), %rax
	movq	%rax, 1256(%rsp)
	movq	320(%rcx), %rax
	movq	%rax, 1264(%rsp)
	movq	328(%rcx), %rax
	movq	%rax, 1272(%rsp)
	movq	336(%rcx), %rax
	movq	%rax, 1280(%rsp)
	movq	344(%rcx), %rax
	movq	%rax, 1288(%rsp)
	movq	352(%rcx), %rax
	movq	%rax, 1296(%rsp)
	movq	360(%rcx), %rax
	movq	%rax, 1304(%rsp)
	movq	368(%rcx), %rax
	movq	%rax, 1312(%rsp)
	movq	376(%rcx), %rax
	movq	%rax, 1320(%rsp)
	movq	384(%rcx), %rax
	movq	%rax, 1328(%rsp)
	movq	392(%rcx), %rax
	movq	%rax, 1336(%rsp)
	movq	400(%rcx), %rax
	movq	%rax, 1344(%rsp)
	movq	408(%rcx), %rax
	movq	%rax, 1352(%rsp)
	movq	416(%rcx), %rax
	movq	%rax, 1360(%rsp)
	movq	424(%rcx), %rax
	movq	%rax, 1368(%rsp)
	movq	432(%rcx), %rax
	movq	%rax, 1376(%rsp)
	movq	440(%rcx), %rax
	movq	%rax, 1384(%rsp)
	movq	448(%rcx), %rax
	movq	%rax, 1392(%rsp)
	movq	456(%rcx), %rax
	movq	%rax, 1400(%rsp)
	movq	464(%rcx), %rax
	movq	%rax, 1408(%rsp)
	movq	472(%rcx), %rax
	movq	%rax, 1416(%rsp)
	movq	480(%rcx), %rax
	movq	%rax, 1424(%rsp)
	movq	488(%rcx), %rax
	movq	%rax, 1432(%rsp)
	movq	496(%rcx), %rax
	movq	%rax, 1440(%rsp)
	movq	504(%rcx), %rax
	movq	%rax, 1448(%rsp)
	movq	512(%rcx), %rax
	movq	%rax, 1456(%rsp)
	movq	520(%rcx), %rax
	movq	%rax, 1464(%rsp)
	movq	528(%rcx), %rax
	movq	%rax, 1472(%rsp)
	movq	536(%rcx), %rax
	movq	%rax, 1480(%rsp)
	movq	544(%rcx), %rax
	movq	%rax, 1488(%rsp)
	movq	552(%rcx), %rax
	movq	%rax, 1496(%rsp)
	movq	560(%rcx), %rax
	movq	%rax, 1504(%rsp)
	movq	568(%rcx), %rax
	movq	%rax, 1512(%rsp)
	movq	576(%rcx), %rax
	movq	%rax, 1520(%rsp)
	movq	584(%rcx), %rax
	movq	%rax, 1528(%rsp)
	movq	592(%rcx), %rax
	movq	%rax, 1536(%rsp)
	movq	600(%rcx), %rax
	movq	%rax, 1544(%rsp)
	movq	608(%rcx), %rax
	movq	%rax, 1552(%rsp)
	movq	616(%rcx), %rax
	movq	%rax, 1560(%rsp)
	movq	624(%rcx), %rax
	movq	%rax, 1568(%rsp)
	movq	632(%rcx), %rax
	movq	%rax, 1576(%rsp)
	movq	640(%rcx), %rax
	movq	%rax, 1584(%rsp)
	movq	648(%rcx), %rax
	movq	%rax, 1592(%rsp)
	movq	656(%rcx), %rax
	movq	%rax, 1600(%rsp)
	movq	664(%rcx), %rax
	movq	%rax, 1608(%rsp)
	movq	672(%rcx), %rax
	movq	%rax, 1616(%rsp)
	movq	680(%rcx), %rax
	movq	%rax, 1624(%rsp)
	movq	688(%rcx), %rax
	movq	%rax, 1632(%rsp)
	movq	696(%rcx), %rax
	movq	%rax, 1640(%rsp)
	movq	704(%rcx), %rax
	movq	%rax, 1648(%rsp)
	movq	712(%rcx), %rax
	movq	%rax, 1656(%rsp)
	movq	720(%rcx), %rax
	movq	%rax, 1664(%rsp)
	movq	728(%rcx), %rax
	movq	%rax, 1672(%rsp)
	movq	736(%rcx), %rax
	movq	%rax, 1680(%rsp)
	movq	744(%rcx), %rax
	movq	%rax, 1688(%rsp)
	movq	752(%rcx), %rax
	movq	%rax, 1696(%rsp)
	movq	760(%rcx), %rax
	movq	%rax, 1704(%rsp)
	movq	768(%rcx), %rax
	movq	%rax, 1712(%rsp)
	movq	776(%rcx), %rax
	movq	%rax, 1720(%rsp)
	movq	784(%rcx), %rax
	movq	%rax, 1728(%rsp)
	movq	792(%rcx), %rax
	movq	%rax, 1736(%rsp)
	movq	800(%rcx), %rax
	movq	%rax, 1744(%rsp)
	movq	808(%rcx), %rax
	movq	%rax, 1752(%rsp)
	movq	816(%rcx), %rax
	movq	%rax, 1760(%rsp)
	movq	824(%rcx), %rax
	movq	%rax, 1768(%rsp)
	movq	832(%rcx), %rax
	movq	%rax, 1776(%rsp)
	movq	840(%rcx), %rax
	movq	%rax, 1784(%rsp)
	movq	848(%rcx), %rax
	movq	%rax, 1792(%rsp)
	movq	856(%rcx), %rax
	movq	%rax, 1800(%rsp)
	movq	864(%rcx), %rax
	movq	%rax, 1808(%rsp)
	movq	872(%rcx), %rax
	movq	%rax, 1816(%rsp)
	movq	880(%rcx), %rax
	movq	%rax, 1824(%rsp)
	movq	888(%rcx), %rax
	movq	%rax, 1832(%rsp)
	movq	896(%rcx), %rax
	movq	%rax, 1840(%rsp)
	movq	904(%rcx), %rax
	movq	%rax, 1848(%rsp)
	movq	912(%rcx), %rax
	movq	%rax, 1856(%rsp)
	movq	920(%rcx), %rax
	movq	%rax, 1864(%rsp)
	movq	928(%rcx), %rax
	movq	%rax, 1872(%rsp)
	movq	936(%rcx), %rax
	movq	%rax, 1880(%rsp)
	movq	944(%rcx), %rax
	movq	%rax, 1888(%rsp)
	movq	952(%rcx), %rax
	movq	%rax, 1896(%rsp)
	movq	960(%rcx), %rax
	movq	%rax, 1904(%rsp)
	movq	968(%rcx), %rax
	movq	%rax, 1912(%rsp)
	movq	976(%rcx), %rax
	movq	%rax, 1920(%rsp)
	movq	984(%rcx), %rax
	movq	%rax, 1928(%rsp)
	movq	992(%rcx), %rax
	movq	%rax, 1936(%rsp)
	movq	1000(%rcx), %rax
	movq	%rax, 1944(%rsp)
	movq	1008(%rcx), %rax
	movq	%rax, 1952(%rsp)
	movq	1016(%rcx), %rax
	movq	%rax, 1960(%rsp)
	movq	1024(%rcx), %rax
	movq	%rax, 1968(%rsp)
	movq	1032(%rcx), %rax
	movq	%rax, 1976(%rsp)
	movq	1040(%rcx), %rax
	movq	%rax, 1984(%rsp)
	movq	1048(%rcx), %rax
	movq	%rax, 1992(%rsp)
	movq	1056(%rcx), %rax
	movq	%rax, 2000(%rsp)
	movq	1064(%rcx), %rax
	movq	%rax, 2008(%rsp)
	movq	1072(%rcx), %rax
	movq	%rax, 2016(%rsp)
	movq	1080(%rcx), %rax
	movq	%rax, 2024(%rsp)
	movq	1088(%rcx), %rax
	movq	%rax, 2032(%rsp)
	movq	1096(%rcx), %rax
	movq	%rax, 2040(%rsp)
	movq	1104(%rcx), %rax
	movq	%rax, 2048(%rsp)
	movq	1112(%rcx), %rax
	movq	%rax, 2056(%rsp)
	movq	1120(%rcx), %rax
	movq	%rax, 2064(%rsp)
	movq	1128(%rcx), %rax
	movq	%rax, 2072(%rsp)
	movq	1136(%rcx), %rax
	movq	%rax, 2080(%rsp)
	movq	1144(%rcx), %rax
	movq	%rax, 2088(%rsp)
	movq	1152(%rcx), %rax
	movq	%rax, 2096(%rsp)
	movq	1160(%rcx), %rax
	movq	%rax, 2104(%rsp)
	movq	1168(%rcx), %rax
	movq	%rax, 2112(%rsp)
	movq	1176(%rcx), %rax
	movq	%rax, 2120(%rsp)
	movq	1184(%rcx), %rax
	movq	%rax, 2128(%rsp)
	movq	1192(%rcx), %rax
	movq	%rax, 2136(%rsp)
	movq	1200(%rcx), %rax
	movq	%rax, 2144(%rsp)
	movq	1208(%rcx), %rax
	movq	%rax, 2152(%rsp)
	movq	1216(%rcx), %rax
	movq	%rax, 2160(%rsp)
	movq	1224(%rcx), %rax
	movq	%rax, 2168(%rsp)
	movq	1232(%rcx), %rax
	movq	%rax, 2176(%rsp)
	movq	1240(%rcx), %rax
	movq	%rax, 2184(%rsp)
	movq	1248(%rcx), %rax
	movq	%rax, 2192(%rsp)
	movq	1256(%rcx), %rax
	movq	%rax, 2200(%rsp)
	movq	1264(%rcx), %rax
	movq	%rax, 2208(%rsp)
	movq	1272(%rcx), %rax
	movq	%rax, 2216(%rsp)
	movq	1280(%rcx), %rax
	movq	%rax, 2224(%rsp)
	movq	1288(%rcx), %rax
	movq	%rax, 2232(%rsp)
	movq	1296(%rcx), %rax
	movq	%rax, 2240(%rsp)
	movq	1304(%rcx), %rax
	movq	%rax, 2248(%rsp)
	movq	1312(%rcx), %rax
	movq	%rax, 2256(%rsp)
	movq	1320(%rcx), %rax
	movq	%rax, 2264(%rsp)
	movq	1328(%rcx), %rax
	movq	%rax, 2272(%rsp)
	movq	1336(%rcx), %rax
	movq	%rax, 2280(%rsp)
	movq	1344(%rcx), %rax
	movq	%rax, 2288(%rsp)
	movq	1352(%rcx), %rax
	movq	%rax, 2296(%rsp)
	movq	1360(%rcx), %rax
	movq	%rax, 2304(%rsp)
	movq	1368(%rcx), %rax
	movq	%rax, 2312(%rsp)
	movq	1376(%rcx), %rax
	movq	%rax, 2320(%rsp)
	movq	1384(%rcx), %rax
	movq	%rax, 2328(%rsp)
	movq	1392(%rcx), %rax
	movq	%rax, 2336(%rsp)
	movq	1400(%rcx), %rax
	movq	%rax, 2344(%rsp)
	movq	1408(%rcx), %rax
	movq	%rax, 2352(%rsp)
	movq	1416(%rcx), %rax
	movq	%rax, 2360(%rsp)
	movq	1424(%rcx), %rax
	movq	%rax, 2368(%rsp)
	movq	1432(%rcx), %rax
	movq	%rax, 2376(%rsp)
	movq	1440(%rcx), %rax
	movq	%rax, 2384(%rsp)
	movq	1448(%rcx), %rax
	movq	%rax, 2392(%rsp)
	movq	1456(%rcx), %rax
	movq	%rax, 2400(%rsp)
	movq	1464(%rcx), %rax
	movq	%rax, 2408(%rsp)
	movq	1472(%rcx), %rax
	movq	%rax, 2416(%rsp)
	movq	1480(%rcx), %rax
	movq	%rax, 2424(%rsp)
	movq	1488(%rcx), %rax
	movq	%rax, 2432(%rsp)
	movq	1496(%rcx), %rax
	movq	%rax, 2440(%rsp)
	movq	1504(%rcx), %rax
	movq	%rax, 2448(%rsp)
	movq	1512(%rcx), %rax
	movq	%rax, 2456(%rsp)
	movq	1520(%rcx), %rax
	movq	%rax, 2464(%rsp)
	movq	1528(%rcx), %rax
	movq	%rax, 2472(%rsp)
	movq	1536(%rcx), %rax
	movq	%rax, 2480(%rsp)
	movq	1544(%rcx), %rax
	movq	%rax, 2488(%rsp)
	movq	1552(%rcx), %rax
	movq	%rax, 2496(%rsp)
	movq	1560(%rcx), %rax
	movq	%rax, 2504(%rsp)
	movq	1568(%rcx), %rax
	movq	%rax, 2512(%rsp)
	movq	1576(%rcx), %rax
	movq	%rax, 2520(%rsp)
	movq	1584(%rcx), %rax
	movq	%rax, 2528(%rsp)
	movq	1592(%rcx), %rax
	movq	%rax, 2536(%rsp)
	movq	1600(%rcx), %rax
	movq	%rax, 2544(%rsp)
	movq	1608(%rcx), %rax
	movq	%rax, 2552(%rsp)
	movq	1616(%rcx), %rax
	movq	%rax, 2560(%rsp)
	movq	1624(%rcx), %rax
	movq	%rax, 2568(%rsp)
	movq	1632(%rcx), %rax
	movq	%rax, 2576(%rsp)
	movq	1640(%rcx), %rax
	movq	%rax, 2584(%rsp)
	movq	1648(%rcx), %rax
	movq	%rax, 2592(%rsp)
	movq	1656(%rcx), %rax
	movq	%rax, 2600(%rsp)
	movq	1664(%rcx), %rax
	movq	%rax, 2608(%rsp)
	movq	1672(%rcx), %rax
	movq	%rax, 2616(%rsp)
	movq	1680(%rcx), %rax
	movq	%rax, 2624(%rsp)
	movq	1688(%rcx), %rax
	movq	%rax, 2632(%rsp)
	movq	1696(%rcx), %rax
	movq	%rax, 2640(%rsp)
	movq	1704(%rcx), %rax
	movq	%rax, 2648(%rsp)
	movq	1712(%rcx), %rax
	movq	%rax, 2656(%rsp)
	movq	1720(%rcx), %rax
	movq	%rax, 2664(%rsp)
	movq	1728(%rcx), %rax
	movq	%rax, 2672(%rsp)
	movq	1736(%rcx), %rax
	movq	%rax, 2680(%rsp)
	movq	1744(%rcx), %rax
	movq	%rax, 2688(%rsp)
	movq	1752(%rcx), %rax
	movq	%rax, 2696(%rsp)
	movq	1760(%rcx), %rax
	movq	%rax, 2704(%rsp)
	movq	1768(%rcx), %rax
	movq	%rax, 2712(%rsp)
	movq	1776(%rcx), %rax
	movq	%rax, 2720(%rsp)
	movq	1784(%rcx), %rax
	movq	%rax, 2728(%rsp)
	movq	1792(%rcx), %rax
	movq	%rax, 2736(%rsp)
	movq	1800(%rcx), %rax
	movq	%rax, 2744(%rsp)
	movq	1808(%rcx), %rax
	movq	%rax, 2752(%rsp)
	movq	1816(%rcx), %rax
	movq	%rax, 2760(%rsp)
	movq	1824(%rcx), %rax
	movq	%rax, 2768(%rsp)
	movq	1832(%rcx), %rax
	movq	%rax, 2776(%rsp)
	movq	1840(%rcx), %rax
	movq	%rax, 2784(%rsp)
	movq	1848(%rcx), %rax
	movq	%rax, 2792(%rsp)
	movq	1856(%rcx), %rax
	movq	%rax, 2800(%rsp)
	movq	1864(%rcx), %rax
	movq	%rax, 2808(%rsp)
	movq	1872(%rcx), %rax
	movq	%rax, 2816(%rsp)
	movq	1880(%rcx), %rax
	movq	%rax, 2824(%rsp)
	movq	1888(%rcx), %rax
	movq	%rax, 2832(%rsp)
	movq	1896(%rcx), %rax
	movq	%rax, 2840(%rsp)
	movq	1904(%rcx), %rax
	movq	%rax, 2848(%rsp)
	movq	1912(%rcx), %rax
	movq	%rax, 2856(%rsp)
	movq	1920(%rcx), %rax
	movq	%rax, 2864(%rsp)
	movq	1928(%rcx), %rax
	movq	%rax, 2872(%rsp)
	movq	1936(%rcx), %rax
	movq	%rax, 2880(%rsp)
	movq	1944(%rcx), %rax
	movq	%rax, 2888(%rsp)
	movq	1952(%rcx), %rax
	movq	%rax, 2896(%rsp)
	movq	1960(%rcx), %rax
	movq	%rax, 2904(%rsp)
	movq	1968(%rcx), %rax
	movq	%rax, 2912(%rsp)
	movq	1976(%rcx), %rax
	movq	%rax, 2920(%rsp)
	movq	1984(%rcx), %rax
	movq	%rax, 2928(%rsp)
	movq	1992(%rcx), %rax
	movq	%rax, 2936(%rsp)
	movq	2000(%rcx), %rax
	movq	%rax, 2944(%rsp)
	movq	2008(%rcx), %rax
	movq	%rax, 2952(%rsp)
	movq	2016(%rcx), %rax
	movq	%rax, 2960(%rsp)
	movq	2024(%rcx), %rax
	movq	%rax, 2968(%rsp)
	movq	2032(%rcx), %rax
	movq	%rax, 2976(%rsp)
	movq	2040(%rcx), %rax
	movq	%rax, 2984(%rsp)
	movq	2048(%rcx), %rax
	movq	%rax, 2992(%rsp)
	movq	2056(%rcx), %rax
	movq	%rax, 3000(%rsp)
	movq	2064(%rcx), %rax
	movq	%rax, 3008(%rsp)
	movq	2072(%rcx), %rax
	movq	%rax, 3016(%rsp)
	movq	2080(%rcx), %rax
	movq	%rax, 3024(%rsp)
	movq	2088(%rcx), %rax
	movq	%rax, 3032(%rsp)
	movq	2096(%rcx), %rax
	movq	%rax, 3040(%rsp)
	movq	2104(%rcx), %rax
	movq	%rax, 3048(%rsp)
	movq	2112(%rcx), %rax
	movq	%rax, 3056(%rsp)
	movq	2120(%rcx), %rax
	movq	%rax, 3064(%rsp)
	movq	2128(%rcx), %rax
	movq	%rax, 3072(%rsp)
	movq	2136(%rcx), %rax
	movq	%rax, 3080(%rsp)
	movq	2144(%rcx), %rax
	movq	%rax, 3088(%rsp)
	movq	2152(%rcx), %rax
	movq	%rax, 3096(%rsp)
	movq	2160(%rcx), %rax
	movq	%rax, 3104(%rsp)
	movq	2168(%rcx), %rax
	movq	%rax, 3112(%rsp)
	movq	2176(%rcx), %rax
	movq	%rax, 3120(%rsp)
	movq	2184(%rcx), %rax
	movq	%rax, 3128(%rsp)
	movq	2192(%rcx), %rax
	movq	%rax, 3136(%rsp)
	movq	2200(%rcx), %rax
	movq	%rax, 3144(%rsp)
	movq	2208(%rcx), %rax
	movq	%rax, 3152(%rsp)
	movq	2216(%rcx), %rax
	movq	%rax, 3160(%rsp)
	movq	2224(%rcx), %rax
	movq	%rax, 3168(%rsp)
	movq	2232(%rcx), %rax
	movq	%rax, 3176(%rsp)
	movq	2240(%rcx), %rax
	movq	%rax, 3184(%rsp)
	movq	2248(%rcx), %rax
	movq	%rax, 3192(%rsp)
	movq	2256(%rcx), %rax
	movq	%rax, 3200(%rsp)
	movq	2264(%rcx), %rax
	movq	%rax, 3208(%rsp)
	movq	2272(%rcx), %rax
	movq	%rax, 3216(%rsp)
	movq	2280(%rcx), %rax
	movq	%rax, 3224(%rsp)
	movq	2288(%rcx), %rax
	movq	%rax, 3232(%rsp)
	movq	2296(%rcx), %rax
	movq	%rax, 3240(%rsp)
	movq	2304(%rcx), %rax
	movq	%rax, 3248(%rsp)
	movq	2312(%rcx), %rax
	movq	%rax, 3256(%rsp)
	movq	2320(%rcx), %rax
	movq	%rax, 3264(%rsp)
	movq	2328(%rcx), %rax
	movq	%rax, 3272(%rsp)
	movq	2336(%rcx), %rax
	movq	%rax, 3280(%rsp)
	movq	2344(%rcx), %rax
	movq	%rax, 3288(%rsp)
	movq	2352(%rcx), %rax
	movq	%rax, 3296(%rsp)
	movq	2360(%rcx), %rax
	movq	%rax, 3304(%rsp)
	movq	2368(%rcx), %rax
	movq	%rax, 3312(%rsp)
	movq	2376(%rcx), %rax
	movq	%rax, 3320(%rsp)
	movq	2384(%rcx), %rax
	movq	%rax, 3328(%rsp)
	movq	2392(%rcx), %rax
	movq	%rax, 3336(%rsp)
	movq	2400(%rcx), %rax
	movq	%rax, 3344(%rsp)
	movq	2408(%rcx), %rax
	movq	%rax, 3352(%rsp)
	movq	2416(%rcx), %rax
	movq	%rax, 3360(%rsp)
	movq	2424(%rcx), %rax
	movq	%rax, 3368(%rsp)
	movq	2432(%rcx), %rax
	movq	%rax, 3376(%rsp)
	movq	2440(%rcx), %rax
	movq	%rax, 3384(%rsp)
	movq	2448(%rcx), %rax
	movq	%rax, 3392(%rsp)
	movq	2456(%rcx), %rax
	movq	%rax, 3400(%rsp)
	movq	2464(%rcx), %rax
	movq	%rax, 3408(%rsp)
	movq	2472(%rcx), %rax
	movq	%rax, 3416(%rsp)
	movq	2480(%rcx), %rax
	movq	%rax, 3424(%rsp)
	movq	2488(%rcx), %rax
	movq	%rax, 3432(%rsp)
	movq	2496(%rcx), %rax
	movq	%rax, 3440(%rsp)
	movq	2504(%rcx), %rax
	movq	%rax, 3448(%rsp)
	movq	2512(%rcx), %rax
	movq	%rax, 3456(%rsp)
	movq	2520(%rcx), %rax
	movq	%rax, 3464(%rsp)
	movq	2528(%rcx), %rax
	movq	%rax, 3472(%rsp)
	movq	2536(%rcx), %rax
	movq	%rax, 3480(%rsp)
	movq	2544(%rcx), %rax
	movq	%rax, 3488(%rsp)
	movq	2552(%rcx), %rax
	movq	%rax, 3496(%rsp)
	movq	2560(%rcx), %rax
	movq	%rax, 3504(%rsp)
	movq	2568(%rcx), %rax
	movq	%rax, 3512(%rsp)
	movq	2576(%rcx), %rax
	movq	%rax, 3520(%rsp)
	movq	2584(%rcx), %rax
	movq	%rax, 3528(%rsp)
	movq	2592(%rcx), %rax
	movq	%rax, 3536(%rsp)
	movq	2600(%rcx), %rax
	movq	%rax, 3544(%rsp)
	movq	2608(%rcx), %rax
	movq	%rax, 3552(%rsp)
	movq	2616(%rcx), %rax
	movq	%rax, 3560(%rsp)
	movq	2624(%rcx), %rax
	movq	%rax, 3568(%rsp)
	movq	2632(%rcx), %rax
	movq	%rax, 3576(%rsp)
	movq	2640(%rcx), %rax
	movq	%rax, 3584(%rsp)
	movq	2648(%rcx), %rax
	movq	%rax, 3592(%rsp)
	movq	2656(%rcx), %rax
	movq	%rax, 3600(%rsp)
	movq	2664(%rcx), %rax
	movq	%rax, 3608(%rsp)
	movq	2672(%rcx), %rax
	movq	%rax, 3616(%rsp)
	movq	2680(%rcx), %rax
	movq	%rax, 3624(%rsp)
	movq	2688(%rcx), %rax
	movq	%rax, 3632(%rsp)
	movq	2696(%rcx), %rax
	movq	%rax, 3640(%rsp)
	movq	2704(%rcx), %rax
	movq	%rax, 3648(%rsp)
	movq	2712(%rcx), %rax
	movq	%rax, 3656(%rsp)
	movq	2720(%rcx), %rax
	movq	%rax, 3664(%rsp)
	movq	2728(%rcx), %rax
	movq	%rax, 3672(%rsp)
	movq	2736(%rcx), %rax
	movq	%rax, 3680(%rsp)
	movq	2744(%rcx), %rax
	movq	%rax, 3688(%rsp)
	movq	2752(%rcx), %rax
	movq	%rax, 3696(%rsp)
	movq	2760(%rcx), %rax
	movq	%rax, 3704(%rsp)
	movq	2768(%rcx), %rax
	movq	%rax, 3712(%rsp)
	movq	2776(%rcx), %rax
	movq	%rax, 3720(%rsp)
	movq	2784(%rcx), %rax
	movq	%rax, 3728(%rsp)
	movq	2792(%rcx), %rax
	movq	%rax, 3736(%rsp)
	movq	2800(%rcx), %rax
	movq	%rax, 3744(%rsp)
	movq	2808(%rcx), %rax
	movq	%rax, 3752(%rsp)
	movq	2816(%rcx), %rax
	movq	%rax, 3760(%rsp)
	movq	2824(%rcx), %rax
	movq	%rax, 3768(%rsp)
	movq	2832(%rcx), %rax
	movq	%rax, 3776(%rsp)
	movq	2840(%rcx), %rax
	movq	%rax, 3784(%rsp)
	movq	2848(%rcx), %rax
	movq	%rax, 3792(%rsp)
	movq	2856(%rcx), %rax
	movq	%rax, 3800(%rsp)
	movq	2864(%rcx), %rax
	movq	%rax, 3808(%rsp)
	movq	2872(%rcx), %rax
	movq	%rax, 3816(%rsp)
	movq	2880(%rcx), %rax
	movq	%rax, 3824(%rsp)
	movq	2888(%rcx), %rax
	movq	%rax, 3832(%rsp)
	movq	2896(%rcx), %rax
	movq	%rax, 3840(%rsp)
	movq	2904(%rcx), %rax
	movq	%rax, 3848(%rsp)
	movq	2912(%rcx), %rax
	movq	%rax, 3856(%rsp)
	movq	2920(%rcx), %rax
	movq	%rax, 3864(%rsp)
	movq	2928(%rcx), %rax
	movq	%rax, 3872(%rsp)
	movq	2936(%rcx), %rax
	movq	%rax, 3880(%rsp)
	movq	2944(%rcx), %rax
	movq	%rax, 3888(%rsp)
	movq	2952(%rcx), %rax
	movq	%rax, 3896(%rsp)
	movq	2960(%rcx), %rax
	movq	%rax, 3904(%rsp)
	movq	2968(%rcx), %rax
	movq	%rax, 3912(%rsp)
	movq	2976(%rcx), %rax
	movq	%rax, 3920(%rsp)
	movq	2984(%rcx), %rax
	movq	%rax, 3928(%rsp)
	movq	2992(%rcx), %rax
	movq	%rax, 3936(%rsp)
	movq	3000(%rcx), %rax
	movq	%rax, 3944(%rsp)
	movq	3008(%rcx), %rax
	movq	%rax, 3952(%rsp)
	movq	3016(%rcx), %rax
	movq	%rax, 3960(%rsp)
	movq	3024(%rcx), %rax
	movq	%rax, 3968(%rsp)
	movq	3032(%rcx), %rax
	movq	%rax, 3976(%rsp)
	movq	3040(%rcx), %rax
	movq	%rax, 3984(%rsp)
	movq	3048(%rcx), %rax
	movq	%rax, 3992(%rsp)
	movq	3056(%rcx), %rax
	movq	%rax, 4000(%rsp)
	movq	3064(%rcx), %rax
	movq	%rax, 4008(%rsp)
	movq	3072(%rcx), %rax
	movq	%rax, 4016(%rsp)
	movq	3080(%rcx), %rax
	movq	%rax, 4024(%rsp)
	movq	3088(%rcx), %rax
	movq	%rax, 4032(%rsp)
	movq	3096(%rcx), %rax
	movq	%rax, 4040(%rsp)
	movq	3104(%rcx), %rax
	movq	%rax, 4048(%rsp)
	movq	3112(%rcx), %rax
	movq	%rax, 4056(%rsp)
	movq	3120(%rcx), %rax
	movq	%rax, 4064(%rsp)
	movq	3128(%rcx), %rax
	movq	%rax, 4072(%rsp)
	movq	3136(%rcx), %rax
	movq	%rax, 4080(%rsp)
	movq	3144(%rcx), %rax
	movq	%rax, 4088(%rsp)
	movq	3152(%rcx), %rax
	movq	%rax, 4096(%rsp)
	movq	3160(%rcx), %rax
	movq	%rax, 4104(%rsp)
	movq	3168(%rcx), %rax
	movq	%rax, 4112(%rsp)
	movq	3176(%rcx), %rax
	movq	%rax, 4120(%rsp)
	movq	3184(%rcx), %rax
	movq	%rax, 4128(%rsp)
	movq	3192(%rcx), %rax
	movq	%rax, 4136(%rsp)
	movq	3200(%rcx), %rax
	movq	%rax, 4144(%rsp)
	movq	3208(%rcx), %rax
	movq	%rax, 4152(%rsp)
	movq	3216(%rcx), %rax
	movq	%rax, 4160(%rsp)
	movq	3224(%rcx), %rax
	movq	%rax, 4168(%rsp)
	movq	3232(%rcx), %rax
	movq	%rax, 4176(%rsp)
	movq	3240(%rcx), %rax
	movq	%rax, 4184(%rsp)
	movq	3248(%rcx), %rax
	movq	%rax, 4192(%rsp)
	movq	3256(%rcx), %rax
	movq	%rax, 4200(%rsp)
	movq	3264(%rcx), %rax
	movq	%rax, 4208(%rsp)
	movq	3272(%rcx), %rax
	movq	%rax, 4216(%rsp)
	movq	3280(%rcx), %rax
	movq	%rax, 4224(%rsp)
	movq	3288(%rcx), %rax
	movq	%rax, 4232(%rsp)
	movq	3296(%rcx), %rax
	movq	%rax, 4240(%rsp)
	movq	3304(%rcx), %rax
	movq	%rax, 4248(%rsp)
	movq	3312(%rcx), %rax
	movq	%rax, 4256(%rsp)
	movq	3320(%rcx), %rax
	movq	%rax, 4264(%rsp)
	movq	3328(%rcx), %rax
	movq	%rax, 4272(%rsp)
	movq	3336(%rcx), %rax
	movq	%rax, 4280(%rsp)
	movq	3344(%rcx), %rax
	movq	%rax, 4288(%rsp)
	movq	3352(%rcx), %rax
	movq	%rax, 4296(%rsp)
	movq	3360(%rcx), %rax
	movq	%rax, 4304(%rsp)
	movq	3368(%rcx), %rax
	movq	%rax, 4312(%rsp)
	movq	3376(%rcx), %rax
	movq	%rax, 4320(%rsp)
	movq	3384(%rcx), %rax
	movq	%rax, 4328(%rsp)
	movq	3392(%rcx), %rax
	movq	%rax, 4336(%rsp)
	movq	3400(%rcx), %rax
	movq	%rax, 4344(%rsp)
	movq	3408(%rcx), %rax
	movq	%rax, 4352(%rsp)
	movq	3416(%rcx), %rax
	movq	%rax, 4360(%rsp)
	movq	3424(%rcx), %rax
	movq	%rax, 4368(%rsp)
	movq	3432(%rcx), %rax
	movq	%rax, 4376(%rsp)
	movq	3440(%rcx), %rax
	movq	%rax, 4384(%rsp)
	movq	3448(%rcx), %rax
	movq	%rax, 4392(%rsp)
	movq	3456(%rcx), %rax
	movq	%rax, 4400(%rsp)
	movq	3464(%rcx), %rax
	movq	%rax, 4408(%rsp)
	movq	3472(%rcx), %rax
	movq	%rax, 4416(%rsp)
	movq	3480(%rcx), %rax
	movq	%rax, 4424(%rsp)
	movq	3488(%rcx), %rax
	movq	%rax, 4432(%rsp)
	movq	3496(%rcx), %rax
	movq	%rax, 4440(%rsp)
	movq	3504(%rcx), %rax
	movq	%rax, 4448(%rsp)
	movq	3512(%rcx), %rax
	movq	%rax, 4456(%rsp)
	movq	3520(%rcx), %rax
	movq	%rax, 4464(%rsp)
	movq	3528(%rcx), %rax
	movq	%rax, 4472(%rsp)
	movq	3536(%rcx), %rax
	movq	%rax, 4480(%rsp)
	movq	3544(%rcx), %rax
	movq	%rax, 4488(%rsp)
	movq	3552(%rcx), %rax
	movq	%rax, 4496(%rsp)
	movq	3560(%rcx), %rax
	movq	%rax, 4504(%rsp)
	movq	3568(%rcx), %rax
	movq	%rax, 4512(%rsp)
	movq	3576(%rcx), %rax
	movq	%rax, 4520(%rsp)
	movq	3584(%rcx), %rax
	movq	%rax, 4528(%rsp)
	movq	3592(%rcx), %rax
	movq	%rax, 4536(%rsp)
	movq	3600(%rcx), %rax
	movq	%rax, 4544(%rsp)
	movq	3608(%rcx), %rax
	movq	%rax, 4552(%rsp)
	movq	3616(%rcx), %rax
	movq	%rax, 4560(%rsp)
	movq	3624(%rcx), %rax
	movq	%rax, 4568(%rsp)
	movq	3632(%rcx), %rax
	movq	%rax, 4576(%rsp)
	movq	3640(%rcx), %rax
	movq	%rax, 4584(%rsp)
	movq	3648(%rcx), %rax
	movq	%rax, 4592(%rsp)
	movq	3656(%rcx), %rax
	movq	%rax, 4600(%rsp)
	movq	3664(%rcx), %rax
	movq	%rax, 4608(%rsp)
	movq	3672(%rcx), %rax
	movq	%rax, 4616(%rsp)
	movq	3680(%rcx), %rax
	movq	%rax, 4624(%rsp)
	movq	3688(%rcx), %rax
	movq	%rax, 4632(%rsp)
	movq	3696(%rcx), %rax
	movq	%rax, 4640(%rsp)
	movq	3704(%rcx), %rax
	movq	%rax, 4648(%rsp)
	movq	3712(%rcx), %rax
	movq	%rax, 4656(%rsp)
	movq	3720(%rcx), %rax
	movq	%rax, 4664(%rsp)
	movq	3728(%rcx), %rax
	movq	%rax, 4672(%rsp)
	movq	3736(%rcx), %rax
	movq	%rax, 4680(%rsp)
	movq	3744(%rcx), %rax
	movq	%rax, 4688(%rsp)
	movq	3752(%rcx), %rax
	movq	%rax, 4696(%rsp)
	movq	3760(%rcx), %rax
	movq	%rax, 4704(%rsp)
	movq	3768(%rcx), %rax
	movq	%rax, 4712(%rsp)
	movq	3776(%rcx), %rax
	movq	%rax, 4720(%rsp)
	movq	3784(%rcx), %rax
	movq	%rax, 4728(%rsp)
	movq	3792(%rcx), %rax
	movq	%rax, 4736(%rsp)
	movq	3800(%rcx), %rax
	movq	%rax, 4744(%rsp)
	movq	3808(%rcx), %rax
	movq	%rax, 4752(%rsp)
	movq	3816(%rcx), %rax
	movq	%rax, 4760(%rsp)
	movq	3824(%rcx), %rax
	movq	%rax, 4768(%rsp)
	movq	3832(%rcx), %rax
	movq	%rax, 4776(%rsp)
	movq	3840(%rcx), %rax
	movq	%rax, 4784(%rsp)
	movq	3848(%rcx), %rax
	movq	%rax, 4792(%rsp)
	movq	3856(%rcx), %rax
	movq	%rax, 4800(%rsp)
	movq	3864(%rcx), %rax
	movq	%rax, 4808(%rsp)
	movq	3872(%rcx), %rax
	movq	%rax, 4816(%rsp)
	movq	3880(%rcx), %rax
	movq	%rax, 4824(%rsp)
	movq	3888(%rcx), %rax
	movq	%rax, 4832(%rsp)
	movq	3896(%rcx), %rax
	movq	%rax, 4840(%rsp)
	movq	3904(%rcx), %rax
	movq	%rax, 4848(%rsp)
	movq	3912(%rcx), %rax
	movq	%rax, 4856(%rsp)
	movq	3920(%rcx), %rax
	movq	%rax, 4864(%rsp)
	movq	3928(%rcx), %rax
	movq	%rax, 4872(%rsp)
	movq	3936(%rcx), %rax
	movq	%rax, 4880(%rsp)
	movq	3944(%rcx), %rax
	movq	%rax, 4888(%rsp)
	movq	3952(%rcx), %rax
	movq	%rax, 4896(%rsp)
	movq	3960(%rcx), %rax
	movq	%rax, 4904(%rsp)
	movq	3968(%rcx), %rax
	movq	%rax, 4912(%rsp)
	movq	3976(%rcx), %rax
	movq	%rax, 4920(%rsp)
	movq	3984(%rcx), %rax
	movq	%rax, 4928(%rsp)
	movq	3992(%rcx), %rax
	movq	%rax, 4936(%rsp)
	movq	4000(%rcx), %rax
	movq	%rax, 4944(%rsp)
	movq	4008(%rcx), %rax
	movq	%rax, 4952(%rsp)
	movq	4016(%rcx), %rax
	movq	%rax, 4960(%rsp)
	movq	4024(%rcx), %rax
	movq	%rax, 4968(%rsp)
	movq	4032(%rcx), %rax
	movq	%rax, 4976(%rsp)
	movq	4040(%rcx), %rax
	movq	%rax, 4984(%rsp)
	movq	4048(%rcx), %rax
	movq	%rax, 4992(%rsp)
	movq	4056(%rcx), %rax
	movq	%rax, 5000(%rsp)
	movq	4064(%rcx), %rax
	movq	%rax, 5008(%rsp)
	movq	4072(%rcx), %rax
	movq	%rax, 5016(%rsp)
	movq	4080(%rcx), %rax
	movq	%rax, 5024(%rsp)
	movq	4088(%rcx), %rax
	movq	%rax, 5032(%rsp)
	movq	4096(%rcx), %rax
	movq	%rax, 5040(%rsp)
	movq	4104(%rcx), %rax
	movq	%rax, 5048(%rsp)
	movq	4112(%rcx), %rax
	movq	%rax, 5056(%rsp)
	movq	4120(%rcx), %rax
	movq	%rax, 5064(%rsp)
	movq	4128(%rcx), %rax
	movq	%rax, 5072(%rsp)
	movq	4136(%rcx), %rax
	movq	%rax, 5080(%rsp)
	movq	4144(%rcx), %rax
	movq	%rax, 5088(%rsp)
	movq	4152(%rcx), %rax
	movq	%rax, 5096(%rsp)
	movq	4160(%rcx), %rax
	movq	%rax, 5104(%rsp)
	movq	4168(%rcx), %rax
	movq	%rax, 5112(%rsp)
	movq	4176(%rcx), %rax
	movq	%rax, 5120(%rsp)
	movq	4184(%rcx), %rax
	movq	%rax, 5128(%rsp)
	movq	4192(%rcx), %rax
	movq	%rax, 5136(%rsp)
	movq	4200(%rcx), %rax
	movq	%rax, 5144(%rsp)
	movq	4208(%rcx), %rax
	movq	%rax, 5152(%rsp)
	movq	4216(%rcx), %rax
	movq	%rax, 5160(%rsp)
	movq	4224(%rcx), %rax
	movq	%rax, 5168(%rsp)
	movq	4232(%rcx), %rax
	movq	%rax, 5176(%rsp)
	movq	4240(%rcx), %rax
	movq	%rax, 5184(%rsp)
	movq	4248(%rcx), %rax
	movq	%rax, 5192(%rsp)
	movq	4256(%rcx), %rax
	movq	%rax, 5200(%rsp)
	movq	4264(%rcx), %rax
	movq	%rax, 5208(%rsp)
	movq	4272(%rcx), %rax
	movq	%rax, 5216(%rsp)
	movq	4280(%rcx), %rax
	movq	%rax, 5224(%rsp)
	movq	4288(%rcx), %rax
	movq	%rax, 5232(%rsp)
	movq	4296(%rcx), %rax
	movq	%rax, 5240(%rsp)
	movq	4304(%rcx), %rax
	movq	%rax, 5248(%rsp)
	movq	4312(%rcx), %rax
	movq	%rax, 5256(%rsp)
	movq	4320(%rcx), %rax
	movq	%rax, 5264(%rsp)
	movq	4328(%rcx), %rax
	movq	%rax, 5272(%rsp)
	movq	4336(%rcx), %rax
	movq	%rax, 5280(%rsp)
	movq	4344(%rcx), %rax
	movq	%rax, 5288(%rsp)
	movq	4352(%rcx), %rax
	movq	%rax, 5296(%rsp)
	movq	4360(%rcx), %rax
	movq	%rax, 5304(%rsp)
	movq	4368(%rcx), %rax
	movq	%rax, 5312(%rsp)
	movq	4376(%rcx), %rax
	movq	%rax, 5320(%rsp)
	movq	4384(%rcx), %rax
	movq	%rax, 5328(%rsp)
	movq	4392(%rcx), %rax
	movq	%rax, 5336(%rsp)
	movq	4400(%rcx), %rax
	movq	%rax, 5344(%rsp)
	movq	4408(%rcx), %rax
	movq	%rax, 5352(%rsp)
	movq	4416(%rcx), %rax
	movq	%rax, 5360(%rsp)
	movq	4424(%rcx), %rax
	movq	%rax, 5368(%rsp)
	movq	4432(%rcx), %rax
	movq	%rax, 5376(%rsp)
	movq	4440(%rcx), %rax
	movq	%rax, 5384(%rsp)
	movq	4448(%rcx), %rax
	movq	%rax, 5392(%rsp)
	movq	4456(%rcx), %rax
	movq	%rax, 5400(%rsp)
	movq	4464(%rcx), %rax
	movq	%rax, 5408(%rsp)
	movq	4472(%rcx), %rax
	movq	%rax, 5416(%rsp)
	movq	4480(%rcx), %rax
	movq	%rax, 5424(%rsp)
	movq	4488(%rcx), %rax
	movq	%rax, 5432(%rsp)
	movq	4496(%rcx), %rax
	movq	%rax, 5440(%rsp)
	movq	4504(%rcx), %rax
	movq	%rax, 5448(%rsp)
	movq	4512(%rcx), %rax
	movq	%rax, 5456(%rsp)
	movq	4520(%rcx), %rax
	movq	%rax, 5464(%rsp)
	movq	4528(%rcx), %rax
	movq	%rax, 5472(%rsp)
	movq	4536(%rcx), %rax
	movq	%rax, 5480(%rsp)
	movq	4544(%rcx), %rax
	movq	%rax, 5488(%rsp)
	movq	4552(%rcx), %rax
	movq	%rax, 5496(%rsp)
	movq	4560(%rcx), %rax
	movq	%rax, 5504(%rsp)
	movq	4568(%rcx), %rax
	movq	%rax, 5512(%rsp)
	movq	4576(%rcx), %rax
	movq	%rax, 5520(%rsp)
	movq	4584(%rcx), %rax
	movq	%rax, 5528(%rsp)
	movq	4592(%rcx), %rax
	movq	%rax, 5536(%rsp)
	movq	4600(%rcx), %rax
	movq	%rax, 5544(%rsp)
	movq	4608(%rcx), %rax
	movq	%rax, 5552(%rsp)
	movq	4616(%rcx), %rax
	movq	%rax, 5560(%rsp)
	movq	4624(%rcx), %rax
	movq	%rax, 5568(%rsp)
	movq	4632(%rcx), %rax
	movq	%rax, 5576(%rsp)
	movq	4640(%rcx), %rax
	movq	%rax, 5584(%rsp)
	movq	4648(%rcx), %rax
	movq	%rax, 5592(%rsp)
	movq	4656(%rcx), %rax
	movq	%rax, 5600(%rsp)
	movq	4664(%rcx), %rax
	movq	%rax, 5608(%rsp)
	movq	4672(%rcx), %rax
	movq	%rax, 5616(%rsp)
	movq	4680(%rcx), %rax
	movq	%rax, 5624(%rsp)
	movq	4688(%rcx), %rax
	movq	%rax, 5632(%rsp)
	movq	4696(%rcx), %rax
	movq	%rax, 5640(%rsp)
	movq	4704(%rcx), %rax
	movq	%rax, 5648(%rsp)
	movq	4712(%rcx), %rax
	movq	%rax, 5656(%rsp)
	movq	4720(%rcx), %rax
	movq	%rax, 5664(%rsp)
	movq	4728(%rcx), %rax
	movq	%rax, 5672(%rsp)
	movq	4736(%rcx), %rax
	movq	%rax, 5680(%rsp)
	movq	4744(%rcx), %rax
	movq	%rax, 5688(%rsp)
	movq	4752(%rcx), %rax
	movq	%rax, 5696(%rsp)
	movq	4760(%rcx), %rax
	movq	%rax, 5704(%rsp)
	movq	4768(%rcx), %rax
	movq	%rax, 5712(%rsp)
	movq	4776(%rcx), %rax
	movq	%rax, 5720(%rsp)
	movq	4784(%rcx), %rax
	movq	%rax, 5728(%rsp)
	movq	4792(%rcx), %rax
	movq	%rax, 5736(%rsp)
	movq	4800(%rcx), %rax
	movq	%rax, 5744(%rsp)
	movq	4808(%rcx), %rax
	movq	%rax, 5752(%rsp)
	movq	4816(%rcx), %rax
	movq	%rax, 5760(%rsp)
	movq	4824(%rcx), %rax
	movq	%rax, 5768(%rsp)
	movq	4832(%rcx), %rax
	movq	%rax, 5776(%rsp)
	movq	4840(%rcx), %rax
	movq	%rax, 5784(%rsp)
	movq	4848(%rcx), %rax
	movq	%rax, 5792(%rsp)
	movq	4856(%rcx), %rax
	movq	%rax, 5800(%rsp)
	movq	4864(%rcx), %rax
	movq	%rax, 5808(%rsp)
	movq	4872(%rcx), %rax
	movq	%rax, 5816(%rsp)
	movq	4880(%rcx), %rax
	movq	%rax, 5824(%rsp)
	movq	4888(%rcx), %rax
	movq	%rax, 5832(%rsp)
	movq	4896(%rcx), %rax
	movq	%rax, 5840(%rsp)
	movq	4904(%rcx), %rax
	movq	%rax, 5848(%rsp)
	movq	4912(%rcx), %rax
	movq	%rax, 5856(%rsp)
	movq	4920(%rcx), %rax
	movq	%rax, 5864(%rsp)
	movq	4928(%rcx), %rax
	movq	%rax, 5872(%rsp)
	movq	4936(%rcx), %rax
	movq	%rax, 5880(%rsp)
	movq	4944(%rcx), %rax
	movq	%rax, 5888(%rsp)
	movq	4952(%rcx), %rax
	movq	%rax, 5896(%rsp)
	movq	4960(%rcx), %rax
	movq	%rax, 5904(%rsp)
	movq	4968(%rcx), %rax
	movq	%rax, 5912(%rsp)
	movq	4976(%rcx), %rax
	movq	%rax, 5920(%rsp)
	movq	4984(%rcx), %rax
	movq	%rax, 5928(%rsp)
	movq	4992(%rcx), %rax
	movq	%rax, 5936(%rsp)
	movq	5000(%rcx), %rax
	movq	%rax, 5944(%rsp)
	movq	5008(%rcx), %rax
	movq	%rax, 5952(%rsp)
	movq	5016(%rcx), %rax
	movq	%rax, 5960(%rsp)
	movq	5024(%rcx), %rax
	movq	%rax, 5968(%rsp)
	movq	5032(%rcx), %rax
	movq	%rax, 5976(%rsp)
	movq	5040(%rcx), %rax
	movq	%rax, 5984(%rsp)
	movq	5048(%rcx), %rax
	movq	%rax, 5992(%rsp)
	movq	5056(%rcx), %rax
	movq	%rax, 6000(%rsp)
	movq	5064(%rcx), %rax
	movq	%rax, 6008(%rsp)
	movq	5072(%rcx), %rax
	movq	%rax, 6016(%rsp)
	movq	5080(%rcx), %rax
	movq	%rax, 6024(%rsp)
	movq	5088(%rcx), %rax
	movq	%rax, 6032(%rsp)
	movq	5096(%rcx), %rax
	movq	%rax, 6040(%rsp)
	movq	5104(%rcx), %rax
	movq	%rax, 6048(%rsp)
	movq	5112(%rcx), %rax
	movq	%rax, 6056(%rsp)
	movq	5120(%rcx), %rax
	movq	%rax, 6064(%rsp)
	movq	5128(%rcx), %rax
	movq	%rax, 6072(%rsp)
	movq	5136(%rcx), %rax
	movq	%rax, 6080(%rsp)
	movq	5144(%rcx), %rax
	movq	%rax, 6088(%rsp)
	movq	5152(%rcx), %rax
	movq	%rax, 6096(%rsp)
	movq	5160(%rcx), %rax
	movq	%rax, 6104(%rsp)
	movq	5168(%rcx), %rax
	movq	%rax, 6112(%rsp)
	movq	5176(%rcx), %rax
	movq	%rax, 6120(%rsp)
	movq	5184(%rcx), %rax
	movq	%rax, 6128(%rsp)
	movq	5192(%rcx), %rax
	movq	%rax, 6136(%rsp)
	movq	5200(%rcx), %rax
	movq	%rax, 6144(%rsp)
	movq	5208(%rcx), %rax
	movq	%rax, 6152(%rsp)
	movq	5216(%rcx), %rax
	movq	%rax, 6160(%rsp)
	movq	5224(%rcx), %rax
	movq	%rax, 6168(%rsp)
	movq	5232(%rcx), %rax
	movq	%rax, 6176(%rsp)
	movq	5240(%rcx), %rax
	movq	%rax, 6184(%rsp)
	movq	5248(%rcx), %rax
	movq	%rax, 6192(%rsp)
	movq	5256(%rcx), %rax
	movq	%rax, 6200(%rsp)
	movq	5264(%rcx), %rax
	movq	%rax, 6208(%rsp)
	movq	5272(%rcx), %rax
	movq	%rax, 6216(%rsp)
	movq	5280(%rcx), %rax
	movq	%rax, 6224(%rsp)
	movq	5288(%rcx), %rax
	movq	%rax, 6232(%rsp)
	movq	5296(%rcx), %rax
	movq	%rax, 6240(%rsp)
	movq	5304(%rcx), %rax
	movq	%rax, 6248(%rsp)
	movq	5312(%rcx), %rax
	movq	%rax, 6256(%rsp)
	movq	5320(%rcx), %rax
	movq	%rax, 6264(%rsp)
	movq	5328(%rcx), %rax
	movq	%rax, 6272(%rsp)
	movq	5336(%rcx), %rax
	movq	%rax, 6280(%rsp)
	movq	5344(%rcx), %rax
	movq	%rax, 6288(%rsp)
	movq	5352(%rcx), %rax
	movq	%rax, 6296(%rsp)
	movq	5360(%rcx), %rax
	movq	%rax, 6304(%rsp)
	movq	5368(%rcx), %rax
	movq	%rax, 6312(%rsp)
	movq	5376(%rcx), %rax
	movq	%rax, 6320(%rsp)
	movq	5384(%rcx), %rax
	movq	%rax, 6328(%rsp)
	movq	5392(%rcx), %rax
	movq	%rax, 6336(%rsp)
	movq	5400(%rcx), %rax
	movq	%rax, 6344(%rsp)
	movq	5408(%rcx), %rax
	movq	%rax, 6352(%rsp)
	movq	5416(%rcx), %rax
	movq	%rax, 6360(%rsp)
	movq	5424(%rcx), %rax
	movq	%rax, 6368(%rsp)
	movq	5432(%rcx), %rax
	movq	%rax, 6376(%rsp)
	movq	5440(%rcx), %rax
	movq	%rax, 6384(%rsp)
	movq	5448(%rcx), %rax
	movq	%rax, 6392(%rsp)
	movq	5456(%rcx), %rax
	movq	%rax, 6400(%rsp)
	movq	5464(%rcx), %rax
	movq	%rax, 6408(%rsp)
	movq	5472(%rcx), %rax
	movq	%rax, 6416(%rsp)
	movq	5480(%rcx), %rax
	movq	%rax, 6424(%rsp)
	leaq	6432(%rsp), %rax
	leaq	944(%rsp), %rcx
	call	Laes128ctr$1
Lmayo2_crypto_sign_open$91:
	movq	6432(%rsp), %rax
	movq	%rax, 99552(%rsp)
	movq	6440(%rsp), %rax
	movq	%rax, 99560(%rsp)
	movq	6448(%rsp), %rax
	movq	%rax, 99568(%rsp)
	movq	6456(%rsp), %rax
	movq	%rax, 99576(%rsp)
	movq	6464(%rsp), %rax
	movq	%rax, 99584(%rsp)
	movq	6472(%rsp), %rax
	movq	%rax, 99592(%rsp)
	movq	6480(%rsp), %rax
	movq	%rax, 99600(%rsp)
	movq	6488(%rsp), %rax
	movq	%rax, 99608(%rsp)
	movq	6496(%rsp), %rax
	movq	%rax, 99616(%rsp)
	movq	6504(%rsp), %rax
	movq	%rax, 99624(%rsp)
	movq	6512(%rsp), %rax
	movq	%rax, 99632(%rsp)
	movq	6520(%rsp), %rax
	movq	%rax, 99640(%rsp)
	movq	6528(%rsp), %rax
	movq	%rax, 99648(%rsp)
	movq	6536(%rsp), %rax
	movq	%rax, 99656(%rsp)
	movq	6544(%rsp), %rax
	movq	%rax, 99664(%rsp)
	movq	6552(%rsp), %rax
	movq	%rax, 99672(%rsp)
	movq	6560(%rsp), %rax
	movq	%rax, 99680(%rsp)
	movq	6568(%rsp), %rax
	movq	%rax, 99688(%rsp)
	movq	6576(%rsp), %rax
	movq	%rax, 99696(%rsp)
	movq	6584(%rsp), %rax
	movq	%rax, 99704(%rsp)
	movq	6592(%rsp), %rax
	movq	%rax, 99712(%rsp)
	movq	6600(%rsp), %rax
	movq	%rax, 99720(%rsp)
	movq	6608(%rsp), %rax
	movq	%rax, 99728(%rsp)
	movq	6616(%rsp), %rax
	movq	%rax, 99736(%rsp)
	movq	6624(%rsp), %rax
	movq	%rax, 99744(%rsp)
	movq	6632(%rsp), %rax
	movq	%rax, 99752(%rsp)
	movq	6640(%rsp), %rax
	movq	%rax, 99760(%rsp)
	movq	6648(%rsp), %rax
	movq	%rax, 99768(%rsp)
	movq	6656(%rsp), %rax
	movq	%rax, 99776(%rsp)
	movq	6664(%rsp), %rax
	movq	%rax, 99784(%rsp)
	movq	6672(%rsp), %rax
	movq	%rax, 99792(%rsp)
	movq	6680(%rsp), %rax
	movq	%rax, 99800(%rsp)
	movq	6688(%rsp), %rax
	movq	%rax, 99808(%rsp)
	movq	6696(%rsp), %rax
	movq	%rax, 99816(%rsp)
	movq	6704(%rsp), %rax
	movq	%rax, 99824(%rsp)
	movq	6712(%rsp), %rax
	movq	%rax, 99832(%rsp)
	movq	6720(%rsp), %rax
	movq	%rax, 99840(%rsp)
	movq	6728(%rsp), %rax
	movq	%rax, 99848(%rsp)
	movq	6736(%rsp), %rax
	movq	%rax, 99856(%rsp)
	movq	6744(%rsp), %rax
	movq	%rax, 99864(%rsp)
	movq	6752(%rsp), %rax
	movq	%rax, 99872(%rsp)
	movq	6760(%rsp), %rax
	movq	%rax, 99880(%rsp)
	movq	6768(%rsp), %rax
	movq	%rax, 99888(%rsp)
	movq	6776(%rsp), %rax
	movq	%rax, 99896(%rsp)
	movq	6784(%rsp), %rax
	movq	%rax, 99904(%rsp)
	movq	6792(%rsp), %rax
	movq	%rax, 99912(%rsp)
	movq	6800(%rsp), %rax
	movq	%rax, 99920(%rsp)
	movq	6808(%rsp), %rax
	movq	%rax, 99928(%rsp)
	movq	6816(%rsp), %rax
	movq	%rax, 99936(%rsp)
	movq	6824(%rsp), %rax
	movq	%rax, 99944(%rsp)
	movq	6832(%rsp), %rax
	movq	%rax, 99952(%rsp)
	movq	6840(%rsp), %rax
	movq	%rax, 99960(%rsp)
	movq	6848(%rsp), %rax
	movq	%rax, 99968(%rsp)
	movq	6856(%rsp), %rax
	movq	%rax, 99976(%rsp)
	movq	6864(%rsp), %rax
	movq	%rax, 99984(%rsp)
	movq	6872(%rsp), %rax
	movq	%rax, 99992(%rsp)
	movq	6880(%rsp), %rax
	movq	%rax, 100000(%rsp)
	movq	6888(%rsp), %rax
	movq	%rax, 100008(%rsp)
	movq	6896(%rsp), %rax
	movq	%rax, 100016(%rsp)
	movq	6904(%rsp), %rax
	movq	%rax, 100024(%rsp)
	movq	6912(%rsp), %rax
	movq	%rax, 100032(%rsp)
	movq	6920(%rsp), %rax
	movq	%rax, 100040(%rsp)
	movq	6928(%rsp), %rax
	movq	%rax, 100048(%rsp)
	movq	6936(%rsp), %rax
	movq	%rax, 100056(%rsp)
	movq	6944(%rsp), %rax
	movq	%rax, 100064(%rsp)
	movq	6952(%rsp), %rax
	movq	%rax, 100072(%rsp)
	movq	6960(%rsp), %rax
	movq	%rax, 100080(%rsp)
	movq	6968(%rsp), %rax
	movq	%rax, 100088(%rsp)
	movq	6976(%rsp), %rax
	movq	%rax, 100096(%rsp)
	movq	6984(%rsp), %rax
	movq	%rax, 100104(%rsp)
	movq	6992(%rsp), %rax
	movq	%rax, 100112(%rsp)
	movq	7000(%rsp), %rax
	movq	%rax, 100120(%rsp)
	movq	7008(%rsp), %rax
	movq	%rax, 100128(%rsp)
	movq	7016(%rsp), %rax
	movq	%rax, 100136(%rsp)
	movq	7024(%rsp), %rax
	movq	%rax, 100144(%rsp)
	movq	7032(%rsp), %rax
	movq	%rax, 100152(%rsp)
	movq	7040(%rsp), %rax
	movq	%rax, 100160(%rsp)
	movq	7048(%rsp), %rax
	movq	%rax, 100168(%rsp)
	movq	7056(%rsp), %rax
	movq	%rax, 100176(%rsp)
	movq	7064(%rsp), %rax
	movq	%rax, 100184(%rsp)
	movq	7072(%rsp), %rax
	movq	%rax, 100192(%rsp)
	movq	7080(%rsp), %rax
	movq	%rax, 100200(%rsp)
	movq	7088(%rsp), %rax
	movq	%rax, 100208(%rsp)
	movq	7096(%rsp), %rax
	movq	%rax, 100216(%rsp)
	movq	7104(%rsp), %rax
	movq	%rax, 100224(%rsp)
	movq	7112(%rsp), %rax
	movq	%rax, 100232(%rsp)
	movq	7120(%rsp), %rax
	movq	%rax, 100240(%rsp)
	movq	7128(%rsp), %rax
	movq	%rax, 100248(%rsp)
	movq	7136(%rsp), %rax
	movq	%rax, 100256(%rsp)
	movq	7144(%rsp), %rax
	movq	%rax, 100264(%rsp)
	movq	7152(%rsp), %rax
	movq	%rax, 100272(%rsp)
	movq	7160(%rsp), %rax
	movq	%rax, 100280(%rsp)
	movq	7168(%rsp), %rax
	movq	%rax, 100288(%rsp)
	movq	7176(%rsp), %rax
	movq	%rax, 100296(%rsp)
	movq	7184(%rsp), %rax
	movq	%rax, 100304(%rsp)
	movq	7192(%rsp), %rax
	movq	%rax, 100312(%rsp)
	movq	7200(%rsp), %rax
	movq	%rax, 100320(%rsp)
	movq	7208(%rsp), %rax
	movq	%rax, 100328(%rsp)
	movq	7216(%rsp), %rax
	movq	%rax, 100336(%rsp)
	movq	7224(%rsp), %rax
	movq	%rax, 100344(%rsp)
	movq	7232(%rsp), %rax
	movq	%rax, 100352(%rsp)
	movq	7240(%rsp), %rax
	movq	%rax, 100360(%rsp)
	movq	7248(%rsp), %rax
	movq	%rax, 100368(%rsp)
	movq	7256(%rsp), %rax
	movq	%rax, 100376(%rsp)
	movq	7264(%rsp), %rax
	movq	%rax, 100384(%rsp)
	movq	7272(%rsp), %rax
	movq	%rax, 100392(%rsp)
	movq	7280(%rsp), %rax
	movq	%rax, 100400(%rsp)
	movq	7288(%rsp), %rax
	movq	%rax, 100408(%rsp)
	movq	7296(%rsp), %rax
	movq	%rax, 100416(%rsp)
	movq	7304(%rsp), %rax
	movq	%rax, 100424(%rsp)
	movq	7312(%rsp), %rax
	movq	%rax, 100432(%rsp)
	movq	7320(%rsp), %rax
	movq	%rax, 100440(%rsp)
	movq	7328(%rsp), %rax
	movq	%rax, 100448(%rsp)
	movq	7336(%rsp), %rax
	movq	%rax, 100456(%rsp)
	movq	7344(%rsp), %rax
	movq	%rax, 100464(%rsp)
	movq	7352(%rsp), %rax
	movq	%rax, 100472(%rsp)
	movq	7360(%rsp), %rax
	movq	%rax, 100480(%rsp)
	movq	7368(%rsp), %rax
	movq	%rax, 100488(%rsp)
	movq	7376(%rsp), %rax
	movq	%rax, 100496(%rsp)
	movq	7384(%rsp), %rax
	movq	%rax, 100504(%rsp)
	movq	7392(%rsp), %rax
	movq	%rax, 100512(%rsp)
	movq	7400(%rsp), %rax
	movq	%rax, 100520(%rsp)
	movq	7408(%rsp), %rax
	movq	%rax, 100528(%rsp)
	movq	7416(%rsp), %rax
	movq	%rax, 100536(%rsp)
	movq	7424(%rsp), %rax
	movq	%rax, 100544(%rsp)
	movq	7432(%rsp), %rax
	movq	%rax, 100552(%rsp)
	movq	7440(%rsp), %rax
	movq	%rax, 100560(%rsp)
	movq	7448(%rsp), %rax
	movq	%rax, 100568(%rsp)
	movq	7456(%rsp), %rax
	movq	%rax, 100576(%rsp)
	movq	7464(%rsp), %rax
	movq	%rax, 100584(%rsp)
	movq	7472(%rsp), %rax
	movq	%rax, 100592(%rsp)
	movq	7480(%rsp), %rax
	movq	%rax, 100600(%rsp)
	movq	7488(%rsp), %rax
	movq	%rax, 100608(%rsp)
	movq	7496(%rsp), %rax
	movq	%rax, 100616(%rsp)
	movq	7504(%rsp), %rax
	movq	%rax, 100624(%rsp)
	movq	7512(%rsp), %rax
	movq	%rax, 100632(%rsp)
	movq	7520(%rsp), %rax
	movq	%rax, 100640(%rsp)
	movq	7528(%rsp), %rax
	movq	%rax, 100648(%rsp)
	movq	7536(%rsp), %rax
	movq	%rax, 100656(%rsp)
	movq	7544(%rsp), %rax
	movq	%rax, 100664(%rsp)
	movq	7552(%rsp), %rax
	movq	%rax, 100672(%rsp)
	movq	7560(%rsp), %rax
	movq	%rax, 100680(%rsp)
	movq	7568(%rsp), %rax
	movq	%rax, 100688(%rsp)
	movq	7576(%rsp), %rax
	movq	%rax, 100696(%rsp)
	movq	7584(%rsp), %rax
	movq	%rax, 100704(%rsp)
	movq	7592(%rsp), %rax
	movq	%rax, 100712(%rsp)
	movq	7600(%rsp), %rax
	movq	%rax, 100720(%rsp)
	movq	7608(%rsp), %rax
	movq	%rax, 100728(%rsp)
	movq	7616(%rsp), %rax
	movq	%rax, 100736(%rsp)
	movq	7624(%rsp), %rax
	movq	%rax, 100744(%rsp)
	movq	7632(%rsp), %rax
	movq	%rax, 100752(%rsp)
	movq	7640(%rsp), %rax
	movq	%rax, 100760(%rsp)
	movq	7648(%rsp), %rax
	movq	%rax, 100768(%rsp)
	movq	7656(%rsp), %rax
	movq	%rax, 100776(%rsp)
	movq	7664(%rsp), %rax
	movq	%rax, 100784(%rsp)
	movq	7672(%rsp), %rax
	movq	%rax, 100792(%rsp)
	movq	7680(%rsp), %rax
	movq	%rax, 100800(%rsp)
	movq	7688(%rsp), %rax
	movq	%rax, 100808(%rsp)
	movq	7696(%rsp), %rax
	movq	%rax, 100816(%rsp)
	movq	7704(%rsp), %rax
	movq	%rax, 100824(%rsp)
	movq	7712(%rsp), %rax
	movq	%rax, 100832(%rsp)
	movq	7720(%rsp), %rax
	movq	%rax, 100840(%rsp)
	movq	7728(%rsp), %rax
	movq	%rax, 100848(%rsp)
	movq	7736(%rsp), %rax
	movq	%rax, 100856(%rsp)
	movq	7744(%rsp), %rax
	movq	%rax, 100864(%rsp)
	movq	7752(%rsp), %rax
	movq	%rax, 100872(%rsp)
	movq	7760(%rsp), %rax
	movq	%rax, 100880(%rsp)
	movq	7768(%rsp), %rax
	movq	%rax, 100888(%rsp)
	movq	7776(%rsp), %rax
	movq	%rax, 100896(%rsp)
	movq	7784(%rsp), %rax
	movq	%rax, 100904(%rsp)
	movq	7792(%rsp), %rax
	movq	%rax, 100912(%rsp)
	movq	7800(%rsp), %rax
	movq	%rax, 100920(%rsp)
	movq	7808(%rsp), %rax
	movq	%rax, 100928(%rsp)
	movq	7816(%rsp), %rax
	movq	%rax, 100936(%rsp)
	movq	7824(%rsp), %rax
	movq	%rax, 100944(%rsp)
	movq	7832(%rsp), %rax
	movq	%rax, 100952(%rsp)
	movq	7840(%rsp), %rax
	movq	%rax, 100960(%rsp)
	movq	7848(%rsp), %rax
	movq	%rax, 100968(%rsp)
	movq	7856(%rsp), %rax
	movq	%rax, 100976(%rsp)
	movq	7864(%rsp), %rax
	movq	%rax, 100984(%rsp)
	movq	7872(%rsp), %rax
	movq	%rax, 100992(%rsp)
	movq	7880(%rsp), %rax
	movq	%rax, 101000(%rsp)
	movq	7888(%rsp), %rax
	movq	%rax, 101008(%rsp)
	movq	7896(%rsp), %rax
	movq	%rax, 101016(%rsp)
	movq	7904(%rsp), %rax
	movq	%rax, 101024(%rsp)
	movq	7912(%rsp), %rax
	movq	%rax, 101032(%rsp)
	movq	7920(%rsp), %rax
	movq	%rax, 101040(%rsp)
	movq	7928(%rsp), %rax
	movq	%rax, 101048(%rsp)
	movq	7936(%rsp), %rax
	movq	%rax, 101056(%rsp)
	movq	7944(%rsp), %rax
	movq	%rax, 101064(%rsp)
	movq	7952(%rsp), %rax
	movq	%rax, 101072(%rsp)
	movq	7960(%rsp), %rax
	movq	%rax, 101080(%rsp)
	movq	7968(%rsp), %rax
	movq	%rax, 101088(%rsp)
	movq	7976(%rsp), %rax
	movq	%rax, 101096(%rsp)
	movq	7984(%rsp), %rax
	movq	%rax, 101104(%rsp)
	movq	7992(%rsp), %rax
	movq	%rax, 101112(%rsp)
	movq	8000(%rsp), %rax
	movq	%rax, 101120(%rsp)
	movq	8008(%rsp), %rax
	movq	%rax, 101128(%rsp)
	movq	8016(%rsp), %rax
	movq	%rax, 101136(%rsp)
	movq	8024(%rsp), %rax
	movq	%rax, 101144(%rsp)
	movq	8032(%rsp), %rax
	movq	%rax, 101152(%rsp)
	movq	8040(%rsp), %rax
	movq	%rax, 101160(%rsp)
	movq	8048(%rsp), %rax
	movq	%rax, 101168(%rsp)
	movq	8056(%rsp), %rax
	movq	%rax, 101176(%rsp)
	movq	8064(%rsp), %rax
	movq	%rax, 101184(%rsp)
	movq	8072(%rsp), %rax
	movq	%rax, 101192(%rsp)
	movq	8080(%rsp), %rax
	movq	%rax, 101200(%rsp)
	movq	8088(%rsp), %rax
	movq	%rax, 101208(%rsp)
	movq	8096(%rsp), %rax
	movq	%rax, 101216(%rsp)
	movq	8104(%rsp), %rax
	movq	%rax, 101224(%rsp)
	movq	8112(%rsp), %rax
	movq	%rax, 101232(%rsp)
	movq	8120(%rsp), %rax
	movq	%rax, 101240(%rsp)
	movq	8128(%rsp), %rax
	movq	%rax, 101248(%rsp)
	movq	8136(%rsp), %rax
	movq	%rax, 101256(%rsp)
	movq	8144(%rsp), %rax
	movq	%rax, 101264(%rsp)
	movq	8152(%rsp), %rax
	movq	%rax, 101272(%rsp)
	movq	8160(%rsp), %rax
	movq	%rax, 101280(%rsp)
	movq	8168(%rsp), %rax
	movq	%rax, 101288(%rsp)
	movq	8176(%rsp), %rax
	movq	%rax, 101296(%rsp)
	movq	8184(%rsp), %rax
	movq	%rax, 101304(%rsp)
	movq	8192(%rsp), %rax
	movq	%rax, 101312(%rsp)
	movq	8200(%rsp), %rax
	movq	%rax, 101320(%rsp)
	movq	8208(%rsp), %rax
	movq	%rax, 101328(%rsp)
	movq	8216(%rsp), %rax
	movq	%rax, 101336(%rsp)
	movq	8224(%rsp), %rax
	movq	%rax, 101344(%rsp)
	movq	8232(%rsp), %rax
	movq	%rax, 101352(%rsp)
	movq	8240(%rsp), %rax
	movq	%rax, 101360(%rsp)
	movq	8248(%rsp), %rax
	movq	%rax, 101368(%rsp)
	movq	8256(%rsp), %rax
	movq	%rax, 101376(%rsp)
	movq	8264(%rsp), %rax
	movq	%rax, 101384(%rsp)
	movq	8272(%rsp), %rax
	movq	%rax, 101392(%rsp)
	movq	8280(%rsp), %rax
	movq	%rax, 101400(%rsp)
	movq	8288(%rsp), %rax
	movq	%rax, 101408(%rsp)
	movq	8296(%rsp), %rax
	movq	%rax, 101416(%rsp)
	movq	8304(%rsp), %rax
	movq	%rax, 101424(%rsp)
	movq	8312(%rsp), %rax
	movq	%rax, 101432(%rsp)
	movq	8320(%rsp), %rax
	movq	%rax, 101440(%rsp)
	movq	8328(%rsp), %rax
	movq	%rax, 101448(%rsp)
	movq	8336(%rsp), %rax
	movq	%rax, 101456(%rsp)
	movq	8344(%rsp), %rax
	movq	%rax, 101464(%rsp)
	movq	8352(%rsp), %rax
	movq	%rax, 101472(%rsp)
	movq	8360(%rsp), %rax
	movq	%rax, 101480(%rsp)
	movq	8368(%rsp), %rax
	movq	%rax, 101488(%rsp)
	movq	8376(%rsp), %rax
	movq	%rax, 101496(%rsp)
	movq	8384(%rsp), %rax
	movq	%rax, 101504(%rsp)
	movq	8392(%rsp), %rax
	movq	%rax, 101512(%rsp)
	movq	8400(%rsp), %rax
	movq	%rax, 101520(%rsp)
	movq	8408(%rsp), %rax
	movq	%rax, 101528(%rsp)
	movq	8416(%rsp), %rax
	movq	%rax, 101536(%rsp)
	movq	8424(%rsp), %rax
	movq	%rax, 101544(%rsp)
	movq	8432(%rsp), %rax
	movq	%rax, 101552(%rsp)
	movq	8440(%rsp), %rax
	movq	%rax, 101560(%rsp)
	movq	8448(%rsp), %rax
	movq	%rax, 101568(%rsp)
	movq	8456(%rsp), %rax
	movq	%rax, 101576(%rsp)
	movq	8464(%rsp), %rax
	movq	%rax, 101584(%rsp)
	movq	8472(%rsp), %rax
	movq	%rax, 101592(%rsp)
	movq	8480(%rsp), %rax
	movq	%rax, 101600(%rsp)
	movq	8488(%rsp), %rax
	movq	%rax, 101608(%rsp)
	movq	8496(%rsp), %rax
	movq	%rax, 101616(%rsp)
	movq	8504(%rsp), %rax
	movq	%rax, 101624(%rsp)
	movq	8512(%rsp), %rax
	movq	%rax, 101632(%rsp)
	movq	8520(%rsp), %rax
	movq	%rax, 101640(%rsp)
	movq	8528(%rsp), %rax
	movq	%rax, 101648(%rsp)
	movq	8536(%rsp), %rax
	movq	%rax, 101656(%rsp)
	movq	8544(%rsp), %rax
	movq	%rax, 101664(%rsp)
	movq	8552(%rsp), %rax
	movq	%rax, 101672(%rsp)
	movq	8560(%rsp), %rax
	movq	%rax, 101680(%rsp)
	movq	8568(%rsp), %rax
	movq	%rax, 101688(%rsp)
	movq	8576(%rsp), %rax
	movq	%rax, 101696(%rsp)
	movq	8584(%rsp), %rax
	movq	%rax, 101704(%rsp)
	movq	8592(%rsp), %rax
	movq	%rax, 101712(%rsp)
	movq	8600(%rsp), %rax
	movq	%rax, 101720(%rsp)
	movq	8608(%rsp), %rax
	movq	%rax, 101728(%rsp)
	movq	8616(%rsp), %rax
	movq	%rax, 101736(%rsp)
	movq	8624(%rsp), %rax
	movq	%rax, 101744(%rsp)
	movq	8632(%rsp), %rax
	movq	%rax, 101752(%rsp)
	movq	8640(%rsp), %rax
	movq	%rax, 101760(%rsp)
	movq	8648(%rsp), %rax
	movq	%rax, 101768(%rsp)
	movq	8656(%rsp), %rax
	movq	%rax, 101776(%rsp)
	movq	8664(%rsp), %rax
	movq	%rax, 101784(%rsp)
	movq	8672(%rsp), %rax
	movq	%rax, 101792(%rsp)
	movq	8680(%rsp), %rax
	movq	%rax, 101800(%rsp)
	movq	8688(%rsp), %rax
	movq	%rax, 101808(%rsp)
	movq	8696(%rsp), %rax
	movq	%rax, 101816(%rsp)
	movq	8704(%rsp), %rax
	movq	%rax, 101824(%rsp)
	movq	8712(%rsp), %rax
	movq	%rax, 101832(%rsp)
	movq	8720(%rsp), %rax
	movq	%rax, 101840(%rsp)
	movq	8728(%rsp), %rax
	movq	%rax, 101848(%rsp)
	movq	8736(%rsp), %rax
	movq	%rax, 101856(%rsp)
	movq	8744(%rsp), %rax
	movq	%rax, 101864(%rsp)
	movq	8752(%rsp), %rax
	movq	%rax, 101872(%rsp)
	movq	8760(%rsp), %rax
	movq	%rax, 101880(%rsp)
	movq	8768(%rsp), %rax
	movq	%rax, 101888(%rsp)
	movq	8776(%rsp), %rax
	movq	%rax, 101896(%rsp)
	movq	8784(%rsp), %rax
	movq	%rax, 101904(%rsp)
	movq	8792(%rsp), %rax
	movq	%rax, 101912(%rsp)
	movq	8800(%rsp), %rax
	movq	%rax, 101920(%rsp)
	movq	8808(%rsp), %rax
	movq	%rax, 101928(%rsp)
	movq	8816(%rsp), %rax
	movq	%rax, 101936(%rsp)
	movq	8824(%rsp), %rax
	movq	%rax, 101944(%rsp)
	movq	8832(%rsp), %rax
	movq	%rax, 101952(%rsp)
	movq	8840(%rsp), %rax
	movq	%rax, 101960(%rsp)
	movq	8848(%rsp), %rax
	movq	%rax, 101968(%rsp)
	movq	8856(%rsp), %rax
	movq	%rax, 101976(%rsp)
	movq	8864(%rsp), %rax
	movq	%rax, 101984(%rsp)
	movq	8872(%rsp), %rax
	movq	%rax, 101992(%rsp)
	movq	8880(%rsp), %rax
	movq	%rax, 102000(%rsp)
	movq	8888(%rsp), %rax
	movq	%rax, 102008(%rsp)
	movq	8896(%rsp), %rax
	movq	%rax, 102016(%rsp)
	movq	8904(%rsp), %rax
	movq	%rax, 102024(%rsp)
	movq	8912(%rsp), %rax
	movq	%rax, 102032(%rsp)
	movq	8920(%rsp), %rax
	movq	%rax, 102040(%rsp)
	movq	8928(%rsp), %rax
	movq	%rax, 102048(%rsp)
	movq	8936(%rsp), %rax
	movq	%rax, 102056(%rsp)
	movq	8944(%rsp), %rax
	movq	%rax, 102064(%rsp)
	movq	8952(%rsp), %rax
	movq	%rax, 102072(%rsp)
	movq	8960(%rsp), %rax
	movq	%rax, 102080(%rsp)
	movq	8968(%rsp), %rax
	movq	%rax, 102088(%rsp)
	movq	8976(%rsp), %rax
	movq	%rax, 102096(%rsp)
	movq	8984(%rsp), %rax
	movq	%rax, 102104(%rsp)
	movq	8992(%rsp), %rax
	movq	%rax, 102112(%rsp)
	movq	9000(%rsp), %rax
	movq	%rax, 102120(%rsp)
	movq	9008(%rsp), %rax
	movq	%rax, 102128(%rsp)
	movq	9016(%rsp), %rax
	movq	%rax, 102136(%rsp)
	movq	9024(%rsp), %rax
	movq	%rax, 102144(%rsp)
	movq	9032(%rsp), %rax
	movq	%rax, 102152(%rsp)
	movq	9040(%rsp), %rax
	movq	%rax, 102160(%rsp)
	movq	9048(%rsp), %rax
	movq	%rax, 102168(%rsp)
	movq	9056(%rsp), %rax
	movq	%rax, 102176(%rsp)
	movq	9064(%rsp), %rax
	movq	%rax, 102184(%rsp)
	movq	9072(%rsp), %rax
	movq	%rax, 102192(%rsp)
	movq	9080(%rsp), %rax
	movq	%rax, 102200(%rsp)
	movq	9088(%rsp), %rax
	movq	%rax, 102208(%rsp)
	movq	9096(%rsp), %rax
	movq	%rax, 102216(%rsp)
	movq	9104(%rsp), %rax
	movq	%rax, 102224(%rsp)
	movq	9112(%rsp), %rax
	movq	%rax, 102232(%rsp)
	movq	9120(%rsp), %rax
	movq	%rax, 102240(%rsp)
	movq	9128(%rsp), %rax
	movq	%rax, 102248(%rsp)
	movq	9136(%rsp), %rax
	movq	%rax, 102256(%rsp)
	movq	9144(%rsp), %rax
	movq	%rax, 102264(%rsp)
	movq	9152(%rsp), %rax
	movq	%rax, 102272(%rsp)
	movq	9160(%rsp), %rax
	movq	%rax, 102280(%rsp)
	movq	9168(%rsp), %rax
	movq	%rax, 102288(%rsp)
	movq	9176(%rsp), %rax
	movq	%rax, 102296(%rsp)
	movq	9184(%rsp), %rax
	movq	%rax, 102304(%rsp)
	movq	9192(%rsp), %rax
	movq	%rax, 102312(%rsp)
	movq	9200(%rsp), %rax
	movq	%rax, 102320(%rsp)
	movq	9208(%rsp), %rax
	movq	%rax, 102328(%rsp)
	movq	9216(%rsp), %rax
	movq	%rax, 102336(%rsp)
	movq	9224(%rsp), %rax
	movq	%rax, 102344(%rsp)
	movq	9232(%rsp), %rax
	movq	%rax, 102352(%rsp)
	movq	9240(%rsp), %rax
	movq	%rax, 102360(%rsp)
	movq	9248(%rsp), %rax
	movq	%rax, 102368(%rsp)
	movq	9256(%rsp), %rax
	movq	%rax, 102376(%rsp)
	movq	9264(%rsp), %rax
	movq	%rax, 102384(%rsp)
	movq	9272(%rsp), %rax
	movq	%rax, 102392(%rsp)
	movq	9280(%rsp), %rax
	movq	%rax, 102400(%rsp)
	movq	9288(%rsp), %rax
	movq	%rax, 102408(%rsp)
	movq	9296(%rsp), %rax
	movq	%rax, 102416(%rsp)
	movq	9304(%rsp), %rax
	movq	%rax, 102424(%rsp)
	movq	9312(%rsp), %rax
	movq	%rax, 102432(%rsp)
	movq	9320(%rsp), %rax
	movq	%rax, 102440(%rsp)
	movq	9328(%rsp), %rax
	movq	%rax, 102448(%rsp)
	movq	9336(%rsp), %rax
	movq	%rax, 102456(%rsp)
	movq	9344(%rsp), %rax
	movq	%rax, 102464(%rsp)
	movq	9352(%rsp), %rax
	movq	%rax, 102472(%rsp)
	movq	9360(%rsp), %rax
	movq	%rax, 102480(%rsp)
	movq	9368(%rsp), %rax
	movq	%rax, 102488(%rsp)
	movq	9376(%rsp), %rax
	movq	%rax, 102496(%rsp)
	movq	9384(%rsp), %rax
	movq	%rax, 102504(%rsp)
	movq	9392(%rsp), %rax
	movq	%rax, 102512(%rsp)
	movq	9400(%rsp), %rax
	movq	%rax, 102520(%rsp)
	movq	9408(%rsp), %rax
	movq	%rax, 102528(%rsp)
	movq	9416(%rsp), %rax
	movq	%rax, 102536(%rsp)
	movq	9424(%rsp), %rax
	movq	%rax, 102544(%rsp)
	movq	9432(%rsp), %rax
	movq	%rax, 102552(%rsp)
	movq	9440(%rsp), %rax
	movq	%rax, 102560(%rsp)
	movq	9448(%rsp), %rax
	movq	%rax, 102568(%rsp)
	movq	9456(%rsp), %rax
	movq	%rax, 102576(%rsp)
	movq	9464(%rsp), %rax
	movq	%rax, 102584(%rsp)
	movq	9472(%rsp), %rax
	movq	%rax, 102592(%rsp)
	movq	9480(%rsp), %rax
	movq	%rax, 102600(%rsp)
	movq	9488(%rsp), %rax
	movq	%rax, 102608(%rsp)
	movq	9496(%rsp), %rax
	movq	%rax, 102616(%rsp)
	movq	9504(%rsp), %rax
	movq	%rax, 102624(%rsp)
	movq	9512(%rsp), %rax
	movq	%rax, 102632(%rsp)
	movq	9520(%rsp), %rax
	movq	%rax, 102640(%rsp)
	movq	9528(%rsp), %rax
	movq	%rax, 102648(%rsp)
	movq	9536(%rsp), %rax
	movq	%rax, 102656(%rsp)
	movq	9544(%rsp), %rax
	movq	%rax, 102664(%rsp)
	movq	9552(%rsp), %rax
	movq	%rax, 102672(%rsp)
	movq	9560(%rsp), %rax
	movq	%rax, 102680(%rsp)
	movq	9568(%rsp), %rax
	movq	%rax, 102688(%rsp)
	movq	9576(%rsp), %rax
	movq	%rax, 102696(%rsp)
	movq	9584(%rsp), %rax
	movq	%rax, 102704(%rsp)
	movq	9592(%rsp), %rax
	movq	%rax, 102712(%rsp)
	movq	9600(%rsp), %rax
	movq	%rax, 102720(%rsp)
	movq	9608(%rsp), %rax
	movq	%rax, 102728(%rsp)
	movq	9616(%rsp), %rax
	movq	%rax, 102736(%rsp)
	movq	9624(%rsp), %rax
	movq	%rax, 102744(%rsp)
	movq	9632(%rsp), %rax
	movq	%rax, 102752(%rsp)
	movq	9640(%rsp), %rax
	movq	%rax, 102760(%rsp)
	movq	9648(%rsp), %rax
	movq	%rax, 102768(%rsp)
	movq	9656(%rsp), %rax
	movq	%rax, 102776(%rsp)
	movq	9664(%rsp), %rax
	movq	%rax, 102784(%rsp)
	movq	9672(%rsp), %rax
	movq	%rax, 102792(%rsp)
	movq	9680(%rsp), %rax
	movq	%rax, 102800(%rsp)
	movq	9688(%rsp), %rax
	movq	%rax, 102808(%rsp)
	movq	9696(%rsp), %rax
	movq	%rax, 102816(%rsp)
	movq	9704(%rsp), %rax
	movq	%rax, 102824(%rsp)
	movq	9712(%rsp), %rax
	movq	%rax, 102832(%rsp)
	movq	9720(%rsp), %rax
	movq	%rax, 102840(%rsp)
	movq	9728(%rsp), %rax
	movq	%rax, 102848(%rsp)
	movq	9736(%rsp), %rax
	movq	%rax, 102856(%rsp)
	movq	9744(%rsp), %rax
	movq	%rax, 102864(%rsp)
	movq	9752(%rsp), %rax
	movq	%rax, 102872(%rsp)
	movq	9760(%rsp), %rax
	movq	%rax, 102880(%rsp)
	movq	9768(%rsp), %rax
	movq	%rax, 102888(%rsp)
	movq	9776(%rsp), %rax
	movq	%rax, 102896(%rsp)
	movq	9784(%rsp), %rax
	movq	%rax, 102904(%rsp)
	movq	9792(%rsp), %rax
	movq	%rax, 102912(%rsp)
	movq	9800(%rsp), %rax
	movq	%rax, 102920(%rsp)
	movq	9808(%rsp), %rax
	movq	%rax, 102928(%rsp)
	movq	9816(%rsp), %rax
	movq	%rax, 102936(%rsp)
	movq	9824(%rsp), %rax
	movq	%rax, 102944(%rsp)
	movq	9832(%rsp), %rax
	movq	%rax, 102952(%rsp)
	movq	9840(%rsp), %rax
	movq	%rax, 102960(%rsp)
	movq	9848(%rsp), %rax
	movq	%rax, 102968(%rsp)
	movq	9856(%rsp), %rax
	movq	%rax, 102976(%rsp)
	movq	9864(%rsp), %rax
	movq	%rax, 102984(%rsp)
	movq	9872(%rsp), %rax
	movq	%rax, 102992(%rsp)
	movq	9880(%rsp), %rax
	movq	%rax, 103000(%rsp)
	movq	9888(%rsp), %rax
	movq	%rax, 103008(%rsp)
	movq	9896(%rsp), %rax
	movq	%rax, 103016(%rsp)
	movq	9904(%rsp), %rax
	movq	%rax, 103024(%rsp)
	movq	9912(%rsp), %rax
	movq	%rax, 103032(%rsp)
	movq	9920(%rsp), %rax
	movq	%rax, 103040(%rsp)
	movq	9928(%rsp), %rax
	movq	%rax, 103048(%rsp)
	movq	9936(%rsp), %rax
	movq	%rax, 103056(%rsp)
	movq	9944(%rsp), %rax
	movq	%rax, 103064(%rsp)
	movq	9952(%rsp), %rax
	movq	%rax, 103072(%rsp)
	movq	9960(%rsp), %rax
	movq	%rax, 103080(%rsp)
	movq	9968(%rsp), %rax
	movq	%rax, 103088(%rsp)
	movq	9976(%rsp), %rax
	movq	%rax, 103096(%rsp)
	movq	9984(%rsp), %rax
	movq	%rax, 103104(%rsp)
	movq	9992(%rsp), %rax
	movq	%rax, 103112(%rsp)
	movq	10000(%rsp), %rax
	movq	%rax, 103120(%rsp)
	movq	10008(%rsp), %rax
	movq	%rax, 103128(%rsp)
	movq	10016(%rsp), %rax
	movq	%rax, 103136(%rsp)
	movq	10024(%rsp), %rax
	movq	%rax, 103144(%rsp)
	movq	10032(%rsp), %rax
	movq	%rax, 103152(%rsp)
	movq	10040(%rsp), %rax
	movq	%rax, 103160(%rsp)
	movq	10048(%rsp), %rax
	movq	%rax, 103168(%rsp)
	movq	10056(%rsp), %rax
	movq	%rax, 103176(%rsp)
	movq	10064(%rsp), %rax
	movq	%rax, 103184(%rsp)
	movq	10072(%rsp), %rax
	movq	%rax, 103192(%rsp)
	movq	10080(%rsp), %rax
	movq	%rax, 103200(%rsp)
	movq	10088(%rsp), %rax
	movq	%rax, 103208(%rsp)
	movq	10096(%rsp), %rax
	movq	%rax, 103216(%rsp)
	movq	10104(%rsp), %rax
	movq	%rax, 103224(%rsp)
	movq	10112(%rsp), %rax
	movq	%rax, 103232(%rsp)
	movq	10120(%rsp), %rax
	movq	%rax, 103240(%rsp)
	movq	10128(%rsp), %rax
	movq	%rax, 103248(%rsp)
	movq	10136(%rsp), %rax
	movq	%rax, 103256(%rsp)
	movq	10144(%rsp), %rax
	movq	%rax, 103264(%rsp)
	movq	10152(%rsp), %rax
	movq	%rax, 103272(%rsp)
	movq	10160(%rsp), %rax
	movq	%rax, 103280(%rsp)
	movq	10168(%rsp), %rax
	movq	%rax, 103288(%rsp)
	movq	10176(%rsp), %rax
	movq	%rax, 103296(%rsp)
	movq	10184(%rsp), %rax
	movq	%rax, 103304(%rsp)
	movq	10192(%rsp), %rax
	movq	%rax, 103312(%rsp)
	movq	10200(%rsp), %rax
	movq	%rax, 103320(%rsp)
	movq	10208(%rsp), %rax
	movq	%rax, 103328(%rsp)
	movq	10216(%rsp), %rax
	movq	%rax, 103336(%rsp)
	movq	10224(%rsp), %rax
	movq	%rax, 103344(%rsp)
	movq	10232(%rsp), %rax
	movq	%rax, 103352(%rsp)
	movq	10240(%rsp), %rax
	movq	%rax, 103360(%rsp)
	movq	10248(%rsp), %rax
	movq	%rax, 103368(%rsp)
	movq	10256(%rsp), %rax
	movq	%rax, 103376(%rsp)
	movq	10264(%rsp), %rax
	movq	%rax, 103384(%rsp)
	movq	10272(%rsp), %rax
	movq	%rax, 103392(%rsp)
	movq	10280(%rsp), %rax
	movq	%rax, 103400(%rsp)
	movq	10288(%rsp), %rax
	movq	%rax, 103408(%rsp)
	movq	10296(%rsp), %rax
	movq	%rax, 103416(%rsp)
	movq	10304(%rsp), %rax
	movq	%rax, 103424(%rsp)
	movq	10312(%rsp), %rax
	movq	%rax, 103432(%rsp)
	movq	10320(%rsp), %rax
	movq	%rax, 103440(%rsp)
	movq	10328(%rsp), %rax
	movq	%rax, 103448(%rsp)
	movq	10336(%rsp), %rax
	movq	%rax, 103456(%rsp)
	movq	10344(%rsp), %rax
	movq	%rax, 103464(%rsp)
	movq	10352(%rsp), %rax
	movq	%rax, 103472(%rsp)
	movq	10360(%rsp), %rax
	movq	%rax, 103480(%rsp)
	movq	10368(%rsp), %rax
	movq	%rax, 103488(%rsp)
	movq	10376(%rsp), %rax
	movq	%rax, 103496(%rsp)
	movq	10384(%rsp), %rax
	movq	%rax, 103504(%rsp)
	movq	10392(%rsp), %rax
	movq	%rax, 103512(%rsp)
	movq	10400(%rsp), %rax
	movq	%rax, 103520(%rsp)
	movq	10408(%rsp), %rax
	movq	%rax, 103528(%rsp)
	movq	10416(%rsp), %rax
	movq	%rax, 103536(%rsp)
	movq	10424(%rsp), %rax
	movq	%rax, 103544(%rsp)
	movq	10432(%rsp), %rax
	movq	%rax, 103552(%rsp)
	movq	10440(%rsp), %rax
	movq	%rax, 103560(%rsp)
	movq	10448(%rsp), %rax
	movq	%rax, 103568(%rsp)
	movq	10456(%rsp), %rax
	movq	%rax, 103576(%rsp)
	movq	10464(%rsp), %rax
	movq	%rax, 103584(%rsp)
	movq	10472(%rsp), %rax
	movq	%rax, 103592(%rsp)
	movq	10480(%rsp), %rax
	movq	%rax, 103600(%rsp)
	movq	10488(%rsp), %rax
	movq	%rax, 103608(%rsp)
	movq	10496(%rsp), %rax
	movq	%rax, 103616(%rsp)
	movq	10504(%rsp), %rax
	movq	%rax, 103624(%rsp)
	movq	10512(%rsp), %rax
	movq	%rax, 103632(%rsp)
	movq	10520(%rsp), %rax
	movq	%rax, 103640(%rsp)
	movq	10528(%rsp), %rax
	movq	%rax, 103648(%rsp)
	movq	10536(%rsp), %rax
	movq	%rax, 103656(%rsp)
	movq	10544(%rsp), %rax
	movq	%rax, 103664(%rsp)
	movq	10552(%rsp), %rax
	movq	%rax, 103672(%rsp)
	movq	10560(%rsp), %rax
	movq	%rax, 103680(%rsp)
	movq	10568(%rsp), %rax
	movq	%rax, 103688(%rsp)
	movq	10576(%rsp), %rax
	movq	%rax, 103696(%rsp)
	movq	10584(%rsp), %rax
	movq	%rax, 103704(%rsp)
	movq	10592(%rsp), %rax
	movq	%rax, 103712(%rsp)
	movq	10600(%rsp), %rax
	movq	%rax, 103720(%rsp)
	movq	10608(%rsp), %rax
	movq	%rax, 103728(%rsp)
	movq	10616(%rsp), %rax
	movq	%rax, 103736(%rsp)
	movq	10624(%rsp), %rax
	movq	%rax, 103744(%rsp)
	movq	10632(%rsp), %rax
	movq	%rax, 103752(%rsp)
	movq	10640(%rsp), %rax
	movq	%rax, 103760(%rsp)
	movq	10648(%rsp), %rax
	movq	%rax, 103768(%rsp)
	movq	10656(%rsp), %rax
	movq	%rax, 103776(%rsp)
	movq	10664(%rsp), %rax
	movq	%rax, 103784(%rsp)
	movq	10672(%rsp), %rax
	movq	%rax, 103792(%rsp)
	movq	10680(%rsp), %rax
	movq	%rax, 103800(%rsp)
	movq	10688(%rsp), %rax
	movq	%rax, 103808(%rsp)
	movq	10696(%rsp), %rax
	movq	%rax, 103816(%rsp)
	movq	10704(%rsp), %rax
	movq	%rax, 103824(%rsp)
	movq	10712(%rsp), %rax
	movq	%rax, 103832(%rsp)
	movq	10720(%rsp), %rax
	movq	%rax, 103840(%rsp)
	movq	10728(%rsp), %rax
	movq	%rax, 103848(%rsp)
	movq	10736(%rsp), %rax
	movq	%rax, 103856(%rsp)
	movq	10744(%rsp), %rax
	movq	%rax, 103864(%rsp)
	movq	10752(%rsp), %rax
	movq	%rax, 103872(%rsp)
	movq	10760(%rsp), %rax
	movq	%rax, 103880(%rsp)
	movq	10768(%rsp), %rax
	movq	%rax, 103888(%rsp)
	movq	10776(%rsp), %rax
	movq	%rax, 103896(%rsp)
	movq	10784(%rsp), %rax
	movq	%rax, 103904(%rsp)
	movq	10792(%rsp), %rax
	movq	%rax, 103912(%rsp)
	movq	10800(%rsp), %rax
	movq	%rax, 103920(%rsp)
	movq	10808(%rsp), %rax
	movq	%rax, 103928(%rsp)
	movq	10816(%rsp), %rax
	movq	%rax, 103936(%rsp)
	movq	10824(%rsp), %rax
	movq	%rax, 103944(%rsp)
	movq	10832(%rsp), %rax
	movq	%rax, 103952(%rsp)
	movq	10840(%rsp), %rax
	movq	%rax, 103960(%rsp)
	movq	10848(%rsp), %rax
	movq	%rax, 103968(%rsp)
	movq	10856(%rsp), %rax
	movq	%rax, 103976(%rsp)
	movq	10864(%rsp), %rax
	movq	%rax, 103984(%rsp)
	movq	10872(%rsp), %rax
	movq	%rax, 103992(%rsp)
	movq	10880(%rsp), %rax
	movq	%rax, 104000(%rsp)
	movq	10888(%rsp), %rax
	movq	%rax, 104008(%rsp)
	movq	10896(%rsp), %rax
	movq	%rax, 104016(%rsp)
	movq	10904(%rsp), %rax
	movq	%rax, 104024(%rsp)
	movq	10912(%rsp), %rax
	movq	%rax, 104032(%rsp)
	movq	10920(%rsp), %rax
	movq	%rax, 104040(%rsp)
	movq	10928(%rsp), %rax
	movq	%rax, 104048(%rsp)
	movq	10936(%rsp), %rax
	movq	%rax, 104056(%rsp)
	movq	10944(%rsp), %rax
	movq	%rax, 104064(%rsp)
	movq	10952(%rsp), %rax
	movq	%rax, 104072(%rsp)
	movq	10960(%rsp), %rax
	movq	%rax, 104080(%rsp)
	movq	10968(%rsp), %rax
	movq	%rax, 104088(%rsp)
	movq	10976(%rsp), %rax
	movq	%rax, 104096(%rsp)
	movq	10984(%rsp), %rax
	movq	%rax, 104104(%rsp)
	movq	10992(%rsp), %rax
	movq	%rax, 104112(%rsp)
	movq	11000(%rsp), %rax
	movq	%rax, 104120(%rsp)
	movq	11008(%rsp), %rax
	movq	%rax, 104128(%rsp)
	movq	11016(%rsp), %rax
	movq	%rax, 104136(%rsp)
	movq	11024(%rsp), %rax
	movq	%rax, 104144(%rsp)
	movq	11032(%rsp), %rax
	movq	%rax, 104152(%rsp)
	movq	11040(%rsp), %rax
	movq	%rax, 104160(%rsp)
	movq	11048(%rsp), %rax
	movq	%rax, 104168(%rsp)
	movq	11056(%rsp), %rax
	movq	%rax, 104176(%rsp)
	movq	11064(%rsp), %rax
	movq	%rax, 104184(%rsp)
	movq	11072(%rsp), %rax
	movq	%rax, 104192(%rsp)
	movq	11080(%rsp), %rax
	movq	%rax, 104200(%rsp)
	movq	11088(%rsp), %rax
	movq	%rax, 104208(%rsp)
	movq	11096(%rsp), %rax
	movq	%rax, 104216(%rsp)
	movq	11104(%rsp), %rax
	movq	%rax, 104224(%rsp)
	movq	11112(%rsp), %rax
	movq	%rax, 104232(%rsp)
	movq	11120(%rsp), %rax
	movq	%rax, 104240(%rsp)
	movq	11128(%rsp), %rax
	movq	%rax, 104248(%rsp)
	movq	11136(%rsp), %rax
	movq	%rax, 104256(%rsp)
	movq	11144(%rsp), %rax
	movq	%rax, 104264(%rsp)
	movq	11152(%rsp), %rax
	movq	%rax, 104272(%rsp)
	movq	11160(%rsp), %rax
	movq	%rax, 104280(%rsp)
	movq	11168(%rsp), %rax
	movq	%rax, 104288(%rsp)
	movq	11176(%rsp), %rax
	movq	%rax, 104296(%rsp)
	movq	11184(%rsp), %rax
	movq	%rax, 104304(%rsp)
	movq	11192(%rsp), %rax
	movq	%rax, 104312(%rsp)
	movq	11200(%rsp), %rax
	movq	%rax, 104320(%rsp)
	movq	11208(%rsp), %rax
	movq	%rax, 104328(%rsp)
	movq	11216(%rsp), %rax
	movq	%rax, 104336(%rsp)
	movq	11224(%rsp), %rax
	movq	%rax, 104344(%rsp)
	movq	11232(%rsp), %rax
	movq	%rax, 104352(%rsp)
	movq	11240(%rsp), %rax
	movq	%rax, 104360(%rsp)
	movq	11248(%rsp), %rax
	movq	%rax, 104368(%rsp)
	movq	11256(%rsp), %rax
	movq	%rax, 104376(%rsp)
	movq	11264(%rsp), %rax
	movq	%rax, 104384(%rsp)
	movq	11272(%rsp), %rax
	movq	%rax, 104392(%rsp)
	movq	11280(%rsp), %rax
	movq	%rax, 104400(%rsp)
	movq	11288(%rsp), %rax
	movq	%rax, 104408(%rsp)
	movq	11296(%rsp), %rax
	movq	%rax, 104416(%rsp)
	movq	11304(%rsp), %rax
	movq	%rax, 104424(%rsp)
	movq	11312(%rsp), %rax
	movq	%rax, 104432(%rsp)
	movq	11320(%rsp), %rax
	movq	%rax, 104440(%rsp)
	movq	11328(%rsp), %rax
	movq	%rax, 104448(%rsp)
	movq	11336(%rsp), %rax
	movq	%rax, 104456(%rsp)
	movq	11344(%rsp), %rax
	movq	%rax, 104464(%rsp)
	movq	11352(%rsp), %rax
	movq	%rax, 104472(%rsp)
	movq	11360(%rsp), %rax
	movq	%rax, 104480(%rsp)
	movq	11368(%rsp), %rax
	movq	%rax, 104488(%rsp)
	movq	11376(%rsp), %rax
	movq	%rax, 104496(%rsp)
	movq	11384(%rsp), %rax
	movq	%rax, 104504(%rsp)
	movq	11392(%rsp), %rax
	movq	%rax, 104512(%rsp)
	movq	11400(%rsp), %rax
	movq	%rax, 104520(%rsp)
	movq	11408(%rsp), %rax
	movq	%rax, 104528(%rsp)
	movq	11416(%rsp), %rax
	movq	%rax, 104536(%rsp)
	movq	11424(%rsp), %rax
	movq	%rax, 104544(%rsp)
	movq	11432(%rsp), %rax
	movq	%rax, 104552(%rsp)
	movq	11440(%rsp), %rax
	movq	%rax, 104560(%rsp)
	movq	11448(%rsp), %rax
	movq	%rax, 104568(%rsp)
	movq	11456(%rsp), %rax
	movq	%rax, 104576(%rsp)
	movq	11464(%rsp), %rax
	movq	%rax, 104584(%rsp)
	movq	11472(%rsp), %rax
	movq	%rax, 104592(%rsp)
	movq	11480(%rsp), %rax
	movq	%rax, 104600(%rsp)
	movq	11488(%rsp), %rax
	movq	%rax, 104608(%rsp)
	movq	11496(%rsp), %rax
	movq	%rax, 104616(%rsp)
	movq	11504(%rsp), %rax
	movq	%rax, 104624(%rsp)
	movq	11512(%rsp), %rax
	movq	%rax, 104632(%rsp)
	movq	11520(%rsp), %rax
	movq	%rax, 104640(%rsp)
	movq	11528(%rsp), %rax
	movq	%rax, 104648(%rsp)
	movq	11536(%rsp), %rax
	movq	%rax, 104656(%rsp)
	movq	11544(%rsp), %rax
	movq	%rax, 104664(%rsp)
	movq	11552(%rsp), %rax
	movq	%rax, 104672(%rsp)
	movq	11560(%rsp), %rax
	movq	%rax, 104680(%rsp)
	movq	11568(%rsp), %rax
	movq	%rax, 104688(%rsp)
	movq	11576(%rsp), %rax
	movq	%rax, 104696(%rsp)
	movq	11584(%rsp), %rax
	movq	%rax, 104704(%rsp)
	movq	11592(%rsp), %rax
	movq	%rax, 104712(%rsp)
	movq	11600(%rsp), %rax
	movq	%rax, 104720(%rsp)
	movq	11608(%rsp), %rax
	movq	%rax, 104728(%rsp)
	movq	11616(%rsp), %rax
	movq	%rax, 104736(%rsp)
	movq	11624(%rsp), %rax
	movq	%rax, 104744(%rsp)
	movq	11632(%rsp), %rax
	movq	%rax, 104752(%rsp)
	movq	11640(%rsp), %rax
	movq	%rax, 104760(%rsp)
	movq	11648(%rsp), %rax
	movq	%rax, 104768(%rsp)
	movq	11656(%rsp), %rax
	movq	%rax, 104776(%rsp)
	movq	11664(%rsp), %rax
	movq	%rax, 104784(%rsp)
	movq	11672(%rsp), %rax
	movq	%rax, 104792(%rsp)
	movq	11680(%rsp), %rax
	movq	%rax, 104800(%rsp)
	movq	11688(%rsp), %rax
	movq	%rax, 104808(%rsp)
	movq	11696(%rsp), %rax
	movq	%rax, 104816(%rsp)
	movq	11704(%rsp), %rax
	movq	%rax, 104824(%rsp)
	movq	11712(%rsp), %rax
	movq	%rax, 104832(%rsp)
	movq	11720(%rsp), %rax
	movq	%rax, 104840(%rsp)
	movq	11728(%rsp), %rax
	movq	%rax, 104848(%rsp)
	movq	11736(%rsp), %rax
	movq	%rax, 104856(%rsp)
	movq	11744(%rsp), %rax
	movq	%rax, 104864(%rsp)
	movq	11752(%rsp), %rax
	movq	%rax, 104872(%rsp)
	movq	11760(%rsp), %rax
	movq	%rax, 104880(%rsp)
	movq	11768(%rsp), %rax
	movq	%rax, 104888(%rsp)
	movq	11776(%rsp), %rax
	movq	%rax, 104896(%rsp)
	movq	11784(%rsp), %rax
	movq	%rax, 104904(%rsp)
	movq	11792(%rsp), %rax
	movq	%rax, 104912(%rsp)
	movq	11800(%rsp), %rax
	movq	%rax, 104920(%rsp)
	movq	11808(%rsp), %rax
	movq	%rax, 104928(%rsp)
	movq	11816(%rsp), %rax
	movq	%rax, 104936(%rsp)
	movq	11824(%rsp), %rax
	movq	%rax, 104944(%rsp)
	movq	11832(%rsp), %rax
	movq	%rax, 104952(%rsp)
	movq	11840(%rsp), %rax
	movq	%rax, 104960(%rsp)
	movq	11848(%rsp), %rax
	movq	%rax, 104968(%rsp)
	movq	11856(%rsp), %rax
	movq	%rax, 104976(%rsp)
	movq	11864(%rsp), %rax
	movq	%rax, 104984(%rsp)
	movq	11872(%rsp), %rax
	movq	%rax, 104992(%rsp)
	movq	11880(%rsp), %rax
	movq	%rax, 105000(%rsp)
	movq	11888(%rsp), %rax
	movq	%rax, 105008(%rsp)
	movq	11896(%rsp), %rax
	movq	%rax, 105016(%rsp)
	movq	11904(%rsp), %rax
	movq	%rax, 105024(%rsp)
	movq	11912(%rsp), %rax
	movq	%rax, 105032(%rsp)
	movq	11920(%rsp), %rax
	movq	%rax, 105040(%rsp)
	movq	11928(%rsp), %rax
	movq	%rax, 105048(%rsp)
	movq	11936(%rsp), %rax
	movq	%rax, 105056(%rsp)
	movq	11944(%rsp), %rax
	movq	%rax, 105064(%rsp)
	movq	11952(%rsp), %rax
	movq	%rax, 105072(%rsp)
	movq	11960(%rsp), %rax
	movq	%rax, 105080(%rsp)
	movq	11968(%rsp), %rax
	movq	%rax, 105088(%rsp)
	movq	11976(%rsp), %rax
	movq	%rax, 105096(%rsp)
	movq	11984(%rsp), %rax
	movq	%rax, 105104(%rsp)
	movq	11992(%rsp), %rax
	movq	%rax, 105112(%rsp)
	movq	12000(%rsp), %rax
	movq	%rax, 105120(%rsp)
	movq	12008(%rsp), %rax
	movq	%rax, 105128(%rsp)
	movq	12016(%rsp), %rax
	movq	%rax, 105136(%rsp)
	movq	12024(%rsp), %rax
	movq	%rax, 105144(%rsp)
	movq	12032(%rsp), %rax
	movq	%rax, 105152(%rsp)
	movq	12040(%rsp), %rax
	movq	%rax, 105160(%rsp)
	movq	12048(%rsp), %rax
	movq	%rax, 105168(%rsp)
	movq	12056(%rsp), %rax
	movq	%rax, 105176(%rsp)
	movq	12064(%rsp), %rax
	movq	%rax, 105184(%rsp)
	movq	12072(%rsp), %rax
	movq	%rax, 105192(%rsp)
	movq	12080(%rsp), %rax
	movq	%rax, 105200(%rsp)
	movq	12088(%rsp), %rax
	movq	%rax, 105208(%rsp)
	movq	12096(%rsp), %rax
	movq	%rax, 105216(%rsp)
	movq	12104(%rsp), %rax
	movq	%rax, 105224(%rsp)
	movq	12112(%rsp), %rax
	movq	%rax, 105232(%rsp)
	movq	12120(%rsp), %rax
	movq	%rax, 105240(%rsp)
	movq	12128(%rsp), %rax
	movq	%rax, 105248(%rsp)
	movq	12136(%rsp), %rax
	movq	%rax, 105256(%rsp)
	movq	12144(%rsp), %rax
	movq	%rax, 105264(%rsp)
	movq	12152(%rsp), %rax
	movq	%rax, 105272(%rsp)
	movq	12160(%rsp), %rax
	movq	%rax, 105280(%rsp)
	movq	12168(%rsp), %rax
	movq	%rax, 105288(%rsp)
	movq	12176(%rsp), %rax
	movq	%rax, 105296(%rsp)
	movq	12184(%rsp), %rax
	movq	%rax, 105304(%rsp)
	movq	12192(%rsp), %rax
	movq	%rax, 105312(%rsp)
	movq	12200(%rsp), %rax
	movq	%rax, 105320(%rsp)
	movq	12208(%rsp), %rax
	movq	%rax, 105328(%rsp)
	movq	12216(%rsp), %rax
	movq	%rax, 105336(%rsp)
	movq	12224(%rsp), %rax
	movq	%rax, 105344(%rsp)
	movq	12232(%rsp), %rax
	movq	%rax, 105352(%rsp)
	movq	12240(%rsp), %rax
	movq	%rax, 105360(%rsp)
	movq	12248(%rsp), %rax
	movq	%rax, 105368(%rsp)
	movq	12256(%rsp), %rax
	movq	%rax, 105376(%rsp)
	movq	12264(%rsp), %rax
	movq	%rax, 105384(%rsp)
	movq	12272(%rsp), %rax
	movq	%rax, 105392(%rsp)
	movq	12280(%rsp), %rax
	movq	%rax, 105400(%rsp)
	movq	12288(%rsp), %rax
	movq	%rax, 105408(%rsp)
	movq	12296(%rsp), %rax
	movq	%rax, 105416(%rsp)
	movq	12304(%rsp), %rax
	movq	%rax, 105424(%rsp)
	movq	12312(%rsp), %rax
	movq	%rax, 105432(%rsp)
	movq	12320(%rsp), %rax
	movq	%rax, 105440(%rsp)
	movq	12328(%rsp), %rax
	movq	%rax, 105448(%rsp)
	movq	12336(%rsp), %rax
	movq	%rax, 105456(%rsp)
	movq	12344(%rsp), %rax
	movq	%rax, 105464(%rsp)
	movq	12352(%rsp), %rax
	movq	%rax, 105472(%rsp)
	movq	12360(%rsp), %rax
	movq	%rax, 105480(%rsp)
	movq	12368(%rsp), %rax
	movq	%rax, 105488(%rsp)
	movq	12376(%rsp), %rax
	movq	%rax, 105496(%rsp)
	movq	12384(%rsp), %rax
	movq	%rax, 105504(%rsp)
	movq	12392(%rsp), %rax
	movq	%rax, 105512(%rsp)
	movq	12400(%rsp), %rax
	movq	%rax, 105520(%rsp)
	movq	12408(%rsp), %rax
	movq	%rax, 105528(%rsp)
	movq	12416(%rsp), %rax
	movq	%rax, 105536(%rsp)
	movq	12424(%rsp), %rax
	movq	%rax, 105544(%rsp)
	movq	12432(%rsp), %rax
	movq	%rax, 105552(%rsp)
	movq	12440(%rsp), %rax
	movq	%rax, 105560(%rsp)
	movq	12448(%rsp), %rax
	movq	%rax, 105568(%rsp)
	movq	12456(%rsp), %rax
	movq	%rax, 105576(%rsp)
	movq	12464(%rsp), %rax
	movq	%rax, 105584(%rsp)
	movq	12472(%rsp), %rax
	movq	%rax, 105592(%rsp)
	movq	12480(%rsp), %rax
	movq	%rax, 105600(%rsp)
	movq	12488(%rsp), %rax
	movq	%rax, 105608(%rsp)
	movq	12496(%rsp), %rax
	movq	%rax, 105616(%rsp)
	movq	12504(%rsp), %rax
	movq	%rax, 105624(%rsp)
	movq	12512(%rsp), %rax
	movq	%rax, 105632(%rsp)
	movq	12520(%rsp), %rax
	movq	%rax, 105640(%rsp)
	movq	12528(%rsp), %rax
	movq	%rax, 105648(%rsp)
	movq	12536(%rsp), %rax
	movq	%rax, 105656(%rsp)
	movq	12544(%rsp), %rax
	movq	%rax, 105664(%rsp)
	movq	12552(%rsp), %rax
	movq	%rax, 105672(%rsp)
	movq	12560(%rsp), %rax
	movq	%rax, 105680(%rsp)
	movq	12568(%rsp), %rax
	movq	%rax, 105688(%rsp)
	movq	12576(%rsp), %rax
	movq	%rax, 105696(%rsp)
	movq	12584(%rsp), %rax
	movq	%rax, 105704(%rsp)
	movq	12592(%rsp), %rax
	movq	%rax, 105712(%rsp)
	movq	12600(%rsp), %rax
	movq	%rax, 105720(%rsp)
	movq	12608(%rsp), %rax
	movq	%rax, 105728(%rsp)
	movq	12616(%rsp), %rax
	movq	%rax, 105736(%rsp)
	movq	12624(%rsp), %rax
	movq	%rax, 105744(%rsp)
	movq	12632(%rsp), %rax
	movq	%rax, 105752(%rsp)
	movq	12640(%rsp), %rax
	movq	%rax, 105760(%rsp)
	movq	12648(%rsp), %rax
	movq	%rax, 105768(%rsp)
	movq	12656(%rsp), %rax
	movq	%rax, 105776(%rsp)
	movq	12664(%rsp), %rax
	movq	%rax, 105784(%rsp)
	movq	12672(%rsp), %rax
	movq	%rax, 105792(%rsp)
	movq	12680(%rsp), %rax
	movq	%rax, 105800(%rsp)
	movq	12688(%rsp), %rax
	movq	%rax, 105808(%rsp)
	movq	12696(%rsp), %rax
	movq	%rax, 105816(%rsp)
	movq	12704(%rsp), %rax
	movq	%rax, 105824(%rsp)
	movq	12712(%rsp), %rax
	movq	%rax, 105832(%rsp)
	movq	12720(%rsp), %rax
	movq	%rax, 105840(%rsp)
	movq	12728(%rsp), %rax
	movq	%rax, 105848(%rsp)
	movq	12736(%rsp), %rax
	movq	%rax, 105856(%rsp)
	movq	12744(%rsp), %rax
	movq	%rax, 105864(%rsp)
	movq	12752(%rsp), %rax
	movq	%rax, 105872(%rsp)
	movq	12760(%rsp), %rax
	movq	%rax, 105880(%rsp)
	movq	12768(%rsp), %rax
	movq	%rax, 105888(%rsp)
	movq	12776(%rsp), %rax
	movq	%rax, 105896(%rsp)
	movq	12784(%rsp), %rax
	movq	%rax, 105904(%rsp)
	movq	12792(%rsp), %rax
	movq	%rax, 105912(%rsp)
	movq	12800(%rsp), %rax
	movq	%rax, 105920(%rsp)
	movq	12808(%rsp), %rax
	movq	%rax, 105928(%rsp)
	movq	12816(%rsp), %rax
	movq	%rax, 105936(%rsp)
	movq	12824(%rsp), %rax
	movq	%rax, 105944(%rsp)
	movq	12832(%rsp), %rax
	movq	%rax, 105952(%rsp)
	movq	12840(%rsp), %rax
	movq	%rax, 105960(%rsp)
	movq	12848(%rsp), %rax
	movq	%rax, 105968(%rsp)
	movq	12856(%rsp), %rax
	movq	%rax, 105976(%rsp)
	movq	12864(%rsp), %rax
	movq	%rax, 105984(%rsp)
	movq	12872(%rsp), %rax
	movq	%rax, 105992(%rsp)
	movq	12880(%rsp), %rax
	movq	%rax, 106000(%rsp)
	movq	12888(%rsp), %rax
	movq	%rax, 106008(%rsp)
	movq	12896(%rsp), %rax
	movq	%rax, 106016(%rsp)
	movq	12904(%rsp), %rax
	movq	%rax, 106024(%rsp)
	movq	12912(%rsp), %rax
	movq	%rax, 106032(%rsp)
	movq	12920(%rsp), %rax
	movq	%rax, 106040(%rsp)
	movq	12928(%rsp), %rax
	movq	%rax, 106048(%rsp)
	movq	12936(%rsp), %rax
	movq	%rax, 106056(%rsp)
	movq	12944(%rsp), %rax
	movq	%rax, 106064(%rsp)
	movq	12952(%rsp), %rax
	movq	%rax, 106072(%rsp)
	movq	12960(%rsp), %rax
	movq	%rax, 106080(%rsp)
	movq	12968(%rsp), %rax
	movq	%rax, 106088(%rsp)
	movq	12976(%rsp), %rax
	movq	%rax, 106096(%rsp)
	movq	12984(%rsp), %rax
	movq	%rax, 106104(%rsp)
	movq	12992(%rsp), %rax
	movq	%rax, 106112(%rsp)
	movq	13000(%rsp), %rax
	movq	%rax, 106120(%rsp)
	movq	13008(%rsp), %rax
	movq	%rax, 106128(%rsp)
	movq	13016(%rsp), %rax
	movq	%rax, 106136(%rsp)
	movq	13024(%rsp), %rax
	movq	%rax, 106144(%rsp)
	movq	13032(%rsp), %rax
	movq	%rax, 106152(%rsp)
	movq	13040(%rsp), %rax
	movq	%rax, 106160(%rsp)
	movq	13048(%rsp), %rax
	movq	%rax, 106168(%rsp)
	movq	13056(%rsp), %rax
	movq	%rax, 106176(%rsp)
	movq	13064(%rsp), %rax
	movq	%rax, 106184(%rsp)
	movq	13072(%rsp), %rax
	movq	%rax, 106192(%rsp)
	movq	13080(%rsp), %rax
	movq	%rax, 106200(%rsp)
	movq	13088(%rsp), %rax
	movq	%rax, 106208(%rsp)
	movq	13096(%rsp), %rax
	movq	%rax, 106216(%rsp)
	movq	13104(%rsp), %rax
	movq	%rax, 106224(%rsp)
	movq	13112(%rsp), %rax
	movq	%rax, 106232(%rsp)
	movq	13120(%rsp), %rax
	movq	%rax, 106240(%rsp)
	movq	13128(%rsp), %rax
	movq	%rax, 106248(%rsp)
	movq	13136(%rsp), %rax
	movq	%rax, 106256(%rsp)
	movq	13144(%rsp), %rax
	movq	%rax, 106264(%rsp)
	movq	13152(%rsp), %rax
	movq	%rax, 106272(%rsp)
	movq	13160(%rsp), %rax
	movq	%rax, 106280(%rsp)
	movq	13168(%rsp), %rax
	movq	%rax, 106288(%rsp)
	movq	13176(%rsp), %rax
	movq	%rax, 106296(%rsp)
	movq	13184(%rsp), %rax
	movq	%rax, 106304(%rsp)
	movq	13192(%rsp), %rax
	movq	%rax, 106312(%rsp)
	movq	13200(%rsp), %rax
	movq	%rax, 106320(%rsp)
	movq	13208(%rsp), %rax
	movq	%rax, 106328(%rsp)
	movq	13216(%rsp), %rax
	movq	%rax, 106336(%rsp)
	movq	13224(%rsp), %rax
	movq	%rax, 106344(%rsp)
	movq	13232(%rsp), %rax
	movq	%rax, 106352(%rsp)
	movq	13240(%rsp), %rax
	movq	%rax, 106360(%rsp)
	movq	13248(%rsp), %rax
	movq	%rax, 106368(%rsp)
	movq	13256(%rsp), %rax
	movq	%rax, 106376(%rsp)
	movq	13264(%rsp), %rax
	movq	%rax, 106384(%rsp)
	movq	13272(%rsp), %rax
	movq	%rax, 106392(%rsp)
	movq	13280(%rsp), %rax
	movq	%rax, 106400(%rsp)
	movq	13288(%rsp), %rax
	movq	%rax, 106408(%rsp)
	movq	13296(%rsp), %rax
	movq	%rax, 106416(%rsp)
	movq	13304(%rsp), %rax
	movq	%rax, 106424(%rsp)
	movq	13312(%rsp), %rax
	movq	%rax, 106432(%rsp)
	movq	13320(%rsp), %rax
	movq	%rax, 106440(%rsp)
	movq	13328(%rsp), %rax
	movq	%rax, 106448(%rsp)
	movq	13336(%rsp), %rax
	movq	%rax, 106456(%rsp)
	movq	13344(%rsp), %rax
	movq	%rax, 106464(%rsp)
	movq	13352(%rsp), %rax
	movq	%rax, 106472(%rsp)
	movq	13360(%rsp), %rax
	movq	%rax, 106480(%rsp)
	movq	13368(%rsp), %rax
	movq	%rax, 106488(%rsp)
	movq	13376(%rsp), %rax
	movq	%rax, 106496(%rsp)
	movq	13384(%rsp), %rax
	movq	%rax, 106504(%rsp)
	movq	13392(%rsp), %rax
	movq	%rax, 106512(%rsp)
	movq	13400(%rsp), %rax
	movq	%rax, 106520(%rsp)
	movq	13408(%rsp), %rax
	movq	%rax, 106528(%rsp)
	movq	13416(%rsp), %rax
	movq	%rax, 106536(%rsp)
	movq	13424(%rsp), %rax
	movq	%rax, 106544(%rsp)
	movq	13432(%rsp), %rax
	movq	%rax, 106552(%rsp)
	movq	13440(%rsp), %rax
	movq	%rax, 106560(%rsp)
	movq	13448(%rsp), %rax
	movq	%rax, 106568(%rsp)
	movq	13456(%rsp), %rax
	movq	%rax, 106576(%rsp)
	movq	13464(%rsp), %rax
	movq	%rax, 106584(%rsp)
	movq	13472(%rsp), %rax
	movq	%rax, 106592(%rsp)
	movq	13480(%rsp), %rax
	movq	%rax, 106600(%rsp)
	movq	13488(%rsp), %rax
	movq	%rax, 106608(%rsp)
	movq	13496(%rsp), %rax
	movq	%rax, 106616(%rsp)
	movq	13504(%rsp), %rax
	movq	%rax, 106624(%rsp)
	movq	13512(%rsp), %rax
	movq	%rax, 106632(%rsp)
	movq	13520(%rsp), %rax
	movq	%rax, 106640(%rsp)
	movq	13528(%rsp), %rax
	movq	%rax, 106648(%rsp)
	movq	13536(%rsp), %rax
	movq	%rax, 106656(%rsp)
	movq	13544(%rsp), %rax
	movq	%rax, 106664(%rsp)
	movq	13552(%rsp), %rax
	movq	%rax, 106672(%rsp)
	movq	13560(%rsp), %rax
	movq	%rax, 106680(%rsp)
	movq	13568(%rsp), %rax
	movq	%rax, 106688(%rsp)
	movq	13576(%rsp), %rax
	movq	%rax, 106696(%rsp)
	movq	13584(%rsp), %rax
	movq	%rax, 106704(%rsp)
	movq	13592(%rsp), %rax
	movq	%rax, 106712(%rsp)
	movq	13600(%rsp), %rax
	movq	%rax, 106720(%rsp)
	movq	13608(%rsp), %rax
	movq	%rax, 106728(%rsp)
	movq	13616(%rsp), %rax
	movq	%rax, 106736(%rsp)
	movq	13624(%rsp), %rax
	movq	%rax, 106744(%rsp)
	movq	13632(%rsp), %rax
	movq	%rax, 106752(%rsp)
	movq	13640(%rsp), %rax
	movq	%rax, 106760(%rsp)
	movq	13648(%rsp), %rax
	movq	%rax, 106768(%rsp)
	movq	13656(%rsp), %rax
	movq	%rax, 106776(%rsp)
	movq	13664(%rsp), %rax
	movq	%rax, 106784(%rsp)
	movq	13672(%rsp), %rax
	movq	%rax, 106792(%rsp)
	movq	13680(%rsp), %rax
	movq	%rax, 106800(%rsp)
	movq	13688(%rsp), %rax
	movq	%rax, 106808(%rsp)
	movq	13696(%rsp), %rax
	movq	%rax, 106816(%rsp)
	movq	13704(%rsp), %rax
	movq	%rax, 106824(%rsp)
	movq	13712(%rsp), %rax
	movq	%rax, 106832(%rsp)
	movq	13720(%rsp), %rax
	movq	%rax, 106840(%rsp)
	movq	13728(%rsp), %rax
	movq	%rax, 106848(%rsp)
	movq	13736(%rsp), %rax
	movq	%rax, 106856(%rsp)
	movq	13744(%rsp), %rax
	movq	%rax, 106864(%rsp)
	movq	13752(%rsp), %rax
	movq	%rax, 106872(%rsp)
	movq	13760(%rsp), %rax
	movq	%rax, 106880(%rsp)
	movq	13768(%rsp), %rax
	movq	%rax, 106888(%rsp)
	movq	13776(%rsp), %rax
	movq	%rax, 106896(%rsp)
	movq	13784(%rsp), %rax
	movq	%rax, 106904(%rsp)
	movq	13792(%rsp), %rax
	movq	%rax, 106912(%rsp)
	movq	13800(%rsp), %rax
	movq	%rax, 106920(%rsp)
	movq	13808(%rsp), %rax
	movq	%rax, 106928(%rsp)
	movq	13816(%rsp), %rax
	movq	%rax, 106936(%rsp)
	movq	13824(%rsp), %rax
	movq	%rax, 106944(%rsp)
	movq	13832(%rsp), %rax
	movq	%rax, 106952(%rsp)
	movq	13840(%rsp), %rax
	movq	%rax, 106960(%rsp)
	movq	13848(%rsp), %rax
	movq	%rax, 106968(%rsp)
	movq	13856(%rsp), %rax
	movq	%rax, 106976(%rsp)
	movq	13864(%rsp), %rax
	movq	%rax, 106984(%rsp)
	movq	13872(%rsp), %rax
	movq	%rax, 106992(%rsp)
	movq	13880(%rsp), %rax
	movq	%rax, 107000(%rsp)
	movq	13888(%rsp), %rax
	movq	%rax, 107008(%rsp)
	movq	13896(%rsp), %rax
	movq	%rax, 107016(%rsp)
	movq	13904(%rsp), %rax
	movq	%rax, 107024(%rsp)
	movq	13912(%rsp), %rax
	movq	%rax, 107032(%rsp)
	movq	13920(%rsp), %rax
	movq	%rax, 107040(%rsp)
	movq	13928(%rsp), %rax
	movq	%rax, 107048(%rsp)
	movq	13936(%rsp), %rax
	movq	%rax, 107056(%rsp)
	movq	13944(%rsp), %rax
	movq	%rax, 107064(%rsp)
	movq	13952(%rsp), %rax
	movq	%rax, 107072(%rsp)
	movq	13960(%rsp), %rax
	movq	%rax, 107080(%rsp)
	movq	13968(%rsp), %rax
	movq	%rax, 107088(%rsp)
	movq	13976(%rsp), %rax
	movq	%rax, 107096(%rsp)
	movq	13984(%rsp), %rax
	movq	%rax, 107104(%rsp)
	movq	13992(%rsp), %rax
	movq	%rax, 107112(%rsp)
	movq	14000(%rsp), %rax
	movq	%rax, 107120(%rsp)
	movq	14008(%rsp), %rax
	movq	%rax, 107128(%rsp)
	movq	14016(%rsp), %rax
	movq	%rax, 107136(%rsp)
	movq	14024(%rsp), %rax
	movq	%rax, 107144(%rsp)
	movq	14032(%rsp), %rax
	movq	%rax, 107152(%rsp)
	movq	14040(%rsp), %rax
	movq	%rax, 107160(%rsp)
	movq	14048(%rsp), %rax
	movq	%rax, 107168(%rsp)
	movq	14056(%rsp), %rax
	movq	%rax, 107176(%rsp)
	movq	14064(%rsp), %rax
	movq	%rax, 107184(%rsp)
	movq	14072(%rsp), %rax
	movq	%rax, 107192(%rsp)
	movq	14080(%rsp), %rax
	movq	%rax, 107200(%rsp)
	movq	14088(%rsp), %rax
	movq	%rax, 107208(%rsp)
	movq	14096(%rsp), %rax
	movq	%rax, 107216(%rsp)
	movq	14104(%rsp), %rax
	movq	%rax, 107224(%rsp)
	movq	14112(%rsp), %rax
	movq	%rax, 107232(%rsp)
	movq	14120(%rsp), %rax
	movq	%rax, 107240(%rsp)
	movq	14128(%rsp), %rax
	movq	%rax, 107248(%rsp)
	movq	14136(%rsp), %rax
	movq	%rax, 107256(%rsp)
	movq	14144(%rsp), %rax
	movq	%rax, 107264(%rsp)
	movq	14152(%rsp), %rax
	movq	%rax, 107272(%rsp)
	movq	14160(%rsp), %rax
	movq	%rax, 107280(%rsp)
	movq	14168(%rsp), %rax
	movq	%rax, 107288(%rsp)
	movq	14176(%rsp), %rax
	movq	%rax, 107296(%rsp)
	movq	14184(%rsp), %rax
	movq	%rax, 107304(%rsp)
	movq	14192(%rsp), %rax
	movq	%rax, 107312(%rsp)
	movq	14200(%rsp), %rax
	movq	%rax, 107320(%rsp)
	movq	14208(%rsp), %rax
	movq	%rax, 107328(%rsp)
	movq	14216(%rsp), %rax
	movq	%rax, 107336(%rsp)
	movq	14224(%rsp), %rax
	movq	%rax, 107344(%rsp)
	movq	14232(%rsp), %rax
	movq	%rax, 107352(%rsp)
	movq	14240(%rsp), %rax
	movq	%rax, 107360(%rsp)
	movq	14248(%rsp), %rax
	movq	%rax, 107368(%rsp)
	movq	14256(%rsp), %rax
	movq	%rax, 107376(%rsp)
	movq	14264(%rsp), %rax
	movq	%rax, 107384(%rsp)
	movq	14272(%rsp), %rax
	movq	%rax, 107392(%rsp)
	movq	14280(%rsp), %rax
	movq	%rax, 107400(%rsp)
	movq	14288(%rsp), %rax
	movq	%rax, 107408(%rsp)
	movq	14296(%rsp), %rax
	movq	%rax, 107416(%rsp)
	movq	14304(%rsp), %rax
	movq	%rax, 107424(%rsp)
	movq	14312(%rsp), %rax
	movq	%rax, 107432(%rsp)
	movq	14320(%rsp), %rax
	movq	%rax, 107440(%rsp)
	movq	14328(%rsp), %rax
	movq	%rax, 107448(%rsp)
	movq	14336(%rsp), %rax
	movq	%rax, 107456(%rsp)
	movq	14344(%rsp), %rax
	movq	%rax, 107464(%rsp)
	movq	14352(%rsp), %rax
	movq	%rax, 107472(%rsp)
	movq	14360(%rsp), %rax
	movq	%rax, 107480(%rsp)
	movq	14368(%rsp), %rax
	movq	%rax, 107488(%rsp)
	movq	14376(%rsp), %rax
	movq	%rax, 107496(%rsp)
	movq	14384(%rsp), %rax
	movq	%rax, 107504(%rsp)
	movq	14392(%rsp), %rax
	movq	%rax, 107512(%rsp)
	movq	14400(%rsp), %rax
	movq	%rax, 107520(%rsp)
	movq	14408(%rsp), %rax
	movq	%rax, 107528(%rsp)
	movq	14416(%rsp), %rax
	movq	%rax, 107536(%rsp)
	movq	14424(%rsp), %rax
	movq	%rax, 107544(%rsp)
	movq	14432(%rsp), %rax
	movq	%rax, 107552(%rsp)
	movq	14440(%rsp), %rax
	movq	%rax, 107560(%rsp)
	movq	14448(%rsp), %rax
	movq	%rax, 107568(%rsp)
	movq	14456(%rsp), %rax
	movq	%rax, 107576(%rsp)
	movq	14464(%rsp), %rax
	movq	%rax, 107584(%rsp)
	movq	14472(%rsp), %rax
	movq	%rax, 107592(%rsp)
	movq	14480(%rsp), %rax
	movq	%rax, 107600(%rsp)
	movq	14488(%rsp), %rax
	movq	%rax, 107608(%rsp)
	movq	14496(%rsp), %rax
	movq	%rax, 107616(%rsp)
	movq	14504(%rsp), %rax
	movq	%rax, 107624(%rsp)
	movq	14512(%rsp), %rax
	movq	%rax, 107632(%rsp)
	movq	14520(%rsp), %rax
	movq	%rax, 107640(%rsp)
	movq	14528(%rsp), %rax
	movq	%rax, 107648(%rsp)
	movq	14536(%rsp), %rax
	movq	%rax, 107656(%rsp)
	movq	14544(%rsp), %rax
	movq	%rax, 107664(%rsp)
	movq	14552(%rsp), %rax
	movq	%rax, 107672(%rsp)
	movq	14560(%rsp), %rax
	movq	%rax, 107680(%rsp)
	movq	14568(%rsp), %rax
	movq	%rax, 107688(%rsp)
	movq	14576(%rsp), %rax
	movq	%rax, 107696(%rsp)
	movq	14584(%rsp), %rax
	movq	%rax, 107704(%rsp)
	movq	14592(%rsp), %rax
	movq	%rax, 107712(%rsp)
	movq	14600(%rsp), %rax
	movq	%rax, 107720(%rsp)
	movq	14608(%rsp), %rax
	movq	%rax, 107728(%rsp)
	movq	14616(%rsp), %rax
	movq	%rax, 107736(%rsp)
	movq	14624(%rsp), %rax
	movq	%rax, 107744(%rsp)
	movq	14632(%rsp), %rax
	movq	%rax, 107752(%rsp)
	movq	14640(%rsp), %rax
	movq	%rax, 107760(%rsp)
	movq	14648(%rsp), %rax
	movq	%rax, 107768(%rsp)
	movq	14656(%rsp), %rax
	movq	%rax, 107776(%rsp)
	movq	14664(%rsp), %rax
	movq	%rax, 107784(%rsp)
	movq	14672(%rsp), %rax
	movq	%rax, 107792(%rsp)
	movq	14680(%rsp), %rax
	movq	%rax, 107800(%rsp)
	movq	14688(%rsp), %rax
	movq	%rax, 107808(%rsp)
	movq	14696(%rsp), %rax
	movq	%rax, 107816(%rsp)
	movq	14704(%rsp), %rax
	movq	%rax, 107824(%rsp)
	movq	14712(%rsp), %rax
	movq	%rax, 107832(%rsp)
	movq	14720(%rsp), %rax
	movq	%rax, 107840(%rsp)
	movq	14728(%rsp), %rax
	movq	%rax, 107848(%rsp)
	movq	14736(%rsp), %rax
	movq	%rax, 107856(%rsp)
	movq	14744(%rsp), %rax
	movq	%rax, 107864(%rsp)
	movq	14752(%rsp), %rax
	movq	%rax, 107872(%rsp)
	movq	14760(%rsp), %rax
	movq	%rax, 107880(%rsp)
	movq	14768(%rsp), %rax
	movq	%rax, 107888(%rsp)
	movq	14776(%rsp), %rax
	movq	%rax, 107896(%rsp)
	movq	14784(%rsp), %rax
	movq	%rax, 107904(%rsp)
	movq	14792(%rsp), %rax
	movq	%rax, 107912(%rsp)
	movq	14800(%rsp), %rax
	movq	%rax, 107920(%rsp)
	movq	14808(%rsp), %rax
	movq	%rax, 107928(%rsp)
	movq	14816(%rsp), %rax
	movq	%rax, 107936(%rsp)
	movq	14824(%rsp), %rax
	movq	%rax, 107944(%rsp)
	movq	14832(%rsp), %rax
	movq	%rax, 107952(%rsp)
	movq	14840(%rsp), %rax
	movq	%rax, 107960(%rsp)
	movq	14848(%rsp), %rax
	movq	%rax, 107968(%rsp)
	movq	14856(%rsp), %rax
	movq	%rax, 107976(%rsp)
	movq	14864(%rsp), %rax
	movq	%rax, 107984(%rsp)
	movq	14872(%rsp), %rax
	movq	%rax, 107992(%rsp)
	movq	14880(%rsp), %rax
	movq	%rax, 108000(%rsp)
	movq	14888(%rsp), %rax
	movq	%rax, 108008(%rsp)
	movq	14896(%rsp), %rax
	movq	%rax, 108016(%rsp)
	movq	14904(%rsp), %rax
	movq	%rax, 108024(%rsp)
	movq	14912(%rsp), %rax
	movq	%rax, 108032(%rsp)
	movq	14920(%rsp), %rax
	movq	%rax, 108040(%rsp)
	movq	14928(%rsp), %rax
	movq	%rax, 108048(%rsp)
	movq	14936(%rsp), %rax
	movq	%rax, 108056(%rsp)
	movq	14944(%rsp), %rax
	movq	%rax, 108064(%rsp)
	movq	14952(%rsp), %rax
	movq	%rax, 108072(%rsp)
	movq	14960(%rsp), %rax
	movq	%rax, 108080(%rsp)
	movq	14968(%rsp), %rax
	movq	%rax, 108088(%rsp)
	movq	14976(%rsp), %rax
	movq	%rax, 108096(%rsp)
	movq	14984(%rsp), %rax
	movq	%rax, 108104(%rsp)
	movq	14992(%rsp), %rax
	movq	%rax, 108112(%rsp)
	movq	15000(%rsp), %rax
	movq	%rax, 108120(%rsp)
	movq	15008(%rsp), %rax
	movq	%rax, 108128(%rsp)
	movq	15016(%rsp), %rax
	movq	%rax, 108136(%rsp)
	movq	15024(%rsp), %rax
	movq	%rax, 108144(%rsp)
	movq	15032(%rsp), %rax
	movq	%rax, 108152(%rsp)
	movq	15040(%rsp), %rax
	movq	%rax, 108160(%rsp)
	movq	15048(%rsp), %rax
	movq	%rax, 108168(%rsp)
	movq	15056(%rsp), %rax
	movq	%rax, 108176(%rsp)
	movq	15064(%rsp), %rax
	movq	%rax, 108184(%rsp)
	movq	15072(%rsp), %rax
	movq	%rax, 108192(%rsp)
	movq	15080(%rsp), %rax
	movq	%rax, 108200(%rsp)
	movq	15088(%rsp), %rax
	movq	%rax, 108208(%rsp)
	movq	15096(%rsp), %rax
	movq	%rax, 108216(%rsp)
	movq	15104(%rsp), %rax
	movq	%rax, 108224(%rsp)
	movq	15112(%rsp), %rax
	movq	%rax, 108232(%rsp)
	movq	15120(%rsp), %rax
	movq	%rax, 108240(%rsp)
	movq	15128(%rsp), %rax
	movq	%rax, 108248(%rsp)
	movq	15136(%rsp), %rax
	movq	%rax, 108256(%rsp)
	movq	15144(%rsp), %rax
	movq	%rax, 108264(%rsp)
	movq	15152(%rsp), %rax
	movq	%rax, 108272(%rsp)
	movq	15160(%rsp), %rax
	movq	%rax, 108280(%rsp)
	movq	15168(%rsp), %rax
	movq	%rax, 108288(%rsp)
	movq	15176(%rsp), %rax
	movq	%rax, 108296(%rsp)
	movq	15184(%rsp), %rax
	movq	%rax, 108304(%rsp)
	movq	15192(%rsp), %rax
	movq	%rax, 108312(%rsp)
	movq	15200(%rsp), %rax
	movq	%rax, 108320(%rsp)
	movq	15208(%rsp), %rax
	movq	%rax, 108328(%rsp)
	movq	15216(%rsp), %rax
	movq	%rax, 108336(%rsp)
	movq	15224(%rsp), %rax
	movq	%rax, 108344(%rsp)
	movq	15232(%rsp), %rax
	movq	%rax, 108352(%rsp)
	movq	15240(%rsp), %rax
	movq	%rax, 108360(%rsp)
	movq	15248(%rsp), %rax
	movq	%rax, 108368(%rsp)
	movq	15256(%rsp), %rax
	movq	%rax, 108376(%rsp)
	movq	15264(%rsp), %rax
	movq	%rax, 108384(%rsp)
	movq	15272(%rsp), %rax
	movq	%rax, 108392(%rsp)
	movq	15280(%rsp), %rax
	movq	%rax, 108400(%rsp)
	movq	15288(%rsp), %rax
	movq	%rax, 108408(%rsp)
	movq	15296(%rsp), %rax
	movq	%rax, 108416(%rsp)
	movq	15304(%rsp), %rax
	movq	%rax, 108424(%rsp)
	movq	15312(%rsp), %rax
	movq	%rax, 108432(%rsp)
	movq	15320(%rsp), %rax
	movq	%rax, 108440(%rsp)
	movq	15328(%rsp), %rax
	movq	%rax, 108448(%rsp)
	movq	15336(%rsp), %rax
	movq	%rax, 108456(%rsp)
	movq	15344(%rsp), %rax
	movq	%rax, 108464(%rsp)
	movq	15352(%rsp), %rax
	movq	%rax, 108472(%rsp)
	movq	15360(%rsp), %rax
	movq	%rax, 108480(%rsp)
	movq	15368(%rsp), %rax
	movq	%rax, 108488(%rsp)
	movq	15376(%rsp), %rax
	movq	%rax, 108496(%rsp)
	movq	15384(%rsp), %rax
	movq	%rax, 108504(%rsp)
	movq	15392(%rsp), %rax
	movq	%rax, 108512(%rsp)
	movq	15400(%rsp), %rax
	movq	%rax, 108520(%rsp)
	movq	15408(%rsp), %rax
	movq	%rax, 108528(%rsp)
	movq	15416(%rsp), %rax
	movq	%rax, 108536(%rsp)
	movq	15424(%rsp), %rax
	movq	%rax, 108544(%rsp)
	movq	15432(%rsp), %rax
	movq	%rax, 108552(%rsp)
	movq	15440(%rsp), %rax
	movq	%rax, 108560(%rsp)
	movq	15448(%rsp), %rax
	movq	%rax, 108568(%rsp)
	movq	15456(%rsp), %rax
	movq	%rax, 108576(%rsp)
	movq	15464(%rsp), %rax
	movq	%rax, 108584(%rsp)
	movq	15472(%rsp), %rax
	movq	%rax, 108592(%rsp)
	movq	15480(%rsp), %rax
	movq	%rax, 108600(%rsp)
	movq	15488(%rsp), %rax
	movq	%rax, 108608(%rsp)
	movq	15496(%rsp), %rax
	movq	%rax, 108616(%rsp)
	movq	15504(%rsp), %rax
	movq	%rax, 108624(%rsp)
	movq	15512(%rsp), %rax
	movq	%rax, 108632(%rsp)
	movq	15520(%rsp), %rax
	movq	%rax, 108640(%rsp)
	movq	15528(%rsp), %rax
	movq	%rax, 108648(%rsp)
	movq	15536(%rsp), %rax
	movq	%rax, 108656(%rsp)
	movq	15544(%rsp), %rax
	movq	%rax, 108664(%rsp)
	movq	15552(%rsp), %rax
	movq	%rax, 108672(%rsp)
	movq	15560(%rsp), %rax
	movq	%rax, 108680(%rsp)
	movq	15568(%rsp), %rax
	movq	%rax, 108688(%rsp)
	movq	15576(%rsp), %rax
	movq	%rax, 108696(%rsp)
	movq	15584(%rsp), %rax
	movq	%rax, 108704(%rsp)
	movq	15592(%rsp), %rax
	movq	%rax, 108712(%rsp)
	movq	15600(%rsp), %rax
	movq	%rax, 108720(%rsp)
	movq	15608(%rsp), %rax
	movq	%rax, 108728(%rsp)
	movq	15616(%rsp), %rax
	movq	%rax, 108736(%rsp)
	movq	15624(%rsp), %rax
	movq	%rax, 108744(%rsp)
	movq	15632(%rsp), %rax
	movq	%rax, 108752(%rsp)
	movq	15640(%rsp), %rax
	movq	%rax, 108760(%rsp)
	movq	15648(%rsp), %rax
	movq	%rax, 108768(%rsp)
	movq	15656(%rsp), %rax
	movq	%rax, 108776(%rsp)
	movq	15664(%rsp), %rax
	movq	%rax, 108784(%rsp)
	movq	15672(%rsp), %rax
	movq	%rax, 108792(%rsp)
	movq	15680(%rsp), %rax
	movq	%rax, 108800(%rsp)
	movq	15688(%rsp), %rax
	movq	%rax, 108808(%rsp)
	movq	15696(%rsp), %rax
	movq	%rax, 108816(%rsp)
	movq	15704(%rsp), %rax
	movq	%rax, 108824(%rsp)
	movq	15712(%rsp), %rax
	movq	%rax, 108832(%rsp)
	movq	15720(%rsp), %rax
	movq	%rax, 108840(%rsp)
	movq	15728(%rsp), %rax
	movq	%rax, 108848(%rsp)
	movq	15736(%rsp), %rax
	movq	%rax, 108856(%rsp)
	movq	15744(%rsp), %rax
	movq	%rax, 108864(%rsp)
	movq	15752(%rsp), %rax
	movq	%rax, 108872(%rsp)
	movq	15760(%rsp), %rax
	movq	%rax, 108880(%rsp)
	movq	15768(%rsp), %rax
	movq	%rax, 108888(%rsp)
	movq	15776(%rsp), %rax
	movq	%rax, 108896(%rsp)
	movq	15784(%rsp), %rax
	movq	%rax, 108904(%rsp)
	movq	15792(%rsp), %rax
	movq	%rax, 108912(%rsp)
	movq	15800(%rsp), %rax
	movq	%rax, 108920(%rsp)
	movq	15808(%rsp), %rax
	movq	%rax, 108928(%rsp)
	movq	15816(%rsp), %rax
	movq	%rax, 108936(%rsp)
	movq	15824(%rsp), %rax
	movq	%rax, 108944(%rsp)
	movq	15832(%rsp), %rax
	movq	%rax, 108952(%rsp)
	movq	15840(%rsp), %rax
	movq	%rax, 108960(%rsp)
	movq	15848(%rsp), %rax
	movq	%rax, 108968(%rsp)
	movq	15856(%rsp), %rax
	movq	%rax, 108976(%rsp)
	movq	15864(%rsp), %rax
	movq	%rax, 108984(%rsp)
	movq	15872(%rsp), %rax
	movq	%rax, 108992(%rsp)
	movq	15880(%rsp), %rax
	movq	%rax, 109000(%rsp)
	movq	15888(%rsp), %rax
	movq	%rax, 109008(%rsp)
	movq	15896(%rsp), %rax
	movq	%rax, 109016(%rsp)
	movq	15904(%rsp), %rax
	movq	%rax, 109024(%rsp)
	movq	15912(%rsp), %rax
	movq	%rax, 109032(%rsp)
	movq	15920(%rsp), %rax
	movq	%rax, 109040(%rsp)
	movq	15928(%rsp), %rax
	movq	%rax, 109048(%rsp)
	movq	15936(%rsp), %rax
	movq	%rax, 109056(%rsp)
	movq	15944(%rsp), %rax
	movq	%rax, 109064(%rsp)
	movq	15952(%rsp), %rax
	movq	%rax, 109072(%rsp)
	movq	15960(%rsp), %rax
	movq	%rax, 109080(%rsp)
	movq	15968(%rsp), %rax
	movq	%rax, 109088(%rsp)
	movq	15976(%rsp), %rax
	movq	%rax, 109096(%rsp)
	movq	15984(%rsp), %rax
	movq	%rax, 109104(%rsp)
	movq	15992(%rsp), %rax
	movq	%rax, 109112(%rsp)
	movq	16000(%rsp), %rax
	movq	%rax, 109120(%rsp)
	movq	16008(%rsp), %rax
	movq	%rax, 109128(%rsp)
	movq	16016(%rsp), %rax
	movq	%rax, 109136(%rsp)
	movq	16024(%rsp), %rax
	movq	%rax, 109144(%rsp)
	movq	16032(%rsp), %rax
	movq	%rax, 109152(%rsp)
	movq	16040(%rsp), %rax
	movq	%rax, 109160(%rsp)
	movq	16048(%rsp), %rax
	movq	%rax, 109168(%rsp)
	movq	16056(%rsp), %rax
	movq	%rax, 109176(%rsp)
	movq	16064(%rsp), %rax
	movq	%rax, 109184(%rsp)
	movq	16072(%rsp), %rax
	movq	%rax, 109192(%rsp)
	movq	16080(%rsp), %rax
	movq	%rax, 109200(%rsp)
	movq	16088(%rsp), %rax
	movq	%rax, 109208(%rsp)
	movq	16096(%rsp), %rax
	movq	%rax, 109216(%rsp)
	movq	16104(%rsp), %rax
	movq	%rax, 109224(%rsp)
	movq	16112(%rsp), %rax
	movq	%rax, 109232(%rsp)
	movq	16120(%rsp), %rax
	movq	%rax, 109240(%rsp)
	movq	16128(%rsp), %rax
	movq	%rax, 109248(%rsp)
	movq	16136(%rsp), %rax
	movq	%rax, 109256(%rsp)
	movq	16144(%rsp), %rax
	movq	%rax, 109264(%rsp)
	movq	16152(%rsp), %rax
	movq	%rax, 109272(%rsp)
	movq	16160(%rsp), %rax
	movq	%rax, 109280(%rsp)
	movq	16168(%rsp), %rax
	movq	%rax, 109288(%rsp)
	movq	16176(%rsp), %rax
	movq	%rax, 109296(%rsp)
	movq	16184(%rsp), %rax
	movq	%rax, 109304(%rsp)
	movq	16192(%rsp), %rax
	movq	%rax, 109312(%rsp)
	movq	16200(%rsp), %rax
	movq	%rax, 109320(%rsp)
	movq	16208(%rsp), %rax
	movq	%rax, 109328(%rsp)
	movq	16216(%rsp), %rax
	movq	%rax, 109336(%rsp)
	movq	16224(%rsp), %rax
	movq	%rax, 109344(%rsp)
	movq	16232(%rsp), %rax
	movq	%rax, 109352(%rsp)
	movq	16240(%rsp), %rax
	movq	%rax, 109360(%rsp)
	movq	16248(%rsp), %rax
	movq	%rax, 109368(%rsp)
	movq	16256(%rsp), %rax
	movq	%rax, 109376(%rsp)
	movq	16264(%rsp), %rax
	movq	%rax, 109384(%rsp)
	movq	16272(%rsp), %rax
	movq	%rax, 109392(%rsp)
	movq	16280(%rsp), %rax
	movq	%rax, 109400(%rsp)
	movq	16288(%rsp), %rax
	movq	%rax, 109408(%rsp)
	movq	16296(%rsp), %rax
	movq	%rax, 109416(%rsp)
	movq	16304(%rsp), %rax
	movq	%rax, 109424(%rsp)
	movq	16312(%rsp), %rax
	movq	%rax, 109432(%rsp)
	movq	16320(%rsp), %rax
	movq	%rax, 109440(%rsp)
	movq	16328(%rsp), %rax
	movq	%rax, 109448(%rsp)
	movq	16336(%rsp), %rax
	movq	%rax, 109456(%rsp)
	movq	16344(%rsp), %rax
	movq	%rax, 109464(%rsp)
	movq	16352(%rsp), %rax
	movq	%rax, 109472(%rsp)
	movq	16360(%rsp), %rax
	movq	%rax, 109480(%rsp)
	movq	16368(%rsp), %rax
	movq	%rax, 109488(%rsp)
	movq	16376(%rsp), %rax
	movq	%rax, 109496(%rsp)
	movq	16384(%rsp), %rax
	movq	%rax, 109504(%rsp)
	movq	16392(%rsp), %rax
	movq	%rax, 109512(%rsp)
	movq	16400(%rsp), %rax
	movq	%rax, 109520(%rsp)
	movq	16408(%rsp), %rax
	movq	%rax, 109528(%rsp)
	movq	16416(%rsp), %rax
	movq	%rax, 109536(%rsp)
	movq	16424(%rsp), %rax
	movq	%rax, 109544(%rsp)
	movq	16432(%rsp), %rax
	movq	%rax, 109552(%rsp)
	movq	16440(%rsp), %rax
	movq	%rax, 109560(%rsp)
	movq	16448(%rsp), %rax
	movq	%rax, 109568(%rsp)
	movq	16456(%rsp), %rax
	movq	%rax, 109576(%rsp)
	movq	16464(%rsp), %rax
	movq	%rax, 109584(%rsp)
	movq	16472(%rsp), %rax
	movq	%rax, 109592(%rsp)
	movq	16480(%rsp), %rax
	movq	%rax, 109600(%rsp)
	movq	16488(%rsp), %rax
	movq	%rax, 109608(%rsp)
	movq	16496(%rsp), %rax
	movq	%rax, 109616(%rsp)
	movq	16504(%rsp), %rax
	movq	%rax, 109624(%rsp)
	movq	16512(%rsp), %rax
	movq	%rax, 109632(%rsp)
	movq	16520(%rsp), %rax
	movq	%rax, 109640(%rsp)
	movq	16528(%rsp), %rax
	movq	%rax, 109648(%rsp)
	movq	16536(%rsp), %rax
	movq	%rax, 109656(%rsp)
	movq	16544(%rsp), %rax
	movq	%rax, 109664(%rsp)
	movq	16552(%rsp), %rax
	movq	%rax, 109672(%rsp)
	movq	16560(%rsp), %rax
	movq	%rax, 109680(%rsp)
	movq	16568(%rsp), %rax
	movq	%rax, 109688(%rsp)
	movq	16576(%rsp), %rax
	movq	%rax, 109696(%rsp)
	movq	16584(%rsp), %rax
	movq	%rax, 109704(%rsp)
	movq	16592(%rsp), %rax
	movq	%rax, 109712(%rsp)
	movq	16600(%rsp), %rax
	movq	%rax, 109720(%rsp)
	movq	16608(%rsp), %rax
	movq	%rax, 109728(%rsp)
	movq	16616(%rsp), %rax
	movq	%rax, 109736(%rsp)
	movq	16624(%rsp), %rax
	movq	%rax, 109744(%rsp)
	movq	16632(%rsp), %rax
	movq	%rax, 109752(%rsp)
	movq	16640(%rsp), %rax
	movq	%rax, 109760(%rsp)
	movq	16648(%rsp), %rax
	movq	%rax, 109768(%rsp)
	movq	16656(%rsp), %rax
	movq	%rax, 109776(%rsp)
	movq	16664(%rsp), %rax
	movq	%rax, 109784(%rsp)
	movq	16672(%rsp), %rax
	movq	%rax, 109792(%rsp)
	movq	16680(%rsp), %rax
	movq	%rax, 109800(%rsp)
	movq	16688(%rsp), %rax
	movq	%rax, 109808(%rsp)
	movq	16696(%rsp), %rax
	movq	%rax, 109816(%rsp)
	movq	16704(%rsp), %rax
	movq	%rax, 109824(%rsp)
	movq	16712(%rsp), %rax
	movq	%rax, 109832(%rsp)
	movq	16720(%rsp), %rax
	movq	%rax, 109840(%rsp)
	movq	16728(%rsp), %rax
	movq	%rax, 109848(%rsp)
	movq	16736(%rsp), %rax
	movq	%rax, 109856(%rsp)
	movq	16744(%rsp), %rax
	movq	%rax, 109864(%rsp)
	movq	16752(%rsp), %rax
	movq	%rax, 109872(%rsp)
	movq	16760(%rsp), %rax
	movq	%rax, 109880(%rsp)
	movq	16768(%rsp), %rax
	movq	%rax, 109888(%rsp)
	movq	16776(%rsp), %rax
	movq	%rax, 109896(%rsp)
	movq	16784(%rsp), %rax
	movq	%rax, 109904(%rsp)
	movq	16792(%rsp), %rax
	movq	%rax, 109912(%rsp)
	movq	16800(%rsp), %rax
	movq	%rax, 109920(%rsp)
	movq	16808(%rsp), %rax
	movq	%rax, 109928(%rsp)
	movq	16816(%rsp), %rax
	movq	%rax, 109936(%rsp)
	movq	16824(%rsp), %rax
	movq	%rax, 109944(%rsp)
	movq	16832(%rsp), %rax
	movq	%rax, 109952(%rsp)
	movq	16840(%rsp), %rax
	movq	%rax, 109960(%rsp)
	movq	16848(%rsp), %rax
	movq	%rax, 109968(%rsp)
	movq	16856(%rsp), %rax
	movq	%rax, 109976(%rsp)
	movq	16864(%rsp), %rax
	movq	%rax, 109984(%rsp)
	movq	16872(%rsp), %rax
	movq	%rax, 109992(%rsp)
	movq	16880(%rsp), %rax
	movq	%rax, 110000(%rsp)
	movq	16888(%rsp), %rax
	movq	%rax, 110008(%rsp)
	movq	16896(%rsp), %rax
	movq	%rax, 110016(%rsp)
	movq	16904(%rsp), %rax
	movq	%rax, 110024(%rsp)
	movq	16912(%rsp), %rax
	movq	%rax, 110032(%rsp)
	movq	16920(%rsp), %rax
	movq	%rax, 110040(%rsp)
	movq	16928(%rsp), %rax
	movq	%rax, 110048(%rsp)
	movq	16936(%rsp), %rax
	movq	%rax, 110056(%rsp)
	movq	16944(%rsp), %rax
	movq	%rax, 110064(%rsp)
	movq	16952(%rsp), %rax
	movq	%rax, 110072(%rsp)
	movq	16960(%rsp), %rax
	movq	%rax, 110080(%rsp)
	movq	16968(%rsp), %rax
	movq	%rax, 110088(%rsp)
	movq	16976(%rsp), %rax
	movq	%rax, 110096(%rsp)
	movq	16984(%rsp), %rax
	movq	%rax, 110104(%rsp)
	movq	16992(%rsp), %rax
	movq	%rax, 110112(%rsp)
	movq	17000(%rsp), %rax
	movq	%rax, 110120(%rsp)
	movq	17008(%rsp), %rax
	movq	%rax, 110128(%rsp)
	movq	17016(%rsp), %rax
	movq	%rax, 110136(%rsp)
	movq	17024(%rsp), %rax
	movq	%rax, 110144(%rsp)
	movq	17032(%rsp), %rax
	movq	%rax, 110152(%rsp)
	movq	17040(%rsp), %rax
	movq	%rax, 110160(%rsp)
	movq	17048(%rsp), %rax
	movq	%rax, 110168(%rsp)
	movq	17056(%rsp), %rax
	movq	%rax, 110176(%rsp)
	movq	17064(%rsp), %rax
	movq	%rax, 110184(%rsp)
	movq	17072(%rsp), %rax
	movq	%rax, 110192(%rsp)
	movq	17080(%rsp), %rax
	movq	%rax, 110200(%rsp)
	movq	17088(%rsp), %rax
	movq	%rax, 110208(%rsp)
	movq	17096(%rsp), %rax
	movq	%rax, 110216(%rsp)
	movq	17104(%rsp), %rax
	movq	%rax, 110224(%rsp)
	movq	17112(%rsp), %rax
	movq	%rax, 110232(%rsp)
	movq	17120(%rsp), %rax
	movq	%rax, 110240(%rsp)
	movq	17128(%rsp), %rax
	movq	%rax, 110248(%rsp)
	movq	17136(%rsp), %rax
	movq	%rax, 110256(%rsp)
	movq	17144(%rsp), %rax
	movq	%rax, 110264(%rsp)
	movq	17152(%rsp), %rax
	movq	%rax, 110272(%rsp)
	movq	17160(%rsp), %rax
	movq	%rax, 110280(%rsp)
	movq	17168(%rsp), %rax
	movq	%rax, 110288(%rsp)
	movq	17176(%rsp), %rax
	movq	%rax, 110296(%rsp)
	movq	17184(%rsp), %rax
	movq	%rax, 110304(%rsp)
	movq	17192(%rsp), %rax
	movq	%rax, 110312(%rsp)
	movq	17200(%rsp), %rax
	movq	%rax, 110320(%rsp)
	movq	17208(%rsp), %rax
	movq	%rax, 110328(%rsp)
	movq	17216(%rsp), %rax
	movq	%rax, 110336(%rsp)
	movq	17224(%rsp), %rax
	movq	%rax, 110344(%rsp)
	movq	17232(%rsp), %rax
	movq	%rax, 110352(%rsp)
	movq	17240(%rsp), %rax
	movq	%rax, 110360(%rsp)
	movq	17248(%rsp), %rax
	movq	%rax, 110368(%rsp)
	movq	17256(%rsp), %rax
	movq	%rax, 110376(%rsp)
	movq	17264(%rsp), %rax
	movq	%rax, 110384(%rsp)
	movq	17272(%rsp), %rax
	movq	%rax, 110392(%rsp)
	movq	17280(%rsp), %rax
	movq	%rax, 110400(%rsp)
	movq	17288(%rsp), %rax
	movq	%rax, 110408(%rsp)
	movq	17296(%rsp), %rax
	movq	%rax, 110416(%rsp)
	movq	17304(%rsp), %rax
	movq	%rax, 110424(%rsp)
	movq	17312(%rsp), %rax
	movq	%rax, 110432(%rsp)
	movq	17320(%rsp), %rax
	movq	%rax, 110440(%rsp)
	movq	17328(%rsp), %rax
	movq	%rax, 110448(%rsp)
	movq	17336(%rsp), %rax
	movq	%rax, 110456(%rsp)
	movq	17344(%rsp), %rax
	movq	%rax, 110464(%rsp)
	movq	17352(%rsp), %rax
	movq	%rax, 110472(%rsp)
	movq	17360(%rsp), %rax
	movq	%rax, 110480(%rsp)
	movq	17368(%rsp), %rax
	movq	%rax, 110488(%rsp)
	movq	17376(%rsp), %rax
	movq	%rax, 110496(%rsp)
	movq	17384(%rsp), %rax
	movq	%rax, 110504(%rsp)
	movq	17392(%rsp), %rax
	movq	%rax, 110512(%rsp)
	movq	17400(%rsp), %rax
	movq	%rax, 110520(%rsp)
	movq	17408(%rsp), %rax
	movq	%rax, 110528(%rsp)
	movq	17416(%rsp), %rax
	movq	%rax, 110536(%rsp)
	movq	17424(%rsp), %rax
	movq	%rax, 110544(%rsp)
	movq	17432(%rsp), %rax
	movq	%rax, 110552(%rsp)
	movq	17440(%rsp), %rax
	movq	%rax, 110560(%rsp)
	movq	17448(%rsp), %rax
	movq	%rax, 110568(%rsp)
	movq	17456(%rsp), %rax
	movq	%rax, 110576(%rsp)
	movq	17464(%rsp), %rax
	movq	%rax, 110584(%rsp)
	movq	17472(%rsp), %rax
	movq	%rax, 110592(%rsp)
	movq	17480(%rsp), %rax
	movq	%rax, 110600(%rsp)
	movq	17488(%rsp), %rax
	movq	%rax, 110608(%rsp)
	movq	17496(%rsp), %rax
	movq	%rax, 110616(%rsp)
	movq	17504(%rsp), %rax
	movq	%rax, 110624(%rsp)
	movq	17512(%rsp), %rax
	movq	%rax, 110632(%rsp)
	movq	17520(%rsp), %rax
	movq	%rax, 110640(%rsp)
	movq	17528(%rsp), %rax
	movq	%rax, 110648(%rsp)
	movq	17536(%rsp), %rax
	movq	%rax, 110656(%rsp)
	movq	17544(%rsp), %rax
	movq	%rax, 110664(%rsp)
	movq	17552(%rsp), %rax
	movq	%rax, 110672(%rsp)
	movq	17560(%rsp), %rax
	movq	%rax, 110680(%rsp)
	movq	17568(%rsp), %rax
	movq	%rax, 110688(%rsp)
	movq	17576(%rsp), %rax
	movq	%rax, 110696(%rsp)
	movq	17584(%rsp), %rax
	movq	%rax, 110704(%rsp)
	movq	17592(%rsp), %rax
	movq	%rax, 110712(%rsp)
	movq	17600(%rsp), %rax
	movq	%rax, 110720(%rsp)
	movq	17608(%rsp), %rax
	movq	%rax, 110728(%rsp)
	movq	17616(%rsp), %rax
	movq	%rax, 110736(%rsp)
	movq	17624(%rsp), %rax
	movq	%rax, 110744(%rsp)
	movq	17632(%rsp), %rax
	movq	%rax, 110752(%rsp)
	movq	17640(%rsp), %rax
	movq	%rax, 110760(%rsp)
	movq	17648(%rsp), %rax
	movq	%rax, 110768(%rsp)
	movq	17656(%rsp), %rax
	movq	%rax, 110776(%rsp)
	movq	17664(%rsp), %rax
	movq	%rax, 110784(%rsp)
	movq	17672(%rsp), %rax
	movq	%rax, 110792(%rsp)
	movq	17680(%rsp), %rax
	movq	%rax, 110800(%rsp)
	movq	17688(%rsp), %rax
	movq	%rax, 110808(%rsp)
	movq	17696(%rsp), %rax
	movq	%rax, 110816(%rsp)
	movq	17704(%rsp), %rax
	movq	%rax, 110824(%rsp)
	movq	17712(%rsp), %rax
	movq	%rax, 110832(%rsp)
	movq	17720(%rsp), %rax
	movq	%rax, 110840(%rsp)
	movq	17728(%rsp), %rax
	movq	%rax, 110848(%rsp)
	movq	17736(%rsp), %rax
	movq	%rax, 110856(%rsp)
	movq	17744(%rsp), %rax
	movq	%rax, 110864(%rsp)
	movq	17752(%rsp), %rax
	movq	%rax, 110872(%rsp)
	movq	17760(%rsp), %rax
	movq	%rax, 110880(%rsp)
	movq	17768(%rsp), %rax
	movq	%rax, 110888(%rsp)
	movq	17776(%rsp), %rax
	movq	%rax, 110896(%rsp)
	movq	17784(%rsp), %rax
	movq	%rax, 110904(%rsp)
	movq	17792(%rsp), %rax
	movq	%rax, 110912(%rsp)
	movq	17800(%rsp), %rax
	movq	%rax, 110920(%rsp)
	movq	17808(%rsp), %rax
	movq	%rax, 110928(%rsp)
	movq	17816(%rsp), %rax
	movq	%rax, 110936(%rsp)
	movq	17824(%rsp), %rax
	movq	%rax, 110944(%rsp)
	movq	17832(%rsp), %rax
	movq	%rax, 110952(%rsp)
	movq	17840(%rsp), %rax
	movq	%rax, 110960(%rsp)
	movq	17848(%rsp), %rax
	movq	%rax, 110968(%rsp)
	movq	17856(%rsp), %rax
	movq	%rax, 110976(%rsp)
	movq	17864(%rsp), %rax
	movq	%rax, 110984(%rsp)
	movq	17872(%rsp), %rax
	movq	%rax, 110992(%rsp)
	movq	17880(%rsp), %rax
	movq	%rax, 111000(%rsp)
	movq	17888(%rsp), %rax
	movq	%rax, 111008(%rsp)
	movq	17896(%rsp), %rax
	movq	%rax, 111016(%rsp)
	movq	17904(%rsp), %rax
	movq	%rax, 111024(%rsp)
	movq	17912(%rsp), %rax
	movq	%rax, 111032(%rsp)
	movq	17920(%rsp), %rax
	movq	%rax, 111040(%rsp)
	movq	17928(%rsp), %rax
	movq	%rax, 111048(%rsp)
	movq	17936(%rsp), %rax
	movq	%rax, 111056(%rsp)
	movq	17944(%rsp), %rax
	movq	%rax, 111064(%rsp)
	movq	17952(%rsp), %rax
	movq	%rax, 111072(%rsp)
	movq	17960(%rsp), %rax
	movq	%rax, 111080(%rsp)
	movq	17968(%rsp), %rax
	movq	%rax, 111088(%rsp)
	movq	17976(%rsp), %rax
	movq	%rax, 111096(%rsp)
	movq	17984(%rsp), %rax
	movq	%rax, 111104(%rsp)
	movq	17992(%rsp), %rax
	movq	%rax, 111112(%rsp)
	movq	18000(%rsp), %rax
	movq	%rax, 111120(%rsp)
	movq	18008(%rsp), %rax
	movq	%rax, 111128(%rsp)
	movq	18016(%rsp), %rax
	movq	%rax, 111136(%rsp)
	movq	18024(%rsp), %rax
	movq	%rax, 111144(%rsp)
	movq	18032(%rsp), %rax
	movq	%rax, 111152(%rsp)
	movq	18040(%rsp), %rax
	movq	%rax, 111160(%rsp)
	movq	18048(%rsp), %rax
	movq	%rax, 111168(%rsp)
	movq	18056(%rsp), %rax
	movq	%rax, 111176(%rsp)
	movq	18064(%rsp), %rax
	movq	%rax, 111184(%rsp)
	movq	18072(%rsp), %rax
	movq	%rax, 111192(%rsp)
	movq	18080(%rsp), %rax
	movq	%rax, 111200(%rsp)
	movq	18088(%rsp), %rax
	movq	%rax, 111208(%rsp)
	movq	18096(%rsp), %rax
	movq	%rax, 111216(%rsp)
	movq	18104(%rsp), %rax
	movq	%rax, 111224(%rsp)
	movq	18112(%rsp), %rax
	movq	%rax, 111232(%rsp)
	movq	18120(%rsp), %rax
	movq	%rax, 111240(%rsp)
	movq	18128(%rsp), %rax
	movq	%rax, 111248(%rsp)
	movq	18136(%rsp), %rax
	movq	%rax, 111256(%rsp)
	movq	18144(%rsp), %rax
	movq	%rax, 111264(%rsp)
	movq	18152(%rsp), %rax
	movq	%rax, 111272(%rsp)
	movq	18160(%rsp), %rax
	movq	%rax, 111280(%rsp)
	movq	18168(%rsp), %rax
	movq	%rax, 111288(%rsp)
	movq	18176(%rsp), %rax
	movq	%rax, 111296(%rsp)
	movq	18184(%rsp), %rax
	movq	%rax, 111304(%rsp)
	movq	18192(%rsp), %rax
	movq	%rax, 111312(%rsp)
	movq	18200(%rsp), %rax
	movq	%rax, 111320(%rsp)
	movq	18208(%rsp), %rax
	movq	%rax, 111328(%rsp)
	movq	18216(%rsp), %rax
	movq	%rax, 111336(%rsp)
	movq	18224(%rsp), %rax
	movq	%rax, 111344(%rsp)
	movq	18232(%rsp), %rax
	movq	%rax, 111352(%rsp)
	movq	18240(%rsp), %rax
	movq	%rax, 111360(%rsp)
	movq	18248(%rsp), %rax
	movq	%rax, 111368(%rsp)
	movq	18256(%rsp), %rax
	movq	%rax, 111376(%rsp)
	movq	18264(%rsp), %rax
	movq	%rax, 111384(%rsp)
	movq	18272(%rsp), %rax
	movq	%rax, 111392(%rsp)
	movq	18280(%rsp), %rax
	movq	%rax, 111400(%rsp)
	movq	18288(%rsp), %rax
	movq	%rax, 111408(%rsp)
	movq	18296(%rsp), %rax
	movq	%rax, 111416(%rsp)
	movq	18304(%rsp), %rax
	movq	%rax, 111424(%rsp)
	movq	18312(%rsp), %rax
	movq	%rax, 111432(%rsp)
	movq	18320(%rsp), %rax
	movq	%rax, 111440(%rsp)
	movq	18328(%rsp), %rax
	movq	%rax, 111448(%rsp)
	movq	18336(%rsp), %rax
	movq	%rax, 111456(%rsp)
	movq	18344(%rsp), %rax
	movq	%rax, 111464(%rsp)
	movq	18352(%rsp), %rax
	movq	%rax, 111472(%rsp)
	movq	18360(%rsp), %rax
	movq	%rax, 111480(%rsp)
	movq	18368(%rsp), %rax
	movq	%rax, 111488(%rsp)
	movq	18376(%rsp), %rax
	movq	%rax, 111496(%rsp)
	movq	18384(%rsp), %rax
	movq	%rax, 111504(%rsp)
	movq	18392(%rsp), %rax
	movq	%rax, 111512(%rsp)
	movq	18400(%rsp), %rax
	movq	%rax, 111520(%rsp)
	movq	18408(%rsp), %rax
	movq	%rax, 111528(%rsp)
	movq	18416(%rsp), %rax
	movq	%rax, 111536(%rsp)
	movq	18424(%rsp), %rax
	movq	%rax, 111544(%rsp)
	movq	18432(%rsp), %rax
	movq	%rax, 111552(%rsp)
	movq	18440(%rsp), %rax
	movq	%rax, 111560(%rsp)
	movq	18448(%rsp), %rax
	movq	%rax, 111568(%rsp)
	movq	18456(%rsp), %rax
	movq	%rax, 111576(%rsp)
	movq	18464(%rsp), %rax
	movq	%rax, 111584(%rsp)
	movq	18472(%rsp), %rax
	movq	%rax, 111592(%rsp)
	movq	18480(%rsp), %rax
	movq	%rax, 111600(%rsp)
	movq	18488(%rsp), %rax
	movq	%rax, 111608(%rsp)
	movq	18496(%rsp), %rax
	movq	%rax, 111616(%rsp)
	movq	18504(%rsp), %rax
	movq	%rax, 111624(%rsp)
	movq	18512(%rsp), %rax
	movq	%rax, 111632(%rsp)
	movq	18520(%rsp), %rax
	movq	%rax, 111640(%rsp)
	movq	18528(%rsp), %rax
	movq	%rax, 111648(%rsp)
	movq	18536(%rsp), %rax
	movq	%rax, 111656(%rsp)
	movq	18544(%rsp), %rax
	movq	%rax, 111664(%rsp)
	movq	18552(%rsp), %rax
	movq	%rax, 111672(%rsp)
	movq	18560(%rsp), %rax
	movq	%rax, 111680(%rsp)
	movq	18568(%rsp), %rax
	movq	%rax, 111688(%rsp)
	movq	18576(%rsp), %rax
	movq	%rax, 111696(%rsp)
	movq	18584(%rsp), %rax
	movq	%rax, 111704(%rsp)
	movq	18592(%rsp), %rax
	movq	%rax, 111712(%rsp)
	movq	18600(%rsp), %rax
	movq	%rax, 111720(%rsp)
	movq	18608(%rsp), %rax
	movq	%rax, 111728(%rsp)
	movq	18616(%rsp), %rax
	movq	%rax, 111736(%rsp)
	movq	18624(%rsp), %rax
	movq	%rax, 111744(%rsp)
	movq	18632(%rsp), %rax
	movq	%rax, 111752(%rsp)
	movq	18640(%rsp), %rax
	movq	%rax, 111760(%rsp)
	movq	18648(%rsp), %rax
	movq	%rax, 111768(%rsp)
	movq	18656(%rsp), %rax
	movq	%rax, 111776(%rsp)
	movq	18664(%rsp), %rax
	movq	%rax, 111784(%rsp)
	movq	18672(%rsp), %rax
	movq	%rax, 111792(%rsp)
	movq	18680(%rsp), %rax
	movq	%rax, 111800(%rsp)
	movq	18688(%rsp), %rax
	movq	%rax, 111808(%rsp)
	movq	18696(%rsp), %rax
	movq	%rax, 111816(%rsp)
	movq	18704(%rsp), %rax
	movq	%rax, 111824(%rsp)
	movq	18712(%rsp), %rax
	movq	%rax, 111832(%rsp)
	movq	18720(%rsp), %rax
	movq	%rax, 111840(%rsp)
	movq	18728(%rsp), %rax
	movq	%rax, 111848(%rsp)
	movq	18736(%rsp), %rax
	movq	%rax, 111856(%rsp)
	movq	18744(%rsp), %rax
	movq	%rax, 111864(%rsp)
	movq	18752(%rsp), %rax
	movq	%rax, 111872(%rsp)
	movq	18760(%rsp), %rax
	movq	%rax, 111880(%rsp)
	movq	18768(%rsp), %rax
	movq	%rax, 111888(%rsp)
	movq	18776(%rsp), %rax
	movq	%rax, 111896(%rsp)
	movq	18784(%rsp), %rax
	movq	%rax, 111904(%rsp)
	movq	18792(%rsp), %rax
	movq	%rax, 111912(%rsp)
	movq	18800(%rsp), %rax
	movq	%rax, 111920(%rsp)
	movq	18808(%rsp), %rax
	movq	%rax, 111928(%rsp)
	movq	18816(%rsp), %rax
	movq	%rax, 111936(%rsp)
	movq	18824(%rsp), %rax
	movq	%rax, 111944(%rsp)
	movq	18832(%rsp), %rax
	movq	%rax, 111952(%rsp)
	movq	18840(%rsp), %rax
	movq	%rax, 111960(%rsp)
	movq	18848(%rsp), %rax
	movq	%rax, 111968(%rsp)
	movq	18856(%rsp), %rax
	movq	%rax, 111976(%rsp)
	movq	18864(%rsp), %rax
	movq	%rax, 111984(%rsp)
	movq	18872(%rsp), %rax
	movq	%rax, 111992(%rsp)
	movq	18880(%rsp), %rax
	movq	%rax, 112000(%rsp)
	movq	18888(%rsp), %rax
	movq	%rax, 112008(%rsp)
	movq	18896(%rsp), %rax
	movq	%rax, 112016(%rsp)
	movq	18904(%rsp), %rax
	movq	%rax, 112024(%rsp)
	movq	18912(%rsp), %rax
	movq	%rax, 112032(%rsp)
	movq	18920(%rsp), %rax
	movq	%rax, 112040(%rsp)
	movq	18928(%rsp), %rax
	movq	%rax, 112048(%rsp)
	movq	18936(%rsp), %rax
	movq	%rax, 112056(%rsp)
	movq	18944(%rsp), %rax
	movq	%rax, 112064(%rsp)
	movq	18952(%rsp), %rax
	movq	%rax, 112072(%rsp)
	movq	18960(%rsp), %rax
	movq	%rax, 112080(%rsp)
	movq	18968(%rsp), %rax
	movq	%rax, 112088(%rsp)
	movq	18976(%rsp), %rax
	movq	%rax, 112096(%rsp)
	movq	18984(%rsp), %rax
	movq	%rax, 112104(%rsp)
	movq	18992(%rsp), %rax
	movq	%rax, 112112(%rsp)
	movq	19000(%rsp), %rax
	movq	%rax, 112120(%rsp)
	movq	19008(%rsp), %rax
	movq	%rax, 112128(%rsp)
	movq	19016(%rsp), %rax
	movq	%rax, 112136(%rsp)
	movq	19024(%rsp), %rax
	movq	%rax, 112144(%rsp)
	movq	19032(%rsp), %rax
	movq	%rax, 112152(%rsp)
	movq	19040(%rsp), %rax
	movq	%rax, 112160(%rsp)
	movq	19048(%rsp), %rax
	movq	%rax, 112168(%rsp)
	movq	19056(%rsp), %rax
	movq	%rax, 112176(%rsp)
	movq	19064(%rsp), %rax
	movq	%rax, 112184(%rsp)
	movq	19072(%rsp), %rax
	movq	%rax, 112192(%rsp)
	movq	19080(%rsp), %rax
	movq	%rax, 112200(%rsp)
	movq	19088(%rsp), %rax
	movq	%rax, 112208(%rsp)
	movq	19096(%rsp), %rax
	movq	%rax, 112216(%rsp)
	movq	19104(%rsp), %rax
	movq	%rax, 112224(%rsp)
	movq	19112(%rsp), %rax
	movq	%rax, 112232(%rsp)
	movq	19120(%rsp), %rax
	movq	%rax, 112240(%rsp)
	movq	19128(%rsp), %rax
	movq	%rax, 112248(%rsp)
	movq	19136(%rsp), %rax
	movq	%rax, 112256(%rsp)
	movq	19144(%rsp), %rax
	movq	%rax, 112264(%rsp)
	movq	19152(%rsp), %rax
	movq	%rax, 112272(%rsp)
	movq	19160(%rsp), %rax
	movq	%rax, 112280(%rsp)
	movq	19168(%rsp), %rax
	movq	%rax, 112288(%rsp)
	movq	19176(%rsp), %rax
	movq	%rax, 112296(%rsp)
	movq	19184(%rsp), %rax
	movq	%rax, 112304(%rsp)
	movq	19192(%rsp), %rax
	movq	%rax, 112312(%rsp)
	movq	19200(%rsp), %rax
	movq	%rax, 112320(%rsp)
	movq	19208(%rsp), %rax
	movq	%rax, 112328(%rsp)
	movq	19216(%rsp), %rax
	movq	%rax, 112336(%rsp)
	movq	19224(%rsp), %rax
	movq	%rax, 112344(%rsp)
	movq	19232(%rsp), %rax
	movq	%rax, 112352(%rsp)
	movq	19240(%rsp), %rax
	movq	%rax, 112360(%rsp)
	movq	19248(%rsp), %rax
	movq	%rax, 112368(%rsp)
	movq	19256(%rsp), %rax
	movq	%rax, 112376(%rsp)
	movq	19264(%rsp), %rax
	movq	%rax, 112384(%rsp)
	movq	19272(%rsp), %rax
	movq	%rax, 112392(%rsp)
	movq	19280(%rsp), %rax
	movq	%rax, 112400(%rsp)
	movq	19288(%rsp), %rax
	movq	%rax, 112408(%rsp)
	movq	19296(%rsp), %rax
	movq	%rax, 112416(%rsp)
	movq	19304(%rsp), %rax
	movq	%rax, 112424(%rsp)
	movq	19312(%rsp), %rax
	movq	%rax, 112432(%rsp)
	movq	19320(%rsp), %rax
	movq	%rax, 112440(%rsp)
	movq	19328(%rsp), %rax
	movq	%rax, 112448(%rsp)
	movq	19336(%rsp), %rax
	movq	%rax, 112456(%rsp)
	movq	19344(%rsp), %rax
	movq	%rax, 112464(%rsp)
	movq	19352(%rsp), %rax
	movq	%rax, 112472(%rsp)
	movq	19360(%rsp), %rax
	movq	%rax, 112480(%rsp)
	movq	19368(%rsp), %rax
	movq	%rax, 112488(%rsp)
	movq	19376(%rsp), %rax
	movq	%rax, 112496(%rsp)
	movq	19384(%rsp), %rax
	movq	%rax, 112504(%rsp)
	movq	19392(%rsp), %rax
	movq	%rax, 112512(%rsp)
	movq	19400(%rsp), %rax
	movq	%rax, 112520(%rsp)
	movq	19408(%rsp), %rax
	movq	%rax, 112528(%rsp)
	movq	19416(%rsp), %rax
	movq	%rax, 112536(%rsp)
	movq	19424(%rsp), %rax
	movq	%rax, 112544(%rsp)
	movq	19432(%rsp), %rax
	movq	%rax, 112552(%rsp)
	movq	19440(%rsp), %rax
	movq	%rax, 112560(%rsp)
	movq	19448(%rsp), %rax
	movq	%rax, 112568(%rsp)
	movq	19456(%rsp), %rax
	movq	%rax, 112576(%rsp)
	movq	19464(%rsp), %rax
	movq	%rax, 112584(%rsp)
	movq	19472(%rsp), %rax
	movq	%rax, 112592(%rsp)
	movq	19480(%rsp), %rax
	movq	%rax, 112600(%rsp)
	movq	19488(%rsp), %rax
	movq	%rax, 112608(%rsp)
	movq	19496(%rsp), %rax
	movq	%rax, 112616(%rsp)
	movq	19504(%rsp), %rax
	movq	%rax, 112624(%rsp)
	movq	19512(%rsp), %rax
	movq	%rax, 112632(%rsp)
	movq	19520(%rsp), %rax
	movq	%rax, 112640(%rsp)
	movq	19528(%rsp), %rax
	movq	%rax, 112648(%rsp)
	movq	19536(%rsp), %rax
	movq	%rax, 112656(%rsp)
	movq	19544(%rsp), %rax
	movq	%rax, 112664(%rsp)
	movq	19552(%rsp), %rax
	movq	%rax, 112672(%rsp)
	movq	19560(%rsp), %rax
	movq	%rax, 112680(%rsp)
	movq	19568(%rsp), %rax
	movq	%rax, 112688(%rsp)
	movq	19576(%rsp), %rax
	movq	%rax, 112696(%rsp)
	movq	19584(%rsp), %rax
	movq	%rax, 112704(%rsp)
	movq	19592(%rsp), %rax
	movq	%rax, 112712(%rsp)
	movq	19600(%rsp), %rax
	movq	%rax, 112720(%rsp)
	movq	19608(%rsp), %rax
	movq	%rax, 112728(%rsp)
	movq	19616(%rsp), %rax
	movq	%rax, 112736(%rsp)
	movq	19624(%rsp), %rax
	movq	%rax, 112744(%rsp)
	movq	19632(%rsp), %rax
	movq	%rax, 112752(%rsp)
	movq	19640(%rsp), %rax
	movq	%rax, 112760(%rsp)
	movq	19648(%rsp), %rax
	movq	%rax, 112768(%rsp)
	movq	19656(%rsp), %rax
	movq	%rax, 112776(%rsp)
	movq	19664(%rsp), %rax
	movq	%rax, 112784(%rsp)
	movq	19672(%rsp), %rax
	movq	%rax, 112792(%rsp)
	movq	19680(%rsp), %rax
	movq	%rax, 112800(%rsp)
	movq	19688(%rsp), %rax
	movq	%rax, 112808(%rsp)
	movq	19696(%rsp), %rax
	movq	%rax, 112816(%rsp)
	movq	19704(%rsp), %rax
	movq	%rax, 112824(%rsp)
	movq	19712(%rsp), %rax
	movq	%rax, 112832(%rsp)
	movq	19720(%rsp), %rax
	movq	%rax, 112840(%rsp)
	movq	19728(%rsp), %rax
	movq	%rax, 112848(%rsp)
	movq	19736(%rsp), %rax
	movq	%rax, 112856(%rsp)
	movq	19744(%rsp), %rax
	movq	%rax, 112864(%rsp)
	movq	19752(%rsp), %rax
	movq	%rax, 112872(%rsp)
	movq	19760(%rsp), %rax
	movq	%rax, 112880(%rsp)
	movq	19768(%rsp), %rax
	movq	%rax, 112888(%rsp)
	movq	19776(%rsp), %rax
	movq	%rax, 112896(%rsp)
	movq	19784(%rsp), %rax
	movq	%rax, 112904(%rsp)
	movq	19792(%rsp), %rax
	movq	%rax, 112912(%rsp)
	movq	19800(%rsp), %rax
	movq	%rax, 112920(%rsp)
	movq	19808(%rsp), %rax
	movq	%rax, 112928(%rsp)
	movq	19816(%rsp), %rax
	movq	%rax, 112936(%rsp)
	movq	19824(%rsp), %rax
	movq	%rax, 112944(%rsp)
	movq	19832(%rsp), %rax
	movq	%rax, 112952(%rsp)
	movq	19840(%rsp), %rax
	movq	%rax, 112960(%rsp)
	movq	19848(%rsp), %rax
	movq	%rax, 112968(%rsp)
	movq	19856(%rsp), %rax
	movq	%rax, 112976(%rsp)
	movq	19864(%rsp), %rax
	movq	%rax, 112984(%rsp)
	movq	19872(%rsp), %rax
	movq	%rax, 112992(%rsp)
	movq	19880(%rsp), %rax
	movq	%rax, 113000(%rsp)
	movq	19888(%rsp), %rax
	movq	%rax, 113008(%rsp)
	movq	19896(%rsp), %rax
	movq	%rax, 113016(%rsp)
	movq	19904(%rsp), %rax
	movq	%rax, 113024(%rsp)
	movq	19912(%rsp), %rax
	movq	%rax, 113032(%rsp)
	movq	19920(%rsp), %rax
	movq	%rax, 113040(%rsp)
	movq	19928(%rsp), %rax
	movq	%rax, 113048(%rsp)
	movq	19936(%rsp), %rax
	movq	%rax, 113056(%rsp)
	movq	19944(%rsp), %rax
	movq	%rax, 113064(%rsp)
	movq	19952(%rsp), %rax
	movq	%rax, 113072(%rsp)
	movq	19960(%rsp), %rax
	movq	%rax, 113080(%rsp)
	movq	19968(%rsp), %rax
	movq	%rax, 113088(%rsp)
	movq	19976(%rsp), %rax
	movq	%rax, 113096(%rsp)
	movq	19984(%rsp), %rax
	movq	%rax, 113104(%rsp)
	movq	19992(%rsp), %rax
	movq	%rax, 113112(%rsp)
	movq	20000(%rsp), %rax
	movq	%rax, 113120(%rsp)
	movq	20008(%rsp), %rax
	movq	%rax, 113128(%rsp)
	movq	20016(%rsp), %rax
	movq	%rax, 113136(%rsp)
	movq	20024(%rsp), %rax
	movq	%rax, 113144(%rsp)
	movq	20032(%rsp), %rax
	movq	%rax, 113152(%rsp)
	movq	20040(%rsp), %rax
	movq	%rax, 113160(%rsp)
	movq	20048(%rsp), %rax
	movq	%rax, 113168(%rsp)
	movq	20056(%rsp), %rax
	movq	%rax, 113176(%rsp)
	movq	20064(%rsp), %rax
	movq	%rax, 113184(%rsp)
	movq	20072(%rsp), %rax
	movq	%rax, 113192(%rsp)
	movq	20080(%rsp), %rax
	movq	%rax, 113200(%rsp)
	movq	20088(%rsp), %rax
	movq	%rax, 113208(%rsp)
	movq	20096(%rsp), %rax
	movq	%rax, 113216(%rsp)
	movq	20104(%rsp), %rax
	movq	%rax, 113224(%rsp)
	movq	20112(%rsp), %rax
	movq	%rax, 113232(%rsp)
	movq	20120(%rsp), %rax
	movq	%rax, 113240(%rsp)
	movq	20128(%rsp), %rax
	movq	%rax, 113248(%rsp)
	movq	20136(%rsp), %rax
	movq	%rax, 113256(%rsp)
	movq	20144(%rsp), %rax
	movq	%rax, 113264(%rsp)
	movq	20152(%rsp), %rax
	movq	%rax, 113272(%rsp)
	movq	20160(%rsp), %rax
	movq	%rax, 113280(%rsp)
	movq	20168(%rsp), %rax
	movq	%rax, 113288(%rsp)
	movq	20176(%rsp), %rax
	movq	%rax, 113296(%rsp)
	movq	20184(%rsp), %rax
	movq	%rax, 113304(%rsp)
	movq	20192(%rsp), %rax
	movq	%rax, 113312(%rsp)
	movq	20200(%rsp), %rax
	movq	%rax, 113320(%rsp)
	movq	20208(%rsp), %rax
	movq	%rax, 113328(%rsp)
	movq	20216(%rsp), %rax
	movq	%rax, 113336(%rsp)
	movq	20224(%rsp), %rax
	movq	%rax, 113344(%rsp)
	movq	20232(%rsp), %rax
	movq	%rax, 113352(%rsp)
	movq	20240(%rsp), %rax
	movq	%rax, 113360(%rsp)
	movq	20248(%rsp), %rax
	movq	%rax, 113368(%rsp)
	movq	20256(%rsp), %rax
	movq	%rax, 113376(%rsp)
	movq	20264(%rsp), %rax
	movq	%rax, 113384(%rsp)
	movq	20272(%rsp), %rax
	movq	%rax, 113392(%rsp)
	movq	20280(%rsp), %rax
	movq	%rax, 113400(%rsp)
	movq	20288(%rsp), %rax
	movq	%rax, 113408(%rsp)
	movq	20296(%rsp), %rax
	movq	%rax, 113416(%rsp)
	movq	20304(%rsp), %rax
	movq	%rax, 113424(%rsp)
	movq	20312(%rsp), %rax
	movq	%rax, 113432(%rsp)
	movq	20320(%rsp), %rax
	movq	%rax, 113440(%rsp)
	movq	20328(%rsp), %rax
	movq	%rax, 113448(%rsp)
	movq	20336(%rsp), %rax
	movq	%rax, 113456(%rsp)
	movq	20344(%rsp), %rax
	movq	%rax, 113464(%rsp)
	movq	20352(%rsp), %rax
	movq	%rax, 113472(%rsp)
	movq	20360(%rsp), %rax
	movq	%rax, 113480(%rsp)
	movq	20368(%rsp), %rax
	movq	%rax, 113488(%rsp)
	movq	20376(%rsp), %rax
	movq	%rax, 113496(%rsp)
	movq	20384(%rsp), %rax
	movq	%rax, 113504(%rsp)
	movq	20392(%rsp), %rax
	movq	%rax, 113512(%rsp)
	movq	20400(%rsp), %rax
	movq	%rax, 113520(%rsp)
	movq	20408(%rsp), %rax
	movq	%rax, 113528(%rsp)
	movq	20416(%rsp), %rax
	movq	%rax, 113536(%rsp)
	movq	20424(%rsp), %rax
	movq	%rax, 113544(%rsp)
	movq	20432(%rsp), %rax
	movq	%rax, 113552(%rsp)
	movq	20440(%rsp), %rax
	movq	%rax, 113560(%rsp)
	movq	20448(%rsp), %rax
	movq	%rax, 113568(%rsp)
	movq	20456(%rsp), %rax
	movq	%rax, 113576(%rsp)
	movq	20464(%rsp), %rax
	movq	%rax, 113584(%rsp)
	movq	20472(%rsp), %rax
	movq	%rax, 113592(%rsp)
	movq	20480(%rsp), %rax
	movq	%rax, 113600(%rsp)
	movq	20488(%rsp), %rax
	movq	%rax, 113608(%rsp)
	movq	20496(%rsp), %rax
	movq	%rax, 113616(%rsp)
	movq	20504(%rsp), %rax
	movq	%rax, 113624(%rsp)
	movq	20512(%rsp), %rax
	movq	%rax, 113632(%rsp)
	movq	20520(%rsp), %rax
	movq	%rax, 113640(%rsp)
	movq	20528(%rsp), %rax
	movq	%rax, 113648(%rsp)
	movq	20536(%rsp), %rax
	movq	%rax, 113656(%rsp)
	movq	20544(%rsp), %rax
	movq	%rax, 113664(%rsp)
	movq	20552(%rsp), %rax
	movq	%rax, 113672(%rsp)
	movq	20560(%rsp), %rax
	movq	%rax, 113680(%rsp)
	movq	20568(%rsp), %rax
	movq	%rax, 113688(%rsp)
	movq	20576(%rsp), %rax
	movq	%rax, 113696(%rsp)
	movq	20584(%rsp), %rax
	movq	%rax, 113704(%rsp)
	movq	20592(%rsp), %rax
	movq	%rax, 113712(%rsp)
	movq	20600(%rsp), %rax
	movq	%rax, 113720(%rsp)
	movq	20608(%rsp), %rax
	movq	%rax, 113728(%rsp)
	movq	20616(%rsp), %rax
	movq	%rax, 113736(%rsp)
	movq	20624(%rsp), %rax
	movq	%rax, 113744(%rsp)
	movq	20632(%rsp), %rax
	movq	%rax, 113752(%rsp)
	movq	20640(%rsp), %rax
	movq	%rax, 113760(%rsp)
	movq	20648(%rsp), %rax
	movq	%rax, 113768(%rsp)
	movq	20656(%rsp), %rax
	movq	%rax, 113776(%rsp)
	movq	20664(%rsp), %rax
	movq	%rax, 113784(%rsp)
	movq	20672(%rsp), %rax
	movq	%rax, 113792(%rsp)
	movq	20680(%rsp), %rax
	movq	%rax, 113800(%rsp)
	movq	20688(%rsp), %rax
	movq	%rax, 113808(%rsp)
	movq	20696(%rsp), %rax
	movq	%rax, 113816(%rsp)
	movq	20704(%rsp), %rax
	movq	%rax, 113824(%rsp)
	movq	20712(%rsp), %rax
	movq	%rax, 113832(%rsp)
	movq	20720(%rsp), %rax
	movq	%rax, 113840(%rsp)
	movq	20728(%rsp), %rax
	movq	%rax, 113848(%rsp)
	movq	20736(%rsp), %rax
	movq	%rax, 113856(%rsp)
	movq	20744(%rsp), %rax
	movq	%rax, 113864(%rsp)
	movq	20752(%rsp), %rax
	movq	%rax, 113872(%rsp)
	movq	20760(%rsp), %rax
	movq	%rax, 113880(%rsp)
	movq	20768(%rsp), %rax
	movq	%rax, 113888(%rsp)
	movq	20776(%rsp), %rax
	movq	%rax, 113896(%rsp)
	movq	20784(%rsp), %rax
	movq	%rax, 113904(%rsp)
	movq	20792(%rsp), %rax
	movq	%rax, 113912(%rsp)
	movq	20800(%rsp), %rax
	movq	%rax, 113920(%rsp)
	movq	20808(%rsp), %rax
	movq	%rax, 113928(%rsp)
	movq	20816(%rsp), %rax
	movq	%rax, 113936(%rsp)
	movq	20824(%rsp), %rax
	movq	%rax, 113944(%rsp)
	movq	20832(%rsp), %rax
	movq	%rax, 113952(%rsp)
	movq	20840(%rsp), %rax
	movq	%rax, 113960(%rsp)
	movq	20848(%rsp), %rax
	movq	%rax, 113968(%rsp)
	movq	20856(%rsp), %rax
	movq	%rax, 113976(%rsp)
	movq	20864(%rsp), %rax
	movq	%rax, 113984(%rsp)
	movq	20872(%rsp), %rax
	movq	%rax, 113992(%rsp)
	movq	20880(%rsp), %rax
	movq	%rax, 114000(%rsp)
	movq	20888(%rsp), %rax
	movq	%rax, 114008(%rsp)
	movq	20896(%rsp), %rax
	movq	%rax, 114016(%rsp)
	movq	20904(%rsp), %rax
	movq	%rax, 114024(%rsp)
	movq	20912(%rsp), %rax
	movq	%rax, 114032(%rsp)
	movq	20920(%rsp), %rax
	movq	%rax, 114040(%rsp)
	movq	20928(%rsp), %rax
	movq	%rax, 114048(%rsp)
	movq	20936(%rsp), %rax
	movq	%rax, 114056(%rsp)
	movq	20944(%rsp), %rax
	movq	%rax, 114064(%rsp)
	movq	20952(%rsp), %rax
	movq	%rax, 114072(%rsp)
	movq	20960(%rsp), %rax
	movq	%rax, 114080(%rsp)
	movq	20968(%rsp), %rax
	movq	%rax, 114088(%rsp)
	movq	20976(%rsp), %rax
	movq	%rax, 114096(%rsp)
	movq	20984(%rsp), %rax
	movq	%rax, 114104(%rsp)
	movq	20992(%rsp), %rax
	movq	%rax, 114112(%rsp)
	movq	21000(%rsp), %rax
	movq	%rax, 114120(%rsp)
	movq	21008(%rsp), %rax
	movq	%rax, 114128(%rsp)
	movq	21016(%rsp), %rax
	movq	%rax, 114136(%rsp)
	movq	21024(%rsp), %rax
	movq	%rax, 114144(%rsp)
	movq	21032(%rsp), %rax
	movq	%rax, 114152(%rsp)
	movq	21040(%rsp), %rax
	movq	%rax, 114160(%rsp)
	movq	21048(%rsp), %rax
	movq	%rax, 114168(%rsp)
	movq	21056(%rsp), %rax
	movq	%rax, 114176(%rsp)
	movq	21064(%rsp), %rax
	movq	%rax, 114184(%rsp)
	movq	21072(%rsp), %rax
	movq	%rax, 114192(%rsp)
	movq	21080(%rsp), %rax
	movq	%rax, 114200(%rsp)
	movq	21088(%rsp), %rax
	movq	%rax, 114208(%rsp)
	movq	21096(%rsp), %rax
	movq	%rax, 114216(%rsp)
	movq	21104(%rsp), %rax
	movq	%rax, 114224(%rsp)
	movq	21112(%rsp), %rax
	movq	%rax, 114232(%rsp)
	movq	21120(%rsp), %rax
	movq	%rax, 114240(%rsp)
	movq	21128(%rsp), %rax
	movq	%rax, 114248(%rsp)
	movq	21136(%rsp), %rax
	movq	%rax, 114256(%rsp)
	movq	21144(%rsp), %rax
	movq	%rax, 114264(%rsp)
	movq	21152(%rsp), %rax
	movq	%rax, 114272(%rsp)
	movq	21160(%rsp), %rax
	movq	%rax, 114280(%rsp)
	movq	21168(%rsp), %rax
	movq	%rax, 114288(%rsp)
	movq	21176(%rsp), %rax
	movq	%rax, 114296(%rsp)
	movq	21184(%rsp), %rax
	movq	%rax, 114304(%rsp)
	movq	21192(%rsp), %rax
	movq	%rax, 114312(%rsp)
	movq	21200(%rsp), %rax
	movq	%rax, 114320(%rsp)
	movq	21208(%rsp), %rax
	movq	%rax, 114328(%rsp)
	movq	21216(%rsp), %rax
	movq	%rax, 114336(%rsp)
	movq	21224(%rsp), %rax
	movq	%rax, 114344(%rsp)
	movq	21232(%rsp), %rax
	movq	%rax, 114352(%rsp)
	movq	21240(%rsp), %rax
	movq	%rax, 114360(%rsp)
	movq	21248(%rsp), %rax
	movq	%rax, 114368(%rsp)
	movq	21256(%rsp), %rax
	movq	%rax, 114376(%rsp)
	movq	21264(%rsp), %rax
	movq	%rax, 114384(%rsp)
	movq	21272(%rsp), %rax
	movq	%rax, 114392(%rsp)
	movq	21280(%rsp), %rax
	movq	%rax, 114400(%rsp)
	movq	21288(%rsp), %rax
	movq	%rax, 114408(%rsp)
	movq	21296(%rsp), %rax
	movq	%rax, 114416(%rsp)
	movq	21304(%rsp), %rax
	movq	%rax, 114424(%rsp)
	movq	21312(%rsp), %rax
	movq	%rax, 114432(%rsp)
	movq	21320(%rsp), %rax
	movq	%rax, 114440(%rsp)
	movq	21328(%rsp), %rax
	movq	%rax, 114448(%rsp)
	movq	21336(%rsp), %rax
	movq	%rax, 114456(%rsp)
	movq	21344(%rsp), %rax
	movq	%rax, 114464(%rsp)
	movq	21352(%rsp), %rax
	movq	%rax, 114472(%rsp)
	movq	21360(%rsp), %rax
	movq	%rax, 114480(%rsp)
	movq	21368(%rsp), %rax
	movq	%rax, 114488(%rsp)
	movq	21376(%rsp), %rax
	movq	%rax, 114496(%rsp)
	movq	21384(%rsp), %rax
	movq	%rax, 114504(%rsp)
	movq	21392(%rsp), %rax
	movq	%rax, 114512(%rsp)
	movq	21400(%rsp), %rax
	movq	%rax, 114520(%rsp)
	movq	21408(%rsp), %rax
	movq	%rax, 114528(%rsp)
	movq	21416(%rsp), %rax
	movq	%rax, 114536(%rsp)
	movq	21424(%rsp), %rax
	movq	%rax, 114544(%rsp)
	movq	21432(%rsp), %rax
	movq	%rax, 114552(%rsp)
	movq	21440(%rsp), %rax
	movq	%rax, 114560(%rsp)
	movq	21448(%rsp), %rax
	movq	%rax, 114568(%rsp)
	movq	21456(%rsp), %rax
	movq	%rax, 114576(%rsp)
	movq	21464(%rsp), %rax
	movq	%rax, 114584(%rsp)
	movq	21472(%rsp), %rax
	movq	%rax, 114592(%rsp)
	movq	21480(%rsp), %rax
	movq	%rax, 114600(%rsp)
	movq	21488(%rsp), %rax
	movq	%rax, 114608(%rsp)
	movq	21496(%rsp), %rax
	movq	%rax, 114616(%rsp)
	movq	21504(%rsp), %rax
	movq	%rax, 114624(%rsp)
	movq	21512(%rsp), %rax
	movq	%rax, 114632(%rsp)
	movq	21520(%rsp), %rax
	movq	%rax, 114640(%rsp)
	movq	21528(%rsp), %rax
	movq	%rax, 114648(%rsp)
	movq	21536(%rsp), %rax
	movq	%rax, 114656(%rsp)
	movq	21544(%rsp), %rax
	movq	%rax, 114664(%rsp)
	movq	21552(%rsp), %rax
	movq	%rax, 114672(%rsp)
	movq	21560(%rsp), %rax
	movq	%rax, 114680(%rsp)
	movq	21568(%rsp), %rax
	movq	%rax, 114688(%rsp)
	movq	21576(%rsp), %rax
	movq	%rax, 114696(%rsp)
	movq	21584(%rsp), %rax
	movq	%rax, 114704(%rsp)
	movq	21592(%rsp), %rax
	movq	%rax, 114712(%rsp)
	movq	21600(%rsp), %rax
	movq	%rax, 114720(%rsp)
	movq	21608(%rsp), %rax
	movq	%rax, 114728(%rsp)
	movq	21616(%rsp), %rax
	movq	%rax, 114736(%rsp)
	movq	21624(%rsp), %rax
	movq	%rax, 114744(%rsp)
	movq	21632(%rsp), %rax
	movq	%rax, 114752(%rsp)
	movq	21640(%rsp), %rax
	movq	%rax, 114760(%rsp)
	movq	21648(%rsp), %rax
	movq	%rax, 114768(%rsp)
	movq	21656(%rsp), %rax
	movq	%rax, 114776(%rsp)
	movq	21664(%rsp), %rax
	movq	%rax, 114784(%rsp)
	movq	21672(%rsp), %rax
	movq	%rax, 114792(%rsp)
	movq	21680(%rsp), %rax
	movq	%rax, 114800(%rsp)
	movq	21688(%rsp), %rax
	movq	%rax, 114808(%rsp)
	movq	21696(%rsp), %rax
	movq	%rax, 114816(%rsp)
	movq	21704(%rsp), %rax
	movq	%rax, 114824(%rsp)
	movq	21712(%rsp), %rax
	movq	%rax, 114832(%rsp)
	movq	21720(%rsp), %rax
	movq	%rax, 114840(%rsp)
	movq	21728(%rsp), %rax
	movq	%rax, 114848(%rsp)
	movq	21736(%rsp), %rax
	movq	%rax, 114856(%rsp)
	movq	21744(%rsp), %rax
	movq	%rax, 114864(%rsp)
	movq	21752(%rsp), %rax
	movq	%rax, 114872(%rsp)
	movq	21760(%rsp), %rax
	movq	%rax, 114880(%rsp)
	movq	21768(%rsp), %rax
	movq	%rax, 114888(%rsp)
	movq	21776(%rsp), %rax
	movq	%rax, 114896(%rsp)
	movq	21784(%rsp), %rax
	movq	%rax, 114904(%rsp)
	movq	21792(%rsp), %rax
	movq	%rax, 114912(%rsp)
	movq	21800(%rsp), %rax
	movq	%rax, 114920(%rsp)
	movq	21808(%rsp), %rax
	movq	%rax, 114928(%rsp)
	movq	21816(%rsp), %rax
	movq	%rax, 114936(%rsp)
	movq	21824(%rsp), %rax
	movq	%rax, 114944(%rsp)
	movq	21832(%rsp), %rax
	movq	%rax, 114952(%rsp)
	movq	21840(%rsp), %rax
	movq	%rax, 114960(%rsp)
	movq	21848(%rsp), %rax
	movq	%rax, 114968(%rsp)
	movq	21856(%rsp), %rax
	movq	%rax, 114976(%rsp)
	movq	21864(%rsp), %rax
	movq	%rax, 114984(%rsp)
	movq	21872(%rsp), %rax
	movq	%rax, 114992(%rsp)
	movq	21880(%rsp), %rax
	movq	%rax, 115000(%rsp)
	movq	21888(%rsp), %rax
	movq	%rax, 115008(%rsp)
	movq	21896(%rsp), %rax
	movq	%rax, 115016(%rsp)
	movq	21904(%rsp), %rax
	movq	%rax, 115024(%rsp)
	movq	21912(%rsp), %rax
	movq	%rax, 115032(%rsp)
	movq	21920(%rsp), %rax
	movq	%rax, 115040(%rsp)
	movq	21928(%rsp), %rax
	movq	%rax, 115048(%rsp)
	movq	21936(%rsp), %rax
	movq	%rax, 115056(%rsp)
	movq	21944(%rsp), %rax
	movq	%rax, 115064(%rsp)
	movq	21952(%rsp), %rax
	movq	%rax, 115072(%rsp)
	movq	21960(%rsp), %rax
	movq	%rax, 115080(%rsp)
	movq	21968(%rsp), %rax
	movq	%rax, 115088(%rsp)
	movq	21976(%rsp), %rax
	movq	%rax, 115096(%rsp)
	movq	21984(%rsp), %rax
	movq	%rax, 115104(%rsp)
	movq	21992(%rsp), %rax
	movq	%rax, 115112(%rsp)
	movq	22000(%rsp), %rax
	movq	%rax, 115120(%rsp)
	movq	22008(%rsp), %rax
	movq	%rax, 115128(%rsp)
	movq	22016(%rsp), %rax
	movq	%rax, 115136(%rsp)
	movq	22024(%rsp), %rax
	movq	%rax, 115144(%rsp)
	movq	22032(%rsp), %rax
	movq	%rax, 115152(%rsp)
	movq	22040(%rsp), %rax
	movq	%rax, 115160(%rsp)
	movq	22048(%rsp), %rax
	movq	%rax, 115168(%rsp)
	movq	22056(%rsp), %rax
	movq	%rax, 115176(%rsp)
	movq	22064(%rsp), %rax
	movq	%rax, 115184(%rsp)
	movq	22072(%rsp), %rax
	movq	%rax, 115192(%rsp)
	movq	22080(%rsp), %rax
	movq	%rax, 115200(%rsp)
	movq	22088(%rsp), %rax
	movq	%rax, 115208(%rsp)
	movq	22096(%rsp), %rax
	movq	%rax, 115216(%rsp)
	movq	22104(%rsp), %rax
	movq	%rax, 115224(%rsp)
	movq	22112(%rsp), %rax
	movq	%rax, 115232(%rsp)
	movq	22120(%rsp), %rax
	movq	%rax, 115240(%rsp)
	movq	22128(%rsp), %rax
	movq	%rax, 115248(%rsp)
	movq	22136(%rsp), %rax
	movq	%rax, 115256(%rsp)
	movq	22144(%rsp), %rax
	movq	%rax, 115264(%rsp)
	movq	22152(%rsp), %rax
	movq	%rax, 115272(%rsp)
	movq	22160(%rsp), %rax
	movq	%rax, 115280(%rsp)
	movq	22168(%rsp), %rax
	movq	%rax, 115288(%rsp)
	movq	22176(%rsp), %rax
	movq	%rax, 115296(%rsp)
	movq	22184(%rsp), %rax
	movq	%rax, 115304(%rsp)
	movq	22192(%rsp), %rax
	movq	%rax, 115312(%rsp)
	movq	22200(%rsp), %rax
	movq	%rax, 115320(%rsp)
	movq	22208(%rsp), %rax
	movq	%rax, 115328(%rsp)
	movq	22216(%rsp), %rax
	movq	%rax, 115336(%rsp)
	movq	22224(%rsp), %rax
	movq	%rax, 115344(%rsp)
	movq	22232(%rsp), %rax
	movq	%rax, 115352(%rsp)
	movq	22240(%rsp), %rax
	movq	%rax, 115360(%rsp)
	movq	22248(%rsp), %rax
	movq	%rax, 115368(%rsp)
	movq	22256(%rsp), %rax
	movq	%rax, 115376(%rsp)
	movq	22264(%rsp), %rax
	movq	%rax, 115384(%rsp)
	movq	22272(%rsp), %rax
	movq	%rax, 115392(%rsp)
	movq	22280(%rsp), %rax
	movq	%rax, 115400(%rsp)
	movq	22288(%rsp), %rax
	movq	%rax, 115408(%rsp)
	movq	22296(%rsp), %rax
	movq	%rax, 115416(%rsp)
	movq	22304(%rsp), %rax
	movq	%rax, 115424(%rsp)
	movq	22312(%rsp), %rax
	movq	%rax, 115432(%rsp)
	movq	22320(%rsp), %rax
	movq	%rax, 115440(%rsp)
	movq	22328(%rsp), %rax
	movq	%rax, 115448(%rsp)
	movq	22336(%rsp), %rax
	movq	%rax, 115456(%rsp)
	movq	22344(%rsp), %rax
	movq	%rax, 115464(%rsp)
	movq	22352(%rsp), %rax
	movq	%rax, 115472(%rsp)
	movq	22360(%rsp), %rax
	movq	%rax, 115480(%rsp)
	movq	22368(%rsp), %rax
	movq	%rax, 115488(%rsp)
	movq	22376(%rsp), %rax
	movq	%rax, 115496(%rsp)
	movq	22384(%rsp), %rax
	movq	%rax, 115504(%rsp)
	movq	22392(%rsp), %rax
	movq	%rax, 115512(%rsp)
	movq	22400(%rsp), %rax
	movq	%rax, 115520(%rsp)
	movq	22408(%rsp), %rax
	movq	%rax, 115528(%rsp)
	movq	22416(%rsp), %rax
	movq	%rax, 115536(%rsp)
	movq	22424(%rsp), %rax
	movq	%rax, 115544(%rsp)
	movq	22432(%rsp), %rax
	movq	%rax, 115552(%rsp)
	movq	22440(%rsp), %rax
	movq	%rax, 115560(%rsp)
	movq	22448(%rsp), %rax
	movq	%rax, 115568(%rsp)
	movq	22456(%rsp), %rax
	movq	%rax, 115576(%rsp)
	movq	22464(%rsp), %rax
	movq	%rax, 115584(%rsp)
	movq	22472(%rsp), %rax
	movq	%rax, 115592(%rsp)
	movq	22480(%rsp), %rax
	movq	%rax, 115600(%rsp)
	movq	22488(%rsp), %rax
	movq	%rax, 115608(%rsp)
	movq	22496(%rsp), %rax
	movq	%rax, 115616(%rsp)
	movq	22504(%rsp), %rax
	movq	%rax, 115624(%rsp)
	movq	22512(%rsp), %rax
	movq	%rax, 115632(%rsp)
	movq	22520(%rsp), %rax
	movq	%rax, 115640(%rsp)
	movq	22528(%rsp), %rax
	movq	%rax, 115648(%rsp)
	movq	22536(%rsp), %rax
	movq	%rax, 115656(%rsp)
	movq	22544(%rsp), %rax
	movq	%rax, 115664(%rsp)
	movq	22552(%rsp), %rax
	movq	%rax, 115672(%rsp)
	movq	22560(%rsp), %rax
	movq	%rax, 115680(%rsp)
	movq	22568(%rsp), %rax
	movq	%rax, 115688(%rsp)
	movq	22576(%rsp), %rax
	movq	%rax, 115696(%rsp)
	movq	22584(%rsp), %rax
	movq	%rax, 115704(%rsp)
	movq	22592(%rsp), %rax
	movq	%rax, 115712(%rsp)
	movq	22600(%rsp), %rax
	movq	%rax, 115720(%rsp)
	movq	22608(%rsp), %rax
	movq	%rax, 115728(%rsp)
	movq	22616(%rsp), %rax
	movq	%rax, 115736(%rsp)
	movq	22624(%rsp), %rax
	movq	%rax, 115744(%rsp)
	movq	22632(%rsp), %rax
	movq	%rax, 115752(%rsp)
	movq	22640(%rsp), %rax
	movq	%rax, 115760(%rsp)
	movq	22648(%rsp), %rax
	movq	%rax, 115768(%rsp)
	movq	22656(%rsp), %rax
	movq	%rax, 115776(%rsp)
	movq	22664(%rsp), %rax
	movq	%rax, 115784(%rsp)
	movq	22672(%rsp), %rax
	movq	%rax, 115792(%rsp)
	movq	22680(%rsp), %rax
	movq	%rax, 115800(%rsp)
	movq	22688(%rsp), %rax
	movq	%rax, 115808(%rsp)
	movq	22696(%rsp), %rax
	movq	%rax, 115816(%rsp)
	movq	22704(%rsp), %rax
	movq	%rax, 115824(%rsp)
	movq	22712(%rsp), %rax
	movq	%rax, 115832(%rsp)
	movq	22720(%rsp), %rax
	movq	%rax, 115840(%rsp)
	movq	22728(%rsp), %rax
	movq	%rax, 115848(%rsp)
	movq	22736(%rsp), %rax
	movq	%rax, 115856(%rsp)
	movq	22744(%rsp), %rax
	movq	%rax, 115864(%rsp)
	movq	22752(%rsp), %rax
	movq	%rax, 115872(%rsp)
	movq	22760(%rsp), %rax
	movq	%rax, 115880(%rsp)
	movq	22768(%rsp), %rax
	movq	%rax, 115888(%rsp)
	movq	22776(%rsp), %rax
	movq	%rax, 115896(%rsp)
	movq	22784(%rsp), %rax
	movq	%rax, 115904(%rsp)
	movq	22792(%rsp), %rax
	movq	%rax, 115912(%rsp)
	movq	22800(%rsp), %rax
	movq	%rax, 115920(%rsp)
	movq	22808(%rsp), %rax
	movq	%rax, 115928(%rsp)
	movq	22816(%rsp), %rax
	movq	%rax, 115936(%rsp)
	movq	22824(%rsp), %rax
	movq	%rax, 115944(%rsp)
	movq	22832(%rsp), %rax
	movq	%rax, 115952(%rsp)
	movq	22840(%rsp), %rax
	movq	%rax, 115960(%rsp)
	movq	22848(%rsp), %rax
	movq	%rax, 115968(%rsp)
	movq	22856(%rsp), %rax
	movq	%rax, 115976(%rsp)
	movq	22864(%rsp), %rax
	movq	%rax, 115984(%rsp)
	movq	22872(%rsp), %rax
	movq	%rax, 115992(%rsp)
	movq	22880(%rsp), %rax
	movq	%rax, 116000(%rsp)
	movq	22888(%rsp), %rax
	movq	%rax, 116008(%rsp)
	movq	22896(%rsp), %rax
	movq	%rax, 116016(%rsp)
	movq	22904(%rsp), %rax
	movq	%rax, 116024(%rsp)
	movq	22912(%rsp), %rax
	movq	%rax, 116032(%rsp)
	movq	22920(%rsp), %rax
	movq	%rax, 116040(%rsp)
	movq	22928(%rsp), %rax
	movq	%rax, 116048(%rsp)
	movq	22936(%rsp), %rax
	movq	%rax, 116056(%rsp)
	movq	22944(%rsp), %rax
	movq	%rax, 116064(%rsp)
	movq	22952(%rsp), %rax
	movq	%rax, 116072(%rsp)
	movq	22960(%rsp), %rax
	movq	%rax, 116080(%rsp)
	movq	22968(%rsp), %rax
	movq	%rax, 116088(%rsp)
	movq	22976(%rsp), %rax
	movq	%rax, 116096(%rsp)
	movq	22984(%rsp), %rax
	movq	%rax, 116104(%rsp)
	movq	22992(%rsp), %rax
	movq	%rax, 116112(%rsp)
	movq	23000(%rsp), %rax
	movq	%rax, 116120(%rsp)
	movq	23008(%rsp), %rax
	movq	%rax, 116128(%rsp)
	movq	23016(%rsp), %rax
	movq	%rax, 116136(%rsp)
	movq	23024(%rsp), %rax
	movq	%rax, 116144(%rsp)
	movq	23032(%rsp), %rax
	movq	%rax, 116152(%rsp)
	movq	23040(%rsp), %rax
	movq	%rax, 116160(%rsp)
	movq	23048(%rsp), %rax
	movq	%rax, 116168(%rsp)
	movq	23056(%rsp), %rax
	movq	%rax, 116176(%rsp)
	movq	23064(%rsp), %rax
	movq	%rax, 116184(%rsp)
	movq	23072(%rsp), %rax
	movq	%rax, 116192(%rsp)
	movq	23080(%rsp), %rax
	movq	%rax, 116200(%rsp)
	movq	23088(%rsp), %rax
	movq	%rax, 116208(%rsp)
	movq	23096(%rsp), %rax
	movq	%rax, 116216(%rsp)
	movq	23104(%rsp), %rax
	movq	%rax, 116224(%rsp)
	movq	23112(%rsp), %rax
	movq	%rax, 116232(%rsp)
	movq	23120(%rsp), %rax
	movq	%rax, 116240(%rsp)
	movq	23128(%rsp), %rax
	movq	%rax, 116248(%rsp)
	movq	23136(%rsp), %rax
	movq	%rax, 116256(%rsp)
	movq	23144(%rsp), %rax
	movq	%rax, 116264(%rsp)
	movq	23152(%rsp), %rax
	movq	%rax, 116272(%rsp)
	movq	23160(%rsp), %rax
	movq	%rax, 116280(%rsp)
	movq	23168(%rsp), %rax
	movq	%rax, 116288(%rsp)
	movq	23176(%rsp), %rax
	movq	%rax, 116296(%rsp)
	movq	23184(%rsp), %rax
	movq	%rax, 116304(%rsp)
	movq	23192(%rsp), %rax
	movq	%rax, 116312(%rsp)
	movq	23200(%rsp), %rax
	movq	%rax, 116320(%rsp)
	movq	23208(%rsp), %rax
	movq	%rax, 116328(%rsp)
	movq	23216(%rsp), %rax
	movq	%rax, 116336(%rsp)
	movq	23224(%rsp), %rax
	movq	%rax, 116344(%rsp)
	movq	23232(%rsp), %rax
	movq	%rax, 116352(%rsp)
	movq	23240(%rsp), %rax
	movq	%rax, 116360(%rsp)
	movq	23248(%rsp), %rax
	movq	%rax, 116368(%rsp)
	movq	23256(%rsp), %rax
	movq	%rax, 116376(%rsp)
	movq	23264(%rsp), %rax
	movq	%rax, 116384(%rsp)
	movq	23272(%rsp), %rax
	movq	%rax, 116392(%rsp)
	movq	23280(%rsp), %rax
	movq	%rax, 116400(%rsp)
	movq	23288(%rsp), %rax
	movq	%rax, 116408(%rsp)
	movq	23296(%rsp), %rax
	movq	%rax, 116416(%rsp)
	movq	23304(%rsp), %rax
	movq	%rax, 116424(%rsp)
	movq	23312(%rsp), %rax
	movq	%rax, 116432(%rsp)
	movq	23320(%rsp), %rax
	movq	%rax, 116440(%rsp)
	movq	23328(%rsp), %rax
	movq	%rax, 116448(%rsp)
	movq	23336(%rsp), %rax
	movq	%rax, 116456(%rsp)
	movq	23344(%rsp), %rax
	movq	%rax, 116464(%rsp)
	movq	23352(%rsp), %rax
	movq	%rax, 116472(%rsp)
	movq	23360(%rsp), %rax
	movq	%rax, 116480(%rsp)
	movq	23368(%rsp), %rax
	movq	%rax, 116488(%rsp)
	movq	23376(%rsp), %rax
	movq	%rax, 116496(%rsp)
	movq	23384(%rsp), %rax
	movq	%rax, 116504(%rsp)
	movq	23392(%rsp), %rax
	movq	%rax, 116512(%rsp)
	movq	23400(%rsp), %rax
	movq	%rax, 116520(%rsp)
	movq	23408(%rsp), %rax
	movq	%rax, 116528(%rsp)
	movq	23416(%rsp), %rax
	movq	%rax, 116536(%rsp)
	movq	23424(%rsp), %rax
	movq	%rax, 116544(%rsp)
	movq	23432(%rsp), %rax
	movq	%rax, 116552(%rsp)
	movq	23440(%rsp), %rax
	movq	%rax, 116560(%rsp)
	movq	23448(%rsp), %rax
	movq	%rax, 116568(%rsp)
	movq	23456(%rsp), %rax
	movq	%rax, 116576(%rsp)
	movq	23464(%rsp), %rax
	movq	%rax, 116584(%rsp)
	movq	23472(%rsp), %rax
	movq	%rax, 116592(%rsp)
	movq	23480(%rsp), %rax
	movq	%rax, 116600(%rsp)
	movq	23488(%rsp), %rax
	movq	%rax, 116608(%rsp)
	movq	23496(%rsp), %rax
	movq	%rax, 116616(%rsp)
	movq	23504(%rsp), %rax
	movq	%rax, 116624(%rsp)
	movq	23512(%rsp), %rax
	movq	%rax, 116632(%rsp)
	movq	23520(%rsp), %rax
	movq	%rax, 116640(%rsp)
	movq	23528(%rsp), %rax
	movq	%rax, 116648(%rsp)
	movq	23536(%rsp), %rax
	movq	%rax, 116656(%rsp)
	movq	23544(%rsp), %rax
	movq	%rax, 116664(%rsp)
	movq	23552(%rsp), %rax
	movq	%rax, 116672(%rsp)
	movq	23560(%rsp), %rax
	movq	%rax, 116680(%rsp)
	movq	23568(%rsp), %rax
	movq	%rax, 116688(%rsp)
	movq	23576(%rsp), %rax
	movq	%rax, 116696(%rsp)
	movq	23584(%rsp), %rax
	movq	%rax, 116704(%rsp)
	movq	23592(%rsp), %rax
	movq	%rax, 116712(%rsp)
	movq	23600(%rsp), %rax
	movq	%rax, 116720(%rsp)
	movq	23608(%rsp), %rax
	movq	%rax, 116728(%rsp)
	movq	23616(%rsp), %rax
	movq	%rax, 116736(%rsp)
	movq	23624(%rsp), %rax
	movq	%rax, 116744(%rsp)
	movq	23632(%rsp), %rax
	movq	%rax, 116752(%rsp)
	movq	23640(%rsp), %rax
	movq	%rax, 116760(%rsp)
	movq	23648(%rsp), %rax
	movq	%rax, 116768(%rsp)
	movq	23656(%rsp), %rax
	movq	%rax, 116776(%rsp)
	movq	23664(%rsp), %rax
	movq	%rax, 116784(%rsp)
	movq	23672(%rsp), %rax
	movq	%rax, 116792(%rsp)
	movq	23680(%rsp), %rax
	movq	%rax, 116800(%rsp)
	movq	23688(%rsp), %rax
	movq	%rax, 116808(%rsp)
	movq	23696(%rsp), %rax
	movq	%rax, 116816(%rsp)
	movq	23704(%rsp), %rax
	movq	%rax, 116824(%rsp)
	movq	23712(%rsp), %rax
	movq	%rax, 116832(%rsp)
	movq	23720(%rsp), %rax
	movq	%rax, 116840(%rsp)
	movq	23728(%rsp), %rax
	movq	%rax, 116848(%rsp)
	movq	23736(%rsp), %rax
	movq	%rax, 116856(%rsp)
	movq	23744(%rsp), %rax
	movq	%rax, 116864(%rsp)
	movq	23752(%rsp), %rax
	movq	%rax, 116872(%rsp)
	movq	23760(%rsp), %rax
	movq	%rax, 116880(%rsp)
	movq	23768(%rsp), %rax
	movq	%rax, 116888(%rsp)
	movq	23776(%rsp), %rax
	movq	%rax, 116896(%rsp)
	movq	23784(%rsp), %rax
	movq	%rax, 116904(%rsp)
	movq	23792(%rsp), %rax
	movq	%rax, 116912(%rsp)
	movq	23800(%rsp), %rax
	movq	%rax, 116920(%rsp)
	movq	23808(%rsp), %rax
	movq	%rax, 116928(%rsp)
	movq	23816(%rsp), %rax
	movq	%rax, 116936(%rsp)
	movq	23824(%rsp), %rax
	movq	%rax, 116944(%rsp)
	movq	23832(%rsp), %rax
	movq	%rax, 116952(%rsp)
	movq	23840(%rsp), %rax
	movq	%rax, 116960(%rsp)
	movq	23848(%rsp), %rax
	movq	%rax, 116968(%rsp)
	movq	23856(%rsp), %rax
	movq	%rax, 116976(%rsp)
	movq	23864(%rsp), %rax
	movq	%rax, 116984(%rsp)
	movq	23872(%rsp), %rax
	movq	%rax, 116992(%rsp)
	movq	23880(%rsp), %rax
	movq	%rax, 117000(%rsp)
	movq	23888(%rsp), %rax
	movq	%rax, 117008(%rsp)
	movq	23896(%rsp), %rax
	movq	%rax, 117016(%rsp)
	movq	23904(%rsp), %rax
	movq	%rax, 117024(%rsp)
	movq	23912(%rsp), %rax
	movq	%rax, 117032(%rsp)
	movq	23920(%rsp), %rax
	movq	%rax, 117040(%rsp)
	movq	23928(%rsp), %rax
	movq	%rax, 117048(%rsp)
	movq	23936(%rsp), %rax
	movq	%rax, 117056(%rsp)
	movq	23944(%rsp), %rax
	movq	%rax, 117064(%rsp)
	movq	23952(%rsp), %rax
	movq	%rax, 117072(%rsp)
	movq	23960(%rsp), %rax
	movq	%rax, 117080(%rsp)
	movq	23968(%rsp), %rax
	movq	%rax, 117088(%rsp)
	movq	23976(%rsp), %rax
	movq	%rax, 117096(%rsp)
	movq	23984(%rsp), %rax
	movq	%rax, 117104(%rsp)
	movq	23992(%rsp), %rax
	movq	%rax, 117112(%rsp)
	movq	24000(%rsp), %rax
	movq	%rax, 117120(%rsp)
	movq	24008(%rsp), %rax
	movq	%rax, 117128(%rsp)
	movq	24016(%rsp), %rax
	movq	%rax, 117136(%rsp)
	movq	24024(%rsp), %rax
	movq	%rax, 117144(%rsp)
	movq	24032(%rsp), %rax
	movq	%rax, 117152(%rsp)
	movq	24040(%rsp), %rax
	movq	%rax, 117160(%rsp)
	movq	24048(%rsp), %rax
	movq	%rax, 117168(%rsp)
	movq	24056(%rsp), %rax
	movq	%rax, 117176(%rsp)
	movq	24064(%rsp), %rax
	movq	%rax, 117184(%rsp)
	movq	24072(%rsp), %rax
	movq	%rax, 117192(%rsp)
	movq	24080(%rsp), %rax
	movq	%rax, 117200(%rsp)
	movq	24088(%rsp), %rax
	movq	%rax, 117208(%rsp)
	movq	24096(%rsp), %rax
	movq	%rax, 117216(%rsp)
	movq	24104(%rsp), %rax
	movq	%rax, 117224(%rsp)
	movq	24112(%rsp), %rax
	movq	%rax, 117232(%rsp)
	movq	24120(%rsp), %rax
	movq	%rax, 117240(%rsp)
	movq	24128(%rsp), %rax
	movq	%rax, 117248(%rsp)
	movq	24136(%rsp), %rax
	movq	%rax, 117256(%rsp)
	movq	24144(%rsp), %rax
	movq	%rax, 117264(%rsp)
	movq	24152(%rsp), %rax
	movq	%rax, 117272(%rsp)
	movq	24160(%rsp), %rax
	movq	%rax, 117280(%rsp)
	movq	24168(%rsp), %rax
	movq	%rax, 117288(%rsp)
	movq	24176(%rsp), %rax
	movq	%rax, 117296(%rsp)
	movq	24184(%rsp), %rax
	movq	%rax, 117304(%rsp)
	movq	24192(%rsp), %rax
	movq	%rax, 117312(%rsp)
	movq	24200(%rsp), %rax
	movq	%rax, 117320(%rsp)
	movq	24208(%rsp), %rax
	movq	%rax, 117328(%rsp)
	movq	24216(%rsp), %rax
	movq	%rax, 117336(%rsp)
	movq	24224(%rsp), %rax
	movq	%rax, 117344(%rsp)
	movq	24232(%rsp), %rax
	movq	%rax, 117352(%rsp)
	movq	24240(%rsp), %rax
	movq	%rax, 117360(%rsp)
	movq	24248(%rsp), %rax
	movq	%rax, 117368(%rsp)
	movq	24256(%rsp), %rax
	movq	%rax, 117376(%rsp)
	movq	24264(%rsp), %rax
	movq	%rax, 117384(%rsp)
	movq	24272(%rsp), %rax
	movq	%rax, 117392(%rsp)
	movq	24280(%rsp), %rax
	movq	%rax, 117400(%rsp)
	movq	24288(%rsp), %rax
	movq	%rax, 117408(%rsp)
	movq	24296(%rsp), %rax
	movq	%rax, 117416(%rsp)
	movq	24304(%rsp), %rax
	movq	%rax, 117424(%rsp)
	movq	24312(%rsp), %rax
	movq	%rax, 117432(%rsp)
	movq	24320(%rsp), %rax
	movq	%rax, 117440(%rsp)
	movq	24328(%rsp), %rax
	movq	%rax, 117448(%rsp)
	movq	24336(%rsp), %rax
	movq	%rax, 117456(%rsp)
	movq	24344(%rsp), %rax
	movq	%rax, 117464(%rsp)
	movq	24352(%rsp), %rax
	movq	%rax, 117472(%rsp)
	movq	24360(%rsp), %rax
	movq	%rax, 117480(%rsp)
	movq	24368(%rsp), %rax
	movq	%rax, 117488(%rsp)
	movq	24376(%rsp), %rax
	movq	%rax, 117496(%rsp)
	movq	24384(%rsp), %rax
	movq	%rax, 117504(%rsp)
	movq	24392(%rsp), %rax
	movq	%rax, 117512(%rsp)
	movq	24400(%rsp), %rax
	movq	%rax, 117520(%rsp)
	movq	24408(%rsp), %rax
	movq	%rax, 117528(%rsp)
	movq	24416(%rsp), %rax
	movq	%rax, 117536(%rsp)
	movq	24424(%rsp), %rax
	movq	%rax, 117544(%rsp)
	movq	24432(%rsp), %rax
	movq	%rax, 117552(%rsp)
	movq	24440(%rsp), %rax
	movq	%rax, 117560(%rsp)
	movq	24448(%rsp), %rax
	movq	%rax, 117568(%rsp)
	movq	24456(%rsp), %rax
	movq	%rax, 117576(%rsp)
	movq	24464(%rsp), %rax
	movq	%rax, 117584(%rsp)
	movq	24472(%rsp), %rax
	movq	%rax, 117592(%rsp)
	movq	24480(%rsp), %rax
	movq	%rax, 117600(%rsp)
	movq	24488(%rsp), %rax
	movq	%rax, 117608(%rsp)
	movq	24496(%rsp), %rax
	movq	%rax, 117616(%rsp)
	movq	24504(%rsp), %rax
	movq	%rax, 117624(%rsp)
	movq	24512(%rsp), %rax
	movq	%rax, 117632(%rsp)
	movq	24520(%rsp), %rax
	movq	%rax, 117640(%rsp)
	movq	24528(%rsp), %rax
	movq	%rax, 117648(%rsp)
	movq	24536(%rsp), %rax
	movq	%rax, 117656(%rsp)
	movq	24544(%rsp), %rax
	movq	%rax, 117664(%rsp)
	movq	24552(%rsp), %rax
	movq	%rax, 117672(%rsp)
	movq	24560(%rsp), %rax
	movq	%rax, 117680(%rsp)
	movq	24568(%rsp), %rax
	movq	%rax, 117688(%rsp)
	movq	24576(%rsp), %rax
	movq	%rax, 117696(%rsp)
	movq	24584(%rsp), %rax
	movq	%rax, 117704(%rsp)
	movq	24592(%rsp), %rax
	movq	%rax, 117712(%rsp)
	movq	24600(%rsp), %rax
	movq	%rax, 117720(%rsp)
	movq	24608(%rsp), %rax
	movq	%rax, 117728(%rsp)
	movq	24616(%rsp), %rax
	movq	%rax, 117736(%rsp)
	movq	24624(%rsp), %rax
	movq	%rax, 117744(%rsp)
	movq	24632(%rsp), %rax
	movq	%rax, 117752(%rsp)
	movq	24640(%rsp), %rax
	movq	%rax, 117760(%rsp)
	movq	24648(%rsp), %rax
	movq	%rax, 117768(%rsp)
	movq	24656(%rsp), %rax
	movq	%rax, 117776(%rsp)
	movq	24664(%rsp), %rax
	movq	%rax, 117784(%rsp)
	movq	24672(%rsp), %rax
	movq	%rax, 117792(%rsp)
	movq	24680(%rsp), %rax
	movq	%rax, 117800(%rsp)
	movq	24688(%rsp), %rax
	movq	%rax, 117808(%rsp)
	movq	24696(%rsp), %rax
	movq	%rax, 117816(%rsp)
	movq	24704(%rsp), %rax
	movq	%rax, 117824(%rsp)
	movq	24712(%rsp), %rax
	movq	%rax, 117832(%rsp)
	movq	24720(%rsp), %rax
	movq	%rax, 117840(%rsp)
	movq	24728(%rsp), %rax
	movq	%rax, 117848(%rsp)
	movq	24736(%rsp), %rax
	movq	%rax, 117856(%rsp)
	movq	24744(%rsp), %rax
	movq	%rax, 117864(%rsp)
	movq	24752(%rsp), %rax
	movq	%rax, 117872(%rsp)
	movq	24760(%rsp), %rax
	movq	%rax, 117880(%rsp)
	movq	24768(%rsp), %rax
	movq	%rax, 117888(%rsp)
	movq	24776(%rsp), %rax
	movq	%rax, 117896(%rsp)
	movq	24784(%rsp), %rax
	movq	%rax, 117904(%rsp)
	movq	24792(%rsp), %rax
	movq	%rax, 117912(%rsp)
	movq	24800(%rsp), %rax
	movq	%rax, 117920(%rsp)
	movq	24808(%rsp), %rax
	movq	%rax, 117928(%rsp)
	movq	24816(%rsp), %rax
	movq	%rax, 117936(%rsp)
	movq	24824(%rsp), %rax
	movq	%rax, 117944(%rsp)
	movq	24832(%rsp), %rax
	movq	%rax, 117952(%rsp)
	movq	24840(%rsp), %rax
	movq	%rax, 117960(%rsp)
	movq	24848(%rsp), %rax
	movq	%rax, 117968(%rsp)
	movq	24856(%rsp), %rax
	movq	%rax, 117976(%rsp)
	movq	24864(%rsp), %rax
	movq	%rax, 117984(%rsp)
	movq	24872(%rsp), %rax
	movq	%rax, 117992(%rsp)
	movq	24880(%rsp), %rax
	movq	%rax, 118000(%rsp)
	movq	24888(%rsp), %rax
	movq	%rax, 118008(%rsp)
	movq	24896(%rsp), %rax
	movq	%rax, 118016(%rsp)
	movq	24904(%rsp), %rax
	movq	%rax, 118024(%rsp)
	movq	24912(%rsp), %rax
	movq	%rax, 118032(%rsp)
	movq	24920(%rsp), %rax
	movq	%rax, 118040(%rsp)
	movq	24928(%rsp), %rax
	movq	%rax, 118048(%rsp)
	movq	24936(%rsp), %rax
	movq	%rax, 118056(%rsp)
	movq	24944(%rsp), %rax
	movq	%rax, 118064(%rsp)
	movq	24952(%rsp), %rax
	movq	%rax, 118072(%rsp)
	movq	24960(%rsp), %rax
	movq	%rax, 118080(%rsp)
	movq	24968(%rsp), %rax
	movq	%rax, 118088(%rsp)
	movq	24976(%rsp), %rax
	movq	%rax, 118096(%rsp)
	movq	24984(%rsp), %rax
	movq	%rax, 118104(%rsp)
	movq	24992(%rsp), %rax
	movq	%rax, 118112(%rsp)
	movq	25000(%rsp), %rax
	movq	%rax, 118120(%rsp)
	movq	25008(%rsp), %rax
	movq	%rax, 118128(%rsp)
	movq	25016(%rsp), %rax
	movq	%rax, 118136(%rsp)
	movq	25024(%rsp), %rax
	movq	%rax, 118144(%rsp)
	movq	25032(%rsp), %rax
	movq	%rax, 118152(%rsp)
	movq	25040(%rsp), %rax
	movq	%rax, 118160(%rsp)
	movq	25048(%rsp), %rax
	movq	%rax, 118168(%rsp)
	movq	25056(%rsp), %rax
	movq	%rax, 118176(%rsp)
	movq	25064(%rsp), %rax
	movq	%rax, 118184(%rsp)
	movq	25072(%rsp), %rax
	movq	%rax, 118192(%rsp)
	movq	25080(%rsp), %rax
	movq	%rax, 118200(%rsp)
	movq	25088(%rsp), %rax
	movq	%rax, 118208(%rsp)
	movq	25096(%rsp), %rax
	movq	%rax, 118216(%rsp)
	movq	25104(%rsp), %rax
	movq	%rax, 118224(%rsp)
	movq	25112(%rsp), %rax
	movq	%rax, 118232(%rsp)
	movq	25120(%rsp), %rax
	movq	%rax, 118240(%rsp)
	movq	25128(%rsp), %rax
	movq	%rax, 118248(%rsp)
	movq	25136(%rsp), %rax
	movq	%rax, 118256(%rsp)
	movq	25144(%rsp), %rax
	movq	%rax, 118264(%rsp)
	movq	25152(%rsp), %rax
	movq	%rax, 118272(%rsp)
	movq	25160(%rsp), %rax
	movq	%rax, 118280(%rsp)
	movq	25168(%rsp), %rax
	movq	%rax, 118288(%rsp)
	movq	25176(%rsp), %rax
	movq	%rax, 118296(%rsp)
	movq	25184(%rsp), %rax
	movq	%rax, 118304(%rsp)
	movq	25192(%rsp), %rax
	movq	%rax, 118312(%rsp)
	movq	25200(%rsp), %rax
	movq	%rax, 118320(%rsp)
	movq	25208(%rsp), %rax
	movq	%rax, 118328(%rsp)
	movq	25216(%rsp), %rax
	movq	%rax, 118336(%rsp)
	movq	25224(%rsp), %rax
	movq	%rax, 118344(%rsp)
	movq	25232(%rsp), %rax
	movq	%rax, 118352(%rsp)
	movq	25240(%rsp), %rax
	movq	%rax, 118360(%rsp)
	movq	25248(%rsp), %rax
	movq	%rax, 118368(%rsp)
	movq	25256(%rsp), %rax
	movq	%rax, 118376(%rsp)
	movq	25264(%rsp), %rax
	movq	%rax, 118384(%rsp)
	movq	25272(%rsp), %rax
	movq	%rax, 118392(%rsp)
	movq	25280(%rsp), %rax
	movq	%rax, 118400(%rsp)
	movq	25288(%rsp), %rax
	movq	%rax, 118408(%rsp)
	movq	25296(%rsp), %rax
	movq	%rax, 118416(%rsp)
	movq	25304(%rsp), %rax
	movq	%rax, 118424(%rsp)
	movq	25312(%rsp), %rax
	movq	%rax, 118432(%rsp)
	movq	25320(%rsp), %rax
	movq	%rax, 118440(%rsp)
	movq	25328(%rsp), %rax
	movq	%rax, 118448(%rsp)
	movq	25336(%rsp), %rax
	movq	%rax, 118456(%rsp)
	movq	25344(%rsp), %rax
	movq	%rax, 118464(%rsp)
	movq	25352(%rsp), %rax
	movq	%rax, 118472(%rsp)
	movq	25360(%rsp), %rax
	movq	%rax, 118480(%rsp)
	movq	25368(%rsp), %rax
	movq	%rax, 118488(%rsp)
	movq	25376(%rsp), %rax
	movq	%rax, 118496(%rsp)
	movq	25384(%rsp), %rax
	movq	%rax, 118504(%rsp)
	movq	25392(%rsp), %rax
	movq	%rax, 118512(%rsp)
	movq	25400(%rsp), %rax
	movq	%rax, 118520(%rsp)
	movq	25408(%rsp), %rax
	movq	%rax, 118528(%rsp)
	movq	25416(%rsp), %rax
	movq	%rax, 118536(%rsp)
	movq	25424(%rsp), %rax
	movq	%rax, 118544(%rsp)
	movq	25432(%rsp), %rax
	movq	%rax, 118552(%rsp)
	movq	25440(%rsp), %rax
	movq	%rax, 118560(%rsp)
	movq	25448(%rsp), %rax
	movq	%rax, 118568(%rsp)
	movq	25456(%rsp), %rax
	movq	%rax, 118576(%rsp)
	movq	25464(%rsp), %rax
	movq	%rax, 118584(%rsp)
	movq	25472(%rsp), %rax
	movq	%rax, 118592(%rsp)
	movq	25480(%rsp), %rax
	movq	%rax, 118600(%rsp)
	movq	25488(%rsp), %rax
	movq	%rax, 118608(%rsp)
	movq	25496(%rsp), %rax
	movq	%rax, 118616(%rsp)
	movq	25504(%rsp), %rax
	movq	%rax, 118624(%rsp)
	movq	25512(%rsp), %rax
	movq	%rax, 118632(%rsp)
	movq	25520(%rsp), %rax
	movq	%rax, 118640(%rsp)
	movq	25528(%rsp), %rax
	movq	%rax, 118648(%rsp)
	movq	25536(%rsp), %rax
	movq	%rax, 118656(%rsp)
	movq	25544(%rsp), %rax
	movq	%rax, 118664(%rsp)
	movq	25552(%rsp), %rax
	movq	%rax, 118672(%rsp)
	movq	25560(%rsp), %rax
	movq	%rax, 118680(%rsp)
	movq	25568(%rsp), %rax
	movq	%rax, 118688(%rsp)
	movq	25576(%rsp), %rax
	movq	%rax, 118696(%rsp)
	movq	25584(%rsp), %rax
	movq	%rax, 118704(%rsp)
	movq	25592(%rsp), %rax
	movq	%rax, 118712(%rsp)
	movq	25600(%rsp), %rax
	movq	%rax, 118720(%rsp)
	movq	25608(%rsp), %rax
	movq	%rax, 118728(%rsp)
	movq	25616(%rsp), %rax
	movq	%rax, 118736(%rsp)
	movq	25624(%rsp), %rax
	movq	%rax, 118744(%rsp)
	movq	25632(%rsp), %rax
	movq	%rax, 118752(%rsp)
	movq	25640(%rsp), %rax
	movq	%rax, 118760(%rsp)
	movq	25648(%rsp), %rax
	movq	%rax, 118768(%rsp)
	movq	25656(%rsp), %rax
	movq	%rax, 118776(%rsp)
	movq	25664(%rsp), %rax
	movq	%rax, 118784(%rsp)
	movq	25672(%rsp), %rax
	movq	%rax, 118792(%rsp)
	movq	25680(%rsp), %rax
	movq	%rax, 118800(%rsp)
	movq	25688(%rsp), %rax
	movq	%rax, 118808(%rsp)
	movq	25696(%rsp), %rax
	movq	%rax, 118816(%rsp)
	movq	25704(%rsp), %rax
	movq	%rax, 118824(%rsp)
	movq	25712(%rsp), %rax
	movq	%rax, 118832(%rsp)
	movq	25720(%rsp), %rax
	movq	%rax, 118840(%rsp)
	movq	25728(%rsp), %rax
	movq	%rax, 118848(%rsp)
	movq	25736(%rsp), %rax
	movq	%rax, 118856(%rsp)
	movq	25744(%rsp), %rax
	movq	%rax, 118864(%rsp)
	movq	25752(%rsp), %rax
	movq	%rax, 118872(%rsp)
	movq	25760(%rsp), %rax
	movq	%rax, 118880(%rsp)
	movq	25768(%rsp), %rax
	movq	%rax, 118888(%rsp)
	movq	25776(%rsp), %rax
	movq	%rax, 118896(%rsp)
	movq	25784(%rsp), %rax
	movq	%rax, 118904(%rsp)
	movq	25792(%rsp), %rax
	movq	%rax, 118912(%rsp)
	movq	25800(%rsp), %rax
	movq	%rax, 118920(%rsp)
	movq	25808(%rsp), %rax
	movq	%rax, 118928(%rsp)
	movq	25816(%rsp), %rax
	movq	%rax, 118936(%rsp)
	movq	25824(%rsp), %rax
	movq	%rax, 118944(%rsp)
	movq	25832(%rsp), %rax
	movq	%rax, 118952(%rsp)
	movq	25840(%rsp), %rax
	movq	%rax, 118960(%rsp)
	movq	25848(%rsp), %rax
	movq	%rax, 118968(%rsp)
	movq	25856(%rsp), %rax
	movq	%rax, 118976(%rsp)
	movq	25864(%rsp), %rax
	movq	%rax, 118984(%rsp)
	movq	25872(%rsp), %rax
	movq	%rax, 118992(%rsp)
	movq	25880(%rsp), %rax
	movq	%rax, 119000(%rsp)
	movq	25888(%rsp), %rax
	movq	%rax, 119008(%rsp)
	movq	25896(%rsp), %rax
	movq	%rax, 119016(%rsp)
	movq	25904(%rsp), %rax
	movq	%rax, 119024(%rsp)
	movq	25912(%rsp), %rax
	movq	%rax, 119032(%rsp)
	movq	25920(%rsp), %rax
	movq	%rax, 119040(%rsp)
	movq	25928(%rsp), %rax
	movq	%rax, 119048(%rsp)
	movq	25936(%rsp), %rax
	movq	%rax, 119056(%rsp)
	movq	25944(%rsp), %rax
	movq	%rax, 119064(%rsp)
	movq	25952(%rsp), %rax
	movq	%rax, 119072(%rsp)
	movq	25960(%rsp), %rax
	movq	%rax, 119080(%rsp)
	movq	25968(%rsp), %rax
	movq	%rax, 119088(%rsp)
	movq	25976(%rsp), %rax
	movq	%rax, 119096(%rsp)
	movq	25984(%rsp), %rax
	movq	%rax, 119104(%rsp)
	movq	25992(%rsp), %rax
	movq	%rax, 119112(%rsp)
	movq	26000(%rsp), %rax
	movq	%rax, 119120(%rsp)
	movq	26008(%rsp), %rax
	movq	%rax, 119128(%rsp)
	movq	26016(%rsp), %rax
	movq	%rax, 119136(%rsp)
	movq	26024(%rsp), %rax
	movq	%rax, 119144(%rsp)
	movq	26032(%rsp), %rax
	movq	%rax, 119152(%rsp)
	movq	26040(%rsp), %rax
	movq	%rax, 119160(%rsp)
	movq	26048(%rsp), %rax
	movq	%rax, 119168(%rsp)
	movq	26056(%rsp), %rax
	movq	%rax, 119176(%rsp)
	movq	26064(%rsp), %rax
	movq	%rax, 119184(%rsp)
	movq	26072(%rsp), %rax
	movq	%rax, 119192(%rsp)
	movq	26080(%rsp), %rax
	movq	%rax, 119200(%rsp)
	movq	26088(%rsp), %rax
	movq	%rax, 119208(%rsp)
	movq	26096(%rsp), %rax
	movq	%rax, 119216(%rsp)
	movq	26104(%rsp), %rax
	movq	%rax, 119224(%rsp)
	movq	26112(%rsp), %rax
	movq	%rax, 119232(%rsp)
	movq	26120(%rsp), %rax
	movq	%rax, 119240(%rsp)
	movq	26128(%rsp), %rax
	movq	%rax, 119248(%rsp)
	movq	26136(%rsp), %rax
	movq	%rax, 119256(%rsp)
	movq	26144(%rsp), %rax
	movq	%rax, 119264(%rsp)
	movq	26152(%rsp), %rax
	movq	%rax, 119272(%rsp)
	movq	26160(%rsp), %rax
	movq	%rax, 119280(%rsp)
	movq	26168(%rsp), %rax
	movq	%rax, 119288(%rsp)
	movq	26176(%rsp), %rax
	movq	%rax, 119296(%rsp)
	movq	26184(%rsp), %rax
	movq	%rax, 119304(%rsp)
	movq	26192(%rsp), %rax
	movq	%rax, 119312(%rsp)
	movq	26200(%rsp), %rax
	movq	%rax, 119320(%rsp)
	movq	26208(%rsp), %rax
	movq	%rax, 119328(%rsp)
	movq	26216(%rsp), %rax
	movq	%rax, 119336(%rsp)
	movq	26224(%rsp), %rax
	movq	%rax, 119344(%rsp)
	movq	26232(%rsp), %rax
	movq	%rax, 119352(%rsp)
	movq	26240(%rsp), %rax
	movq	%rax, 119360(%rsp)
	movq	26248(%rsp), %rax
	movq	%rax, 119368(%rsp)
	movq	26256(%rsp), %rax
	movq	%rax, 119376(%rsp)
	movq	26264(%rsp), %rax
	movq	%rax, 119384(%rsp)
	movq	26272(%rsp), %rax
	movq	%rax, 119392(%rsp)
	movq	26280(%rsp), %rax
	movq	%rax, 119400(%rsp)
	movq	26288(%rsp), %rax
	movq	%rax, 119408(%rsp)
	movq	26296(%rsp), %rax
	movq	%rax, 119416(%rsp)
	movq	26304(%rsp), %rax
	movq	%rax, 119424(%rsp)
	movq	26312(%rsp), %rax
	movq	%rax, 119432(%rsp)
	movq	26320(%rsp), %rax
	movq	%rax, 119440(%rsp)
	movq	26328(%rsp), %rax
	movq	%rax, 119448(%rsp)
	movq	26336(%rsp), %rax
	movq	%rax, 119456(%rsp)
	movq	26344(%rsp), %rax
	movq	%rax, 119464(%rsp)
	movq	26352(%rsp), %rax
	movq	%rax, 119472(%rsp)
	movq	26360(%rsp), %rax
	movq	%rax, 119480(%rsp)
	movq	26368(%rsp), %rax
	movq	%rax, 119488(%rsp)
	movq	26376(%rsp), %rax
	movq	%rax, 119496(%rsp)
	movq	26384(%rsp), %rax
	movq	%rax, 119504(%rsp)
	movq	26392(%rsp), %rax
	movq	%rax, 119512(%rsp)
	movq	26400(%rsp), %rax
	movq	%rax, 119520(%rsp)
	movq	26408(%rsp), %rax
	movq	%rax, 119528(%rsp)
	movq	26416(%rsp), %rax
	movq	%rax, 119536(%rsp)
	movq	26424(%rsp), %rax
	movq	%rax, 119544(%rsp)
	movq	26432(%rsp), %rax
	movq	%rax, 119552(%rsp)
	movq	26440(%rsp), %rax
	movq	%rax, 119560(%rsp)
	movq	26448(%rsp), %rax
	movq	%rax, 119568(%rsp)
	movq	26456(%rsp), %rax
	movq	%rax, 119576(%rsp)
	movq	26464(%rsp), %rax
	movq	%rax, 119584(%rsp)
	movq	26472(%rsp), %rax
	movq	%rax, 119592(%rsp)
	movq	26480(%rsp), %rax
	movq	%rax, 119600(%rsp)
	movq	26488(%rsp), %rax
	movq	%rax, 119608(%rsp)
	movq	26496(%rsp), %rax
	movq	%rax, 119616(%rsp)
	movq	26504(%rsp), %rax
	movq	%rax, 119624(%rsp)
	movq	26512(%rsp), %rax
	movq	%rax, 119632(%rsp)
	movq	26520(%rsp), %rax
	movq	%rax, 119640(%rsp)
	movq	26528(%rsp), %rax
	movq	%rax, 119648(%rsp)
	movq	26536(%rsp), %rax
	movq	%rax, 119656(%rsp)
	movq	26544(%rsp), %rax
	movq	%rax, 119664(%rsp)
	movq	26552(%rsp), %rax
	movq	%rax, 119672(%rsp)
	movq	26560(%rsp), %rax
	movq	%rax, 119680(%rsp)
	movq	26568(%rsp), %rax
	movq	%rax, 119688(%rsp)
	movq	26576(%rsp), %rax
	movq	%rax, 119696(%rsp)
	movq	26584(%rsp), %rax
	movq	%rax, 119704(%rsp)
	movq	26592(%rsp), %rax
	movq	%rax, 119712(%rsp)
	movq	26600(%rsp), %rax
	movq	%rax, 119720(%rsp)
	movq	26608(%rsp), %rax
	movq	%rax, 119728(%rsp)
	movq	26616(%rsp), %rax
	movq	%rax, 119736(%rsp)
	movq	26624(%rsp), %rax
	movq	%rax, 119744(%rsp)
	movq	26632(%rsp), %rax
	movq	%rax, 119752(%rsp)
	movq	26640(%rsp), %rax
	movq	%rax, 119760(%rsp)
	movq	26648(%rsp), %rax
	movq	%rax, 119768(%rsp)
	movq	26656(%rsp), %rax
	movq	%rax, 119776(%rsp)
	movq	26664(%rsp), %rax
	movq	%rax, 119784(%rsp)
	movq	26672(%rsp), %rax
	movq	%rax, 119792(%rsp)
	movq	26680(%rsp), %rax
	movq	%rax, 119800(%rsp)
	movq	26688(%rsp), %rax
	movq	%rax, 119808(%rsp)
	movq	26696(%rsp), %rax
	movq	%rax, 119816(%rsp)
	movq	26704(%rsp), %rax
	movq	%rax, 119824(%rsp)
	movq	26712(%rsp), %rax
	movq	%rax, 119832(%rsp)
	movq	26720(%rsp), %rax
	movq	%rax, 119840(%rsp)
	movq	26728(%rsp), %rax
	movq	%rax, 119848(%rsp)
	movq	26736(%rsp), %rax
	movq	%rax, 119856(%rsp)
	movq	26744(%rsp), %rax
	movq	%rax, 119864(%rsp)
	movq	26752(%rsp), %rax
	movq	%rax, 119872(%rsp)
	movq	26760(%rsp), %rax
	movq	%rax, 119880(%rsp)
	movq	26768(%rsp), %rax
	movq	%rax, 119888(%rsp)
	movq	26776(%rsp), %rax
	movq	%rax, 119896(%rsp)
	movq	26784(%rsp), %rax
	movq	%rax, 119904(%rsp)
	movq	26792(%rsp), %rax
	movq	%rax, 119912(%rsp)
	movq	26800(%rsp), %rax
	movq	%rax, 119920(%rsp)
	movq	26808(%rsp), %rax
	movq	%rax, 119928(%rsp)
	movq	26816(%rsp), %rax
	movq	%rax, 119936(%rsp)
	movq	26824(%rsp), %rax
	movq	%rax, 119944(%rsp)
	movq	26832(%rsp), %rax
	movq	%rax, 119952(%rsp)
	movq	26840(%rsp), %rax
	movq	%rax, 119960(%rsp)
	movq	26848(%rsp), %rax
	movq	%rax, 119968(%rsp)
	movq	26856(%rsp), %rax
	movq	%rax, 119976(%rsp)
	movq	26864(%rsp), %rax
	movq	%rax, 119984(%rsp)
	movq	26872(%rsp), %rax
	movq	%rax, 119992(%rsp)
	movq	26880(%rsp), %rax
	movq	%rax, 120000(%rsp)
	movq	26888(%rsp), %rax
	movq	%rax, 120008(%rsp)
	movq	26896(%rsp), %rax
	movq	%rax, 120016(%rsp)
	movq	26904(%rsp), %rax
	movq	%rax, 120024(%rsp)
	movq	26912(%rsp), %rax
	movq	%rax, 120032(%rsp)
	movq	26920(%rsp), %rax
	movq	%rax, 120040(%rsp)
	movq	26928(%rsp), %rax
	movq	%rax, 120048(%rsp)
	movq	26936(%rsp), %rax
	movq	%rax, 120056(%rsp)
	movq	26944(%rsp), %rax
	movq	%rax, 120064(%rsp)
	movq	26952(%rsp), %rax
	movq	%rax, 120072(%rsp)
	movq	26960(%rsp), %rax
	movq	%rax, 120080(%rsp)
	movq	26968(%rsp), %rax
	movq	%rax, 120088(%rsp)
	movq	26976(%rsp), %rax
	movq	%rax, 120096(%rsp)
	movq	26984(%rsp), %rax
	movq	%rax, 120104(%rsp)
	movq	26992(%rsp), %rax
	movq	%rax, 120112(%rsp)
	movq	27000(%rsp), %rax
	movq	%rax, 120120(%rsp)
	movq	27008(%rsp), %rax
	movq	%rax, 120128(%rsp)
	movq	27016(%rsp), %rax
	movq	%rax, 120136(%rsp)
	movq	27024(%rsp), %rax
	movq	%rax, 120144(%rsp)
	movq	27032(%rsp), %rax
	movq	%rax, 120152(%rsp)
	movq	27040(%rsp), %rax
	movq	%rax, 120160(%rsp)
	movq	27048(%rsp), %rax
	movq	%rax, 120168(%rsp)
	movq	27056(%rsp), %rax
	movq	%rax, 120176(%rsp)
	movq	27064(%rsp), %rax
	movq	%rax, 120184(%rsp)
	movq	27072(%rsp), %rax
	movq	%rax, 120192(%rsp)
	movq	27080(%rsp), %rax
	movq	%rax, 120200(%rsp)
	movq	27088(%rsp), %rax
	movq	%rax, 120208(%rsp)
	movq	27096(%rsp), %rax
	movq	%rax, 120216(%rsp)
	movq	27104(%rsp), %rax
	movq	%rax, 120224(%rsp)
	movq	27112(%rsp), %rax
	movq	%rax, 120232(%rsp)
	movq	27120(%rsp), %rax
	movq	%rax, 120240(%rsp)
	movq	27128(%rsp), %rax
	movq	%rax, 120248(%rsp)
	movq	27136(%rsp), %rax
	movq	%rax, 120256(%rsp)
	movq	27144(%rsp), %rax
	movq	%rax, 120264(%rsp)
	movq	27152(%rsp), %rax
	movq	%rax, 120272(%rsp)
	movq	27160(%rsp), %rax
	movq	%rax, 120280(%rsp)
	movq	27168(%rsp), %rax
	movq	%rax, 120288(%rsp)
	movq	27176(%rsp), %rax
	movq	%rax, 120296(%rsp)
	movq	27184(%rsp), %rax
	movq	%rax, 120304(%rsp)
	movq	27192(%rsp), %rax
	movq	%rax, 120312(%rsp)
	movq	27200(%rsp), %rax
	movq	%rax, 120320(%rsp)
	movq	27208(%rsp), %rax
	movq	%rax, 120328(%rsp)
	movq	27216(%rsp), %rax
	movq	%rax, 120336(%rsp)
	movq	27224(%rsp), %rax
	movq	%rax, 120344(%rsp)
	movq	27232(%rsp), %rax
	movq	%rax, 120352(%rsp)
	movq	27240(%rsp), %rax
	movq	%rax, 120360(%rsp)
	movq	27248(%rsp), %rax
	movq	%rax, 120368(%rsp)
	movq	27256(%rsp), %rax
	movq	%rax, 120376(%rsp)
	movq	27264(%rsp), %rax
	movq	%rax, 120384(%rsp)
	movq	27272(%rsp), %rax
	movq	%rax, 120392(%rsp)
	movq	27280(%rsp), %rax
	movq	%rax, 120400(%rsp)
	movq	27288(%rsp), %rax
	movq	%rax, 120408(%rsp)
	movq	27296(%rsp), %rax
	movq	%rax, 120416(%rsp)
	movq	27304(%rsp), %rax
	movq	%rax, 120424(%rsp)
	movq	27312(%rsp), %rax
	movq	%rax, 120432(%rsp)
	movq	27320(%rsp), %rax
	movq	%rax, 120440(%rsp)
	movq	27328(%rsp), %rax
	movq	%rax, 120448(%rsp)
	movq	27336(%rsp), %rax
	movq	%rax, 120456(%rsp)
	movq	27344(%rsp), %rax
	movq	%rax, 120464(%rsp)
	movq	27352(%rsp), %rax
	movq	%rax, 120472(%rsp)
	movq	27360(%rsp), %rax
	movq	%rax, 120480(%rsp)
	movq	27368(%rsp), %rax
	movq	%rax, 120488(%rsp)
	movq	27376(%rsp), %rax
	movq	%rax, 120496(%rsp)
	movq	27384(%rsp), %rax
	movq	%rax, 120504(%rsp)
	movq	27392(%rsp), %rax
	movq	%rax, 120512(%rsp)
	movq	27400(%rsp), %rax
	movq	%rax, 120520(%rsp)
	movq	27408(%rsp), %rax
	movq	%rax, 120528(%rsp)
	movq	27416(%rsp), %rax
	movq	%rax, 120536(%rsp)
	movq	27424(%rsp), %rax
	movq	%rax, 120544(%rsp)
	movq	27432(%rsp), %rax
	movq	%rax, 120552(%rsp)
	movq	27440(%rsp), %rax
	movq	%rax, 120560(%rsp)
	movq	27448(%rsp), %rax
	movq	%rax, 120568(%rsp)
	movq	27456(%rsp), %rax
	movq	%rax, 120576(%rsp)
	movq	27464(%rsp), %rax
	movq	%rax, 120584(%rsp)
	movq	27472(%rsp), %rax
	movq	%rax, 120592(%rsp)
	movq	27480(%rsp), %rax
	movq	%rax, 120600(%rsp)
	movq	27488(%rsp), %rax
	movq	%rax, 120608(%rsp)
	movq	27496(%rsp), %rax
	movq	%rax, 120616(%rsp)
	movq	27504(%rsp), %rax
	movq	%rax, 120624(%rsp)
	movq	27512(%rsp), %rax
	movq	%rax, 120632(%rsp)
	movq	27520(%rsp), %rax
	movq	%rax, 120640(%rsp)
	movq	27528(%rsp), %rax
	movq	%rax, 120648(%rsp)
	movq	27536(%rsp), %rax
	movq	%rax, 120656(%rsp)
	movq	27544(%rsp), %rax
	movq	%rax, 120664(%rsp)
	movq	27552(%rsp), %rax
	movq	%rax, 120672(%rsp)
	movq	27560(%rsp), %rax
	movq	%rax, 120680(%rsp)
	movq	27568(%rsp), %rax
	movq	%rax, 120688(%rsp)
	movq	27576(%rsp), %rax
	movq	%rax, 120696(%rsp)
	movq	27584(%rsp), %rax
	movq	%rax, 120704(%rsp)
	movq	27592(%rsp), %rax
	movq	%rax, 120712(%rsp)
	movq	27600(%rsp), %rax
	movq	%rax, 120720(%rsp)
	movq	27608(%rsp), %rax
	movq	%rax, 120728(%rsp)
	movq	27616(%rsp), %rax
	movq	%rax, 120736(%rsp)
	movq	27624(%rsp), %rax
	movq	%rax, 120744(%rsp)
	movq	27632(%rsp), %rax
	movq	%rax, 120752(%rsp)
	movq	27640(%rsp), %rax
	movq	%rax, 120760(%rsp)
	movq	27648(%rsp), %rax
	movq	%rax, 120768(%rsp)
	movq	27656(%rsp), %rax
	movq	%rax, 120776(%rsp)
	movq	27664(%rsp), %rax
	movq	%rax, 120784(%rsp)
	movq	27672(%rsp), %rax
	movq	%rax, 120792(%rsp)
	movq	27680(%rsp), %rax
	movq	%rax, 120800(%rsp)
	movq	27688(%rsp), %rax
	movq	%rax, 120808(%rsp)
	movq	27696(%rsp), %rax
	movq	%rax, 120816(%rsp)
	movq	27704(%rsp), %rax
	movq	%rax, 120824(%rsp)
	movq	27712(%rsp), %rax
	movq	%rax, 120832(%rsp)
	movq	27720(%rsp), %rax
	movq	%rax, 120840(%rsp)
	movq	27728(%rsp), %rax
	movq	%rax, 120848(%rsp)
	movq	27736(%rsp), %rax
	movq	%rax, 120856(%rsp)
	movq	27744(%rsp), %rax
	movq	%rax, 120864(%rsp)
	movq	27752(%rsp), %rax
	movq	%rax, 120872(%rsp)
	movq	27760(%rsp), %rax
	movq	%rax, 120880(%rsp)
	movq	27768(%rsp), %rax
	movq	%rax, 120888(%rsp)
	movq	27776(%rsp), %rax
	movq	%rax, 120896(%rsp)
	movq	27784(%rsp), %rax
	movq	%rax, 120904(%rsp)
	movq	27792(%rsp), %rax
	movq	%rax, 120912(%rsp)
	movq	27800(%rsp), %rax
	movq	%rax, 120920(%rsp)
	movq	27808(%rsp), %rax
	movq	%rax, 120928(%rsp)
	movq	27816(%rsp), %rax
	movq	%rax, 120936(%rsp)
	movq	27824(%rsp), %rax
	movq	%rax, 120944(%rsp)
	movq	27832(%rsp), %rax
	movq	%rax, 120952(%rsp)
	movq	27840(%rsp), %rax
	movq	%rax, 120960(%rsp)
	movq	27848(%rsp), %rax
	movq	%rax, 120968(%rsp)
	movq	27856(%rsp), %rax
	movq	%rax, 120976(%rsp)
	movq	27864(%rsp), %rax
	movq	%rax, 120984(%rsp)
	movq	27872(%rsp), %rax
	movq	%rax, 120992(%rsp)
	movq	27880(%rsp), %rax
	movq	%rax, 121000(%rsp)
	movq	27888(%rsp), %rax
	movq	%rax, 121008(%rsp)
	movq	27896(%rsp), %rax
	movq	%rax, 121016(%rsp)
	movq	27904(%rsp), %rax
	movq	%rax, 121024(%rsp)
	movq	27912(%rsp), %rax
	movq	%rax, 121032(%rsp)
	movq	27920(%rsp), %rax
	movq	%rax, 121040(%rsp)
	movq	27928(%rsp), %rax
	movq	%rax, 121048(%rsp)
	movq	27936(%rsp), %rax
	movq	%rax, 121056(%rsp)
	movq	27944(%rsp), %rax
	movq	%rax, 121064(%rsp)
	movq	27952(%rsp), %rax
	movq	%rax, 121072(%rsp)
	movq	27960(%rsp), %rax
	movq	%rax, 121080(%rsp)
	movq	27968(%rsp), %rax
	movq	%rax, 121088(%rsp)
	movq	27976(%rsp), %rax
	movq	%rax, 121096(%rsp)
	movq	27984(%rsp), %rax
	movq	%rax, 121104(%rsp)
	movq	27992(%rsp), %rax
	movq	%rax, 121112(%rsp)
	movq	28000(%rsp), %rax
	movq	%rax, 121120(%rsp)
	movq	28008(%rsp), %rax
	movq	%rax, 121128(%rsp)
	movq	28016(%rsp), %rax
	movq	%rax, 121136(%rsp)
	movq	28024(%rsp), %rax
	movq	%rax, 121144(%rsp)
	movq	28032(%rsp), %rax
	movq	%rax, 121152(%rsp)
	movq	28040(%rsp), %rax
	movq	%rax, 121160(%rsp)
	movq	28048(%rsp), %rax
	movq	%rax, 121168(%rsp)
	movq	28056(%rsp), %rax
	movq	%rax, 121176(%rsp)
	movq	28064(%rsp), %rax
	movq	%rax, 121184(%rsp)
	movq	28072(%rsp), %rax
	movq	%rax, 121192(%rsp)
	movq	28080(%rsp), %rax
	movq	%rax, 121200(%rsp)
	movq	28088(%rsp), %rax
	movq	%rax, 121208(%rsp)
	movq	28096(%rsp), %rax
	movq	%rax, 121216(%rsp)
	movq	28104(%rsp), %rax
	movq	%rax, 121224(%rsp)
	movq	28112(%rsp), %rax
	movq	%rax, 121232(%rsp)
	movq	28120(%rsp), %rax
	movq	%rax, 121240(%rsp)
	movq	28128(%rsp), %rax
	movq	%rax, 121248(%rsp)
	movq	28136(%rsp), %rax
	movq	%rax, 121256(%rsp)
	movq	28144(%rsp), %rax
	movq	%rax, 121264(%rsp)
	movq	28152(%rsp), %rax
	movq	%rax, 121272(%rsp)
	movq	28160(%rsp), %rax
	movq	%rax, 121280(%rsp)
	movq	28168(%rsp), %rax
	movq	%rax, 121288(%rsp)
	movq	28176(%rsp), %rax
	movq	%rax, 121296(%rsp)
	movq	28184(%rsp), %rax
	movq	%rax, 121304(%rsp)
	movq	28192(%rsp), %rax
	movq	%rax, 121312(%rsp)
	movq	28200(%rsp), %rax
	movq	%rax, 121320(%rsp)
	movq	28208(%rsp), %rax
	movq	%rax, 121328(%rsp)
	movq	28216(%rsp), %rax
	movq	%rax, 121336(%rsp)
	movq	28224(%rsp), %rax
	movq	%rax, 121344(%rsp)
	movq	28232(%rsp), %rax
	movq	%rax, 121352(%rsp)
	movq	28240(%rsp), %rax
	movq	%rax, 121360(%rsp)
	movq	28248(%rsp), %rax
	movq	%rax, 121368(%rsp)
	movq	28256(%rsp), %rax
	movq	%rax, 121376(%rsp)
	movq	28264(%rsp), %rax
	movq	%rax, 121384(%rsp)
	movq	28272(%rsp), %rax
	movq	%rax, 121392(%rsp)
	movq	28280(%rsp), %rax
	movq	%rax, 121400(%rsp)
	movq	28288(%rsp), %rax
	movq	%rax, 121408(%rsp)
	movq	28296(%rsp), %rax
	movq	%rax, 121416(%rsp)
	movq	28304(%rsp), %rax
	movq	%rax, 121424(%rsp)
	movq	28312(%rsp), %rax
	movq	%rax, 121432(%rsp)
	movq	28320(%rsp), %rax
	movq	%rax, 121440(%rsp)
	movq	28328(%rsp), %rax
	movq	%rax, 121448(%rsp)
	movq	28336(%rsp), %rax
	movq	%rax, 121456(%rsp)
	movq	28344(%rsp), %rax
	movq	%rax, 121464(%rsp)
	movq	28352(%rsp), %rax
	movq	%rax, 121472(%rsp)
	movq	28360(%rsp), %rax
	movq	%rax, 121480(%rsp)
	movq	28368(%rsp), %rax
	movq	%rax, 121488(%rsp)
	movq	28376(%rsp), %rax
	movq	%rax, 121496(%rsp)
	movq	28384(%rsp), %rax
	movq	%rax, 121504(%rsp)
	movq	28392(%rsp), %rax
	movq	%rax, 121512(%rsp)
	movq	28400(%rsp), %rax
	movq	%rax, 121520(%rsp)
	movq	28408(%rsp), %rax
	movq	%rax, 121528(%rsp)
	movq	28416(%rsp), %rax
	movq	%rax, 121536(%rsp)
	movq	28424(%rsp), %rax
	movq	%rax, 121544(%rsp)
	movq	28432(%rsp), %rax
	movq	%rax, 121552(%rsp)
	movq	28440(%rsp), %rax
	movq	%rax, 121560(%rsp)
	movq	28448(%rsp), %rax
	movq	%rax, 121568(%rsp)
	movq	28456(%rsp), %rax
	movq	%rax, 121576(%rsp)
	movq	28464(%rsp), %rax
	movq	%rax, 121584(%rsp)
	movq	28472(%rsp), %rax
	movq	%rax, 121592(%rsp)
	movq	28480(%rsp), %rax
	movq	%rax, 121600(%rsp)
	movq	28488(%rsp), %rax
	movq	%rax, 121608(%rsp)
	movq	28496(%rsp), %rax
	movq	%rax, 121616(%rsp)
	movq	28504(%rsp), %rax
	movq	%rax, 121624(%rsp)
	movq	28512(%rsp), %rax
	movq	%rax, 121632(%rsp)
	movq	28520(%rsp), %rax
	movq	%rax, 121640(%rsp)
	movq	28528(%rsp), %rax
	movq	%rax, 121648(%rsp)
	movq	28536(%rsp), %rax
	movq	%rax, 121656(%rsp)
	movq	28544(%rsp), %rax
	movq	%rax, 121664(%rsp)
	movq	28552(%rsp), %rax
	movq	%rax, 121672(%rsp)
	movq	28560(%rsp), %rax
	movq	%rax, 121680(%rsp)
	movq	28568(%rsp), %rax
	movq	%rax, 121688(%rsp)
	movq	28576(%rsp), %rax
	movq	%rax, 121696(%rsp)
	movq	28584(%rsp), %rax
	movq	%rax, 121704(%rsp)
	movq	28592(%rsp), %rax
	movq	%rax, 121712(%rsp)
	movq	28600(%rsp), %rax
	movq	%rax, 121720(%rsp)
	movq	28608(%rsp), %rax
	movq	%rax, 121728(%rsp)
	movq	28616(%rsp), %rax
	movq	%rax, 121736(%rsp)
	movq	28624(%rsp), %rax
	movq	%rax, 121744(%rsp)
	movq	28632(%rsp), %rax
	movq	%rax, 121752(%rsp)
	movq	28640(%rsp), %rax
	movq	%rax, 121760(%rsp)
	movq	28648(%rsp), %rax
	movq	%rax, 121768(%rsp)
	movq	28656(%rsp), %rax
	movq	%rax, 121776(%rsp)
	movq	28664(%rsp), %rax
	movq	%rax, 121784(%rsp)
	movq	28672(%rsp), %rax
	movq	%rax, 121792(%rsp)
	movq	28680(%rsp), %rax
	movq	%rax, 121800(%rsp)
	movq	28688(%rsp), %rax
	movq	%rax, 121808(%rsp)
	movq	28696(%rsp), %rax
	movq	%rax, 121816(%rsp)
	movq	28704(%rsp), %rax
	movq	%rax, 121824(%rsp)
	movq	28712(%rsp), %rax
	movq	%rax, 121832(%rsp)
	movq	28720(%rsp), %rax
	movq	%rax, 121840(%rsp)
	movq	28728(%rsp), %rax
	movq	%rax, 121848(%rsp)
	movq	28736(%rsp), %rax
	movq	%rax, 121856(%rsp)
	movq	28744(%rsp), %rax
	movq	%rax, 121864(%rsp)
	movq	28752(%rsp), %rax
	movq	%rax, 121872(%rsp)
	movq	28760(%rsp), %rax
	movq	%rax, 121880(%rsp)
	movq	28768(%rsp), %rax
	movq	%rax, 121888(%rsp)
	movq	28776(%rsp), %rax
	movq	%rax, 121896(%rsp)
	movq	28784(%rsp), %rax
	movq	%rax, 121904(%rsp)
	movq	28792(%rsp), %rax
	movq	%rax, 121912(%rsp)
	movq	28800(%rsp), %rax
	movq	%rax, 121920(%rsp)
	movq	28808(%rsp), %rax
	movq	%rax, 121928(%rsp)
	movq	28816(%rsp), %rax
	movq	%rax, 121936(%rsp)
	movq	28824(%rsp), %rax
	movq	%rax, 121944(%rsp)
	movq	28832(%rsp), %rax
	movq	%rax, 121952(%rsp)
	movq	28840(%rsp), %rax
	movq	%rax, 121960(%rsp)
	movq	28848(%rsp), %rax
	movq	%rax, 121968(%rsp)
	movq	28856(%rsp), %rax
	movq	%rax, 121976(%rsp)
	movq	28864(%rsp), %rax
	movq	%rax, 121984(%rsp)
	movq	28872(%rsp), %rax
	movq	%rax, 121992(%rsp)
	movq	28880(%rsp), %rax
	movq	%rax, 122000(%rsp)
	movq	28888(%rsp), %rax
	movq	%rax, 122008(%rsp)
	movq	28896(%rsp), %rax
	movq	%rax, 122016(%rsp)
	movq	28904(%rsp), %rax
	movq	%rax, 122024(%rsp)
	movq	28912(%rsp), %rax
	movq	%rax, 122032(%rsp)
	movq	28920(%rsp), %rax
	movq	%rax, 122040(%rsp)
	movq	28928(%rsp), %rax
	movq	%rax, 122048(%rsp)
	movq	28936(%rsp), %rax
	movq	%rax, 122056(%rsp)
	movq	28944(%rsp), %rax
	movq	%rax, 122064(%rsp)
	movq	28952(%rsp), %rax
	movq	%rax, 122072(%rsp)
	movq	28960(%rsp), %rax
	movq	%rax, 122080(%rsp)
	movq	28968(%rsp), %rax
	movq	%rax, 122088(%rsp)
	movq	28976(%rsp), %rax
	movq	%rax, 122096(%rsp)
	movq	28984(%rsp), %rax
	movq	%rax, 122104(%rsp)
	movq	28992(%rsp), %rax
	movq	%rax, 122112(%rsp)
	movq	29000(%rsp), %rax
	movq	%rax, 122120(%rsp)
	movq	29008(%rsp), %rax
	movq	%rax, 122128(%rsp)
	movq	29016(%rsp), %rax
	movq	%rax, 122136(%rsp)
	movq	29024(%rsp), %rax
	movq	%rax, 122144(%rsp)
	movq	29032(%rsp), %rax
	movq	%rax, 122152(%rsp)
	movq	29040(%rsp), %rax
	movq	%rax, 122160(%rsp)
	movq	29048(%rsp), %rax
	movq	%rax, 122168(%rsp)
	movq	29056(%rsp), %rax
	movq	%rax, 122176(%rsp)
	movq	29064(%rsp), %rax
	movq	%rax, 122184(%rsp)
	movq	29072(%rsp), %rax
	movq	%rax, 122192(%rsp)
	movq	29080(%rsp), %rax
	movq	%rax, 122200(%rsp)
	movq	29088(%rsp), %rax
	movq	%rax, 122208(%rsp)
	movq	29096(%rsp), %rax
	movq	%rax, 122216(%rsp)
	movq	29104(%rsp), %rax
	movq	%rax, 122224(%rsp)
	movq	29112(%rsp), %rax
	movq	%rax, 122232(%rsp)
	movq	29120(%rsp), %rax
	movq	%rax, 122240(%rsp)
	movq	29128(%rsp), %rax
	movq	%rax, 122248(%rsp)
	movq	29136(%rsp), %rax
	movq	%rax, 122256(%rsp)
	movq	29144(%rsp), %rax
	movq	%rax, 122264(%rsp)
	movq	29152(%rsp), %rax
	movq	%rax, 122272(%rsp)
	movq	29160(%rsp), %rax
	movq	%rax, 122280(%rsp)
	movq	29168(%rsp), %rax
	movq	%rax, 122288(%rsp)
	movq	29176(%rsp), %rax
	movq	%rax, 122296(%rsp)
	movq	29184(%rsp), %rax
	movq	%rax, 122304(%rsp)
	movq	29192(%rsp), %rax
	movq	%rax, 122312(%rsp)
	movq	29200(%rsp), %rax
	movq	%rax, 122320(%rsp)
	movq	29208(%rsp), %rax
	movq	%rax, 122328(%rsp)
	movq	29216(%rsp), %rax
	movq	%rax, 122336(%rsp)
	movq	29224(%rsp), %rax
	movq	%rax, 122344(%rsp)
	movq	29232(%rsp), %rax
	movq	%rax, 122352(%rsp)
	movq	29240(%rsp), %rax
	movq	%rax, 122360(%rsp)
	movq	29248(%rsp), %rax
	movq	%rax, 122368(%rsp)
	movq	29256(%rsp), %rax
	movq	%rax, 122376(%rsp)
	movq	29264(%rsp), %rax
	movq	%rax, 122384(%rsp)
	movq	29272(%rsp), %rax
	movq	%rax, 122392(%rsp)
	movq	29280(%rsp), %rax
	movq	%rax, 122400(%rsp)
	movq	29288(%rsp), %rax
	movq	%rax, 122408(%rsp)
	movq	29296(%rsp), %rax
	movq	%rax, 122416(%rsp)
	movq	29304(%rsp), %rax
	movq	%rax, 122424(%rsp)
	movq	29312(%rsp), %rax
	movq	%rax, 122432(%rsp)
	movq	29320(%rsp), %rax
	movq	%rax, 122440(%rsp)
	movq	29328(%rsp), %rax
	movq	%rax, 122448(%rsp)
	movq	29336(%rsp), %rax
	movq	%rax, 122456(%rsp)
	movq	29344(%rsp), %rax
	movq	%rax, 122464(%rsp)
	movq	29352(%rsp), %rax
	movq	%rax, 122472(%rsp)
	movq	29360(%rsp), %rax
	movq	%rax, 122480(%rsp)
	movq	29368(%rsp), %rax
	movq	%rax, 122488(%rsp)
	movq	29376(%rsp), %rax
	movq	%rax, 122496(%rsp)
	movq	29384(%rsp), %rax
	movq	%rax, 122504(%rsp)
	movq	29392(%rsp), %rax
	movq	%rax, 122512(%rsp)
	movq	29400(%rsp), %rax
	movq	%rax, 122520(%rsp)
	movq	29408(%rsp), %rax
	movq	%rax, 122528(%rsp)
	movq	29416(%rsp), %rax
	movq	%rax, 122536(%rsp)
	movq	29424(%rsp), %rax
	movq	%rax, 122544(%rsp)
	movq	29432(%rsp), %rax
	movq	%rax, 122552(%rsp)
	movq	29440(%rsp), %rax
	movq	%rax, 122560(%rsp)
	movq	29448(%rsp), %rax
	movq	%rax, 122568(%rsp)
	movq	29456(%rsp), %rax
	movq	%rax, 122576(%rsp)
	movq	29464(%rsp), %rax
	movq	%rax, 122584(%rsp)
	movq	29472(%rsp), %rax
	movq	%rax, 122592(%rsp)
	movq	29480(%rsp), %rax
	movq	%rax, 122600(%rsp)
	movq	29488(%rsp), %rax
	movq	%rax, 122608(%rsp)
	movq	29496(%rsp), %rax
	movq	%rax, 122616(%rsp)
	movq	29504(%rsp), %rax
	movq	%rax, 122624(%rsp)
	movq	29512(%rsp), %rax
	movq	%rax, 122632(%rsp)
	movq	29520(%rsp), %rax
	movq	%rax, 122640(%rsp)
	movq	29528(%rsp), %rax
	movq	%rax, 122648(%rsp)
	movq	29536(%rsp), %rax
	movq	%rax, 122656(%rsp)
	movq	29544(%rsp), %rax
	movq	%rax, 122664(%rsp)
	movq	29552(%rsp), %rax
	movq	%rax, 122672(%rsp)
	movq	29560(%rsp), %rax
	movq	%rax, 122680(%rsp)
	movq	29568(%rsp), %rax
	movq	%rax, 122688(%rsp)
	movq	29576(%rsp), %rax
	movq	%rax, 122696(%rsp)
	movq	29584(%rsp), %rax
	movq	%rax, 122704(%rsp)
	movq	29592(%rsp), %rax
	movq	%rax, 122712(%rsp)
	movq	29600(%rsp), %rax
	movq	%rax, 122720(%rsp)
	movq	29608(%rsp), %rax
	movq	%rax, 122728(%rsp)
	movq	29616(%rsp), %rax
	movq	%rax, 122736(%rsp)
	movq	29624(%rsp), %rax
	movq	%rax, 122744(%rsp)
	movq	29632(%rsp), %rax
	movq	%rax, 122752(%rsp)
	movq	29640(%rsp), %rax
	movq	%rax, 122760(%rsp)
	movq	29648(%rsp), %rax
	movq	%rax, 122768(%rsp)
	movq	29656(%rsp), %rax
	movq	%rax, 122776(%rsp)
	movq	29664(%rsp), %rax
	movq	%rax, 122784(%rsp)
	movq	29672(%rsp), %rax
	movq	%rax, 122792(%rsp)
	movq	29680(%rsp), %rax
	movq	%rax, 122800(%rsp)
	movq	29688(%rsp), %rax
	movq	%rax, 122808(%rsp)
	movq	29696(%rsp), %rax
	movq	%rax, 122816(%rsp)
	movq	29704(%rsp), %rax
	movq	%rax, 122824(%rsp)
	movq	29712(%rsp), %rax
	movq	%rax, 122832(%rsp)
	movq	29720(%rsp), %rax
	movq	%rax, 122840(%rsp)
	movq	29728(%rsp), %rax
	movq	%rax, 122848(%rsp)
	movq	29736(%rsp), %rax
	movq	%rax, 122856(%rsp)
	movq	29744(%rsp), %rax
	movq	%rax, 122864(%rsp)
	movq	29752(%rsp), %rax
	movq	%rax, 122872(%rsp)
	movq	29760(%rsp), %rax
	movq	%rax, 122880(%rsp)
	movq	29768(%rsp), %rax
	movq	%rax, 122888(%rsp)
	movq	29776(%rsp), %rax
	movq	%rax, 122896(%rsp)
	movq	29784(%rsp), %rax
	movq	%rax, 122904(%rsp)
	movq	29792(%rsp), %rax
	movq	%rax, 122912(%rsp)
	movq	29800(%rsp), %rax
	movq	%rax, 122920(%rsp)
	movq	29808(%rsp), %rax
	movq	%rax, 122928(%rsp)
	movq	29816(%rsp), %rax
	movq	%rax, 122936(%rsp)
	movq	29824(%rsp), %rax
	movq	%rax, 122944(%rsp)
	movq	29832(%rsp), %rax
	movq	%rax, 122952(%rsp)
	movq	29840(%rsp), %rax
	movq	%rax, 122960(%rsp)
	movq	29848(%rsp), %rax
	movq	%rax, 122968(%rsp)
	movq	29856(%rsp), %rax
	movq	%rax, 122976(%rsp)
	movq	29864(%rsp), %rax
	movq	%rax, 122984(%rsp)
	movq	29872(%rsp), %rax
	movq	%rax, 122992(%rsp)
	movq	29880(%rsp), %rax
	movq	%rax, 123000(%rsp)
	movq	29888(%rsp), %rax
	movq	%rax, 123008(%rsp)
	movq	29896(%rsp), %rax
	movq	%rax, 123016(%rsp)
	movq	29904(%rsp), %rax
	movq	%rax, 123024(%rsp)
	movq	29912(%rsp), %rax
	movq	%rax, 123032(%rsp)
	movq	29920(%rsp), %rax
	movq	%rax, 123040(%rsp)
	movq	29928(%rsp), %rax
	movq	%rax, 123048(%rsp)
	movq	29936(%rsp), %rax
	movq	%rax, 123056(%rsp)
	movq	29944(%rsp), %rax
	movq	%rax, 123064(%rsp)
	movq	29952(%rsp), %rax
	movq	%rax, 123072(%rsp)
	movq	29960(%rsp), %rax
	movq	%rax, 123080(%rsp)
	movq	29968(%rsp), %rax
	movq	%rax, 123088(%rsp)
	movq	29976(%rsp), %rax
	movq	%rax, 123096(%rsp)
	movq	29984(%rsp), %rax
	movq	%rax, 123104(%rsp)
	movq	29992(%rsp), %rax
	movq	%rax, 123112(%rsp)
	movq	30000(%rsp), %rax
	movq	%rax, 123120(%rsp)
	movq	30008(%rsp), %rax
	movq	%rax, 123128(%rsp)
	movq	30016(%rsp), %rax
	movq	%rax, 123136(%rsp)
	movq	30024(%rsp), %rax
	movq	%rax, 123144(%rsp)
	movq	30032(%rsp), %rax
	movq	%rax, 123152(%rsp)
	movq	30040(%rsp), %rax
	movq	%rax, 123160(%rsp)
	movq	30048(%rsp), %rax
	movq	%rax, 123168(%rsp)
	movq	30056(%rsp), %rax
	movq	%rax, 123176(%rsp)
	movq	30064(%rsp), %rax
	movq	%rax, 123184(%rsp)
	movq	30072(%rsp), %rax
	movq	%rax, 123192(%rsp)
	movq	30080(%rsp), %rax
	movq	%rax, 123200(%rsp)
	movq	30088(%rsp), %rax
	movq	%rax, 123208(%rsp)
	movq	30096(%rsp), %rax
	movq	%rax, 123216(%rsp)
	movq	30104(%rsp), %rax
	movq	%rax, 123224(%rsp)
	movq	30112(%rsp), %rax
	movq	%rax, 123232(%rsp)
	movq	30120(%rsp), %rax
	movq	%rax, 123240(%rsp)
	movq	30128(%rsp), %rax
	movq	%rax, 123248(%rsp)
	movq	30136(%rsp), %rax
	movq	%rax, 123256(%rsp)
	movq	30144(%rsp), %rax
	movq	%rax, 123264(%rsp)
	movq	30152(%rsp), %rax
	movq	%rax, 123272(%rsp)
	movq	30160(%rsp), %rax
	movq	%rax, 123280(%rsp)
	movq	30168(%rsp), %rax
	movq	%rax, 123288(%rsp)
	movq	30176(%rsp), %rax
	movq	%rax, 123296(%rsp)
	movq	30184(%rsp), %rax
	movq	%rax, 123304(%rsp)
	movq	30192(%rsp), %rax
	movq	%rax, 123312(%rsp)
	movq	30200(%rsp), %rax
	movq	%rax, 123320(%rsp)
	movq	30208(%rsp), %rax
	movq	%rax, 123328(%rsp)
	movq	30216(%rsp), %rax
	movq	%rax, 123336(%rsp)
	movq	30224(%rsp), %rax
	movq	%rax, 123344(%rsp)
	movq	30232(%rsp), %rax
	movq	%rax, 123352(%rsp)
	movq	30240(%rsp), %rax
	movq	%rax, 123360(%rsp)
	movq	30248(%rsp), %rax
	movq	%rax, 123368(%rsp)
	movq	30256(%rsp), %rax
	movq	%rax, 123376(%rsp)
	movq	30264(%rsp), %rax
	movq	%rax, 123384(%rsp)
	movq	30272(%rsp), %rax
	movq	%rax, 123392(%rsp)
	movq	30280(%rsp), %rax
	movq	%rax, 123400(%rsp)
	movq	30288(%rsp), %rax
	movq	%rax, 123408(%rsp)
	movq	30296(%rsp), %rax
	movq	%rax, 123416(%rsp)
	movq	30304(%rsp), %rax
	movq	%rax, 123424(%rsp)
	movq	30312(%rsp), %rax
	movq	%rax, 123432(%rsp)
	movq	30320(%rsp), %rax
	movq	%rax, 123440(%rsp)
	movq	30328(%rsp), %rax
	movq	%rax, 123448(%rsp)
	movq	30336(%rsp), %rax
	movq	%rax, 123456(%rsp)
	movq	30344(%rsp), %rax
	movq	%rax, 123464(%rsp)
	movq	30352(%rsp), %rax
	movq	%rax, 123472(%rsp)
	movq	30360(%rsp), %rax
	movq	%rax, 123480(%rsp)
	movq	30368(%rsp), %rax
	movq	%rax, 123488(%rsp)
	movq	30376(%rsp), %rax
	movq	%rax, 123496(%rsp)
	movq	30384(%rsp), %rax
	movq	%rax, 123504(%rsp)
	movq	30392(%rsp), %rax
	movq	%rax, 123512(%rsp)
	movq	30400(%rsp), %rax
	movq	%rax, 123520(%rsp)
	movq	30408(%rsp), %rax
	movq	%rax, 123528(%rsp)
	movq	30416(%rsp), %rax
	movq	%rax, 123536(%rsp)
	movq	30424(%rsp), %rax
	movq	%rax, 123544(%rsp)
	movq	30432(%rsp), %rax
	movq	%rax, 123552(%rsp)
	movq	30440(%rsp), %rax
	movq	%rax, 123560(%rsp)
	movq	30448(%rsp), %rax
	movq	%rax, 123568(%rsp)
	movq	30456(%rsp), %rax
	movq	%rax, 123576(%rsp)
	movq	30464(%rsp), %rax
	movq	%rax, 123584(%rsp)
	movq	30472(%rsp), %rax
	movq	%rax, 123592(%rsp)
	movq	30480(%rsp), %rax
	movq	%rax, 123600(%rsp)
	movq	30488(%rsp), %rax
	movq	%rax, 123608(%rsp)
	movq	30496(%rsp), %rax
	movq	%rax, 123616(%rsp)
	movq	30504(%rsp), %rax
	movq	%rax, 123624(%rsp)
	movq	30512(%rsp), %rax
	movq	%rax, 123632(%rsp)
	movq	30520(%rsp), %rax
	movq	%rax, 123640(%rsp)
	movq	30528(%rsp), %rax
	movq	%rax, 123648(%rsp)
	movq	30536(%rsp), %rax
	movq	%rax, 123656(%rsp)
	movq	30544(%rsp), %rax
	movq	%rax, 123664(%rsp)
	movq	30552(%rsp), %rax
	movq	%rax, 123672(%rsp)
	movq	30560(%rsp), %rax
	movq	%rax, 123680(%rsp)
	movq	30568(%rsp), %rax
	movq	%rax, 123688(%rsp)
	movq	30576(%rsp), %rax
	movq	%rax, 123696(%rsp)
	movq	30584(%rsp), %rax
	movq	%rax, 123704(%rsp)
	movq	30592(%rsp), %rax
	movq	%rax, 123712(%rsp)
	movq	30600(%rsp), %rax
	movq	%rax, 123720(%rsp)
	movq	30608(%rsp), %rax
	movq	%rax, 123728(%rsp)
	movq	30616(%rsp), %rax
	movq	%rax, 123736(%rsp)
	movq	30624(%rsp), %rax
	movq	%rax, 123744(%rsp)
	movq	30632(%rsp), %rax
	movq	%rax, 123752(%rsp)
	movq	30640(%rsp), %rax
	movq	%rax, 123760(%rsp)
	movq	30648(%rsp), %rax
	movq	%rax, 123768(%rsp)
	movq	30656(%rsp), %rax
	movq	%rax, 123776(%rsp)
	movq	30664(%rsp), %rax
	movq	%rax, 123784(%rsp)
	movq	30672(%rsp), %rax
	movq	%rax, 123792(%rsp)
	movq	30680(%rsp), %rax
	movq	%rax, 123800(%rsp)
	movq	30688(%rsp), %rax
	movq	%rax, 123808(%rsp)
	movq	30696(%rsp), %rax
	movq	%rax, 123816(%rsp)
	movq	30704(%rsp), %rax
	movq	%rax, 123824(%rsp)
	movq	30712(%rsp), %rax
	movq	%rax, 123832(%rsp)
	movq	30720(%rsp), %rax
	movq	%rax, 123840(%rsp)
	movq	30728(%rsp), %rax
	movq	%rax, 123848(%rsp)
	movq	30736(%rsp), %rax
	movq	%rax, 123856(%rsp)
	movq	30744(%rsp), %rax
	movq	%rax, 123864(%rsp)
	movq	30752(%rsp), %rax
	movq	%rax, 123872(%rsp)
	movq	30760(%rsp), %rax
	movq	%rax, 123880(%rsp)
	movq	30768(%rsp), %rax
	movq	%rax, 123888(%rsp)
	movq	30776(%rsp), %rax
	movq	%rax, 123896(%rsp)
	movq	30784(%rsp), %rax
	movq	%rax, 123904(%rsp)
	movq	30792(%rsp), %rax
	movq	%rax, 123912(%rsp)
	movq	30800(%rsp), %rax
	movq	%rax, 123920(%rsp)
	movq	30808(%rsp), %rax
	movq	%rax, 123928(%rsp)
	movq	30816(%rsp), %rax
	movq	%rax, 123936(%rsp)
	movq	30824(%rsp), %rax
	movq	%rax, 123944(%rsp)
	movq	30832(%rsp), %rax
	movq	%rax, 123952(%rsp)
	movq	30840(%rsp), %rax
	movq	%rax, 123960(%rsp)
	movq	30848(%rsp), %rax
	movq	%rax, 123968(%rsp)
	movq	30856(%rsp), %rax
	movq	%rax, 123976(%rsp)
	movq	30864(%rsp), %rax
	movq	%rax, 123984(%rsp)
	movq	30872(%rsp), %rax
	movq	%rax, 123992(%rsp)
	movq	30880(%rsp), %rax
	movq	%rax, 124000(%rsp)
	movq	30888(%rsp), %rax
	movq	%rax, 124008(%rsp)
	movq	30896(%rsp), %rax
	movq	%rax, 124016(%rsp)
	movq	30904(%rsp), %rax
	movq	%rax, 124024(%rsp)
	movq	30912(%rsp), %rax
	movq	%rax, 124032(%rsp)
	movq	30920(%rsp), %rax
	movq	%rax, 124040(%rsp)
	movq	30928(%rsp), %rax
	movq	%rax, 124048(%rsp)
	movq	30936(%rsp), %rax
	movq	%rax, 124056(%rsp)
	movq	30944(%rsp), %rax
	movq	%rax, 124064(%rsp)
	movq	30952(%rsp), %rax
	movq	%rax, 124072(%rsp)
	movq	30960(%rsp), %rax
	movq	%rax, 124080(%rsp)
	movq	30968(%rsp), %rax
	movq	%rax, 124088(%rsp)
	movq	30976(%rsp), %rax
	movq	%rax, 124096(%rsp)
	movq	30984(%rsp), %rax
	movq	%rax, 124104(%rsp)
	movq	30992(%rsp), %rax
	movq	%rax, 124112(%rsp)
	movq	31000(%rsp), %rax
	movq	%rax, 124120(%rsp)
	movq	31008(%rsp), %rax
	movq	%rax, 124128(%rsp)
	movq	31016(%rsp), %rax
	movq	%rax, 124136(%rsp)
	movq	31024(%rsp), %rax
	movq	%rax, 124144(%rsp)
	movq	31032(%rsp), %rax
	movq	%rax, 124152(%rsp)
	movq	31040(%rsp), %rax
	movq	%rax, 124160(%rsp)
	movq	31048(%rsp), %rax
	movq	%rax, 124168(%rsp)
	movq	31056(%rsp), %rax
	movq	%rax, 124176(%rsp)
	movq	31064(%rsp), %rax
	movq	%rax, 124184(%rsp)
	movq	31072(%rsp), %rax
	movq	%rax, 124192(%rsp)
	movq	31080(%rsp), %rax
	movq	%rax, 124200(%rsp)
	movq	31088(%rsp), %rax
	movq	%rax, 124208(%rsp)
	movq	31096(%rsp), %rax
	movq	%rax, 124216(%rsp)
	movq	31104(%rsp), %rax
	movq	%rax, 124224(%rsp)
	movq	31112(%rsp), %rax
	movq	%rax, 124232(%rsp)
	movq	31120(%rsp), %rax
	movq	%rax, 124240(%rsp)
	movq	31128(%rsp), %rax
	movq	%rax, 124248(%rsp)
	movq	31136(%rsp), %rax
	movq	%rax, 124256(%rsp)
	movq	31144(%rsp), %rax
	movq	%rax, 124264(%rsp)
	movq	31152(%rsp), %rax
	movq	%rax, 124272(%rsp)
	movq	31160(%rsp), %rax
	movq	%rax, 124280(%rsp)
	movq	31168(%rsp), %rax
	movq	%rax, 124288(%rsp)
	movq	31176(%rsp), %rax
	movq	%rax, 124296(%rsp)
	movq	31184(%rsp), %rax
	movq	%rax, 124304(%rsp)
	movq	31192(%rsp), %rax
	movq	%rax, 124312(%rsp)
	movq	31200(%rsp), %rax
	movq	%rax, 124320(%rsp)
	movq	31208(%rsp), %rax
	movq	%rax, 124328(%rsp)
	movq	31216(%rsp), %rax
	movq	%rax, 124336(%rsp)
	movq	31224(%rsp), %rax
	movq	%rax, 124344(%rsp)
	movq	31232(%rsp), %rax
	movq	%rax, 124352(%rsp)
	movq	31240(%rsp), %rax
	movq	%rax, 124360(%rsp)
	movq	31248(%rsp), %rax
	movq	%rax, 124368(%rsp)
	movq	31256(%rsp), %rax
	movq	%rax, 124376(%rsp)
	movq	31264(%rsp), %rax
	movq	%rax, 124384(%rsp)
	movq	31272(%rsp), %rax
	movq	%rax, 124392(%rsp)
	movq	31280(%rsp), %rax
	movq	%rax, 124400(%rsp)
	movq	31288(%rsp), %rax
	movq	%rax, 124408(%rsp)
	movq	31296(%rsp), %rax
	movq	%rax, 124416(%rsp)
	movq	31304(%rsp), %rax
	movq	%rax, 124424(%rsp)
	movq	31312(%rsp), %rax
	movq	%rax, 124432(%rsp)
	movq	31320(%rsp), %rax
	movq	%rax, 124440(%rsp)
	movq	31328(%rsp), %rax
	movq	%rax, 124448(%rsp)
	movq	31336(%rsp), %rax
	movq	%rax, 124456(%rsp)
	movq	31344(%rsp), %rax
	movq	%rax, 124464(%rsp)
	movq	31352(%rsp), %rax
	movq	%rax, 124472(%rsp)
	movq	31360(%rsp), %rax
	movq	%rax, 124480(%rsp)
	movq	31368(%rsp), %rax
	movq	%rax, 124488(%rsp)
	movq	31376(%rsp), %rax
	movq	%rax, 124496(%rsp)
	movq	31384(%rsp), %rax
	movq	%rax, 124504(%rsp)
	movq	31392(%rsp), %rax
	movq	%rax, 124512(%rsp)
	movq	31400(%rsp), %rax
	movq	%rax, 124520(%rsp)
	movq	31408(%rsp), %rax
	movq	%rax, 124528(%rsp)
	movq	31416(%rsp), %rax
	movq	%rax, 124536(%rsp)
	movq	31424(%rsp), %rax
	movq	%rax, 124544(%rsp)
	movq	31432(%rsp), %rax
	movq	%rax, 124552(%rsp)
	movq	31440(%rsp), %rax
	movq	%rax, 124560(%rsp)
	movq	31448(%rsp), %rax
	movq	%rax, 124568(%rsp)
	movq	31456(%rsp), %rax
	movq	%rax, 124576(%rsp)
	movq	31464(%rsp), %rax
	movq	%rax, 124584(%rsp)
	movq	31472(%rsp), %rax
	movq	%rax, 124592(%rsp)
	movq	31480(%rsp), %rax
	movq	%rax, 124600(%rsp)
	movq	31488(%rsp), %rax
	movq	%rax, 124608(%rsp)
	movq	31496(%rsp), %rax
	movq	%rax, 124616(%rsp)
	movq	31504(%rsp), %rax
	movq	%rax, 124624(%rsp)
	movq	31512(%rsp), %rax
	movq	%rax, 124632(%rsp)
	movq	31520(%rsp), %rax
	movq	%rax, 124640(%rsp)
	movq	31528(%rsp), %rax
	movq	%rax, 124648(%rsp)
	movq	31536(%rsp), %rax
	movq	%rax, 124656(%rsp)
	movq	31544(%rsp), %rax
	movq	%rax, 124664(%rsp)
	movq	31552(%rsp), %rax
	movq	%rax, 124672(%rsp)
	movq	31560(%rsp), %rax
	movq	%rax, 124680(%rsp)
	movq	31568(%rsp), %rax
	movq	%rax, 124688(%rsp)
	movq	31576(%rsp), %rax
	movq	%rax, 124696(%rsp)
	movq	31584(%rsp), %rax
	movq	%rax, 124704(%rsp)
	movq	31592(%rsp), %rax
	movq	%rax, 124712(%rsp)
	movq	31600(%rsp), %rax
	movq	%rax, 124720(%rsp)
	movq	31608(%rsp), %rax
	movq	%rax, 124728(%rsp)
	movq	31616(%rsp), %rax
	movq	%rax, 124736(%rsp)
	movq	31624(%rsp), %rax
	movq	%rax, 124744(%rsp)
	movq	31632(%rsp), %rax
	movq	%rax, 124752(%rsp)
	movq	31640(%rsp), %rax
	movq	%rax, 124760(%rsp)
	movq	31648(%rsp), %rax
	movq	%rax, 124768(%rsp)
	movq	31656(%rsp), %rax
	movq	%rax, 124776(%rsp)
	movq	31664(%rsp), %rax
	movq	%rax, 124784(%rsp)
	movq	31672(%rsp), %rax
	movq	%rax, 124792(%rsp)
	movq	31680(%rsp), %rax
	movq	%rax, 124800(%rsp)
	movq	31688(%rsp), %rax
	movq	%rax, 124808(%rsp)
	movq	31696(%rsp), %rax
	movq	%rax, 124816(%rsp)
	movq	31704(%rsp), %rax
	movq	%rax, 124824(%rsp)
	movq	31712(%rsp), %rax
	movq	%rax, 124832(%rsp)
	movq	31720(%rsp), %rax
	movq	%rax, 124840(%rsp)
	movq	31728(%rsp), %rax
	movq	%rax, 124848(%rsp)
	movq	31736(%rsp), %rax
	movq	%rax, 124856(%rsp)
	movq	31744(%rsp), %rax
	movq	%rax, 124864(%rsp)
	movq	31752(%rsp), %rax
	movq	%rax, 124872(%rsp)
	movq	31760(%rsp), %rax
	movq	%rax, 124880(%rsp)
	movq	31768(%rsp), %rax
	movq	%rax, 124888(%rsp)
	movq	31776(%rsp), %rax
	movq	%rax, 124896(%rsp)
	movq	31784(%rsp), %rax
	movq	%rax, 124904(%rsp)
	movq	31792(%rsp), %rax
	movq	%rax, 124912(%rsp)
	movq	31800(%rsp), %rax
	movq	%rax, 124920(%rsp)
	movq	31808(%rsp), %rax
	movq	%rax, 124928(%rsp)
	movq	31816(%rsp), %rax
	movq	%rax, 124936(%rsp)
	movq	31824(%rsp), %rax
	movq	%rax, 124944(%rsp)
	movq	31832(%rsp), %rax
	movq	%rax, 124952(%rsp)
	movq	31840(%rsp), %rax
	movq	%rax, 124960(%rsp)
	movq	31848(%rsp), %rax
	movq	%rax, 124968(%rsp)
	movq	31856(%rsp), %rax
	movq	%rax, 124976(%rsp)
	movq	31864(%rsp), %rax
	movq	%rax, 124984(%rsp)
	movq	31872(%rsp), %rax
	movq	%rax, 124992(%rsp)
	movq	31880(%rsp), %rax
	movq	%rax, 125000(%rsp)
	movq	31888(%rsp), %rax
	movq	%rax, 125008(%rsp)
	movq	31896(%rsp), %rax
	movq	%rax, 125016(%rsp)
	movq	31904(%rsp), %rax
	movq	%rax, 125024(%rsp)
	movq	31912(%rsp), %rax
	movq	%rax, 125032(%rsp)
	movq	31920(%rsp), %rax
	movq	%rax, 125040(%rsp)
	movq	31928(%rsp), %rax
	movq	%rax, 125048(%rsp)
	movq	31936(%rsp), %rax
	movq	%rax, 125056(%rsp)
	movq	31944(%rsp), %rax
	movq	%rax, 125064(%rsp)
	movq	31952(%rsp), %rax
	movq	%rax, 125072(%rsp)
	movq	31960(%rsp), %rax
	movq	%rax, 125080(%rsp)
	movq	31968(%rsp), %rax
	movq	%rax, 125088(%rsp)
	movq	31976(%rsp), %rax
	movq	%rax, 125096(%rsp)
	movq	31984(%rsp), %rax
	movq	%rax, 125104(%rsp)
	movq	31992(%rsp), %rax
	movq	%rax, 125112(%rsp)
	movq	32000(%rsp), %rax
	movq	%rax, 125120(%rsp)
	movq	32008(%rsp), %rax
	movq	%rax, 125128(%rsp)
	movq	32016(%rsp), %rax
	movq	%rax, 125136(%rsp)
	movq	32024(%rsp), %rax
	movq	%rax, 125144(%rsp)
	movq	32032(%rsp), %rax
	movq	%rax, 125152(%rsp)
	movq	32040(%rsp), %rax
	movq	%rax, 125160(%rsp)
	movq	32048(%rsp), %rax
	movq	%rax, 125168(%rsp)
	movq	32056(%rsp), %rax
	movq	%rax, 125176(%rsp)
	movq	32064(%rsp), %rax
	movq	%rax, 125184(%rsp)
	movq	32072(%rsp), %rax
	movq	%rax, 125192(%rsp)
	movq	32080(%rsp), %rax
	movq	%rax, 125200(%rsp)
	movq	32088(%rsp), %rax
	movq	%rax, 125208(%rsp)
	movq	32096(%rsp), %rax
	movq	%rax, 125216(%rsp)
	movq	32104(%rsp), %rax
	movq	%rax, 125224(%rsp)
	movq	32112(%rsp), %rax
	movq	%rax, 125232(%rsp)
	movq	32120(%rsp), %rax
	movq	%rax, 125240(%rsp)
	movq	32128(%rsp), %rax
	movq	%rax, 125248(%rsp)
	movq	32136(%rsp), %rax
	movq	%rax, 125256(%rsp)
	movq	32144(%rsp), %rax
	movq	%rax, 125264(%rsp)
	movq	32152(%rsp), %rax
	movq	%rax, 125272(%rsp)
	movq	32160(%rsp), %rax
	movq	%rax, 125280(%rsp)
	movq	32168(%rsp), %rax
	movq	%rax, 125288(%rsp)
	movq	32176(%rsp), %rax
	movq	%rax, 125296(%rsp)
	movq	32184(%rsp), %rax
	movq	%rax, 125304(%rsp)
	movq	32192(%rsp), %rax
	movq	%rax, 125312(%rsp)
	movq	32200(%rsp), %rax
	movq	%rax, 125320(%rsp)
	movq	32208(%rsp), %rax
	movq	%rax, 125328(%rsp)
	movq	32216(%rsp), %rax
	movq	%rax, 125336(%rsp)
	movq	32224(%rsp), %rax
	movq	%rax, 125344(%rsp)
	movq	32232(%rsp), %rax
	movq	%rax, 125352(%rsp)
	movq	32240(%rsp), %rax
	movq	%rax, 125360(%rsp)
	movq	32248(%rsp), %rax
	movq	%rax, 125368(%rsp)
	movq	32256(%rsp), %rax
	movq	%rax, 125376(%rsp)
	movq	32264(%rsp), %rax
	movq	%rax, 125384(%rsp)
	movq	32272(%rsp), %rax
	movq	%rax, 125392(%rsp)
	movq	32280(%rsp), %rax
	movq	%rax, 125400(%rsp)
	movq	32288(%rsp), %rax
	movq	%rax, 125408(%rsp)
	movq	32296(%rsp), %rax
	movq	%rax, 125416(%rsp)
	movq	32304(%rsp), %rax
	movq	%rax, 125424(%rsp)
	movq	32312(%rsp), %rax
	movq	%rax, 125432(%rsp)
	movq	32320(%rsp), %rax
	movq	%rax, 125440(%rsp)
	movq	32328(%rsp), %rax
	movq	%rax, 125448(%rsp)
	movq	32336(%rsp), %rax
	movq	%rax, 125456(%rsp)
	movq	32344(%rsp), %rax
	movq	%rax, 125464(%rsp)
	movq	32352(%rsp), %rax
	movq	%rax, 125472(%rsp)
	movq	32360(%rsp), %rax
	movq	%rax, 125480(%rsp)
	movq	32368(%rsp), %rax
	movq	%rax, 125488(%rsp)
	movq	32376(%rsp), %rax
	movq	%rax, 125496(%rsp)
	movq	32384(%rsp), %rax
	movq	%rax, 125504(%rsp)
	movq	32392(%rsp), %rax
	movq	%rax, 125512(%rsp)
	movq	32400(%rsp), %rax
	movq	%rax, 125520(%rsp)
	movq	32408(%rsp), %rax
	movq	%rax, 125528(%rsp)
	movq	32416(%rsp), %rax
	movq	%rax, 125536(%rsp)
	movq	32424(%rsp), %rax
	movq	%rax, 125544(%rsp)
	movq	32432(%rsp), %rax
	movq	%rax, 125552(%rsp)
	movq	32440(%rsp), %rax
	movq	%rax, 125560(%rsp)
	movq	32448(%rsp), %rax
	movq	%rax, 125568(%rsp)
	movq	32456(%rsp), %rax
	movq	%rax, 125576(%rsp)
	movq	32464(%rsp), %rax
	movq	%rax, 125584(%rsp)
	movq	32472(%rsp), %rax
	movq	%rax, 125592(%rsp)
	movq	32480(%rsp), %rax
	movq	%rax, 125600(%rsp)
	movq	32488(%rsp), %rax
	movq	%rax, 125608(%rsp)
	movq	32496(%rsp), %rax
	movq	%rax, 125616(%rsp)
	movq	32504(%rsp), %rax
	movq	%rax, 125624(%rsp)
	movq	32512(%rsp), %rax
	movq	%rax, 125632(%rsp)
	movq	32520(%rsp), %rax
	movq	%rax, 125640(%rsp)
	movq	32528(%rsp), %rax
	movq	%rax, 125648(%rsp)
	movq	32536(%rsp), %rax
	movq	%rax, 125656(%rsp)
	movq	32544(%rsp), %rax
	movq	%rax, 125664(%rsp)
	movq	32552(%rsp), %rax
	movq	%rax, 125672(%rsp)
	movq	32560(%rsp), %rax
	movq	%rax, 125680(%rsp)
	movq	32568(%rsp), %rax
	movq	%rax, 125688(%rsp)
	movq	32576(%rsp), %rax
	movq	%rax, 125696(%rsp)
	movq	32584(%rsp), %rax
	movq	%rax, 125704(%rsp)
	movq	32592(%rsp), %rax
	movq	%rax, 125712(%rsp)
	movq	32600(%rsp), %rax
	movq	%rax, 125720(%rsp)
	movq	32608(%rsp), %rax
	movq	%rax, 125728(%rsp)
	movq	32616(%rsp), %rax
	movq	%rax, 125736(%rsp)
	movq	32624(%rsp), %rax
	movq	%rax, 125744(%rsp)
	movq	32632(%rsp), %rax
	movq	%rax, 125752(%rsp)
	movq	32640(%rsp), %rax
	movq	%rax, 125760(%rsp)
	movq	32648(%rsp), %rax
	movq	%rax, 125768(%rsp)
	movq	32656(%rsp), %rax
	movq	%rax, 125776(%rsp)
	movq	32664(%rsp), %rax
	movq	%rax, 125784(%rsp)
	movq	32672(%rsp), %rax
	movq	%rax, 125792(%rsp)
	movq	32680(%rsp), %rax
	movq	%rax, 125800(%rsp)
	movq	32688(%rsp), %rax
	movq	%rax, 125808(%rsp)
	movq	32696(%rsp), %rax
	movq	%rax, 125816(%rsp)
	movq	32704(%rsp), %rax
	movq	%rax, 125824(%rsp)
	movq	32712(%rsp), %rax
	movq	%rax, 125832(%rsp)
	movq	32720(%rsp), %rax
	movq	%rax, 125840(%rsp)
	movq	32728(%rsp), %rax
	movq	%rax, 125848(%rsp)
	movq	32736(%rsp), %rax
	movq	%rax, 125856(%rsp)
	movq	32744(%rsp), %rax
	movq	%rax, 125864(%rsp)
	movq	32752(%rsp), %rax
	movq	%rax, 125872(%rsp)
	movq	32760(%rsp), %rax
	movq	%rax, 125880(%rsp)
	movq	32768(%rsp), %rax
	movq	%rax, 125888(%rsp)
	movq	32776(%rsp), %rax
	movq	%rax, 125896(%rsp)
	movq	32784(%rsp), %rax
	movq	%rax, 125904(%rsp)
	movq	32792(%rsp), %rax
	movq	%rax, 125912(%rsp)
	movq	32800(%rsp), %rax
	movq	%rax, 125920(%rsp)
	movq	32808(%rsp), %rax
	movq	%rax, 125928(%rsp)
	movq	32816(%rsp), %rax
	movq	%rax, 125936(%rsp)
	movq	32824(%rsp), %rax
	movq	%rax, 125944(%rsp)
	movq	32832(%rsp), %rax
	movq	%rax, 125952(%rsp)
	movq	32840(%rsp), %rax
	movq	%rax, 125960(%rsp)
	movq	32848(%rsp), %rax
	movq	%rax, 125968(%rsp)
	movq	32856(%rsp), %rax
	movq	%rax, 125976(%rsp)
	movq	32864(%rsp), %rax
	movq	%rax, 125984(%rsp)
	movq	32872(%rsp), %rax
	movq	%rax, 125992(%rsp)
	movq	32880(%rsp), %rax
	movq	%rax, 126000(%rsp)
	movq	32888(%rsp), %rax
	movq	%rax, 126008(%rsp)
	movq	32896(%rsp), %rax
	movq	%rax, 126016(%rsp)
	movq	32904(%rsp), %rax
	movq	%rax, 126024(%rsp)
	movq	32912(%rsp), %rax
	movq	%rax, 126032(%rsp)
	movq	32920(%rsp), %rax
	movq	%rax, 126040(%rsp)
	movq	32928(%rsp), %rax
	movq	%rax, 126048(%rsp)
	movq	32936(%rsp), %rax
	movq	%rax, 126056(%rsp)
	movq	32944(%rsp), %rax
	movq	%rax, 126064(%rsp)
	movq	32952(%rsp), %rax
	movq	%rax, 126072(%rsp)
	movq	32960(%rsp), %rax
	movq	%rax, 126080(%rsp)
	movq	32968(%rsp), %rax
	movq	%rax, 126088(%rsp)
	movq	32976(%rsp), %rax
	movq	%rax, 126096(%rsp)
	movq	32984(%rsp), %rax
	movq	%rax, 126104(%rsp)
	movq	32992(%rsp), %rax
	movq	%rax, 126112(%rsp)
	movq	33000(%rsp), %rax
	movq	%rax, 126120(%rsp)
	movq	33008(%rsp), %rax
	movq	%rax, 126128(%rsp)
	movq	33016(%rsp), %rax
	movq	%rax, 126136(%rsp)
	movq	33024(%rsp), %rax
	movq	%rax, 126144(%rsp)
	movq	33032(%rsp), %rax
	movq	%rax, 126152(%rsp)
	movq	33040(%rsp), %rax
	movq	%rax, 126160(%rsp)
	movq	33048(%rsp), %rax
	movq	%rax, 126168(%rsp)
	movq	33056(%rsp), %rax
	movq	%rax, 126176(%rsp)
	movq	33064(%rsp), %rax
	movq	%rax, 126184(%rsp)
	movq	33072(%rsp), %rax
	movq	%rax, 126192(%rsp)
	movq	33080(%rsp), %rax
	movq	%rax, 126200(%rsp)
	movq	33088(%rsp), %rax
	movq	%rax, 126208(%rsp)
	movq	33096(%rsp), %rax
	movq	%rax, 126216(%rsp)
	movq	33104(%rsp), %rax
	movq	%rax, 126224(%rsp)
	movq	33112(%rsp), %rax
	movq	%rax, 126232(%rsp)
	movq	33120(%rsp), %rax
	movq	%rax, 126240(%rsp)
	movq	33128(%rsp), %rax
	movq	%rax, 126248(%rsp)
	movq	33136(%rsp), %rax
	movq	%rax, 126256(%rsp)
	movq	33144(%rsp), %rax
	movq	%rax, 126264(%rsp)
	movq	33152(%rsp), %rax
	movq	%rax, 126272(%rsp)
	movq	33160(%rsp), %rax
	movq	%rax, 126280(%rsp)
	movq	33168(%rsp), %rax
	movq	%rax, 126288(%rsp)
	movq	33176(%rsp), %rax
	movq	%rax, 126296(%rsp)
	movq	33184(%rsp), %rax
	movq	%rax, 126304(%rsp)
	movq	33192(%rsp), %rax
	movq	%rax, 126312(%rsp)
	movq	33200(%rsp), %rax
	movq	%rax, 126320(%rsp)
	movq	33208(%rsp), %rax
	movq	%rax, 126328(%rsp)
	movq	33216(%rsp), %rax
	movq	%rax, 126336(%rsp)
	movq	33224(%rsp), %rax
	movq	%rax, 126344(%rsp)
	movq	33232(%rsp), %rax
	movq	%rax, 126352(%rsp)
	movq	33240(%rsp), %rax
	movq	%rax, 126360(%rsp)
	movq	33248(%rsp), %rax
	movq	%rax, 126368(%rsp)
	movq	33256(%rsp), %rax
	movq	%rax, 126376(%rsp)
	movq	33264(%rsp), %rax
	movq	%rax, 126384(%rsp)
	movq	33272(%rsp), %rax
	movq	%rax, 126392(%rsp)
	movq	33280(%rsp), %rax
	movq	%rax, 126400(%rsp)
	movq	33288(%rsp), %rax
	movq	%rax, 126408(%rsp)
	movq	33296(%rsp), %rax
	movq	%rax, 126416(%rsp)
	movq	33304(%rsp), %rax
	movq	%rax, 126424(%rsp)
	movq	33312(%rsp), %rax
	movq	%rax, 126432(%rsp)
	movq	33320(%rsp), %rax
	movq	%rax, 126440(%rsp)
	movq	33328(%rsp), %rax
	movq	%rax, 126448(%rsp)
	movq	33336(%rsp), %rax
	movq	%rax, 126456(%rsp)
	movq	33344(%rsp), %rax
	movq	%rax, 126464(%rsp)
	movq	33352(%rsp), %rax
	movq	%rax, 126472(%rsp)
	movq	33360(%rsp), %rax
	movq	%rax, 126480(%rsp)
	movq	33368(%rsp), %rax
	movq	%rax, 126488(%rsp)
	movq	33376(%rsp), %rax
	movq	%rax, 126496(%rsp)
	movq	33384(%rsp), %rax
	movq	%rax, 126504(%rsp)
	movq	33392(%rsp), %rax
	movq	%rax, 126512(%rsp)
	movq	33400(%rsp), %rax
	movq	%rax, 126520(%rsp)
	movq	33408(%rsp), %rax
	movq	%rax, 126528(%rsp)
	movq	33416(%rsp), %rax
	movq	%rax, 126536(%rsp)
	movq	33424(%rsp), %rax
	movq	%rax, 126544(%rsp)
	movq	33432(%rsp), %rax
	movq	%rax, 126552(%rsp)
	movq	33440(%rsp), %rax
	movq	%rax, 126560(%rsp)
	movq	33448(%rsp), %rax
	movq	%rax, 126568(%rsp)
	movq	33456(%rsp), %rax
	movq	%rax, 126576(%rsp)
	movq	33464(%rsp), %rax
	movq	%rax, 126584(%rsp)
	movq	33472(%rsp), %rax
	movq	%rax, 126592(%rsp)
	movq	33480(%rsp), %rax
	movq	%rax, 126600(%rsp)
	movq	33488(%rsp), %rax
	movq	%rax, 126608(%rsp)
	movq	33496(%rsp), %rax
	movq	%rax, 126616(%rsp)
	movq	33504(%rsp), %rax
	movq	%rax, 126624(%rsp)
	movq	33512(%rsp), %rax
	movq	%rax, 126632(%rsp)
	movq	33520(%rsp), %rax
	movq	%rax, 126640(%rsp)
	movq	33528(%rsp), %rax
	movq	%rax, 126648(%rsp)
	movq	33536(%rsp), %rax
	movq	%rax, 126656(%rsp)
	movq	33544(%rsp), %rax
	movq	%rax, 126664(%rsp)
	movq	33552(%rsp), %rax
	movq	%rax, 126672(%rsp)
	movq	33560(%rsp), %rax
	movq	%rax, 126680(%rsp)
	movq	33568(%rsp), %rax
	movq	%rax, 126688(%rsp)
	movq	33576(%rsp), %rax
	movq	%rax, 126696(%rsp)
	movq	33584(%rsp), %rax
	movq	%rax, 126704(%rsp)
	movq	33592(%rsp), %rax
	movq	%rax, 126712(%rsp)
	movq	33600(%rsp), %rax
	movq	%rax, 126720(%rsp)
	movq	33608(%rsp), %rax
	movq	%rax, 126728(%rsp)
	movq	33616(%rsp), %rax
	movq	%rax, 126736(%rsp)
	movq	33624(%rsp), %rax
	movq	%rax, 126744(%rsp)
	movq	33632(%rsp), %rax
	movq	%rax, 126752(%rsp)
	movq	33640(%rsp), %rax
	movq	%rax, 126760(%rsp)
	movq	33648(%rsp), %rax
	movq	%rax, 126768(%rsp)
	movq	33656(%rsp), %rax
	movq	%rax, 126776(%rsp)
	movq	33664(%rsp), %rax
	movq	%rax, 126784(%rsp)
	movq	33672(%rsp), %rax
	movq	%rax, 126792(%rsp)
	movq	33680(%rsp), %rax
	movq	%rax, 126800(%rsp)
	movq	33688(%rsp), %rax
	movq	%rax, 126808(%rsp)
	movq	33696(%rsp), %rax
	movq	%rax, 126816(%rsp)
	movq	33704(%rsp), %rax
	movq	%rax, 126824(%rsp)
	movq	33712(%rsp), %rax
	movq	%rax, 126832(%rsp)
	movq	33720(%rsp), %rax
	movq	%rax, 126840(%rsp)
	movq	33728(%rsp), %rax
	movq	%rax, 126848(%rsp)
	movq	33736(%rsp), %rax
	movq	%rax, 126856(%rsp)
	movq	33744(%rsp), %rax
	movq	%rax, 126864(%rsp)
	movq	33752(%rsp), %rax
	movq	%rax, 126872(%rsp)
	movq	33760(%rsp), %rax
	movq	%rax, 126880(%rsp)
	movq	33768(%rsp), %rax
	movq	%rax, 126888(%rsp)
	movq	33776(%rsp), %rax
	movq	%rax, 126896(%rsp)
	movq	33784(%rsp), %rax
	movq	%rax, 126904(%rsp)
	movq	33792(%rsp), %rax
	movq	%rax, 126912(%rsp)
	movq	33800(%rsp), %rax
	movq	%rax, 126920(%rsp)
	movq	33808(%rsp), %rax
	movq	%rax, 126928(%rsp)
	movq	33816(%rsp), %rax
	movq	%rax, 126936(%rsp)
	movq	33824(%rsp), %rax
	movq	%rax, 126944(%rsp)
	movq	33832(%rsp), %rax
	movq	%rax, 126952(%rsp)
	movq	33840(%rsp), %rax
	movq	%rax, 126960(%rsp)
	movq	33848(%rsp), %rax
	movq	%rax, 126968(%rsp)
	movq	33856(%rsp), %rax
	movq	%rax, 126976(%rsp)
	movq	33864(%rsp), %rax
	movq	%rax, 126984(%rsp)
	movq	33872(%rsp), %rax
	movq	%rax, 126992(%rsp)
	movq	33880(%rsp), %rax
	movq	%rax, 127000(%rsp)
	movq	33888(%rsp), %rax
	movq	%rax, 127008(%rsp)
	movq	33896(%rsp), %rax
	movq	%rax, 127016(%rsp)
	movq	33904(%rsp), %rax
	movq	%rax, 127024(%rsp)
	movq	33912(%rsp), %rax
	movq	%rax, 127032(%rsp)
	movq	33920(%rsp), %rax
	movq	%rax, 127040(%rsp)
	movq	33928(%rsp), %rax
	movq	%rax, 127048(%rsp)
	movq	33936(%rsp), %rax
	movq	%rax, 127056(%rsp)
	movq	33944(%rsp), %rax
	movq	%rax, 127064(%rsp)
	movq	33952(%rsp), %rax
	movq	%rax, 127072(%rsp)
	movq	33960(%rsp), %rax
	movq	%rax, 127080(%rsp)
	movq	33968(%rsp), %rax
	movq	%rax, 127088(%rsp)
	movq	33976(%rsp), %rax
	movq	%rax, 127096(%rsp)
	movq	33984(%rsp), %rax
	movq	%rax, 127104(%rsp)
	movq	33992(%rsp), %rax
	movq	%rax, 127112(%rsp)
	movq	34000(%rsp), %rax
	movq	%rax, 127120(%rsp)
	movq	34008(%rsp), %rax
	movq	%rax, 127128(%rsp)
	movq	34016(%rsp), %rax
	movq	%rax, 127136(%rsp)
	movq	34024(%rsp), %rax
	movq	%rax, 127144(%rsp)
	movq	34032(%rsp), %rax
	movq	%rax, 127152(%rsp)
	movq	34040(%rsp), %rax
	movq	%rax, 127160(%rsp)
	movq	34048(%rsp), %rax
	movq	%rax, 127168(%rsp)
	movq	34056(%rsp), %rax
	movq	%rax, 127176(%rsp)
	movq	34064(%rsp), %rax
	movq	%rax, 127184(%rsp)
	movq	34072(%rsp), %rax
	movq	%rax, 127192(%rsp)
	movq	34080(%rsp), %rax
	movq	%rax, 127200(%rsp)
	movq	34088(%rsp), %rax
	movq	%rax, 127208(%rsp)
	movq	34096(%rsp), %rax
	movq	%rax, 127216(%rsp)
	movq	34104(%rsp), %rax
	movq	%rax, 127224(%rsp)
	movq	34112(%rsp), %rax
	movq	%rax, 127232(%rsp)
	movq	34120(%rsp), %rax
	movq	%rax, 127240(%rsp)
	movq	34128(%rsp), %rax
	movq	%rax, 127248(%rsp)
	movq	34136(%rsp), %rax
	movq	%rax, 127256(%rsp)
	movq	34144(%rsp), %rax
	movq	%rax, 127264(%rsp)
	movq	34152(%rsp), %rax
	movq	%rax, 127272(%rsp)
	movq	34160(%rsp), %rax
	movq	%rax, 127280(%rsp)
	movq	34168(%rsp), %rax
	movq	%rax, 127288(%rsp)
	movq	34176(%rsp), %rax
	movq	%rax, 127296(%rsp)
	movq	34184(%rsp), %rax
	movq	%rax, 127304(%rsp)
	movq	34192(%rsp), %rax
	movq	%rax, 127312(%rsp)
	movq	34200(%rsp), %rax
	movq	%rax, 127320(%rsp)
	movq	34208(%rsp), %rax
	movq	%rax, 127328(%rsp)
	movq	34216(%rsp), %rax
	movq	%rax, 127336(%rsp)
	movq	34224(%rsp), %rax
	movq	%rax, 127344(%rsp)
	movq	34232(%rsp), %rax
	movq	%rax, 127352(%rsp)
	movq	34240(%rsp), %rax
	movq	%rax, 127360(%rsp)
	movq	34248(%rsp), %rax
	movq	%rax, 127368(%rsp)
	movq	34256(%rsp), %rax
	movq	%rax, 127376(%rsp)
	movq	34264(%rsp), %rax
	movq	%rax, 127384(%rsp)
	movq	34272(%rsp), %rax
	movq	%rax, 127392(%rsp)
	movq	34280(%rsp), %rax
	movq	%rax, 127400(%rsp)
	movq	34288(%rsp), %rax
	movq	%rax, 127408(%rsp)
	movq	34296(%rsp), %rax
	movq	%rax, 127416(%rsp)
	movq	34304(%rsp), %rax
	movq	%rax, 127424(%rsp)
	movq	34312(%rsp), %rax
	movq	%rax, 127432(%rsp)
	movq	34320(%rsp), %rax
	movq	%rax, 127440(%rsp)
	movq	34328(%rsp), %rax
	movq	%rax, 127448(%rsp)
	movq	34336(%rsp), %rax
	movq	%rax, 127456(%rsp)
	movq	34344(%rsp), %rax
	movq	%rax, 127464(%rsp)
	movq	34352(%rsp), %rax
	movq	%rax, 127472(%rsp)
	movq	34360(%rsp), %rax
	movq	%rax, 127480(%rsp)
	movq	34368(%rsp), %rax
	movq	%rax, 127488(%rsp)
	movq	34376(%rsp), %rax
	movq	%rax, 127496(%rsp)
	movq	34384(%rsp), %rax
	movq	%rax, 127504(%rsp)
	movq	34392(%rsp), %rax
	movq	%rax, 127512(%rsp)
	movq	34400(%rsp), %rax
	movq	%rax, 127520(%rsp)
	movq	34408(%rsp), %rax
	movq	%rax, 127528(%rsp)
	movq	34416(%rsp), %rax
	movq	%rax, 127536(%rsp)
	movq	34424(%rsp), %rax
	movq	%rax, 127544(%rsp)
	movq	34432(%rsp), %rax
	movq	%rax, 127552(%rsp)
	movq	34440(%rsp), %rax
	movq	%rax, 127560(%rsp)
	movq	34448(%rsp), %rax
	movq	%rax, 127568(%rsp)
	movq	34456(%rsp), %rax
	movq	%rax, 127576(%rsp)
	movq	34464(%rsp), %rax
	movq	%rax, 127584(%rsp)
	movq	34472(%rsp), %rax
	movq	%rax, 127592(%rsp)
	movq	34480(%rsp), %rax
	movq	%rax, 127600(%rsp)
	movq	34488(%rsp), %rax
	movq	%rax, 127608(%rsp)
	movq	34496(%rsp), %rax
	movq	%rax, 127616(%rsp)
	movq	34504(%rsp), %rax
	movq	%rax, 127624(%rsp)
	movq	34512(%rsp), %rax
	movq	%rax, 127632(%rsp)
	movq	34520(%rsp), %rax
	movq	%rax, 127640(%rsp)
	movq	34528(%rsp), %rax
	movq	%rax, 127648(%rsp)
	movq	34536(%rsp), %rax
	movq	%rax, 127656(%rsp)
	movq	34544(%rsp), %rax
	movq	%rax, 127664(%rsp)
	movq	34552(%rsp), %rax
	movq	%rax, 127672(%rsp)
	movq	34560(%rsp), %rax
	movq	%rax, 127680(%rsp)
	movq	34568(%rsp), %rax
	movq	%rax, 127688(%rsp)
	movq	34576(%rsp), %rax
	movq	%rax, 127696(%rsp)
	movq	34584(%rsp), %rax
	movq	%rax, 127704(%rsp)
	movq	34592(%rsp), %rax
	movq	%rax, 127712(%rsp)
	movq	34600(%rsp), %rax
	movq	%rax, 127720(%rsp)
	movq	34608(%rsp), %rax
	movq	%rax, 127728(%rsp)
	movq	34616(%rsp), %rax
	movq	%rax, 127736(%rsp)
	movq	34624(%rsp), %rax
	movq	%rax, 127744(%rsp)
	movq	34632(%rsp), %rax
	movq	%rax, 127752(%rsp)
	movq	34640(%rsp), %rax
	movq	%rax, 127760(%rsp)
	movq	34648(%rsp), %rax
	movq	%rax, 127768(%rsp)
	movq	34656(%rsp), %rax
	movq	%rax, 127776(%rsp)
	movq	34664(%rsp), %rax
	movq	%rax, 127784(%rsp)
	movq	34672(%rsp), %rax
	movq	%rax, 127792(%rsp)
	movq	34680(%rsp), %rax
	movq	%rax, 127800(%rsp)
	movq	34688(%rsp), %rax
	movq	%rax, 127808(%rsp)
	movq	34696(%rsp), %rax
	movq	%rax, 127816(%rsp)
	movq	34704(%rsp), %rax
	movq	%rax, 127824(%rsp)
	movq	34712(%rsp), %rax
	movq	%rax, 127832(%rsp)
	movq	34720(%rsp), %rax
	movq	%rax, 127840(%rsp)
	movq	34728(%rsp), %rax
	movq	%rax, 127848(%rsp)
	movq	34736(%rsp), %rax
	movq	%rax, 127856(%rsp)
	movq	34744(%rsp), %rax
	movq	%rax, 127864(%rsp)
	movq	34752(%rsp), %rax
	movq	%rax, 127872(%rsp)
	movq	34760(%rsp), %rax
	movq	%rax, 127880(%rsp)
	movq	34768(%rsp), %rax
	movq	%rax, 127888(%rsp)
	movq	34776(%rsp), %rax
	movq	%rax, 127896(%rsp)
	movq	34784(%rsp), %rax
	movq	%rax, 127904(%rsp)
	movq	34792(%rsp), %rax
	movq	%rax, 127912(%rsp)
	movq	34800(%rsp), %rax
	movq	%rax, 127920(%rsp)
	movq	34808(%rsp), %rax
	movq	%rax, 127928(%rsp)
	movq	34816(%rsp), %rax
	movq	%rax, 127936(%rsp)
	movq	34824(%rsp), %rax
	movq	%rax, 127944(%rsp)
	movq	34832(%rsp), %rax
	movq	%rax, 127952(%rsp)
	movq	34840(%rsp), %rax
	movq	%rax, 127960(%rsp)
	movq	34848(%rsp), %rax
	movq	%rax, 127968(%rsp)
	movq	34856(%rsp), %rax
	movq	%rax, 127976(%rsp)
	movq	34864(%rsp), %rax
	movq	%rax, 127984(%rsp)
	movq	34872(%rsp), %rax
	movq	%rax, 127992(%rsp)
	movq	34880(%rsp), %rax
	movq	%rax, 128000(%rsp)
	movq	34888(%rsp), %rax
	movq	%rax, 128008(%rsp)
	movq	34896(%rsp), %rax
	movq	%rax, 128016(%rsp)
	movq	34904(%rsp), %rax
	movq	%rax, 128024(%rsp)
	movq	34912(%rsp), %rax
	movq	%rax, 128032(%rsp)
	movq	34920(%rsp), %rax
	movq	%rax, 128040(%rsp)
	movq	34928(%rsp), %rax
	movq	%rax, 128048(%rsp)
	movq	34936(%rsp), %rax
	movq	%rax, 128056(%rsp)
	movq	34944(%rsp), %rax
	movq	%rax, 128064(%rsp)
	movq	34952(%rsp), %rax
	movq	%rax, 128072(%rsp)
	movq	34960(%rsp), %rax
	movq	%rax, 128080(%rsp)
	movq	34968(%rsp), %rax
	movq	%rax, 128088(%rsp)
	movq	34976(%rsp), %rax
	movq	%rax, 128096(%rsp)
	movq	34984(%rsp), %rax
	movq	%rax, 128104(%rsp)
	movq	34992(%rsp), %rax
	movq	%rax, 128112(%rsp)
	movq	35000(%rsp), %rax
	movq	%rax, 128120(%rsp)
	movq	35008(%rsp), %rax
	movq	%rax, 128128(%rsp)
	movq	35016(%rsp), %rax
	movq	%rax, 128136(%rsp)
	movq	35024(%rsp), %rax
	movq	%rax, 128144(%rsp)
	movq	35032(%rsp), %rax
	movq	%rax, 128152(%rsp)
	movq	35040(%rsp), %rax
	movq	%rax, 128160(%rsp)
	movq	35048(%rsp), %rax
	movq	%rax, 128168(%rsp)
	movq	35056(%rsp), %rax
	movq	%rax, 128176(%rsp)
	movq	35064(%rsp), %rax
	movq	%rax, 128184(%rsp)
	movq	35072(%rsp), %rax
	movq	%rax, 128192(%rsp)
	movq	35080(%rsp), %rax
	movq	%rax, 128200(%rsp)
	movq	35088(%rsp), %rax
	movq	%rax, 128208(%rsp)
	movq	35096(%rsp), %rax
	movq	%rax, 128216(%rsp)
	movq	35104(%rsp), %rax
	movq	%rax, 128224(%rsp)
	movq	35112(%rsp), %rax
	movq	%rax, 128232(%rsp)
	movq	35120(%rsp), %rax
	movq	%rax, 128240(%rsp)
	movq	35128(%rsp), %rax
	movq	%rax, 128248(%rsp)
	movq	35136(%rsp), %rax
	movq	%rax, 128256(%rsp)
	movq	35144(%rsp), %rax
	movq	%rax, 128264(%rsp)
	movq	35152(%rsp), %rax
	movq	%rax, 128272(%rsp)
	movq	35160(%rsp), %rax
	movq	%rax, 128280(%rsp)
	movq	35168(%rsp), %rax
	movq	%rax, 128288(%rsp)
	movq	35176(%rsp), %rax
	movq	%rax, 128296(%rsp)
	movq	35184(%rsp), %rax
	movq	%rax, 128304(%rsp)
	movq	35192(%rsp), %rax
	movq	%rax, 128312(%rsp)
	movq	35200(%rsp), %rax
	movq	%rax, 128320(%rsp)
	movq	35208(%rsp), %rax
	movq	%rax, 128328(%rsp)
	movq	35216(%rsp), %rax
	movq	%rax, 128336(%rsp)
	movq	35224(%rsp), %rax
	movq	%rax, 128344(%rsp)
	movq	35232(%rsp), %rax
	movq	%rax, 128352(%rsp)
	movq	35240(%rsp), %rax
	movq	%rax, 128360(%rsp)
	movq	35248(%rsp), %rax
	movq	%rax, 128368(%rsp)
	movq	35256(%rsp), %rax
	movq	%rax, 128376(%rsp)
	movq	35264(%rsp), %rax
	movq	%rax, 128384(%rsp)
	movq	35272(%rsp), %rax
	movq	%rax, 128392(%rsp)
	movq	35280(%rsp), %rax
	movq	%rax, 128400(%rsp)
	movq	35288(%rsp), %rax
	movq	%rax, 128408(%rsp)
	movq	35296(%rsp), %rax
	movq	%rax, 128416(%rsp)
	movq	35304(%rsp), %rax
	movq	%rax, 128424(%rsp)
	movq	35312(%rsp), %rax
	movq	%rax, 128432(%rsp)
	movq	35320(%rsp), %rax
	movq	%rax, 128440(%rsp)
	movq	35328(%rsp), %rax
	movq	%rax, 128448(%rsp)
	movq	35336(%rsp), %rax
	movq	%rax, 128456(%rsp)
	movq	35344(%rsp), %rax
	movq	%rax, 128464(%rsp)
	movq	35352(%rsp), %rax
	movq	%rax, 128472(%rsp)
	movq	35360(%rsp), %rax
	movq	%rax, 128480(%rsp)
	movq	35368(%rsp), %rax
	movq	%rax, 128488(%rsp)
	movq	35376(%rsp), %rax
	movq	%rax, 128496(%rsp)
	movq	35384(%rsp), %rax
	movq	%rax, 128504(%rsp)
	movq	35392(%rsp), %rax
	movq	%rax, 128512(%rsp)
	movq	35400(%rsp), %rax
	movq	%rax, 128520(%rsp)
	movq	35408(%rsp), %rax
	movq	%rax, 128528(%rsp)
	movq	35416(%rsp), %rax
	movq	%rax, 128536(%rsp)
	movq	35424(%rsp), %rax
	movq	%rax, 128544(%rsp)
	movq	35432(%rsp), %rax
	movq	%rax, 128552(%rsp)
	movq	35440(%rsp), %rax
	movq	%rax, 128560(%rsp)
	movq	35448(%rsp), %rax
	movq	%rax, 128568(%rsp)
	movq	35456(%rsp), %rax
	movq	%rax, 128576(%rsp)
	movq	35464(%rsp), %rax
	movq	%rax, 128584(%rsp)
	movq	35472(%rsp), %rax
	movq	%rax, 128592(%rsp)
	movq	35480(%rsp), %rax
	movq	%rax, 128600(%rsp)
	movq	35488(%rsp), %rax
	movq	%rax, 128608(%rsp)
	movq	35496(%rsp), %rax
	movq	%rax, 128616(%rsp)
	movq	35504(%rsp), %rax
	movq	%rax, 128624(%rsp)
	movq	35512(%rsp), %rax
	movq	%rax, 128632(%rsp)
	movq	35520(%rsp), %rax
	movq	%rax, 128640(%rsp)
	movq	35528(%rsp), %rax
	movq	%rax, 128648(%rsp)
	movq	35536(%rsp), %rax
	movq	%rax, 128656(%rsp)
	movq	35544(%rsp), %rax
	movq	%rax, 128664(%rsp)
	movq	35552(%rsp), %rax
	movq	%rax, 128672(%rsp)
	movq	35560(%rsp), %rax
	movq	%rax, 128680(%rsp)
	movq	35568(%rsp), %rax
	movq	%rax, 128688(%rsp)
	movq	35576(%rsp), %rax
	movq	%rax, 128696(%rsp)
	movq	35584(%rsp), %rax
	movq	%rax, 128704(%rsp)
	movq	35592(%rsp), %rax
	movq	%rax, 128712(%rsp)
	movq	35600(%rsp), %rax
	movq	%rax, 128720(%rsp)
	movq	35608(%rsp), %rax
	movq	%rax, 128728(%rsp)
	movq	35616(%rsp), %rax
	movq	%rax, 128736(%rsp)
	movq	35624(%rsp), %rax
	movq	%rax, 128744(%rsp)
	movq	35632(%rsp), %rax
	movq	%rax, 128752(%rsp)
	movq	35640(%rsp), %rax
	movq	%rax, 128760(%rsp)
	movq	35648(%rsp), %rax
	movq	%rax, 128768(%rsp)
	movq	35656(%rsp), %rax
	movq	%rax, 128776(%rsp)
	movq	35664(%rsp), %rax
	movq	%rax, 128784(%rsp)
	movq	35672(%rsp), %rax
	movq	%rax, 128792(%rsp)
	movq	35680(%rsp), %rax
	movq	%rax, 128800(%rsp)
	movq	35688(%rsp), %rax
	movq	%rax, 128808(%rsp)
	movq	35696(%rsp), %rax
	movq	%rax, 128816(%rsp)
	movq	35704(%rsp), %rax
	movq	%rax, 128824(%rsp)
	movq	35712(%rsp), %rax
	movq	%rax, 128832(%rsp)
	movq	35720(%rsp), %rax
	movq	%rax, 128840(%rsp)
	movq	35728(%rsp), %rax
	movq	%rax, 128848(%rsp)
	movq	35736(%rsp), %rax
	movq	%rax, 128856(%rsp)
	movq	35744(%rsp), %rax
	movq	%rax, 128864(%rsp)
	movq	35752(%rsp), %rax
	movq	%rax, 128872(%rsp)
	movq	35760(%rsp), %rax
	movq	%rax, 128880(%rsp)
	movq	35768(%rsp), %rax
	movq	%rax, 128888(%rsp)
	movq	35776(%rsp), %rax
	movq	%rax, 128896(%rsp)
	movq	35784(%rsp), %rax
	movq	%rax, 128904(%rsp)
	movq	35792(%rsp), %rax
	movq	%rax, 128912(%rsp)
	movq	35800(%rsp), %rax
	movq	%rax, 128920(%rsp)
	movq	35808(%rsp), %rax
	movq	%rax, 128928(%rsp)
	movq	35816(%rsp), %rax
	movq	%rax, 128936(%rsp)
	movq	35824(%rsp), %rax
	movq	%rax, 128944(%rsp)
	movq	35832(%rsp), %rax
	movq	%rax, 128952(%rsp)
	movq	35840(%rsp), %rax
	movq	%rax, 128960(%rsp)
	movq	35848(%rsp), %rax
	movq	%rax, 128968(%rsp)
	movq	35856(%rsp), %rax
	movq	%rax, 128976(%rsp)
	movq	35864(%rsp), %rax
	movq	%rax, 128984(%rsp)
	movq	35872(%rsp), %rax
	movq	%rax, 128992(%rsp)
	movq	35880(%rsp), %rax
	movq	%rax, 129000(%rsp)
	movq	35888(%rsp), %rax
	movq	%rax, 129008(%rsp)
	movq	35896(%rsp), %rax
	movq	%rax, 129016(%rsp)
	movq	35904(%rsp), %rax
	movq	%rax, 129024(%rsp)
	movq	35912(%rsp), %rax
	movq	%rax, 129032(%rsp)
	movq	35920(%rsp), %rax
	movq	%rax, 129040(%rsp)
	movq	35928(%rsp), %rax
	movq	%rax, 129048(%rsp)
	movq	35936(%rsp), %rax
	movq	%rax, 129056(%rsp)
	movq	35944(%rsp), %rax
	movq	%rax, 129064(%rsp)
	movq	35952(%rsp), %rax
	movq	%rax, 129072(%rsp)
	movq	35960(%rsp), %rax
	movq	%rax, 129080(%rsp)
	movq	35968(%rsp), %rax
	movq	%rax, 129088(%rsp)
	movq	35976(%rsp), %rax
	movq	%rax, 129096(%rsp)
	movq	35984(%rsp), %rax
	movq	%rax, 129104(%rsp)
	movq	35992(%rsp), %rax
	movq	%rax, 129112(%rsp)
	movq	36000(%rsp), %rax
	movq	%rax, 129120(%rsp)
	movq	36008(%rsp), %rax
	movq	%rax, 129128(%rsp)
	movq	36016(%rsp), %rax
	movq	%rax, 129136(%rsp)
	movq	36024(%rsp), %rax
	movq	%rax, 129144(%rsp)
	movq	36032(%rsp), %rax
	movq	%rax, 129152(%rsp)
	movq	36040(%rsp), %rax
	movq	%rax, 129160(%rsp)
	movq	36048(%rsp), %rax
	movq	%rax, 129168(%rsp)
	movq	36056(%rsp), %rax
	movq	%rax, 129176(%rsp)
	movq	36064(%rsp), %rax
	movq	%rax, 129184(%rsp)
	movq	36072(%rsp), %rax
	movq	%rax, 129192(%rsp)
	movq	36080(%rsp), %rax
	movq	%rax, 129200(%rsp)
	movq	36088(%rsp), %rax
	movq	%rax, 129208(%rsp)
	movq	36096(%rsp), %rax
	movq	%rax, 129216(%rsp)
	movq	36104(%rsp), %rax
	movq	%rax, 129224(%rsp)
	movq	36112(%rsp), %rax
	movq	%rax, 129232(%rsp)
	movq	36120(%rsp), %rax
	movq	%rax, 129240(%rsp)
	movq	36128(%rsp), %rax
	movq	%rax, 129248(%rsp)
	movq	36136(%rsp), %rax
	movq	%rax, 129256(%rsp)
	movq	36144(%rsp), %rax
	movq	%rax, 129264(%rsp)
	movq	36152(%rsp), %rax
	movq	%rax, 129272(%rsp)
	movq	36160(%rsp), %rax
	movq	%rax, 129280(%rsp)
	movq	36168(%rsp), %rax
	movq	%rax, 129288(%rsp)
	movq	36176(%rsp), %rax
	movq	%rax, 129296(%rsp)
	movq	36184(%rsp), %rax
	movq	%rax, 129304(%rsp)
	movq	36192(%rsp), %rax
	movq	%rax, 129312(%rsp)
	movq	36200(%rsp), %rax
	movq	%rax, 129320(%rsp)
	movq	36208(%rsp), %rax
	movq	%rax, 129328(%rsp)
	movq	36216(%rsp), %rax
	movq	%rax, 129336(%rsp)
	movq	36224(%rsp), %rax
	movq	%rax, 129344(%rsp)
	movq	36232(%rsp), %rax
	movq	%rax, 129352(%rsp)
	movq	36240(%rsp), %rax
	movq	%rax, 129360(%rsp)
	movq	36248(%rsp), %rax
	movq	%rax, 129368(%rsp)
	movq	36256(%rsp), %rax
	movq	%rax, 129376(%rsp)
	movq	36264(%rsp), %rax
	movq	%rax, 129384(%rsp)
	movq	36272(%rsp), %rax
	movq	%rax, 129392(%rsp)
	movq	36280(%rsp), %rax
	movq	%rax, 129400(%rsp)
	movq	36288(%rsp), %rax
	movq	%rax, 129408(%rsp)
	movq	36296(%rsp), %rax
	movq	%rax, 129416(%rsp)
	movq	36304(%rsp), %rax
	movq	%rax, 129424(%rsp)
	movq	36312(%rsp), %rax
	movq	%rax, 129432(%rsp)
	movq	36320(%rsp), %rax
	movq	%rax, 129440(%rsp)
	movq	36328(%rsp), %rax
	movq	%rax, 129448(%rsp)
	movq	36336(%rsp), %rax
	movq	%rax, 129456(%rsp)
	movq	36344(%rsp), %rax
	movq	%rax, 129464(%rsp)
	movq	36352(%rsp), %rax
	movq	%rax, 129472(%rsp)
	movq	36360(%rsp), %rax
	movq	%rax, 129480(%rsp)
	movq	36368(%rsp), %rax
	movq	%rax, 129488(%rsp)
	movq	36376(%rsp), %rax
	movq	%rax, 129496(%rsp)
	movq	36384(%rsp), %rax
	movq	%rax, 129504(%rsp)
	movq	36392(%rsp), %rax
	movq	%rax, 129512(%rsp)
	movq	36400(%rsp), %rax
	movq	%rax, 129520(%rsp)
	movq	36408(%rsp), %rax
	movq	%rax, 129528(%rsp)
	movq	36416(%rsp), %rax
	movq	%rax, 129536(%rsp)
	movq	36424(%rsp), %rax
	movq	%rax, 129544(%rsp)
	movq	36432(%rsp), %rax
	movq	%rax, 129552(%rsp)
	movq	36440(%rsp), %rax
	movq	%rax, 129560(%rsp)
	movq	36448(%rsp), %rax
	movq	%rax, 129568(%rsp)
	movq	36456(%rsp), %rax
	movq	%rax, 129576(%rsp)
	movq	36464(%rsp), %rax
	movq	%rax, 129584(%rsp)
	movq	36472(%rsp), %rax
	movq	%rax, 129592(%rsp)
	movq	36480(%rsp), %rax
	movq	%rax, 129600(%rsp)
	movq	36488(%rsp), %rax
	movq	%rax, 129608(%rsp)
	movq	36496(%rsp), %rax
	movq	%rax, 129616(%rsp)
	movq	36504(%rsp), %rax
	movq	%rax, 129624(%rsp)
	movq	36512(%rsp), %rax
	movq	%rax, 129632(%rsp)
	movq	36520(%rsp), %rax
	movq	%rax, 129640(%rsp)
	movq	36528(%rsp), %rax
	movq	%rax, 129648(%rsp)
	movq	36536(%rsp), %rax
	movq	%rax, 129656(%rsp)
	movq	36544(%rsp), %rax
	movq	%rax, 129664(%rsp)
	movq	36552(%rsp), %rax
	movq	%rax, 129672(%rsp)
	movq	36560(%rsp), %rax
	movq	%rax, 129680(%rsp)
	movq	36568(%rsp), %rax
	movq	%rax, 129688(%rsp)
	movq	36576(%rsp), %rax
	movq	%rax, 129696(%rsp)
	movq	36584(%rsp), %rax
	movq	%rax, 129704(%rsp)
	movq	36592(%rsp), %rax
	movq	%rax, 129712(%rsp)
	movq	36600(%rsp), %rax
	movq	%rax, 129720(%rsp)
	movq	36608(%rsp), %rax
	movq	%rax, 129728(%rsp)
	movq	36616(%rsp), %rax
	movq	%rax, 129736(%rsp)
	movq	36624(%rsp), %rax
	movq	%rax, 129744(%rsp)
	movq	36632(%rsp), %rax
	movq	%rax, 129752(%rsp)
	movq	36640(%rsp), %rax
	movq	%rax, 129760(%rsp)
	movq	36648(%rsp), %rax
	movq	%rax, 129768(%rsp)
	movq	36656(%rsp), %rax
	movq	%rax, 129776(%rsp)
	movq	36664(%rsp), %rax
	movq	%rax, 129784(%rsp)
	movq	36672(%rsp), %rax
	movq	%rax, 129792(%rsp)
	movq	36680(%rsp), %rax
	movq	%rax, 129800(%rsp)
	movq	36688(%rsp), %rax
	movq	%rax, 129808(%rsp)
	movq	36696(%rsp), %rax
	movq	%rax, 129816(%rsp)
	movq	36704(%rsp), %rax
	movq	%rax, 129824(%rsp)
	movq	36712(%rsp), %rax
	movq	%rax, 129832(%rsp)
	movq	36720(%rsp), %rax
	movq	%rax, 129840(%rsp)
	movq	36728(%rsp), %rax
	movq	%rax, 129848(%rsp)
	movq	36736(%rsp), %rax
	movq	%rax, 129856(%rsp)
	movq	36744(%rsp), %rax
	movq	%rax, 129864(%rsp)
	movq	36752(%rsp), %rax
	movq	%rax, 129872(%rsp)
	movq	36760(%rsp), %rax
	movq	%rax, 129880(%rsp)
	movq	36768(%rsp), %rax
	movq	%rax, 129888(%rsp)
	movq	36776(%rsp), %rax
	movq	%rax, 129896(%rsp)
	movq	36784(%rsp), %rax
	movq	%rax, 129904(%rsp)
	movq	36792(%rsp), %rax
	movq	%rax, 129912(%rsp)
	movq	36800(%rsp), %rax
	movq	%rax, 129920(%rsp)
	movq	36808(%rsp), %rax
	movq	%rax, 129928(%rsp)
	movq	36816(%rsp), %rax
	movq	%rax, 129936(%rsp)
	movq	36824(%rsp), %rax
	movq	%rax, 129944(%rsp)
	movq	36832(%rsp), %rax
	movq	%rax, 129952(%rsp)
	movq	36840(%rsp), %rax
	movq	%rax, 129960(%rsp)
	movq	36848(%rsp), %rax
	movq	%rax, 129968(%rsp)
	movq	36856(%rsp), %rax
	movq	%rax, 129976(%rsp)
	movq	36864(%rsp), %rax
	movq	%rax, 129984(%rsp)
	movq	36872(%rsp), %rax
	movq	%rax, 129992(%rsp)
	movq	36880(%rsp), %rax
	movq	%rax, 130000(%rsp)
	movq	36888(%rsp), %rax
	movq	%rax, 130008(%rsp)
	movq	36896(%rsp), %rax
	movq	%rax, 130016(%rsp)
	movq	36904(%rsp), %rax
	movq	%rax, 130024(%rsp)
	movq	36912(%rsp), %rax
	movq	%rax, 130032(%rsp)
	movq	36920(%rsp), %rax
	movq	%rax, 130040(%rsp)
	movq	36928(%rsp), %rax
	movq	%rax, 130048(%rsp)
	movq	36936(%rsp), %rax
	movq	%rax, 130056(%rsp)
	movq	36944(%rsp), %rax
	movq	%rax, 130064(%rsp)
	movq	36952(%rsp), %rax
	movq	%rax, 130072(%rsp)
	movq	36960(%rsp), %rax
	movq	%rax, 130080(%rsp)
	movq	36968(%rsp), %rax
	movq	%rax, 130088(%rsp)
	movq	36976(%rsp), %rax
	movq	%rax, 130096(%rsp)
	movq	36984(%rsp), %rax
	movq	%rax, 130104(%rsp)
	movq	36992(%rsp), %rax
	movq	%rax, 130112(%rsp)
	movq	37000(%rsp), %rax
	movq	%rax, 130120(%rsp)
	movq	37008(%rsp), %rax
	movq	%rax, 130128(%rsp)
	movq	37016(%rsp), %rax
	movq	%rax, 130136(%rsp)
	movq	37024(%rsp), %rax
	movq	%rax, 130144(%rsp)
	movq	37032(%rsp), %rax
	movq	%rax, 130152(%rsp)
	movq	37040(%rsp), %rax
	movq	%rax, 130160(%rsp)
	movq	37048(%rsp), %rax
	movq	%rax, 130168(%rsp)
	movq	37056(%rsp), %rax
	movq	%rax, 130176(%rsp)
	movq	37064(%rsp), %rax
	movq	%rax, 130184(%rsp)
	movq	37072(%rsp), %rax
	movq	%rax, 130192(%rsp)
	movq	37080(%rsp), %rax
	movq	%rax, 130200(%rsp)
	movq	37088(%rsp), %rax
	movq	%rax, 130208(%rsp)
	movq	37096(%rsp), %rax
	movq	%rax, 130216(%rsp)
	movq	37104(%rsp), %rax
	movq	%rax, 130224(%rsp)
	movq	37112(%rsp), %rax
	movq	%rax, 130232(%rsp)
	movq	37120(%rsp), %rax
	movq	%rax, 130240(%rsp)
	movq	37128(%rsp), %rax
	movq	%rax, 130248(%rsp)
	movq	37136(%rsp), %rax
	movq	%rax, 130256(%rsp)
	movq	37144(%rsp), %rax
	movq	%rax, 130264(%rsp)
	movq	37152(%rsp), %rax
	movq	%rax, 130272(%rsp)
	movq	37160(%rsp), %rax
	movq	%rax, 130280(%rsp)
	movq	37168(%rsp), %rax
	movq	%rax, 130288(%rsp)
	movq	37176(%rsp), %rax
	movq	%rax, 130296(%rsp)
	movq	37184(%rsp), %rax
	movq	%rax, 130304(%rsp)
	movq	37192(%rsp), %rax
	movq	%rax, 130312(%rsp)
	movq	37200(%rsp), %rax
	movq	%rax, 130320(%rsp)
	movq	37208(%rsp), %rax
	movq	%rax, 130328(%rsp)
	movq	37216(%rsp), %rax
	movq	%rax, 130336(%rsp)
	movq	37224(%rsp), %rax
	movq	%rax, 130344(%rsp)
	movq	37232(%rsp), %rax
	movq	%rax, 130352(%rsp)
	movq	37240(%rsp), %rax
	movq	%rax, 130360(%rsp)
	movq	37248(%rsp), %rax
	movq	%rax, 130368(%rsp)
	movq	37256(%rsp), %rax
	movq	%rax, 130376(%rsp)
	movq	37264(%rsp), %rax
	movq	%rax, 130384(%rsp)
	movq	37272(%rsp), %rax
	movq	%rax, 130392(%rsp)
	movq	37280(%rsp), %rax
	movq	%rax, 130400(%rsp)
	movq	37288(%rsp), %rax
	movq	%rax, 130408(%rsp)
	movq	37296(%rsp), %rax
	movq	%rax, 130416(%rsp)
	movq	37304(%rsp), %rax
	movq	%rax, 130424(%rsp)
	movq	37312(%rsp), %rax
	movq	%rax, 130432(%rsp)
	movq	37320(%rsp), %rax
	movq	%rax, 130440(%rsp)
	movq	37328(%rsp), %rax
	movq	%rax, 130448(%rsp)
	movq	37336(%rsp), %rax
	movq	%rax, 130456(%rsp)
	movq	37344(%rsp), %rax
	movq	%rax, 130464(%rsp)
	movq	37352(%rsp), %rax
	movq	%rax, 130472(%rsp)
	movq	37360(%rsp), %rax
	movq	%rax, 130480(%rsp)
	movq	37368(%rsp), %rax
	movq	%rax, 130488(%rsp)
	movq	37376(%rsp), %rax
	movq	%rax, 130496(%rsp)
	movq	37384(%rsp), %rax
	movq	%rax, 130504(%rsp)
	movq	37392(%rsp), %rax
	movq	%rax, 130512(%rsp)
	movq	37400(%rsp), %rax
	movq	%rax, 130520(%rsp)
	movq	37408(%rsp), %rax
	movq	%rax, 130528(%rsp)
	movq	37416(%rsp), %rax
	movq	%rax, 130536(%rsp)
	movq	37424(%rsp), %rax
	movq	%rax, 130544(%rsp)
	movq	37432(%rsp), %rax
	movq	%rax, 130552(%rsp)
	movq	37440(%rsp), %rax
	movq	%rax, 130560(%rsp)
	movq	37448(%rsp), %rax
	movq	%rax, 130568(%rsp)
	movq	37456(%rsp), %rax
	movq	%rax, 130576(%rsp)
	movq	37464(%rsp), %rax
	movq	%rax, 130584(%rsp)
	movq	37472(%rsp), %rax
	movq	%rax, 130592(%rsp)
	movq	37480(%rsp), %rax
	movq	%rax, 130600(%rsp)
	movq	37488(%rsp), %rax
	movq	%rax, 130608(%rsp)
	movq	37496(%rsp), %rax
	movq	%rax, 130616(%rsp)
	movq	37504(%rsp), %rax
	movq	%rax, 130624(%rsp)
	movq	37512(%rsp), %rax
	movq	%rax, 130632(%rsp)
	movq	37520(%rsp), %rax
	movq	%rax, 130640(%rsp)
	movq	37528(%rsp), %rax
	movq	%rax, 130648(%rsp)
	movq	37536(%rsp), %rax
	movq	%rax, 130656(%rsp)
	movq	37544(%rsp), %rax
	movq	%rax, 130664(%rsp)
	movq	37552(%rsp), %rax
	movq	%rax, 130672(%rsp)
	movq	37560(%rsp), %rax
	movq	%rax, 130680(%rsp)
	movq	37568(%rsp), %rax
	movq	%rax, 130688(%rsp)
	movq	37576(%rsp), %rax
	movq	%rax, 130696(%rsp)
	movq	37584(%rsp), %rax
	movq	%rax, 130704(%rsp)
	movq	37592(%rsp), %rax
	movq	%rax, 130712(%rsp)
	movq	37600(%rsp), %rax
	movq	%rax, 130720(%rsp)
	movq	37608(%rsp), %rax
	movq	%rax, 130728(%rsp)
	movq	37616(%rsp), %rax
	movq	%rax, 130736(%rsp)
	movq	37624(%rsp), %rax
	movq	%rax, 130744(%rsp)
	movq	37632(%rsp), %rax
	movq	%rax, 130752(%rsp)
	movq	37640(%rsp), %rax
	movq	%rax, 130760(%rsp)
	movq	37648(%rsp), %rax
	movq	%rax, 130768(%rsp)
	movq	37656(%rsp), %rax
	movq	%rax, 130776(%rsp)
	movq	37664(%rsp), %rax
	movq	%rax, 130784(%rsp)
	movq	37672(%rsp), %rax
	movq	%rax, 130792(%rsp)
	movq	37680(%rsp), %rax
	movq	%rax, 130800(%rsp)
	movq	37688(%rsp), %rax
	movq	%rax, 130808(%rsp)
	movq	37696(%rsp), %rax
	movq	%rax, 130816(%rsp)
	movq	37704(%rsp), %rax
	movq	%rax, 130824(%rsp)
	movq	37712(%rsp), %rax
	movq	%rax, 130832(%rsp)
	movq	37720(%rsp), %rax
	movq	%rax, 130840(%rsp)
	movq	37728(%rsp), %rax
	movq	%rax, 130848(%rsp)
	movq	37736(%rsp), %rax
	movq	%rax, 130856(%rsp)
	movq	37744(%rsp), %rax
	movq	%rax, 130864(%rsp)
	movq	37752(%rsp), %rax
	movq	%rax, 130872(%rsp)
	movq	37760(%rsp), %rax
	movq	%rax, 130880(%rsp)
	movq	37768(%rsp), %rax
	movq	%rax, 130888(%rsp)
	movq	37776(%rsp), %rax
	movq	%rax, 130896(%rsp)
	movq	37784(%rsp), %rax
	movq	%rax, 130904(%rsp)
	movq	37792(%rsp), %rax
	movq	%rax, 130912(%rsp)
	movq	37800(%rsp), %rax
	movq	%rax, 130920(%rsp)
	movq	37808(%rsp), %rax
	movq	%rax, 130928(%rsp)
	movq	37816(%rsp), %rax
	movq	%rax, 130936(%rsp)
	movq	37824(%rsp), %rax
	movq	%rax, 130944(%rsp)
	movq	37832(%rsp), %rax
	movq	%rax, 130952(%rsp)
	movq	37840(%rsp), %rax
	movq	%rax, 130960(%rsp)
	movq	37848(%rsp), %rax
	movq	%rax, 130968(%rsp)
	movq	37856(%rsp), %rax
	movq	%rax, 130976(%rsp)
	movq	37864(%rsp), %rax
	movq	%rax, 130984(%rsp)
	movq	37872(%rsp), %rax
	movq	%rax, 130992(%rsp)
	movq	37880(%rsp), %rax
	movq	%rax, 131000(%rsp)
	movq	37888(%rsp), %rax
	movq	%rax, 131008(%rsp)
	movq	37896(%rsp), %rax
	movq	%rax, 131016(%rsp)
	movq	37904(%rsp), %rax
	movq	%rax, 131024(%rsp)
	movq	37912(%rsp), %rax
	movq	%rax, 131032(%rsp)
	movq	37920(%rsp), %rax
	movq	%rax, 131040(%rsp)
	movq	37928(%rsp), %rax
	movq	%rax, 131048(%rsp)
	movq	37936(%rsp), %rax
	movq	%rax, 131056(%rsp)
	movq	37944(%rsp), %rax
	movq	%rax, 131064(%rsp)
	movq	37952(%rsp), %rax
	movq	%rax, 131072(%rsp)
	movq	37960(%rsp), %rax
	movq	%rax, 131080(%rsp)
	movq	37968(%rsp), %rax
	movq	%rax, 131088(%rsp)
	movq	37976(%rsp), %rax
	movq	%rax, 131096(%rsp)
	movq	37984(%rsp), %rax
	movq	%rax, 131104(%rsp)
	movq	37992(%rsp), %rax
	movq	%rax, 131112(%rsp)
	movq	38000(%rsp), %rax
	movq	%rax, 131120(%rsp)
	movq	38008(%rsp), %rax
	movq	%rax, 131128(%rsp)
	movq	38016(%rsp), %rax
	movq	%rax, 131136(%rsp)
	movq	38024(%rsp), %rax
	movq	%rax, 131144(%rsp)
	movq	38032(%rsp), %rax
	movq	%rax, 131152(%rsp)
	movq	38040(%rsp), %rax
	movq	%rax, 131160(%rsp)
	movq	38048(%rsp), %rax
	movq	%rax, 131168(%rsp)
	movq	38056(%rsp), %rax
	movq	%rax, 131176(%rsp)
	movq	38064(%rsp), %rax
	movq	%rax, 131184(%rsp)
	movq	38072(%rsp), %rax
	movq	%rax, 131192(%rsp)
	movq	38080(%rsp), %rax
	movq	%rax, 131200(%rsp)
	movq	38088(%rsp), %rax
	movq	%rax, 131208(%rsp)
	movq	38096(%rsp), %rax
	movq	%rax, 131216(%rsp)
	movq	38104(%rsp), %rax
	movq	%rax, 131224(%rsp)
	movq	38112(%rsp), %rax
	movq	%rax, 131232(%rsp)
	movq	38120(%rsp), %rax
	movq	%rax, 131240(%rsp)
	movq	38128(%rsp), %rax
	movq	%rax, 131248(%rsp)
	movq	38136(%rsp), %rax
	movq	%rax, 131256(%rsp)
	movq	38144(%rsp), %rax
	movq	%rax, 131264(%rsp)
	movq	38152(%rsp), %rax
	movq	%rax, 131272(%rsp)
	movq	38160(%rsp), %rax
	movq	%rax, 131280(%rsp)
	movq	38168(%rsp), %rax
	movq	%rax, 131288(%rsp)
	movq	38176(%rsp), %rax
	movq	%rax, 131296(%rsp)
	movq	38184(%rsp), %rax
	movq	%rax, 131304(%rsp)
	movq	38192(%rsp), %rax
	movq	%rax, 131312(%rsp)
	movq	38200(%rsp), %rax
	movq	%rax, 131320(%rsp)
	movq	38208(%rsp), %rax
	movq	%rax, 131328(%rsp)
	movq	38216(%rsp), %rax
	movq	%rax, 131336(%rsp)
	movq	38224(%rsp), %rax
	movq	%rax, 131344(%rsp)
	movq	38232(%rsp), %rax
	movq	%rax, 131352(%rsp)
	movq	38240(%rsp), %rax
	movq	%rax, 131360(%rsp)
	movq	38248(%rsp), %rax
	movq	%rax, 131368(%rsp)
	movq	38256(%rsp), %rax
	movq	%rax, 131376(%rsp)
	movq	38264(%rsp), %rax
	movq	%rax, 131384(%rsp)
	movq	38272(%rsp), %rax
	movq	%rax, 131392(%rsp)
	movq	38280(%rsp), %rax
	movq	%rax, 131400(%rsp)
	movq	38288(%rsp), %rax
	movq	%rax, 131408(%rsp)
	movq	38296(%rsp), %rax
	movq	%rax, 131416(%rsp)
	movq	38304(%rsp), %rax
	movq	%rax, 131424(%rsp)
	movq	38312(%rsp), %rax
	movq	%rax, 131432(%rsp)
	movq	38320(%rsp), %rax
	movq	%rax, 131440(%rsp)
	movq	38328(%rsp), %rax
	movq	%rax, 131448(%rsp)
	movq	38336(%rsp), %rax
	movq	%rax, 131456(%rsp)
	movq	38344(%rsp), %rax
	movq	%rax, 131464(%rsp)
	movq	38352(%rsp), %rax
	movq	%rax, 131472(%rsp)
	movq	38360(%rsp), %rax
	movq	%rax, 131480(%rsp)
	movq	38368(%rsp), %rax
	movq	%rax, 131488(%rsp)
	movq	38376(%rsp), %rax
	movq	%rax, 131496(%rsp)
	movq	38384(%rsp), %rax
	movq	%rax, 131504(%rsp)
	movq	38392(%rsp), %rax
	movq	%rax, 131512(%rsp)
	movq	38400(%rsp), %rax
	movq	%rax, 131520(%rsp)
	movq	38408(%rsp), %rax
	movq	%rax, 131528(%rsp)
	movq	38416(%rsp), %rax
	movq	%rax, 131536(%rsp)
	movq	38424(%rsp), %rax
	movq	%rax, 131544(%rsp)
	movq	38432(%rsp), %rax
	movq	%rax, 131552(%rsp)
	movq	38440(%rsp), %rax
	movq	%rax, 131560(%rsp)
	movq	38448(%rsp), %rax
	movq	%rax, 131568(%rsp)
	movq	38456(%rsp), %rax
	movq	%rax, 131576(%rsp)
	movq	38464(%rsp), %rax
	movq	%rax, 131584(%rsp)
	movq	38472(%rsp), %rax
	movq	%rax, 131592(%rsp)
	movq	38480(%rsp), %rax
	movq	%rax, 131600(%rsp)
	movq	38488(%rsp), %rax
	movq	%rax, 131608(%rsp)
	movq	38496(%rsp), %rax
	movq	%rax, 131616(%rsp)
	movq	38504(%rsp), %rax
	movq	%rax, 131624(%rsp)
	movq	38512(%rsp), %rax
	movq	%rax, 131632(%rsp)
	movq	38520(%rsp), %rax
	movq	%rax, 131640(%rsp)
	movq	38528(%rsp), %rax
	movq	%rax, 131648(%rsp)
	movq	38536(%rsp), %rax
	movq	%rax, 131656(%rsp)
	movq	38544(%rsp), %rax
	movq	%rax, 131664(%rsp)
	movq	38552(%rsp), %rax
	movq	%rax, 131672(%rsp)
	movq	38560(%rsp), %rax
	movq	%rax, 131680(%rsp)
	movq	38568(%rsp), %rax
	movq	%rax, 131688(%rsp)
	movq	38576(%rsp), %rax
	movq	%rax, 131696(%rsp)
	movq	38584(%rsp), %rax
	movq	%rax, 131704(%rsp)
	movq	38592(%rsp), %rax
	movq	%rax, 131712(%rsp)
	movq	38600(%rsp), %rax
	movq	%rax, 131720(%rsp)
	movq	38608(%rsp), %rax
	movq	%rax, 131728(%rsp)
	movq	38616(%rsp), %rax
	movq	%rax, 131736(%rsp)
	movq	38624(%rsp), %rax
	movq	%rax, 131744(%rsp)
	movq	38632(%rsp), %rax
	movq	%rax, 131752(%rsp)
	movq	38640(%rsp), %rax
	movq	%rax, 131760(%rsp)
	movq	38648(%rsp), %rax
	movq	%rax, 131768(%rsp)
	movq	38656(%rsp), %rax
	movq	%rax, 131776(%rsp)
	movq	38664(%rsp), %rax
	movq	%rax, 131784(%rsp)
	movq	38672(%rsp), %rax
	movq	%rax, 131792(%rsp)
	movq	38680(%rsp), %rax
	movq	%rax, 131800(%rsp)
	movq	38688(%rsp), %rax
	movq	%rax, 131808(%rsp)
	movq	38696(%rsp), %rax
	movq	%rax, 131816(%rsp)
	movq	38704(%rsp), %rax
	movq	%rax, 131824(%rsp)
	movq	38712(%rsp), %rax
	movq	%rax, 131832(%rsp)
	movq	38720(%rsp), %rax
	movq	%rax, 131840(%rsp)
	movq	38728(%rsp), %rax
	movq	%rax, 131848(%rsp)
	movq	38736(%rsp), %rax
	movq	%rax, 131856(%rsp)
	movq	38744(%rsp), %rax
	movq	%rax, 131864(%rsp)
	movq	38752(%rsp), %rax
	movq	%rax, 131872(%rsp)
	movq	38760(%rsp), %rax
	movq	%rax, 131880(%rsp)
	movq	38768(%rsp), %rax
	movq	%rax, 131888(%rsp)
	movq	38776(%rsp), %rax
	movq	%rax, 131896(%rsp)
	movq	38784(%rsp), %rax
	movq	%rax, 131904(%rsp)
	movq	38792(%rsp), %rax
	movq	%rax, 131912(%rsp)
	movq	38800(%rsp), %rax
	movq	%rax, 131920(%rsp)
	movq	38808(%rsp), %rax
	movq	%rax, 131928(%rsp)
	movq	38816(%rsp), %rax
	movq	%rax, 131936(%rsp)
	movq	38824(%rsp), %rax
	movq	%rax, 131944(%rsp)
	movq	38832(%rsp), %rax
	movq	%rax, 131952(%rsp)
	movq	38840(%rsp), %rax
	movq	%rax, 131960(%rsp)
	movq	38848(%rsp), %rax
	movq	%rax, 131968(%rsp)
	movq	38856(%rsp), %rax
	movq	%rax, 131976(%rsp)
	movq	38864(%rsp), %rax
	movq	%rax, 131984(%rsp)
	movq	38872(%rsp), %rax
	movq	%rax, 131992(%rsp)
	movq	38880(%rsp), %rax
	movq	%rax, 132000(%rsp)
	movq	38888(%rsp), %rax
	movq	%rax, 132008(%rsp)
	movq	38896(%rsp), %rax
	movq	%rax, 132016(%rsp)
	movq	38904(%rsp), %rax
	movq	%rax, 132024(%rsp)
	movq	38912(%rsp), %rax
	movq	%rax, 132032(%rsp)
	movq	38920(%rsp), %rax
	movq	%rax, 132040(%rsp)
	movq	38928(%rsp), %rax
	movq	%rax, 132048(%rsp)
	movq	38936(%rsp), %rax
	movq	%rax, 132056(%rsp)
	movq	38944(%rsp), %rax
	movq	%rax, 132064(%rsp)
	movq	38952(%rsp), %rax
	movq	%rax, 132072(%rsp)
	movq	38960(%rsp), %rax
	movq	%rax, 132080(%rsp)
	movq	38968(%rsp), %rax
	movq	%rax, 132088(%rsp)
	movq	38976(%rsp), %rax
	movq	%rax, 132096(%rsp)
	movq	38984(%rsp), %rax
	movq	%rax, 132104(%rsp)
	movq	38992(%rsp), %rax
	movq	%rax, 132112(%rsp)
	movq	39000(%rsp), %rax
	movq	%rax, 132120(%rsp)
	movq	39008(%rsp), %rax
	movq	%rax, 132128(%rsp)
	movq	39016(%rsp), %rax
	movq	%rax, 132136(%rsp)
	movq	39024(%rsp), %rax
	movq	%rax, 132144(%rsp)
	movq	39032(%rsp), %rax
	movq	%rax, 132152(%rsp)
	movq	39040(%rsp), %rax
	movq	%rax, 132160(%rsp)
	movq	39048(%rsp), %rax
	movq	%rax, 132168(%rsp)
	movq	39056(%rsp), %rax
	movq	%rax, 132176(%rsp)
	movq	39064(%rsp), %rax
	movq	%rax, 132184(%rsp)
	movq	39072(%rsp), %rax
	movq	%rax, 132192(%rsp)
	movq	39080(%rsp), %rax
	movq	%rax, 132200(%rsp)
	movq	39088(%rsp), %rax
	movq	%rax, 132208(%rsp)
	movq	39096(%rsp), %rax
	movq	%rax, 132216(%rsp)
	movq	39104(%rsp), %rax
	movq	%rax, 132224(%rsp)
	movq	39112(%rsp), %rax
	movq	%rax, 132232(%rsp)
	movq	39120(%rsp), %rax
	movq	%rax, 132240(%rsp)
	movq	39128(%rsp), %rax
	movq	%rax, 132248(%rsp)
	movq	39136(%rsp), %rax
	movq	%rax, 132256(%rsp)
	movq	39144(%rsp), %rax
	movq	%rax, 132264(%rsp)
	movq	39152(%rsp), %rax
	movq	%rax, 132272(%rsp)
	movq	39160(%rsp), %rax
	movq	%rax, 132280(%rsp)
	movq	39168(%rsp), %rax
	movq	%rax, 132288(%rsp)
	movq	39176(%rsp), %rax
	movq	%rax, 132296(%rsp)
	movq	39184(%rsp), %rax
	movq	%rax, 132304(%rsp)
	movq	39192(%rsp), %rax
	movq	%rax, 132312(%rsp)
	movq	39200(%rsp), %rax
	movq	%rax, 132320(%rsp)
	movq	39208(%rsp), %rax
	movq	%rax, 132328(%rsp)
	movq	39216(%rsp), %rax
	movq	%rax, 132336(%rsp)
	movq	39224(%rsp), %rax
	movq	%rax, 132344(%rsp)
	movq	39232(%rsp), %rax
	movq	%rax, 132352(%rsp)
	movq	39240(%rsp), %rax
	movq	%rax, 132360(%rsp)
	movq	39248(%rsp), %rax
	movq	%rax, 132368(%rsp)
	movq	39256(%rsp), %rax
	movq	%rax, 132376(%rsp)
	movq	39264(%rsp), %rax
	movq	%rax, 132384(%rsp)
	movq	39272(%rsp), %rax
	movq	%rax, 132392(%rsp)
	movq	39280(%rsp), %rax
	movq	%rax, 132400(%rsp)
	movq	39288(%rsp), %rax
	movq	%rax, 132408(%rsp)
	movq	39296(%rsp), %rax
	movq	%rax, 132416(%rsp)
	movq	39304(%rsp), %rax
	movq	%rax, 132424(%rsp)
	movq	39312(%rsp), %rax
	movq	%rax, 132432(%rsp)
	movq	39320(%rsp), %rax
	movq	%rax, 132440(%rsp)
	movq	39328(%rsp), %rax
	movq	%rax, 132448(%rsp)
	movq	39336(%rsp), %rax
	movq	%rax, 132456(%rsp)
	movq	39344(%rsp), %rax
	movq	%rax, 132464(%rsp)
	movq	39352(%rsp), %rax
	movq	%rax, 132472(%rsp)
	movq	39360(%rsp), %rax
	movq	%rax, 132480(%rsp)
	movq	39368(%rsp), %rax
	movq	%rax, 132488(%rsp)
	movq	39376(%rsp), %rax
	movq	%rax, 132496(%rsp)
	movq	39384(%rsp), %rax
	movq	%rax, 132504(%rsp)
	movq	39392(%rsp), %rax
	movq	%rax, 132512(%rsp)
	movq	39400(%rsp), %rax
	movq	%rax, 132520(%rsp)
	movq	39408(%rsp), %rax
	movq	%rax, 132528(%rsp)
	movq	39416(%rsp), %rax
	movq	%rax, 132536(%rsp)
	movq	39424(%rsp), %rax
	movq	%rax, 132544(%rsp)
	movq	39432(%rsp), %rax
	movq	%rax, 132552(%rsp)
	movq	39440(%rsp), %rax
	movq	%rax, 132560(%rsp)
	movq	39448(%rsp), %rax
	movq	%rax, 132568(%rsp)
	movq	39456(%rsp), %rax
	movq	%rax, 132576(%rsp)
	movq	39464(%rsp), %rax
	movq	%rax, 132584(%rsp)
	movq	39472(%rsp), %rax
	movq	%rax, 132592(%rsp)
	movq	39480(%rsp), %rax
	movq	%rax, 132600(%rsp)
	movq	39488(%rsp), %rax
	movq	%rax, 132608(%rsp)
	movq	39496(%rsp), %rax
	movq	%rax, 132616(%rsp)
	movq	39504(%rsp), %rax
	movq	%rax, 132624(%rsp)
	movq	39512(%rsp), %rax
	movq	%rax, 132632(%rsp)
	movq	39520(%rsp), %rax
	movq	%rax, 132640(%rsp)
	movq	39528(%rsp), %rax
	movq	%rax, 132648(%rsp)
	movq	39536(%rsp), %rax
	movq	%rax, 132656(%rsp)
	movq	39544(%rsp), %rax
	movq	%rax, 132664(%rsp)
	movq	39552(%rsp), %rax
	movq	%rax, 132672(%rsp)
	movq	39560(%rsp), %rax
	movq	%rax, 132680(%rsp)
	movq	39568(%rsp), %rax
	movq	%rax, 132688(%rsp)
	movq	39576(%rsp), %rax
	movq	%rax, 132696(%rsp)
	movq	39584(%rsp), %rax
	movq	%rax, 132704(%rsp)
	movq	39592(%rsp), %rax
	movq	%rax, 132712(%rsp)
	movq	39600(%rsp), %rax
	movq	%rax, 132720(%rsp)
	movq	39608(%rsp), %rax
	movq	%rax, 132728(%rsp)
	movq	39616(%rsp), %rax
	movq	%rax, 132736(%rsp)
	movq	39624(%rsp), %rax
	movq	%rax, 132744(%rsp)
	movq	39632(%rsp), %rax
	movq	%rax, 132752(%rsp)
	movq	39640(%rsp), %rax
	movq	%rax, 132760(%rsp)
	movq	39648(%rsp), %rax
	movq	%rax, 132768(%rsp)
	movq	39656(%rsp), %rax
	movq	%rax, 132776(%rsp)
	movq	39664(%rsp), %rax
	movq	%rax, 132784(%rsp)
	movq	39672(%rsp), %rax
	movq	%rax, 132792(%rsp)
	movq	39680(%rsp), %rax
	movq	%rax, 132800(%rsp)
	movq	39688(%rsp), %rax
	movq	%rax, 132808(%rsp)
	movq	39696(%rsp), %rax
	movq	%rax, 132816(%rsp)
	movq	39704(%rsp), %rax
	movq	%rax, 132824(%rsp)
	movq	39712(%rsp), %rax
	movq	%rax, 132832(%rsp)
	movq	39720(%rsp), %rax
	movq	%rax, 132840(%rsp)
	movq	39728(%rsp), %rax
	movq	%rax, 132848(%rsp)
	movq	39736(%rsp), %rax
	movq	%rax, 132856(%rsp)
	movq	39744(%rsp), %rax
	movq	%rax, 132864(%rsp)
	movq	39752(%rsp), %rax
	movq	%rax, 132872(%rsp)
	movq	39760(%rsp), %rax
	movq	%rax, 132880(%rsp)
	movq	39768(%rsp), %rax
	movq	%rax, 132888(%rsp)
	movq	39776(%rsp), %rax
	movq	%rax, 132896(%rsp)
	movq	39784(%rsp), %rax
	movq	%rax, 132904(%rsp)
	movq	39792(%rsp), %rax
	movq	%rax, 132912(%rsp)
	movq	39800(%rsp), %rax
	movq	%rax, 132920(%rsp)
	movq	39808(%rsp), %rax
	movq	%rax, 132928(%rsp)
	movq	39816(%rsp), %rax
	movq	%rax, 132936(%rsp)
	movq	39824(%rsp), %rax
	movq	%rax, 132944(%rsp)
	movq	39832(%rsp), %rax
	movq	%rax, 132952(%rsp)
	movq	39840(%rsp), %rax
	movq	%rax, 132960(%rsp)
	movq	39848(%rsp), %rax
	movq	%rax, 132968(%rsp)
	movq	39856(%rsp), %rax
	movq	%rax, 132976(%rsp)
	movq	39864(%rsp), %rax
	movq	%rax, 132984(%rsp)
	movq	39872(%rsp), %rax
	movq	%rax, 132992(%rsp)
	movq	39880(%rsp), %rax
	movq	%rax, 133000(%rsp)
	movq	39888(%rsp), %rax
	movq	%rax, 133008(%rsp)
	movq	39896(%rsp), %rax
	movq	%rax, 133016(%rsp)
	movq	39904(%rsp), %rax
	movq	%rax, 133024(%rsp)
	movq	39912(%rsp), %rax
	movq	%rax, 133032(%rsp)
	movq	39920(%rsp), %rax
	movq	%rax, 133040(%rsp)
	movq	39928(%rsp), %rax
	movq	%rax, 133048(%rsp)
	movq	39936(%rsp), %rax
	movq	%rax, 133056(%rsp)
	movq	39944(%rsp), %rax
	movq	%rax, 133064(%rsp)
	movq	39952(%rsp), %rax
	movq	%rax, 133072(%rsp)
	movq	39960(%rsp), %rax
	movq	%rax, 133080(%rsp)
	movq	39968(%rsp), %rax
	movq	%rax, 133088(%rsp)
	movq	39976(%rsp), %rax
	movq	%rax, 133096(%rsp)
	movq	39984(%rsp), %rax
	movq	%rax, 133104(%rsp)
	movq	39992(%rsp), %rax
	movq	%rax, 133112(%rsp)
	movq	40000(%rsp), %rax
	movq	%rax, 133120(%rsp)
	movq	40008(%rsp), %rax
	movq	%rax, 133128(%rsp)
	movq	40016(%rsp), %rax
	movq	%rax, 133136(%rsp)
	movq	40024(%rsp), %rax
	movq	%rax, 133144(%rsp)
	movq	40032(%rsp), %rax
	movq	%rax, 133152(%rsp)
	movq	40040(%rsp), %rax
	movq	%rax, 133160(%rsp)
	movq	40048(%rsp), %rax
	movq	%rax, 133168(%rsp)
	movq	40056(%rsp), %rax
	movq	%rax, 133176(%rsp)
	movq	40064(%rsp), %rax
	movq	%rax, 133184(%rsp)
	movq	40072(%rsp), %rax
	movq	%rax, 133192(%rsp)
	movq	40080(%rsp), %rax
	movq	%rax, 133200(%rsp)
	movq	40088(%rsp), %rax
	movq	%rax, 133208(%rsp)
	movq	40096(%rsp), %rax
	movq	%rax, 133216(%rsp)
	movq	40104(%rsp), %rax
	movq	%rax, 133224(%rsp)
	movq	40112(%rsp), %rax
	movq	%rax, 133232(%rsp)
	movq	40120(%rsp), %rax
	movq	%rax, 133240(%rsp)
	movq	40128(%rsp), %rax
	movq	%rax, 133248(%rsp)
	movq	40136(%rsp), %rax
	movq	%rax, 133256(%rsp)
	movq	40144(%rsp), %rax
	movq	%rax, 133264(%rsp)
	movq	40152(%rsp), %rax
	movq	%rax, 133272(%rsp)
	movq	40160(%rsp), %rax
	movq	%rax, 133280(%rsp)
	movq	40168(%rsp), %rax
	movq	%rax, 133288(%rsp)
	movq	40176(%rsp), %rax
	movq	%rax, 133296(%rsp)
	movq	40184(%rsp), %rax
	movq	%rax, 133304(%rsp)
	movq	40192(%rsp), %rax
	movq	%rax, 133312(%rsp)
	movq	40200(%rsp), %rax
	movq	%rax, 133320(%rsp)
	movq	40208(%rsp), %rax
	movq	%rax, 133328(%rsp)
	movq	40216(%rsp), %rax
	movq	%rax, 133336(%rsp)
	movq	40224(%rsp), %rax
	movq	%rax, 133344(%rsp)
	movq	40232(%rsp), %rax
	movq	%rax, 133352(%rsp)
	movq	40240(%rsp), %rax
	movq	%rax, 133360(%rsp)
	movq	40248(%rsp), %rax
	movq	%rax, 133368(%rsp)
	movq	40256(%rsp), %rax
	movq	%rax, 133376(%rsp)
	movq	40264(%rsp), %rax
	movq	%rax, 133384(%rsp)
	movq	40272(%rsp), %rax
	movq	%rax, 133392(%rsp)
	movq	40280(%rsp), %rax
	movq	%rax, 133400(%rsp)
	movq	40288(%rsp), %rax
	movq	%rax, 133408(%rsp)
	movq	40296(%rsp), %rax
	movq	%rax, 133416(%rsp)
	movq	40304(%rsp), %rax
	movq	%rax, 133424(%rsp)
	movq	40312(%rsp), %rax
	movq	%rax, 133432(%rsp)
	movq	40320(%rsp), %rax
	movq	%rax, 133440(%rsp)
	movq	40328(%rsp), %rax
	movq	%rax, 133448(%rsp)
	movq	40336(%rsp), %rax
	movq	%rax, 133456(%rsp)
	movq	40344(%rsp), %rax
	movq	%rax, 133464(%rsp)
	movq	40352(%rsp), %rax
	movq	%rax, 133472(%rsp)
	movq	40360(%rsp), %rax
	movq	%rax, 133480(%rsp)
	movq	40368(%rsp), %rax
	movq	%rax, 133488(%rsp)
	movq	40376(%rsp), %rax
	movq	%rax, 133496(%rsp)
	movq	40384(%rsp), %rax
	movq	%rax, 133504(%rsp)
	movq	40392(%rsp), %rax
	movq	%rax, 133512(%rsp)
	movq	40400(%rsp), %rax
	movq	%rax, 133520(%rsp)
	movq	40408(%rsp), %rax
	movq	%rax, 133528(%rsp)
	movq	40416(%rsp), %rax
	movq	%rax, 133536(%rsp)
	movq	40424(%rsp), %rax
	movq	%rax, 133544(%rsp)
	movq	40432(%rsp), %rax
	movq	%rax, 133552(%rsp)
	movq	40440(%rsp), %rax
	movq	%rax, 133560(%rsp)
	movq	40448(%rsp), %rax
	movq	%rax, 133568(%rsp)
	movq	40456(%rsp), %rax
	movq	%rax, 133576(%rsp)
	movq	40464(%rsp), %rax
	movq	%rax, 133584(%rsp)
	movq	40472(%rsp), %rax
	movq	%rax, 133592(%rsp)
	movq	40480(%rsp), %rax
	movq	%rax, 133600(%rsp)
	movq	40488(%rsp), %rax
	movq	%rax, 133608(%rsp)
	movq	40496(%rsp), %rax
	movq	%rax, 133616(%rsp)
	movq	40504(%rsp), %rax
	movq	%rax, 133624(%rsp)
	movq	40512(%rsp), %rax
	movq	%rax, 133632(%rsp)
	movq	40520(%rsp), %rax
	movq	%rax, 133640(%rsp)
	movq	40528(%rsp), %rax
	movq	%rax, 133648(%rsp)
	movq	40536(%rsp), %rax
	movq	%rax, 133656(%rsp)
	movq	40544(%rsp), %rax
	movq	%rax, 133664(%rsp)
	movq	40552(%rsp), %rax
	movq	%rax, 133672(%rsp)
	movq	40560(%rsp), %rax
	movq	%rax, 133680(%rsp)
	movq	40568(%rsp), %rax
	movq	%rax, 133688(%rsp)
	movq	40576(%rsp), %rax
	movq	%rax, 133696(%rsp)
	movq	40584(%rsp), %rax
	movq	%rax, 133704(%rsp)
	movq	40592(%rsp), %rax
	movq	%rax, 133712(%rsp)
	movq	40600(%rsp), %rax
	movq	%rax, 133720(%rsp)
	movq	40608(%rsp), %rax
	movq	%rax, 133728(%rsp)
	movq	40616(%rsp), %rax
	movq	%rax, 133736(%rsp)
	movq	40624(%rsp), %rax
	movq	%rax, 133744(%rsp)
	movq	40632(%rsp), %rax
	movq	%rax, 133752(%rsp)
	movq	40640(%rsp), %rax
	movq	%rax, 133760(%rsp)
	movq	40648(%rsp), %rax
	movq	%rax, 133768(%rsp)
	movq	40656(%rsp), %rax
	movq	%rax, 133776(%rsp)
	movq	40664(%rsp), %rax
	movq	%rax, 133784(%rsp)
	movq	40672(%rsp), %rax
	movq	%rax, 133792(%rsp)
	movq	40680(%rsp), %rax
	movq	%rax, 133800(%rsp)
	movq	40688(%rsp), %rax
	movq	%rax, 133808(%rsp)
	movq	40696(%rsp), %rax
	movq	%rax, 133816(%rsp)
	movq	40704(%rsp), %rax
	movq	%rax, 133824(%rsp)
	movq	40712(%rsp), %rax
	movq	%rax, 133832(%rsp)
	movq	40720(%rsp), %rax
	movq	%rax, 133840(%rsp)
	movq	40728(%rsp), %rax
	movq	%rax, 133848(%rsp)
	movq	40736(%rsp), %rax
	movq	%rax, 133856(%rsp)
	movq	40744(%rsp), %rax
	movq	%rax, 133864(%rsp)
	movq	40752(%rsp), %rax
	movq	%rax, 133872(%rsp)
	movq	40760(%rsp), %rax
	movq	%rax, 133880(%rsp)
	movq	40768(%rsp), %rax
	movq	%rax, 133888(%rsp)
	movq	40776(%rsp), %rax
	movq	%rax, 133896(%rsp)
	movq	40784(%rsp), %rax
	movq	%rax, 133904(%rsp)
	movq	40792(%rsp), %rax
	movq	%rax, 133912(%rsp)
	movq	40800(%rsp), %rax
	movq	%rax, 133920(%rsp)
	movq	40808(%rsp), %rax
	movq	%rax, 133928(%rsp)
	movq	40816(%rsp), %rax
	movq	%rax, 133936(%rsp)
	movq	40824(%rsp), %rax
	movq	%rax, 133944(%rsp)
	movq	40832(%rsp), %rax
	movq	%rax, 133952(%rsp)
	movq	40840(%rsp), %rax
	movq	%rax, 133960(%rsp)
	movq	40848(%rsp), %rax
	movq	%rax, 133968(%rsp)
	movq	40856(%rsp), %rax
	movq	%rax, 133976(%rsp)
	movq	40864(%rsp), %rax
	movq	%rax, 133984(%rsp)
	movq	40872(%rsp), %rax
	movq	%rax, 133992(%rsp)
	movq	40880(%rsp), %rax
	movq	%rax, 134000(%rsp)
	movq	40888(%rsp), %rax
	movq	%rax, 134008(%rsp)
	movq	40896(%rsp), %rax
	movq	%rax, 134016(%rsp)
	movq	40904(%rsp), %rax
	movq	%rax, 134024(%rsp)
	movq	40912(%rsp), %rax
	movq	%rax, 134032(%rsp)
	movq	40920(%rsp), %rax
	movq	%rax, 134040(%rsp)
	movq	40928(%rsp), %rax
	movq	%rax, 134048(%rsp)
	movq	40936(%rsp), %rax
	movq	%rax, 134056(%rsp)
	movq	40944(%rsp), %rax
	movq	%rax, 134064(%rsp)
	movq	40952(%rsp), %rax
	movq	%rax, 134072(%rsp)
	movq	40960(%rsp), %rax
	movq	%rax, 134080(%rsp)
	movq	40968(%rsp), %rax
	movq	%rax, 134088(%rsp)
	movq	40976(%rsp), %rax
	movq	%rax, 134096(%rsp)
	movq	40984(%rsp), %rax
	movq	%rax, 134104(%rsp)
	movq	40992(%rsp), %rax
	movq	%rax, 134112(%rsp)
	movq	41000(%rsp), %rax
	movq	%rax, 134120(%rsp)
	movq	41008(%rsp), %rax
	movq	%rax, 134128(%rsp)
	movq	41016(%rsp), %rax
	movq	%rax, 134136(%rsp)
	movq	41024(%rsp), %rax
	movq	%rax, 134144(%rsp)
	movq	41032(%rsp), %rax
	movq	%rax, 134152(%rsp)
	movq	41040(%rsp), %rax
	movq	%rax, 134160(%rsp)
	movq	41048(%rsp), %rax
	movq	%rax, 134168(%rsp)
	movq	41056(%rsp), %rax
	movq	%rax, 134176(%rsp)
	movq	41064(%rsp), %rax
	movq	%rax, 134184(%rsp)
	movq	41072(%rsp), %rax
	movq	%rax, 134192(%rsp)
	movq	41080(%rsp), %rax
	movq	%rax, 134200(%rsp)
	movq	41088(%rsp), %rax
	movq	%rax, 134208(%rsp)
	movq	41096(%rsp), %rax
	movq	%rax, 134216(%rsp)
	movq	41104(%rsp), %rax
	movq	%rax, 134224(%rsp)
	movq	41112(%rsp), %rax
	movq	%rax, 134232(%rsp)
	movq	41120(%rsp), %rax
	movq	%rax, 134240(%rsp)
	movq	41128(%rsp), %rax
	movq	%rax, 134248(%rsp)
	movq	41136(%rsp), %rax
	movq	%rax, 134256(%rsp)
	movq	41144(%rsp), %rax
	movq	%rax, 134264(%rsp)
	movq	41152(%rsp), %rax
	movq	%rax, 134272(%rsp)
	movq	41160(%rsp), %rax
	movq	%rax, 134280(%rsp)
	movq	41168(%rsp), %rax
	movq	%rax, 134288(%rsp)
	movq	41176(%rsp), %rax
	movq	%rax, 134296(%rsp)
	movq	41184(%rsp), %rax
	movq	%rax, 134304(%rsp)
	movq	41192(%rsp), %rax
	movq	%rax, 134312(%rsp)
	movq	41200(%rsp), %rax
	movq	%rax, 134320(%rsp)
	movq	41208(%rsp), %rax
	movq	%rax, 134328(%rsp)
	movq	41216(%rsp), %rax
	movq	%rax, 134336(%rsp)
	movq	41224(%rsp), %rax
	movq	%rax, 134344(%rsp)
	movq	41232(%rsp), %rax
	movq	%rax, 134352(%rsp)
	movq	41240(%rsp), %rax
	movq	%rax, 134360(%rsp)
	movq	41248(%rsp), %rax
	movq	%rax, 134368(%rsp)
	movq	41256(%rsp), %rax
	movq	%rax, 134376(%rsp)
	movq	41264(%rsp), %rax
	movq	%rax, 134384(%rsp)
	movq	41272(%rsp), %rax
	movq	%rax, 134392(%rsp)
	movq	41280(%rsp), %rax
	movq	%rax, 134400(%rsp)
	movq	41288(%rsp), %rax
	movq	%rax, 134408(%rsp)
	movq	41296(%rsp), %rax
	movq	%rax, 134416(%rsp)
	movq	41304(%rsp), %rax
	movq	%rax, 134424(%rsp)
	movq	41312(%rsp), %rax
	movq	%rax, 134432(%rsp)
	movq	41320(%rsp), %rax
	movq	%rax, 134440(%rsp)
	movq	41328(%rsp), %rax
	movq	%rax, 134448(%rsp)
	movq	41336(%rsp), %rax
	movq	%rax, 134456(%rsp)
	movq	41344(%rsp), %rax
	movq	%rax, 134464(%rsp)
	movq	41352(%rsp), %rax
	movq	%rax, 134472(%rsp)
	movq	41360(%rsp), %rax
	movq	%rax, 134480(%rsp)
	movq	41368(%rsp), %rax
	movq	%rax, 134488(%rsp)
	movq	41376(%rsp), %rax
	movq	%rax, 134496(%rsp)
	movq	41384(%rsp), %rax
	movq	%rax, 134504(%rsp)
	movq	41392(%rsp), %rax
	movq	%rax, 134512(%rsp)
	movq	41400(%rsp), %rax
	movq	%rax, 134520(%rsp)
	movq	41408(%rsp), %rax
	movq	%rax, 134528(%rsp)
	movq	41416(%rsp), %rax
	movq	%rax, 134536(%rsp)
	movq	41424(%rsp), %rax
	movq	%rax, 134544(%rsp)
	movq	41432(%rsp), %rax
	movq	%rax, 134552(%rsp)
	movq	41440(%rsp), %rax
	movq	%rax, 134560(%rsp)
	movq	41448(%rsp), %rax
	movq	%rax, 134568(%rsp)
	movq	41456(%rsp), %rax
	movq	%rax, 134576(%rsp)
	movq	41464(%rsp), %rax
	movq	%rax, 134584(%rsp)
	movq	41472(%rsp), %rax
	movq	%rax, 134592(%rsp)
	movq	41480(%rsp), %rax
	movq	%rax, 134600(%rsp)
	movq	41488(%rsp), %rax
	movq	%rax, 134608(%rsp)
	movq	41496(%rsp), %rax
	movq	%rax, 134616(%rsp)
	movq	41504(%rsp), %rax
	movq	%rax, 134624(%rsp)
	movq	41512(%rsp), %rax
	movq	%rax, 134632(%rsp)
	movq	41520(%rsp), %rax
	movq	%rax, 134640(%rsp)
	movq	41528(%rsp), %rax
	movq	%rax, 134648(%rsp)
	movq	41536(%rsp), %rax
	movq	%rax, 134656(%rsp)
	movq	41544(%rsp), %rax
	movq	%rax, 134664(%rsp)
	movq	41552(%rsp), %rax
	movq	%rax, 134672(%rsp)
	movq	41560(%rsp), %rax
	movq	%rax, 134680(%rsp)
	movq	41568(%rsp), %rax
	movq	%rax, 134688(%rsp)
	movq	41576(%rsp), %rax
	movq	%rax, 134696(%rsp)
	movq	41584(%rsp), %rax
	movq	%rax, 134704(%rsp)
	movq	41592(%rsp), %rax
	movq	%rax, 134712(%rsp)
	movq	41600(%rsp), %rax
	movq	%rax, 134720(%rsp)
	movq	41608(%rsp), %rax
	movq	%rax, 134728(%rsp)
	movq	41616(%rsp), %rax
	movq	%rax, 134736(%rsp)
	movq	41624(%rsp), %rax
	movq	%rax, 134744(%rsp)
	movq	41632(%rsp), %rax
	movq	%rax, 134752(%rsp)
	movq	41640(%rsp), %rax
	movq	%rax, 134760(%rsp)
	movq	41648(%rsp), %rax
	movq	%rax, 134768(%rsp)
	movq	41656(%rsp), %rax
	movq	%rax, 134776(%rsp)
	movq	41664(%rsp), %rax
	movq	%rax, 134784(%rsp)
	movq	41672(%rsp), %rax
	movq	%rax, 134792(%rsp)
	movq	41680(%rsp), %rax
	movq	%rax, 134800(%rsp)
	movq	41688(%rsp), %rax
	movq	%rax, 134808(%rsp)
	movq	41696(%rsp), %rax
	movq	%rax, 134816(%rsp)
	movq	41704(%rsp), %rax
	movq	%rax, 134824(%rsp)
	movq	41712(%rsp), %rax
	movq	%rax, 134832(%rsp)
	movq	41720(%rsp), %rax
	movq	%rax, 134840(%rsp)
	movq	41728(%rsp), %rax
	movq	%rax, 134848(%rsp)
	movq	41736(%rsp), %rax
	movq	%rax, 134856(%rsp)
	movq	41744(%rsp), %rax
	movq	%rax, 134864(%rsp)
	movq	41752(%rsp), %rax
	movq	%rax, 134872(%rsp)
	movq	41760(%rsp), %rax
	movq	%rax, 134880(%rsp)
	movq	41768(%rsp), %rax
	movq	%rax, 134888(%rsp)
	movq	41776(%rsp), %rax
	movq	%rax, 134896(%rsp)
	movq	41784(%rsp), %rax
	movq	%rax, 134904(%rsp)
	movq	41792(%rsp), %rax
	movq	%rax, 134912(%rsp)
	movq	41800(%rsp), %rax
	movq	%rax, 134920(%rsp)
	movq	41808(%rsp), %rax
	movq	%rax, 134928(%rsp)
	movq	41816(%rsp), %rax
	movq	%rax, 134936(%rsp)
	movq	41824(%rsp), %rax
	movq	%rax, 134944(%rsp)
	movq	41832(%rsp), %rax
	movq	%rax, 134952(%rsp)
	movq	41840(%rsp), %rax
	movq	%rax, 134960(%rsp)
	movq	41848(%rsp), %rax
	movq	%rax, 134968(%rsp)
	movq	41856(%rsp), %rax
	movq	%rax, 134976(%rsp)
	movq	41864(%rsp), %rax
	movq	%rax, 134984(%rsp)
	movq	41872(%rsp), %rax
	movq	%rax, 134992(%rsp)
	movq	41880(%rsp), %rax
	movq	%rax, 135000(%rsp)
	movq	41888(%rsp), %rax
	movq	%rax, 135008(%rsp)
	movq	41896(%rsp), %rax
	movq	%rax, 135016(%rsp)
	movq	41904(%rsp), %rax
	movq	%rax, 135024(%rsp)
	movq	41912(%rsp), %rax
	movq	%rax, 135032(%rsp)
	movq	41920(%rsp), %rax
	movq	%rax, 135040(%rsp)
	movq	41928(%rsp), %rax
	movq	%rax, 135048(%rsp)
	movq	41936(%rsp), %rax
	movq	%rax, 135056(%rsp)
	movq	41944(%rsp), %rax
	movq	%rax, 135064(%rsp)
	movq	41952(%rsp), %rax
	movq	%rax, 135072(%rsp)
	movq	41960(%rsp), %rax
	movq	%rax, 135080(%rsp)
	movq	41968(%rsp), %rax
	movq	%rax, 135088(%rsp)
	movq	41976(%rsp), %rax
	movq	%rax, 135096(%rsp)
	movq	41984(%rsp), %rax
	movq	%rax, 135104(%rsp)
	movq	41992(%rsp), %rax
	movq	%rax, 135112(%rsp)
	movq	42000(%rsp), %rax
	movq	%rax, 135120(%rsp)
	movq	42008(%rsp), %rax
	movq	%rax, 135128(%rsp)
	movq	42016(%rsp), %rax
	movq	%rax, 135136(%rsp)
	movq	42024(%rsp), %rax
	movq	%rax, 135144(%rsp)
	movq	42032(%rsp), %rax
	movq	%rax, 135152(%rsp)
	movq	42040(%rsp), %rax
	movq	%rax, 135160(%rsp)
	movq	42048(%rsp), %rax
	movq	%rax, 135168(%rsp)
	movq	42056(%rsp), %rax
	movq	%rax, 135176(%rsp)
	movq	42064(%rsp), %rax
	movq	%rax, 135184(%rsp)
	movq	42072(%rsp), %rax
	movq	%rax, 135192(%rsp)
	movq	42080(%rsp), %rax
	movq	%rax, 135200(%rsp)
	movq	42088(%rsp), %rax
	movq	%rax, 135208(%rsp)
	movq	42096(%rsp), %rax
	movq	%rax, 135216(%rsp)
	movq	42104(%rsp), %rax
	movq	%rax, 135224(%rsp)
	movq	42112(%rsp), %rax
	movq	%rax, 135232(%rsp)
	movq	42120(%rsp), %rax
	movq	%rax, 135240(%rsp)
	movq	42128(%rsp), %rax
	movq	%rax, 135248(%rsp)
	movq	42136(%rsp), %rax
	movq	%rax, 135256(%rsp)
	movq	42144(%rsp), %rax
	movq	%rax, 135264(%rsp)
	movq	42152(%rsp), %rax
	movq	%rax, 135272(%rsp)
	movq	42160(%rsp), %rax
	movq	%rax, 135280(%rsp)
	movq	42168(%rsp), %rax
	movq	%rax, 135288(%rsp)
	movq	42176(%rsp), %rax
	movq	%rax, 135296(%rsp)
	movq	42184(%rsp), %rax
	movq	%rax, 135304(%rsp)
	movq	42192(%rsp), %rax
	movq	%rax, 135312(%rsp)
	movq	42200(%rsp), %rax
	movq	%rax, 135320(%rsp)
	movq	42208(%rsp), %rax
	movq	%rax, 135328(%rsp)
	movq	42216(%rsp), %rax
	movq	%rax, 135336(%rsp)
	movq	42224(%rsp), %rax
	movq	%rax, 135344(%rsp)
	movq	42232(%rsp), %rax
	movq	%rax, 135352(%rsp)
	movq	42240(%rsp), %rax
	movq	%rax, 135360(%rsp)
	movq	42248(%rsp), %rax
	movq	%rax, 135368(%rsp)
	movq	42256(%rsp), %rax
	movq	%rax, 135376(%rsp)
	movq	42264(%rsp), %rax
	movq	%rax, 135384(%rsp)
	movq	42272(%rsp), %rax
	movq	%rax, 135392(%rsp)
	movq	42280(%rsp), %rax
	movq	%rax, 135400(%rsp)
	movq	42288(%rsp), %rax
	movq	%rax, 135408(%rsp)
	movq	42296(%rsp), %rax
	movq	%rax, 135416(%rsp)
	movq	42304(%rsp), %rax
	movq	%rax, 135424(%rsp)
	movq	42312(%rsp), %rax
	movq	%rax, 135432(%rsp)
	movq	42320(%rsp), %rax
	movq	%rax, 135440(%rsp)
	movq	42328(%rsp), %rax
	movq	%rax, 135448(%rsp)
	movq	42336(%rsp), %rax
	movq	%rax, 135456(%rsp)
	movq	42344(%rsp), %rax
	movq	%rax, 135464(%rsp)
	movq	42352(%rsp), %rax
	movq	%rax, 135472(%rsp)
	movq	42360(%rsp), %rax
	movq	%rax, 135480(%rsp)
	movq	42368(%rsp), %rax
	movq	%rax, 135488(%rsp)
	movq	42376(%rsp), %rax
	movq	%rax, 135496(%rsp)
	movq	42384(%rsp), %rax
	movq	%rax, 135504(%rsp)
	movq	42392(%rsp), %rax
	movq	%rax, 135512(%rsp)
	movq	42400(%rsp), %rax
	movq	%rax, 135520(%rsp)
	movq	42408(%rsp), %rax
	movq	%rax, 135528(%rsp)
	movq	42416(%rsp), %rax
	movq	%rax, 135536(%rsp)
	movq	42424(%rsp), %rax
	movq	%rax, 135544(%rsp)
	movq	42432(%rsp), %rax
	movq	%rax, 135552(%rsp)
	movq	42440(%rsp), %rax
	movq	%rax, 135560(%rsp)
	movq	42448(%rsp), %rax
	movq	%rax, 135568(%rsp)
	movq	42456(%rsp), %rax
	movq	%rax, 135576(%rsp)
	movq	42464(%rsp), %rax
	movq	%rax, 135584(%rsp)
	movq	42472(%rsp), %rax
	movq	%rax, 135592(%rsp)
	movq	42480(%rsp), %rax
	movq	%rax, 135600(%rsp)
	movq	42488(%rsp), %rax
	movq	%rax, 135608(%rsp)
	movq	42496(%rsp), %rax
	movq	%rax, 135616(%rsp)
	movq	42504(%rsp), %rax
	movq	%rax, 135624(%rsp)
	movq	42512(%rsp), %rax
	movq	%rax, 135632(%rsp)
	movq	42520(%rsp), %rax
	movq	%rax, 135640(%rsp)
	movq	42528(%rsp), %rax
	movq	%rax, 135648(%rsp)
	movq	42536(%rsp), %rax
	movq	%rax, 135656(%rsp)
	movq	42544(%rsp), %rax
	movq	%rax, 135664(%rsp)
	movq	42552(%rsp), %rax
	movq	%rax, 135672(%rsp)
	movq	42560(%rsp), %rax
	movq	%rax, 135680(%rsp)
	movq	42568(%rsp), %rax
	movq	%rax, 135688(%rsp)
	movq	42576(%rsp), %rax
	movq	%rax, 135696(%rsp)
	movq	42584(%rsp), %rax
	movq	%rax, 135704(%rsp)
	movq	42592(%rsp), %rax
	movq	%rax, 135712(%rsp)
	movq	42600(%rsp), %rax
	movq	%rax, 135720(%rsp)
	movq	42608(%rsp), %rax
	movq	%rax, 135728(%rsp)
	movq	42616(%rsp), %rax
	movq	%rax, 135736(%rsp)
	movq	42624(%rsp), %rax
	movq	%rax, 135744(%rsp)
	movq	42632(%rsp), %rax
	movq	%rax, 135752(%rsp)
	movq	42640(%rsp), %rax
	movq	%rax, 135760(%rsp)
	movq	42648(%rsp), %rax
	movq	%rax, 135768(%rsp)
	movq	42656(%rsp), %rax
	movq	%rax, 135776(%rsp)
	movq	42664(%rsp), %rax
	movq	%rax, 135784(%rsp)
	movq	42672(%rsp), %rax
	movq	%rax, 135792(%rsp)
	movq	42680(%rsp), %rax
	movq	%rax, 135800(%rsp)
	movq	42688(%rsp), %rax
	movq	%rax, 135808(%rsp)
	movq	42696(%rsp), %rax
	movq	%rax, 135816(%rsp)
	movq	42704(%rsp), %rax
	movq	%rax, 135824(%rsp)
	movq	42712(%rsp), %rax
	movq	%rax, 135832(%rsp)
	movq	42720(%rsp), %rax
	movq	%rax, 135840(%rsp)
	movq	42728(%rsp), %rax
	movq	%rax, 135848(%rsp)
	movq	42736(%rsp), %rax
	movq	%rax, 135856(%rsp)
	movq	42744(%rsp), %rax
	movq	%rax, 135864(%rsp)
	movq	42752(%rsp), %rax
	movq	%rax, 135872(%rsp)
	movq	42760(%rsp), %rax
	movq	%rax, 135880(%rsp)
	movq	42768(%rsp), %rax
	movq	%rax, 135888(%rsp)
	movq	42776(%rsp), %rax
	movq	%rax, 135896(%rsp)
	movq	42784(%rsp), %rax
	movq	%rax, 135904(%rsp)
	movq	42792(%rsp), %rax
	movq	%rax, 135912(%rsp)
	movq	42800(%rsp), %rax
	movq	%rax, 135920(%rsp)
	movq	42808(%rsp), %rax
	movq	%rax, 135928(%rsp)
	movq	42816(%rsp), %rax
	movq	%rax, 135936(%rsp)
	movq	42824(%rsp), %rax
	movq	%rax, 135944(%rsp)
	movq	42832(%rsp), %rax
	movq	%rax, 135952(%rsp)
	movq	42840(%rsp), %rax
	movq	%rax, 135960(%rsp)
	movq	42848(%rsp), %rax
	movq	%rax, 135968(%rsp)
	movq	42856(%rsp), %rax
	movq	%rax, 135976(%rsp)
	movq	42864(%rsp), %rax
	movq	%rax, 135984(%rsp)
	movq	42872(%rsp), %rax
	movq	%rax, 135992(%rsp)
	movq	42880(%rsp), %rax
	movq	%rax, 136000(%rsp)
	movq	42888(%rsp), %rax
	movq	%rax, 136008(%rsp)
	movq	42896(%rsp), %rax
	movq	%rax, 136016(%rsp)
	movq	42904(%rsp), %rax
	movq	%rax, 136024(%rsp)
	movq	42912(%rsp), %rax
	movq	%rax, 136032(%rsp)
	movq	42920(%rsp), %rax
	movq	%rax, 136040(%rsp)
	movq	42928(%rsp), %rax
	movq	%rax, 136048(%rsp)
	movq	42936(%rsp), %rax
	movq	%rax, 136056(%rsp)
	movq	42944(%rsp), %rax
	movq	%rax, 136064(%rsp)
	movq	42952(%rsp), %rax
	movq	%rax, 136072(%rsp)
	movq	42960(%rsp), %rax
	movq	%rax, 136080(%rsp)
	movq	42968(%rsp), %rax
	movq	%rax, 136088(%rsp)
	movq	42976(%rsp), %rax
	movq	%rax, 136096(%rsp)
	movq	42984(%rsp), %rax
	movq	%rax, 136104(%rsp)
	movq	42992(%rsp), %rax
	movq	%rax, 136112(%rsp)
	movq	43000(%rsp), %rax
	movq	%rax, 136120(%rsp)
	movq	43008(%rsp), %rax
	movq	%rax, 136128(%rsp)
	movq	43016(%rsp), %rax
	movq	%rax, 136136(%rsp)
	movq	43024(%rsp), %rax
	movq	%rax, 136144(%rsp)
	movq	43032(%rsp), %rax
	movq	%rax, 136152(%rsp)
	movq	43040(%rsp), %rax
	movq	%rax, 136160(%rsp)
	movq	43048(%rsp), %rax
	movq	%rax, 136168(%rsp)
	movq	43056(%rsp), %rax
	movq	%rax, 136176(%rsp)
	movq	43064(%rsp), %rax
	movq	%rax, 136184(%rsp)
	movq	43072(%rsp), %rax
	movq	%rax, 136192(%rsp)
	movq	43080(%rsp), %rax
	movq	%rax, 136200(%rsp)
	movq	43088(%rsp), %rax
	movq	%rax, 136208(%rsp)
	movq	43096(%rsp), %rax
	movq	%rax, 136216(%rsp)
	movq	43104(%rsp), %rax
	movq	%rax, 136224(%rsp)
	movq	43112(%rsp), %rax
	movq	%rax, 136232(%rsp)
	movq	43120(%rsp), %rax
	movq	%rax, 136240(%rsp)
	movq	43128(%rsp), %rax
	movq	%rax, 136248(%rsp)
	movq	43136(%rsp), %rax
	movq	%rax, 136256(%rsp)
	movq	43144(%rsp), %rax
	movq	%rax, 136264(%rsp)
	movq	43152(%rsp), %rax
	movq	%rax, 136272(%rsp)
	movq	43160(%rsp), %rax
	movq	%rax, 136280(%rsp)
	movq	43168(%rsp), %rax
	movq	%rax, 136288(%rsp)
	movq	43176(%rsp), %rax
	movq	%rax, 136296(%rsp)
	movq	43184(%rsp), %rax
	movq	%rax, 136304(%rsp)
	movq	43192(%rsp), %rax
	movq	%rax, 136312(%rsp)
	movq	43200(%rsp), %rax
	movq	%rax, 136320(%rsp)
	movq	43208(%rsp), %rax
	movq	%rax, 136328(%rsp)
	movq	43216(%rsp), %rax
	movq	%rax, 136336(%rsp)
	movq	43224(%rsp), %rax
	movq	%rax, 136344(%rsp)
	movq	43232(%rsp), %rax
	movq	%rax, 136352(%rsp)
	movq	43240(%rsp), %rax
	movq	%rax, 136360(%rsp)
	movq	43248(%rsp), %rax
	movq	%rax, 136368(%rsp)
	movq	43256(%rsp), %rax
	movq	%rax, 136376(%rsp)
	movq	43264(%rsp), %rax
	movq	%rax, 136384(%rsp)
	movq	43272(%rsp), %rax
	movq	%rax, 136392(%rsp)
	movq	43280(%rsp), %rax
	movq	%rax, 136400(%rsp)
	movq	43288(%rsp), %rax
	movq	%rax, 136408(%rsp)
	movq	43296(%rsp), %rax
	movq	%rax, 136416(%rsp)
	movq	43304(%rsp), %rax
	movq	%rax, 136424(%rsp)
	movq	43312(%rsp), %rax
	movq	%rax, 136432(%rsp)
	movq	43320(%rsp), %rax
	movq	%rax, 136440(%rsp)
	movq	43328(%rsp), %rax
	movq	%rax, 136448(%rsp)
	movq	43336(%rsp), %rax
	movq	%rax, 136456(%rsp)
	movq	43344(%rsp), %rax
	movq	%rax, 136464(%rsp)
	movq	43352(%rsp), %rax
	movq	%rax, 136472(%rsp)
	movq	43360(%rsp), %rax
	movq	%rax, 136480(%rsp)
	movq	43368(%rsp), %rax
	movq	%rax, 136488(%rsp)
	movq	43376(%rsp), %rax
	movq	%rax, 136496(%rsp)
	movq	43384(%rsp), %rax
	movq	%rax, 136504(%rsp)
	movq	43392(%rsp), %rax
	movq	%rax, 136512(%rsp)
	movq	43400(%rsp), %rax
	movq	%rax, 136520(%rsp)
	movq	43408(%rsp), %rax
	movq	%rax, 136528(%rsp)
	movq	43416(%rsp), %rax
	movq	%rax, 136536(%rsp)
	movq	43424(%rsp), %rax
	movq	%rax, 136544(%rsp)
	movq	43432(%rsp), %rax
	movq	%rax, 136552(%rsp)
	movq	43440(%rsp), %rax
	movq	%rax, 136560(%rsp)
	movq	43448(%rsp), %rax
	movq	%rax, 136568(%rsp)
	movq	43456(%rsp), %rax
	movq	%rax, 136576(%rsp)
	movq	43464(%rsp), %rax
	movq	%rax, 136584(%rsp)
	movq	43472(%rsp), %rax
	movq	%rax, 136592(%rsp)
	movq	43480(%rsp), %rax
	movq	%rax, 136600(%rsp)
	movq	43488(%rsp), %rax
	movq	%rax, 136608(%rsp)
	movq	43496(%rsp), %rax
	movq	%rax, 136616(%rsp)
	movq	43504(%rsp), %rax
	movq	%rax, 136624(%rsp)
	movq	43512(%rsp), %rax
	movq	%rax, 136632(%rsp)
	movq	43520(%rsp), %rax
	movq	%rax, 136640(%rsp)
	movq	43528(%rsp), %rax
	movq	%rax, 136648(%rsp)
	movq	43536(%rsp), %rax
	movq	%rax, 136656(%rsp)
	movq	43544(%rsp), %rax
	movq	%rax, 136664(%rsp)
	movq	43552(%rsp), %rax
	movq	%rax, 136672(%rsp)
	movq	43560(%rsp), %rax
	movq	%rax, 136680(%rsp)
	movq	43568(%rsp), %rax
	movq	%rax, 136688(%rsp)
	movq	43576(%rsp), %rax
	movq	%rax, 136696(%rsp)
	movq	43584(%rsp), %rax
	movq	%rax, 136704(%rsp)
	movq	43592(%rsp), %rax
	movq	%rax, 136712(%rsp)
	movq	43600(%rsp), %rax
	movq	%rax, 136720(%rsp)
	movq	43608(%rsp), %rax
	movq	%rax, 136728(%rsp)
	movq	43616(%rsp), %rax
	movq	%rax, 136736(%rsp)
	movq	43624(%rsp), %rax
	movq	%rax, 136744(%rsp)
	movq	43632(%rsp), %rax
	movq	%rax, 136752(%rsp)
	movq	43640(%rsp), %rax
	movq	%rax, 136760(%rsp)
	movq	43648(%rsp), %rax
	movq	%rax, 136768(%rsp)
	movq	43656(%rsp), %rax
	movq	%rax, 136776(%rsp)
	movq	43664(%rsp), %rax
	movq	%rax, 136784(%rsp)
	movq	43672(%rsp), %rax
	movq	%rax, 136792(%rsp)
	movq	43680(%rsp), %rax
	movq	%rax, 136800(%rsp)
	movq	43688(%rsp), %rax
	movq	%rax, 136808(%rsp)
	movq	43696(%rsp), %rax
	movq	%rax, 136816(%rsp)
	movq	43704(%rsp), %rax
	movq	%rax, 136824(%rsp)
	movq	43712(%rsp), %rax
	movq	%rax, 136832(%rsp)
	movq	43720(%rsp), %rax
	movq	%rax, 136840(%rsp)
	movq	43728(%rsp), %rax
	movq	%rax, 136848(%rsp)
	movq	43736(%rsp), %rax
	movq	%rax, 136856(%rsp)
	movq	43744(%rsp), %rax
	movq	%rax, 136864(%rsp)
	movq	43752(%rsp), %rax
	movq	%rax, 136872(%rsp)
	movq	43760(%rsp), %rax
	movq	%rax, 136880(%rsp)
	movq	43768(%rsp), %rax
	movq	%rax, 136888(%rsp)
	movq	43776(%rsp), %rax
	movq	%rax, 136896(%rsp)
	movq	43784(%rsp), %rax
	movq	%rax, 136904(%rsp)
	movq	43792(%rsp), %rax
	movq	%rax, 136912(%rsp)
	movq	43800(%rsp), %rax
	movq	%rax, 136920(%rsp)
	movq	43808(%rsp), %rax
	movq	%rax, 136928(%rsp)
	movq	43816(%rsp), %rax
	movq	%rax, 136936(%rsp)
	movq	43824(%rsp), %rax
	movq	%rax, 136944(%rsp)
	movq	43832(%rsp), %rax
	movq	%rax, 136952(%rsp)
	movq	43840(%rsp), %rax
	movq	%rax, 136960(%rsp)
	movq	43848(%rsp), %rax
	movq	%rax, 136968(%rsp)
	movq	43856(%rsp), %rax
	movq	%rax, 136976(%rsp)
	movq	43864(%rsp), %rax
	movq	%rax, 136984(%rsp)
	movq	43872(%rsp), %rax
	movq	%rax, 136992(%rsp)
	movq	43880(%rsp), %rax
	movq	%rax, 137000(%rsp)
	movq	43888(%rsp), %rax
	movq	%rax, 137008(%rsp)
	movq	43896(%rsp), %rax
	movq	%rax, 137016(%rsp)
	movq	43904(%rsp), %rax
	movq	%rax, 137024(%rsp)
	movq	43912(%rsp), %rax
	movq	%rax, 137032(%rsp)
	movq	43920(%rsp), %rax
	movq	%rax, 137040(%rsp)
	movq	43928(%rsp), %rax
	movq	%rax, 137048(%rsp)
	movq	43936(%rsp), %rax
	movq	%rax, 137056(%rsp)
	movq	43944(%rsp), %rax
	movq	%rax, 137064(%rsp)
	movq	43952(%rsp), %rax
	movq	%rax, 137072(%rsp)
	movq	43960(%rsp), %rax
	movq	%rax, 137080(%rsp)
	movq	43968(%rsp), %rax
	movq	%rax, 137088(%rsp)
	movq	43976(%rsp), %rax
	movq	%rax, 137096(%rsp)
	movq	43984(%rsp), %rax
	movq	%rax, 137104(%rsp)
	movq	43992(%rsp), %rax
	movq	%rax, 137112(%rsp)
	movq	44000(%rsp), %rax
	movq	%rax, 137120(%rsp)
	movq	44008(%rsp), %rax
	movq	%rax, 137128(%rsp)
	movq	44016(%rsp), %rax
	movq	%rax, 137136(%rsp)
	movq	44024(%rsp), %rax
	movq	%rax, 137144(%rsp)
	movq	44032(%rsp), %rax
	movq	%rax, 137152(%rsp)
	movq	44040(%rsp), %rax
	movq	%rax, 137160(%rsp)
	movq	44048(%rsp), %rax
	movq	%rax, 137168(%rsp)
	movq	44056(%rsp), %rax
	movq	%rax, 137176(%rsp)
	movq	44064(%rsp), %rax
	movq	%rax, 137184(%rsp)
	movq	44072(%rsp), %rax
	movq	%rax, 137192(%rsp)
	movq	44080(%rsp), %rax
	movq	%rax, 137200(%rsp)
	movq	44088(%rsp), %rax
	movq	%rax, 137208(%rsp)
	movq	44096(%rsp), %rax
	movq	%rax, 137216(%rsp)
	movq	44104(%rsp), %rax
	movq	%rax, 137224(%rsp)
	movq	44112(%rsp), %rax
	movq	%rax, 137232(%rsp)
	movq	44120(%rsp), %rax
	movq	%rax, 137240(%rsp)
	movq	44128(%rsp), %rax
	movq	%rax, 137248(%rsp)
	movq	44136(%rsp), %rax
	movq	%rax, 137256(%rsp)
	movq	44144(%rsp), %rax
	movq	%rax, 137264(%rsp)
	movq	44152(%rsp), %rax
	movq	%rax, 137272(%rsp)
	movq	44160(%rsp), %rax
	movq	%rax, 137280(%rsp)
	movq	44168(%rsp), %rax
	movq	%rax, 137288(%rsp)
	movq	44176(%rsp), %rax
	movq	%rax, 137296(%rsp)
	movq	44184(%rsp), %rax
	movq	%rax, 137304(%rsp)
	movq	44192(%rsp), %rax
	movq	%rax, 137312(%rsp)
	movq	44200(%rsp), %rax
	movq	%rax, 137320(%rsp)
	movq	44208(%rsp), %rax
	movq	%rax, 137328(%rsp)
	movq	44216(%rsp), %rax
	movq	%rax, 137336(%rsp)
	movq	44224(%rsp), %rax
	movq	%rax, 137344(%rsp)
	movq	44232(%rsp), %rax
	movq	%rax, 137352(%rsp)
	movq	44240(%rsp), %rax
	movq	%rax, 137360(%rsp)
	movq	44248(%rsp), %rax
	movq	%rax, 137368(%rsp)
	movq	44256(%rsp), %rax
	movq	%rax, 137376(%rsp)
	movq	44264(%rsp), %rax
	movq	%rax, 137384(%rsp)
	movq	44272(%rsp), %rax
	movq	%rax, 137392(%rsp)
	movq	44280(%rsp), %rax
	movq	%rax, 137400(%rsp)
	movq	44288(%rsp), %rax
	movq	%rax, 137408(%rsp)
	movq	44296(%rsp), %rax
	movq	%rax, 137416(%rsp)
	movq	44304(%rsp), %rax
	movq	%rax, 137424(%rsp)
	movq	44312(%rsp), %rax
	movq	%rax, 137432(%rsp)
	movq	44320(%rsp), %rax
	movq	%rax, 137440(%rsp)
	movq	44328(%rsp), %rax
	movq	%rax, 137448(%rsp)
	movq	44336(%rsp), %rax
	movq	%rax, 137456(%rsp)
	movq	44344(%rsp), %rax
	movq	%rax, 137464(%rsp)
	movq	44352(%rsp), %rax
	movq	%rax, 137472(%rsp)
	movq	44360(%rsp), %rax
	movq	%rax, 137480(%rsp)
	movq	44368(%rsp), %rax
	movq	%rax, 137488(%rsp)
	movq	44376(%rsp), %rax
	movq	%rax, 137496(%rsp)
	movq	44384(%rsp), %rax
	movq	%rax, 137504(%rsp)
	movq	44392(%rsp), %rax
	movq	%rax, 137512(%rsp)
	movq	44400(%rsp), %rax
	movq	%rax, 137520(%rsp)
	movq	44408(%rsp), %rax
	movq	%rax, 137528(%rsp)
	movq	44416(%rsp), %rax
	movq	%rax, 137536(%rsp)
	movq	44424(%rsp), %rax
	movq	%rax, 137544(%rsp)
	movq	44432(%rsp), %rax
	movq	%rax, 137552(%rsp)
	movq	44440(%rsp), %rax
	movq	%rax, 137560(%rsp)
	movq	44448(%rsp), %rax
	movq	%rax, 137568(%rsp)
	movq	44456(%rsp), %rax
	movq	%rax, 137576(%rsp)
	movq	44464(%rsp), %rax
	movq	%rax, 137584(%rsp)
	movq	44472(%rsp), %rax
	movq	%rax, 137592(%rsp)
	movq	44480(%rsp), %rax
	movq	%rax, 137600(%rsp)
	movq	44488(%rsp), %rax
	movq	%rax, 137608(%rsp)
	movq	44496(%rsp), %rax
	movq	%rax, 137616(%rsp)
	movq	44504(%rsp), %rax
	movq	%rax, 137624(%rsp)
	movq	44512(%rsp), %rax
	movq	%rax, 137632(%rsp)
	movq	44520(%rsp), %rax
	movq	%rax, 137640(%rsp)
	movq	44528(%rsp), %rax
	movq	%rax, 137648(%rsp)
	movq	44536(%rsp), %rax
	movq	%rax, 137656(%rsp)
	movq	44544(%rsp), %rax
	movq	%rax, 137664(%rsp)
	movq	44552(%rsp), %rax
	movq	%rax, 137672(%rsp)
	movq	44560(%rsp), %rax
	movq	%rax, 137680(%rsp)
	movq	44568(%rsp), %rax
	movq	%rax, 137688(%rsp)
	movq	44576(%rsp), %rax
	movq	%rax, 137696(%rsp)
	movq	44584(%rsp), %rax
	movq	%rax, 137704(%rsp)
	movq	44592(%rsp), %rax
	movq	%rax, 137712(%rsp)
	movq	44600(%rsp), %rax
	movq	%rax, 137720(%rsp)
	movq	44608(%rsp), %rax
	movq	%rax, 137728(%rsp)
	movq	44616(%rsp), %rax
	movq	%rax, 137736(%rsp)
	movq	44624(%rsp), %rax
	movq	%rax, 137744(%rsp)
	movq	44632(%rsp), %rax
	movq	%rax, 137752(%rsp)
	movq	44640(%rsp), %rax
	movq	%rax, 137760(%rsp)
	movq	44648(%rsp), %rax
	movq	%rax, 137768(%rsp)
	movq	44656(%rsp), %rax
	movq	%rax, 137776(%rsp)
	movq	44664(%rsp), %rax
	movq	%rax, 137784(%rsp)
	movq	44672(%rsp), %rax
	movq	%rax, 137792(%rsp)
	movq	44680(%rsp), %rax
	movq	%rax, 137800(%rsp)
	movq	44688(%rsp), %rax
	movq	%rax, 137808(%rsp)
	movq	44696(%rsp), %rax
	movq	%rax, 137816(%rsp)
	movq	44704(%rsp), %rax
	movq	%rax, 137824(%rsp)
	movq	44712(%rsp), %rax
	movq	%rax, 137832(%rsp)
	movq	44720(%rsp), %rax
	movq	%rax, 137840(%rsp)
	movq	44728(%rsp), %rax
	movq	%rax, 137848(%rsp)
	movq	44736(%rsp), %rax
	movq	%rax, 137856(%rsp)
	movq	44744(%rsp), %rax
	movq	%rax, 137864(%rsp)
	movq	44752(%rsp), %rax
	movq	%rax, 137872(%rsp)
	movq	44760(%rsp), %rax
	movq	%rax, 137880(%rsp)
	movq	44768(%rsp), %rax
	movq	%rax, 137888(%rsp)
	movq	44776(%rsp), %rax
	movq	%rax, 137896(%rsp)
	movq	44784(%rsp), %rax
	movq	%rax, 137904(%rsp)
	movq	44792(%rsp), %rax
	movq	%rax, 137912(%rsp)
	movq	44800(%rsp), %rax
	movq	%rax, 137920(%rsp)
	movq	44808(%rsp), %rax
	movq	%rax, 137928(%rsp)
	movq	44816(%rsp), %rax
	movq	%rax, 137936(%rsp)
	movq	44824(%rsp), %rax
	movq	%rax, 137944(%rsp)
	movq	44832(%rsp), %rax
	movq	%rax, 137952(%rsp)
	movq	44840(%rsp), %rax
	movq	%rax, 137960(%rsp)
	movq	44848(%rsp), %rax
	movq	%rax, 137968(%rsp)
	movq	44856(%rsp), %rax
	movq	%rax, 137976(%rsp)
	movq	44864(%rsp), %rax
	movq	%rax, 137984(%rsp)
	movq	44872(%rsp), %rax
	movq	%rax, 137992(%rsp)
	movq	44880(%rsp), %rax
	movq	%rax, 138000(%rsp)
	movq	44888(%rsp), %rax
	movq	%rax, 138008(%rsp)
	movq	44896(%rsp), %rax
	movq	%rax, 138016(%rsp)
	movq	44904(%rsp), %rax
	movq	%rax, 138024(%rsp)
	movq	44912(%rsp), %rax
	movq	%rax, 138032(%rsp)
	movq	44920(%rsp), %rax
	movq	%rax, 138040(%rsp)
	movq	44928(%rsp), %rax
	movq	%rax, 138048(%rsp)
	movq	44936(%rsp), %rax
	movq	%rax, 138056(%rsp)
	movq	44944(%rsp), %rax
	movq	%rax, 138064(%rsp)
	movq	44952(%rsp), %rax
	movq	%rax, 138072(%rsp)
	movq	44960(%rsp), %rax
	movq	%rax, 138080(%rsp)
	movq	44968(%rsp), %rax
	movq	%rax, 138088(%rsp)
	movq	44976(%rsp), %rax
	movq	%rax, 138096(%rsp)
	movq	44984(%rsp), %rax
	movq	%rax, 138104(%rsp)
	movq	44992(%rsp), %rax
	movq	%rax, 138112(%rsp)
	movq	45000(%rsp), %rax
	movq	%rax, 138120(%rsp)
	movq	45008(%rsp), %rax
	movq	%rax, 138128(%rsp)
	movq	45016(%rsp), %rax
	movq	%rax, 138136(%rsp)
	movq	45024(%rsp), %rax
	movq	%rax, 138144(%rsp)
	movq	45032(%rsp), %rax
	movq	%rax, 138152(%rsp)
	movq	45040(%rsp), %rax
	movq	%rax, 138160(%rsp)
	movq	45048(%rsp), %rax
	movq	%rax, 138168(%rsp)
	movq	45056(%rsp), %rax
	movq	%rax, 138176(%rsp)
	movq	45064(%rsp), %rax
	movq	%rax, 138184(%rsp)
	movq	45072(%rsp), %rax
	movq	%rax, 138192(%rsp)
	movq	45080(%rsp), %rax
	movq	%rax, 138200(%rsp)
	movq	45088(%rsp), %rax
	movq	%rax, 138208(%rsp)
	movq	45096(%rsp), %rax
	movq	%rax, 138216(%rsp)
	movq	45104(%rsp), %rax
	movq	%rax, 138224(%rsp)
	movq	45112(%rsp), %rax
	movq	%rax, 138232(%rsp)
	movq	45120(%rsp), %rax
	movq	%rax, 138240(%rsp)
	movq	45128(%rsp), %rax
	movq	%rax, 138248(%rsp)
	movq	45136(%rsp), %rax
	movq	%rax, 138256(%rsp)
	movq	45144(%rsp), %rax
	movq	%rax, 138264(%rsp)
	movq	45152(%rsp), %rax
	movq	%rax, 138272(%rsp)
	movq	45160(%rsp), %rax
	movq	%rax, 138280(%rsp)
	movq	45168(%rsp), %rax
	movq	%rax, 138288(%rsp)
	movq	45176(%rsp), %rax
	movq	%rax, 138296(%rsp)
	movq	45184(%rsp), %rax
	movq	%rax, 138304(%rsp)
	movq	45192(%rsp), %rax
	movq	%rax, 138312(%rsp)
	movq	45200(%rsp), %rax
	movq	%rax, 138320(%rsp)
	movq	45208(%rsp), %rax
	movq	%rax, 138328(%rsp)
	movq	45216(%rsp), %rax
	movq	%rax, 138336(%rsp)
	movq	45224(%rsp), %rax
	movq	%rax, 138344(%rsp)
	movq	45232(%rsp), %rax
	movq	%rax, 138352(%rsp)
	movq	45240(%rsp), %rax
	movq	%rax, 138360(%rsp)
	movq	45248(%rsp), %rax
	movq	%rax, 138368(%rsp)
	movq	45256(%rsp), %rax
	movq	%rax, 138376(%rsp)
	movq	45264(%rsp), %rax
	movq	%rax, 138384(%rsp)
	movq	45272(%rsp), %rax
	movq	%rax, 138392(%rsp)
	movq	45280(%rsp), %rax
	movq	%rax, 138400(%rsp)
	movq	45288(%rsp), %rax
	movq	%rax, 138408(%rsp)
	movq	45296(%rsp), %rax
	movq	%rax, 138416(%rsp)
	movq	45304(%rsp), %rax
	movq	%rax, 138424(%rsp)
	movq	45312(%rsp), %rax
	movq	%rax, 138432(%rsp)
	movq	45320(%rsp), %rax
	movq	%rax, 138440(%rsp)
	movq	45328(%rsp), %rax
	movq	%rax, 138448(%rsp)
	movq	45336(%rsp), %rax
	movq	%rax, 138456(%rsp)
	movq	45344(%rsp), %rax
	movq	%rax, 138464(%rsp)
	movq	45352(%rsp), %rax
	movq	%rax, 138472(%rsp)
	movq	45360(%rsp), %rax
	movq	%rax, 138480(%rsp)
	movq	45368(%rsp), %rax
	movq	%rax, 138488(%rsp)
	movq	45376(%rsp), %rax
	movq	%rax, 138496(%rsp)
	movq	45384(%rsp), %rax
	movq	%rax, 138504(%rsp)
	movq	45392(%rsp), %rax
	movq	%rax, 138512(%rsp)
	movq	45400(%rsp), %rax
	movq	%rax, 138520(%rsp)
	movq	45408(%rsp), %rax
	movq	%rax, 138528(%rsp)
	movq	45416(%rsp), %rax
	movq	%rax, 138536(%rsp)
	movq	45424(%rsp), %rax
	movq	%rax, 138544(%rsp)
	movq	45432(%rsp), %rax
	movq	%rax, 138552(%rsp)
	movq	45440(%rsp), %rax
	movq	%rax, 138560(%rsp)
	movq	45448(%rsp), %rax
	movq	%rax, 138568(%rsp)
	movq	45456(%rsp), %rax
	movq	%rax, 138576(%rsp)
	movq	45464(%rsp), %rax
	movq	%rax, 138584(%rsp)
	movq	45472(%rsp), %rax
	movq	%rax, 138592(%rsp)
	movq	45480(%rsp), %rax
	movq	%rax, 138600(%rsp)
	movq	45488(%rsp), %rax
	movq	%rax, 138608(%rsp)
	movq	45496(%rsp), %rax
	movq	%rax, 138616(%rsp)
	movq	45504(%rsp), %rax
	movq	%rax, 138624(%rsp)
	movq	45512(%rsp), %rax
	movq	%rax, 138632(%rsp)
	movq	45520(%rsp), %rax
	movq	%rax, 138640(%rsp)
	movq	45528(%rsp), %rax
	movq	%rax, 138648(%rsp)
	movq	45536(%rsp), %rax
	movq	%rax, 138656(%rsp)
	movq	45544(%rsp), %rax
	movq	%rax, 138664(%rsp)
	movq	45552(%rsp), %rax
	movq	%rax, 138672(%rsp)
	movq	45560(%rsp), %rax
	movq	%rax, 138680(%rsp)
	movq	45568(%rsp), %rax
	movq	%rax, 138688(%rsp)
	movq	45576(%rsp), %rax
	movq	%rax, 138696(%rsp)
	movq	45584(%rsp), %rax
	movq	%rax, 138704(%rsp)
	movq	45592(%rsp), %rax
	movq	%rax, 138712(%rsp)
	movq	45600(%rsp), %rax
	movq	%rax, 138720(%rsp)
	movq	45608(%rsp), %rax
	movq	%rax, 138728(%rsp)
	movq	45616(%rsp), %rax
	movq	%rax, 138736(%rsp)
	movq	45624(%rsp), %rax
	movq	%rax, 138744(%rsp)
	movq	45632(%rsp), %rax
	movq	%rax, 138752(%rsp)
	movq	45640(%rsp), %rax
	movq	%rax, 138760(%rsp)
	movq	45648(%rsp), %rax
	movq	%rax, 138768(%rsp)
	movq	45656(%rsp), %rax
	movq	%rax, 138776(%rsp)
	movq	45664(%rsp), %rax
	movq	%rax, 138784(%rsp)
	movq	45672(%rsp), %rax
	movq	%rax, 138792(%rsp)
	movq	45680(%rsp), %rax
	movq	%rax, 138800(%rsp)
	movq	45688(%rsp), %rax
	movq	%rax, 138808(%rsp)
	movq	45696(%rsp), %rax
	movq	%rax, 138816(%rsp)
	movq	45704(%rsp), %rax
	movq	%rax, 138824(%rsp)
	movq	45712(%rsp), %rax
	movq	%rax, 138832(%rsp)
	movq	45720(%rsp), %rax
	movq	%rax, 138840(%rsp)
	movq	45728(%rsp), %rax
	movq	%rax, 138848(%rsp)
	movq	45736(%rsp), %rax
	movq	%rax, 138856(%rsp)
	movq	45744(%rsp), %rax
	movq	%rax, 138864(%rsp)
	movq	45752(%rsp), %rax
	movq	%rax, 138872(%rsp)
	movq	45760(%rsp), %rax
	movq	%rax, 138880(%rsp)
	movq	45768(%rsp), %rax
	movq	%rax, 138888(%rsp)
	movq	45776(%rsp), %rax
	movq	%rax, 138896(%rsp)
	movq	45784(%rsp), %rax
	movq	%rax, 138904(%rsp)
	movq	45792(%rsp), %rax
	movq	%rax, 138912(%rsp)
	movq	45800(%rsp), %rax
	movq	%rax, 138920(%rsp)
	movq	45808(%rsp), %rax
	movq	%rax, 138928(%rsp)
	movq	45816(%rsp), %rax
	movq	%rax, 138936(%rsp)
	movq	45824(%rsp), %rax
	movq	%rax, 138944(%rsp)
	movq	45832(%rsp), %rax
	movq	%rax, 138952(%rsp)
	movq	45840(%rsp), %rax
	movq	%rax, 138960(%rsp)
	movq	45848(%rsp), %rax
	movq	%rax, 138968(%rsp)
	movq	45856(%rsp), %rax
	movq	%rax, 138976(%rsp)
	movq	45864(%rsp), %rax
	movq	%rax, 138984(%rsp)
	movq	45872(%rsp), %rax
	movq	%rax, 138992(%rsp)
	movq	45880(%rsp), %rax
	movq	%rax, 139000(%rsp)
	movq	45888(%rsp), %rax
	movq	%rax, 139008(%rsp)
	movq	45896(%rsp), %rax
	movq	%rax, 139016(%rsp)
	movq	45904(%rsp), %rax
	movq	%rax, 139024(%rsp)
	movq	45912(%rsp), %rax
	movq	%rax, 139032(%rsp)
	movq	45920(%rsp), %rax
	movq	%rax, 139040(%rsp)
	movq	45928(%rsp), %rax
	movq	%rax, 139048(%rsp)
	movq	45936(%rsp), %rax
	movq	%rax, 139056(%rsp)
	movq	45944(%rsp), %rax
	movq	%rax, 139064(%rsp)
	movq	45952(%rsp), %rax
	movq	%rax, 139072(%rsp)
	movq	45960(%rsp), %rax
	movq	%rax, 139080(%rsp)
	movq	45968(%rsp), %rax
	movq	%rax, 139088(%rsp)
	movq	45976(%rsp), %rax
	movq	%rax, 139096(%rsp)
	movq	45984(%rsp), %rax
	movq	%rax, 139104(%rsp)
	movq	45992(%rsp), %rax
	movq	%rax, 139112(%rsp)
	movq	46000(%rsp), %rax
	movq	%rax, 139120(%rsp)
	movq	46008(%rsp), %rax
	movq	%rax, 139128(%rsp)
	movq	46016(%rsp), %rax
	movq	%rax, 139136(%rsp)
	movq	46024(%rsp), %rax
	movq	%rax, 139144(%rsp)
	movq	46032(%rsp), %rax
	movq	%rax, 139152(%rsp)
	movq	46040(%rsp), %rax
	movq	%rax, 139160(%rsp)
	movq	46048(%rsp), %rax
	movq	%rax, 139168(%rsp)
	movq	46056(%rsp), %rax
	movq	%rax, 139176(%rsp)
	movq	46064(%rsp), %rax
	movq	%rax, 139184(%rsp)
	movq	46072(%rsp), %rax
	movq	%rax, 139192(%rsp)
	movq	46080(%rsp), %rax
	movq	%rax, 139200(%rsp)
	movq	46088(%rsp), %rax
	movq	%rax, 139208(%rsp)
	movq	46096(%rsp), %rax
	movq	%rax, 139216(%rsp)
	movq	46104(%rsp), %rax
	movq	%rax, 139224(%rsp)
	movq	46112(%rsp), %rax
	movq	%rax, 139232(%rsp)
	movq	46120(%rsp), %rax
	movq	%rax, 139240(%rsp)
	movq	46128(%rsp), %rax
	movq	%rax, 139248(%rsp)
	movq	46136(%rsp), %rax
	movq	%rax, 139256(%rsp)
	movq	46144(%rsp), %rax
	movq	%rax, 139264(%rsp)
	movq	46152(%rsp), %rax
	movq	%rax, 139272(%rsp)
	movq	46160(%rsp), %rax
	movq	%rax, 139280(%rsp)
	movq	46168(%rsp), %rax
	movq	%rax, 139288(%rsp)
	movq	46176(%rsp), %rax
	movq	%rax, 139296(%rsp)
	movq	46184(%rsp), %rax
	movq	%rax, 139304(%rsp)
	movq	46192(%rsp), %rax
	movq	%rax, 139312(%rsp)
	movq	46200(%rsp), %rax
	movq	%rax, 139320(%rsp)
	movq	46208(%rsp), %rax
	movq	%rax, 139328(%rsp)
	movq	46216(%rsp), %rax
	movq	%rax, 139336(%rsp)
	movq	46224(%rsp), %rax
	movq	%rax, 139344(%rsp)
	movq	46232(%rsp), %rax
	movq	%rax, 139352(%rsp)
	movq	46240(%rsp), %rax
	movq	%rax, 139360(%rsp)
	movq	46248(%rsp), %rax
	movq	%rax, 139368(%rsp)
	movq	46256(%rsp), %rax
	movq	%rax, 139376(%rsp)
	movq	46264(%rsp), %rax
	movq	%rax, 139384(%rsp)
	movq	46272(%rsp), %rax
	movq	%rax, 139392(%rsp)
	movq	46280(%rsp), %rax
	movq	%rax, 139400(%rsp)
	movq	46288(%rsp), %rax
	movq	%rax, 139408(%rsp)
	movq	46296(%rsp), %rax
	movq	%rax, 139416(%rsp)
	movq	46304(%rsp), %rax
	movq	%rax, 139424(%rsp)
	movq	46312(%rsp), %rax
	movq	%rax, 139432(%rsp)
	movq	46320(%rsp), %rax
	movq	%rax, 139440(%rsp)
	movq	46328(%rsp), %rax
	movq	%rax, 139448(%rsp)
	movq	46336(%rsp), %rax
	movq	%rax, 139456(%rsp)
	movq	46344(%rsp), %rax
	movq	%rax, 139464(%rsp)
	movq	46352(%rsp), %rax
	movq	%rax, 139472(%rsp)
	movq	46360(%rsp), %rax
	movq	%rax, 139480(%rsp)
	movq	46368(%rsp), %rax
	movq	%rax, 139488(%rsp)
	movq	46376(%rsp), %rax
	movq	%rax, 139496(%rsp)
	movq	46384(%rsp), %rax
	movq	%rax, 139504(%rsp)
	movq	46392(%rsp), %rax
	movq	%rax, 139512(%rsp)
	movq	46400(%rsp), %rax
	movq	%rax, 139520(%rsp)
	movq	46408(%rsp), %rax
	movq	%rax, 139528(%rsp)
	movq	46416(%rsp), %rax
	movq	%rax, 139536(%rsp)
	movq	46424(%rsp), %rax
	movq	%rax, 139544(%rsp)
	movq	46432(%rsp), %rax
	movq	%rax, 139552(%rsp)
	movq	46440(%rsp), %rax
	movq	%rax, 139560(%rsp)
	movq	46448(%rsp), %rax
	movq	%rax, 139568(%rsp)
	movq	46456(%rsp), %rax
	movq	%rax, 139576(%rsp)
	movq	46464(%rsp), %rax
	movq	%rax, 139584(%rsp)
	movq	46472(%rsp), %rax
	movq	%rax, 139592(%rsp)
	movq	46480(%rsp), %rax
	movq	%rax, 139600(%rsp)
	movq	46488(%rsp), %rax
	movq	%rax, 139608(%rsp)
	movq	46496(%rsp), %rax
	movq	%rax, 139616(%rsp)
	movq	46504(%rsp), %rax
	movq	%rax, 139624(%rsp)
	movq	46512(%rsp), %rax
	movq	%rax, 139632(%rsp)
	movq	46520(%rsp), %rax
	movq	%rax, 139640(%rsp)
	movq	46528(%rsp), %rax
	movq	%rax, 139648(%rsp)
	movq	46536(%rsp), %rax
	movq	%rax, 139656(%rsp)
	movq	46544(%rsp), %rax
	movq	%rax, 139664(%rsp)
	movq	46552(%rsp), %rax
	movq	%rax, 139672(%rsp)
	movq	46560(%rsp), %rax
	movq	%rax, 139680(%rsp)
	movq	46568(%rsp), %rax
	movq	%rax, 139688(%rsp)
	movq	46576(%rsp), %rax
	movq	%rax, 139696(%rsp)
	movq	46584(%rsp), %rax
	movq	%rax, 139704(%rsp)
	movq	46592(%rsp), %rax
	movq	%rax, 139712(%rsp)
	movq	46600(%rsp), %rax
	movq	%rax, 139720(%rsp)
	movq	46608(%rsp), %rax
	movq	%rax, 139728(%rsp)
	movq	46616(%rsp), %rax
	movq	%rax, 139736(%rsp)
	movq	46624(%rsp), %rax
	movq	%rax, 139744(%rsp)
	movq	46632(%rsp), %rax
	movq	%rax, 139752(%rsp)
	movq	46640(%rsp), %rax
	movq	%rax, 139760(%rsp)
	movq	46648(%rsp), %rax
	movq	%rax, 139768(%rsp)
	movq	46656(%rsp), %rax
	movq	%rax, 139776(%rsp)
	movq	46664(%rsp), %rax
	movq	%rax, 139784(%rsp)
	movq	46672(%rsp), %rax
	movq	%rax, 139792(%rsp)
	movq	46680(%rsp), %rax
	movq	%rax, 139800(%rsp)
	movq	46688(%rsp), %rax
	movq	%rax, 139808(%rsp)
	movq	46696(%rsp), %rax
	movq	%rax, 139816(%rsp)
	movq	46704(%rsp), %rax
	movq	%rax, 139824(%rsp)
	movq	46712(%rsp), %rax
	movq	%rax, 139832(%rsp)
	movq	46720(%rsp), %rax
	movq	%rax, 139840(%rsp)
	movq	46728(%rsp), %rax
	movq	%rax, 139848(%rsp)
	movq	46736(%rsp), %rax
	movq	%rax, 139856(%rsp)
	movq	46744(%rsp), %rax
	movq	%rax, 139864(%rsp)
	movq	46752(%rsp), %rax
	movq	%rax, 139872(%rsp)
	movq	46760(%rsp), %rax
	movq	%rax, 139880(%rsp)
	movq	46768(%rsp), %rax
	movq	%rax, 139888(%rsp)
	movq	46776(%rsp), %rax
	movq	%rax, 139896(%rsp)
	movq	46784(%rsp), %rax
	movq	%rax, 139904(%rsp)
	movq	46792(%rsp), %rax
	movq	%rax, 139912(%rsp)
	movq	46800(%rsp), %rax
	movq	%rax, 139920(%rsp)
	movq	46808(%rsp), %rax
	movq	%rax, 139928(%rsp)
	movq	46816(%rsp), %rax
	movq	%rax, 139936(%rsp)
	movq	46824(%rsp), %rax
	movq	%rax, 139944(%rsp)
	movq	46832(%rsp), %rax
	movq	%rax, 139952(%rsp)
	movq	46840(%rsp), %rax
	movq	%rax, 139960(%rsp)
	movq	46848(%rsp), %rax
	movq	%rax, 139968(%rsp)
	movq	46856(%rsp), %rax
	movq	%rax, 139976(%rsp)
	movq	46864(%rsp), %rax
	movq	%rax, 139984(%rsp)
	movq	46872(%rsp), %rax
	movq	%rax, 139992(%rsp)
	movq	46880(%rsp), %rax
	movq	%rax, 140000(%rsp)
	movq	46888(%rsp), %rax
	movq	%rax, 140008(%rsp)
	movq	46896(%rsp), %rax
	movq	%rax, 140016(%rsp)
	movq	46904(%rsp), %rax
	movq	%rax, 140024(%rsp)
	movq	46912(%rsp), %rax
	movq	%rax, 140032(%rsp)
	movq	46920(%rsp), %rax
	movq	%rax, 140040(%rsp)
	movq	46928(%rsp), %rax
	movq	%rax, 140048(%rsp)
	movq	46936(%rsp), %rax
	movq	%rax, 140056(%rsp)
	movq	46944(%rsp), %rax
	movq	%rax, 140064(%rsp)
	movq	46952(%rsp), %rax
	movq	%rax, 140072(%rsp)
	movq	46960(%rsp), %rax
	movq	%rax, 140080(%rsp)
	movq	46968(%rsp), %rax
	movq	%rax, 140088(%rsp)
	movq	46976(%rsp), %rax
	movq	%rax, 140096(%rsp)
	movq	46984(%rsp), %rax
	movq	%rax, 140104(%rsp)
	movq	46992(%rsp), %rax
	movq	%rax, 140112(%rsp)
	movq	47000(%rsp), %rax
	movq	%rax, 140120(%rsp)
	movq	47008(%rsp), %rax
	movq	%rax, 140128(%rsp)
	movq	47016(%rsp), %rax
	movq	%rax, 140136(%rsp)
	movq	47024(%rsp), %rax
	movq	%rax, 140144(%rsp)
	movq	47032(%rsp), %rax
	movq	%rax, 140152(%rsp)
	movq	47040(%rsp), %rax
	movq	%rax, 140160(%rsp)
	movq	47048(%rsp), %rax
	movq	%rax, 140168(%rsp)
	movq	47056(%rsp), %rax
	movq	%rax, 140176(%rsp)
	movq	47064(%rsp), %rax
	movq	%rax, 140184(%rsp)
	movq	47072(%rsp), %rax
	movq	%rax, 140192(%rsp)
	movq	47080(%rsp), %rax
	movq	%rax, 140200(%rsp)
	movq	47088(%rsp), %rax
	movq	%rax, 140208(%rsp)
	movq	47096(%rsp), %rax
	movq	%rax, 140216(%rsp)
	movq	47104(%rsp), %rax
	movq	%rax, 140224(%rsp)
	movq	47112(%rsp), %rax
	movq	%rax, 140232(%rsp)
	movq	47120(%rsp), %rax
	movq	%rax, 140240(%rsp)
	movq	47128(%rsp), %rax
	movq	%rax, 140248(%rsp)
	movq	47136(%rsp), %rax
	movq	%rax, 140256(%rsp)
	movq	47144(%rsp), %rax
	movq	%rax, 140264(%rsp)
	movq	47152(%rsp), %rax
	movq	%rax, 140272(%rsp)
	movq	47160(%rsp), %rax
	movq	%rax, 140280(%rsp)
	movq	47168(%rsp), %rax
	movq	%rax, 140288(%rsp)
	movq	47176(%rsp), %rax
	movq	%rax, 140296(%rsp)
	movq	47184(%rsp), %rax
	movq	%rax, 140304(%rsp)
	movq	47192(%rsp), %rax
	movq	%rax, 140312(%rsp)
	movq	47200(%rsp), %rax
	movq	%rax, 140320(%rsp)
	movq	47208(%rsp), %rax
	movq	%rax, 140328(%rsp)
	movq	47216(%rsp), %rax
	movq	%rax, 140336(%rsp)
	movq	47224(%rsp), %rax
	movq	%rax, 140344(%rsp)
	movq	47232(%rsp), %rax
	movq	%rax, 140352(%rsp)
	movq	47240(%rsp), %rax
	movq	%rax, 140360(%rsp)
	movq	47248(%rsp), %rax
	movq	%rax, 140368(%rsp)
	movq	47256(%rsp), %rax
	movq	%rax, 140376(%rsp)
	movq	47264(%rsp), %rax
	movq	%rax, 140384(%rsp)
	movq	47272(%rsp), %rax
	movq	%rax, 140392(%rsp)
	movq	47280(%rsp), %rax
	movq	%rax, 140400(%rsp)
	movq	47288(%rsp), %rax
	movq	%rax, 140408(%rsp)
	movq	47296(%rsp), %rax
	movq	%rax, 140416(%rsp)
	movq	47304(%rsp), %rax
	movq	%rax, 140424(%rsp)
	movq	47312(%rsp), %rax
	movq	%rax, 140432(%rsp)
	movq	47320(%rsp), %rax
	movq	%rax, 140440(%rsp)
	movq	47328(%rsp), %rax
	movq	%rax, 140448(%rsp)
	movq	47336(%rsp), %rax
	movq	%rax, 140456(%rsp)
	movq	47344(%rsp), %rax
	movq	%rax, 140464(%rsp)
	movq	47352(%rsp), %rax
	movq	%rax, 140472(%rsp)
	movq	47360(%rsp), %rax
	movq	%rax, 140480(%rsp)
	movq	47368(%rsp), %rax
	movq	%rax, 140488(%rsp)
	movq	47376(%rsp), %rax
	movq	%rax, 140496(%rsp)
	movq	47384(%rsp), %rax
	movq	%rax, 140504(%rsp)
	movq	47392(%rsp), %rax
	movq	%rax, 140512(%rsp)
	movq	47400(%rsp), %rax
	movq	%rax, 140520(%rsp)
	movq	47408(%rsp), %rax
	movq	%rax, 140528(%rsp)
	movq	47416(%rsp), %rax
	movq	%rax, 140536(%rsp)
	movq	47424(%rsp), %rax
	movq	%rax, 140544(%rsp)
	movq	47432(%rsp), %rax
	movq	%rax, 140552(%rsp)
	movq	47440(%rsp), %rax
	movq	%rax, 140560(%rsp)
	movq	47448(%rsp), %rax
	movq	%rax, 140568(%rsp)
	movq	47456(%rsp), %rax
	movq	%rax, 140576(%rsp)
	movq	47464(%rsp), %rax
	movq	%rax, 140584(%rsp)
	movq	47472(%rsp), %rax
	movq	%rax, 140592(%rsp)
	movq	47480(%rsp), %rax
	movq	%rax, 140600(%rsp)
	movq	47488(%rsp), %rax
	movq	%rax, 140608(%rsp)
	movq	47496(%rsp), %rax
	movq	%rax, 140616(%rsp)
	movq	47504(%rsp), %rax
	movq	%rax, 140624(%rsp)
	movq	47512(%rsp), %rax
	movq	%rax, 140632(%rsp)
	movq	47520(%rsp), %rax
	movq	%rax, 140640(%rsp)
	movq	47528(%rsp), %rax
	movq	%rax, 140648(%rsp)
	movq	47536(%rsp), %rax
	movq	%rax, 140656(%rsp)
	movq	47544(%rsp), %rax
	movq	%rax, 140664(%rsp)
	movq	47552(%rsp), %rax
	movq	%rax, 140672(%rsp)
	movq	47560(%rsp), %rax
	movq	%rax, 140680(%rsp)
	movq	47568(%rsp), %rax
	movq	%rax, 140688(%rsp)
	movq	47576(%rsp), %rax
	movq	%rax, 140696(%rsp)
	movq	47584(%rsp), %rax
	movq	%rax, 140704(%rsp)
	movq	47592(%rsp), %rax
	movq	%rax, 140712(%rsp)
	movq	47600(%rsp), %rax
	movq	%rax, 140720(%rsp)
	movq	47608(%rsp), %rax
	movq	%rax, 140728(%rsp)
	movq	47616(%rsp), %rax
	movq	%rax, 140736(%rsp)
	movq	47624(%rsp), %rax
	movq	%rax, 140744(%rsp)
	movq	47632(%rsp), %rax
	movq	%rax, 140752(%rsp)
	movq	47640(%rsp), %rax
	movq	%rax, 140760(%rsp)
	movq	47648(%rsp), %rax
	movq	%rax, 140768(%rsp)
	movq	47656(%rsp), %rax
	movq	%rax, 140776(%rsp)
	movq	47664(%rsp), %rax
	movq	%rax, 140784(%rsp)
	movq	47672(%rsp), %rax
	movq	%rax, 140792(%rsp)
	movq	47680(%rsp), %rax
	movq	%rax, 140800(%rsp)
	movq	47688(%rsp), %rax
	movq	%rax, 140808(%rsp)
	movq	47696(%rsp), %rax
	movq	%rax, 140816(%rsp)
	movq	47704(%rsp), %rax
	movq	%rax, 140824(%rsp)
	movq	47712(%rsp), %rax
	movq	%rax, 140832(%rsp)
	movq	47720(%rsp), %rax
	movq	%rax, 140840(%rsp)
	movq	47728(%rsp), %rax
	movq	%rax, 140848(%rsp)
	movq	47736(%rsp), %rax
	movq	%rax, 140856(%rsp)
	movq	47744(%rsp), %rax
	movq	%rax, 140864(%rsp)
	movq	47752(%rsp), %rax
	movq	%rax, 140872(%rsp)
	movq	47760(%rsp), %rax
	movq	%rax, 140880(%rsp)
	movq	47768(%rsp), %rax
	movq	%rax, 140888(%rsp)
	movq	47776(%rsp), %rax
	movq	%rax, 140896(%rsp)
	movq	47784(%rsp), %rax
	movq	%rax, 140904(%rsp)
	movq	47792(%rsp), %rax
	movq	%rax, 140912(%rsp)
	movq	47800(%rsp), %rax
	movq	%rax, 140920(%rsp)
	movq	47808(%rsp), %rax
	movq	%rax, 140928(%rsp)
	movq	47816(%rsp), %rax
	movq	%rax, 140936(%rsp)
	movq	47824(%rsp), %rax
	movq	%rax, 140944(%rsp)
	movq	47832(%rsp), %rax
	movq	%rax, 140952(%rsp)
	movq	47840(%rsp), %rax
	movq	%rax, 140960(%rsp)
	movq	47848(%rsp), %rax
	movq	%rax, 140968(%rsp)
	movq	47856(%rsp), %rax
	movq	%rax, 140976(%rsp)
	movq	47864(%rsp), %rax
	movq	%rax, 140984(%rsp)
	movq	47872(%rsp), %rax
	movq	%rax, 140992(%rsp)
	movq	47880(%rsp), %rax
	movq	%rax, 141000(%rsp)
	movq	47888(%rsp), %rax
	movq	%rax, 141008(%rsp)
	movq	47896(%rsp), %rax
	movq	%rax, 141016(%rsp)
	movq	47904(%rsp), %rax
	movq	%rax, 141024(%rsp)
	movq	47912(%rsp), %rax
	movq	%rax, 141032(%rsp)
	movq	47920(%rsp), %rax
	movq	%rax, 141040(%rsp)
	movq	47928(%rsp), %rax
	movq	%rax, 141048(%rsp)
	movq	47936(%rsp), %rax
	movq	%rax, 141056(%rsp)
	movq	47944(%rsp), %rax
	movq	%rax, 141064(%rsp)
	movq	47952(%rsp), %rax
	movq	%rax, 141072(%rsp)
	movq	47960(%rsp), %rax
	movq	%rax, 141080(%rsp)
	movq	47968(%rsp), %rax
	movq	%rax, 141088(%rsp)
	movq	47976(%rsp), %rax
	movq	%rax, 141096(%rsp)
	movq	47984(%rsp), %rax
	movq	%rax, 141104(%rsp)
	movq	47992(%rsp), %rax
	movq	%rax, 141112(%rsp)
	movq	48000(%rsp), %rax
	movq	%rax, 141120(%rsp)
	movq	48008(%rsp), %rax
	movq	%rax, 141128(%rsp)
	movq	48016(%rsp), %rax
	movq	%rax, 141136(%rsp)
	movq	48024(%rsp), %rax
	movq	%rax, 141144(%rsp)
	movq	48032(%rsp), %rax
	movq	%rax, 141152(%rsp)
	movq	48040(%rsp), %rax
	movq	%rax, 141160(%rsp)
	movq	48048(%rsp), %rax
	movq	%rax, 141168(%rsp)
	movq	48056(%rsp), %rax
	movq	%rax, 141176(%rsp)
	movq	48064(%rsp), %rax
	movq	%rax, 141184(%rsp)
	movq	48072(%rsp), %rax
	movq	%rax, 141192(%rsp)
	movq	48080(%rsp), %rax
	movq	%rax, 141200(%rsp)
	movq	48088(%rsp), %rax
	movq	%rax, 141208(%rsp)
	movq	48096(%rsp), %rax
	movq	%rax, 141216(%rsp)
	movq	48104(%rsp), %rax
	movq	%rax, 141224(%rsp)
	movq	48112(%rsp), %rax
	movq	%rax, 141232(%rsp)
	movq	48120(%rsp), %rax
	movq	%rax, 141240(%rsp)
	movq	48128(%rsp), %rax
	movq	%rax, 141248(%rsp)
	movq	48136(%rsp), %rax
	movq	%rax, 141256(%rsp)
	movq	48144(%rsp), %rax
	movq	%rax, 141264(%rsp)
	movq	48152(%rsp), %rax
	movq	%rax, 141272(%rsp)
	movq	48160(%rsp), %rax
	movq	%rax, 141280(%rsp)
	movq	48168(%rsp), %rax
	movq	%rax, 141288(%rsp)
	movq	48176(%rsp), %rax
	movq	%rax, 141296(%rsp)
	movq	48184(%rsp), %rax
	movq	%rax, 141304(%rsp)
	movq	48192(%rsp), %rax
	movq	%rax, 141312(%rsp)
	movq	48200(%rsp), %rax
	movq	%rax, 141320(%rsp)
	movq	48208(%rsp), %rax
	movq	%rax, 141328(%rsp)
	movq	48216(%rsp), %rax
	movq	%rax, 141336(%rsp)
	movq	48224(%rsp), %rax
	movq	%rax, 141344(%rsp)
	movq	48232(%rsp), %rax
	movq	%rax, 141352(%rsp)
	movq	48240(%rsp), %rax
	movq	%rax, 141360(%rsp)
	movq	48248(%rsp), %rax
	movq	%rax, 141368(%rsp)
	movq	48256(%rsp), %rax
	movq	%rax, 141376(%rsp)
	movq	48264(%rsp), %rax
	movq	%rax, 141384(%rsp)
	movq	48272(%rsp), %rax
	movq	%rax, 141392(%rsp)
	movq	48280(%rsp), %rax
	movq	%rax, 141400(%rsp)
	movq	48288(%rsp), %rax
	movq	%rax, 141408(%rsp)
	movq	48296(%rsp), %rax
	movq	%rax, 141416(%rsp)
	movq	48304(%rsp), %rax
	movq	%rax, 141424(%rsp)
	movq	48312(%rsp), %rax
	movq	%rax, 141432(%rsp)
	movq	48320(%rsp), %rax
	movq	%rax, 141440(%rsp)
	movq	48328(%rsp), %rax
	movq	%rax, 141448(%rsp)
	movq	48336(%rsp), %rax
	movq	%rax, 141456(%rsp)
	movq	48344(%rsp), %rax
	movq	%rax, 141464(%rsp)
	movq	48352(%rsp), %rax
	movq	%rax, 141472(%rsp)
	movq	48360(%rsp), %rax
	movq	%rax, 141480(%rsp)
	movq	48368(%rsp), %rax
	movq	%rax, 141488(%rsp)
	movq	48376(%rsp), %rax
	movq	%rax, 141496(%rsp)
	movq	48384(%rsp), %rax
	movq	%rax, 141504(%rsp)
	movq	48392(%rsp), %rax
	movq	%rax, 141512(%rsp)
	movq	48400(%rsp), %rax
	movq	%rax, 141520(%rsp)
	movq	48408(%rsp), %rax
	movq	%rax, 141528(%rsp)
	movq	48416(%rsp), %rax
	movq	%rax, 141536(%rsp)
	movq	48424(%rsp), %rax
	movq	%rax, 141544(%rsp)
	movq	48432(%rsp), %rax
	movq	%rax, 141552(%rsp)
	movq	48440(%rsp), %rax
	movq	%rax, 141560(%rsp)
	movq	48448(%rsp), %rax
	movq	%rax, 141568(%rsp)
	movq	48456(%rsp), %rax
	movq	%rax, 141576(%rsp)
	movq	48464(%rsp), %rax
	movq	%rax, 141584(%rsp)
	movq	48472(%rsp), %rax
	movq	%rax, 141592(%rsp)
	movq	48480(%rsp), %rax
	movq	%rax, 141600(%rsp)
	movq	48488(%rsp), %rax
	movq	%rax, 141608(%rsp)
	movq	48496(%rsp), %rax
	movq	%rax, 141616(%rsp)
	movq	48504(%rsp), %rax
	movq	%rax, 141624(%rsp)
	movq	48512(%rsp), %rax
	movq	%rax, 141632(%rsp)
	movq	48520(%rsp), %rax
	movq	%rax, 141640(%rsp)
	movq	48528(%rsp), %rax
	movq	%rax, 141648(%rsp)
	movq	48536(%rsp), %rax
	movq	%rax, 141656(%rsp)
	movq	48544(%rsp), %rax
	movq	%rax, 141664(%rsp)
	movq	48552(%rsp), %rax
	movq	%rax, 141672(%rsp)
	movq	48560(%rsp), %rax
	movq	%rax, 141680(%rsp)
	movq	48568(%rsp), %rax
	movq	%rax, 141688(%rsp)
	movq	48576(%rsp), %rax
	movq	%rax, 141696(%rsp)
	movq	48584(%rsp), %rax
	movq	%rax, 141704(%rsp)
	movq	48592(%rsp), %rax
	movq	%rax, 141712(%rsp)
	movq	48600(%rsp), %rax
	movq	%rax, 141720(%rsp)
	movq	48608(%rsp), %rax
	movq	%rax, 141728(%rsp)
	movq	48616(%rsp), %rax
	movq	%rax, 141736(%rsp)
	movq	48624(%rsp), %rax
	movq	%rax, 141744(%rsp)
	movq	48632(%rsp), %rax
	movq	%rax, 141752(%rsp)
	movq	48640(%rsp), %rax
	movq	%rax, 141760(%rsp)
	movq	48648(%rsp), %rax
	movq	%rax, 141768(%rsp)
	movq	48656(%rsp), %rax
	movq	%rax, 141776(%rsp)
	movq	48664(%rsp), %rax
	movq	%rax, 141784(%rsp)
	movq	48672(%rsp), %rax
	movq	%rax, 141792(%rsp)
	movq	48680(%rsp), %rax
	movq	%rax, 141800(%rsp)
	movq	48688(%rsp), %rax
	movq	%rax, 141808(%rsp)
	movq	48696(%rsp), %rax
	movq	%rax, 141816(%rsp)
	movq	48704(%rsp), %rax
	movq	%rax, 141824(%rsp)
	movq	48712(%rsp), %rax
	movq	%rax, 141832(%rsp)
	movq	48720(%rsp), %rax
	movq	%rax, 141840(%rsp)
	movq	48728(%rsp), %rax
	movq	%rax, 141848(%rsp)
	movq	48736(%rsp), %rax
	movq	%rax, 141856(%rsp)
	movq	48744(%rsp), %rax
	movq	%rax, 141864(%rsp)
	movq	48752(%rsp), %rax
	movq	%rax, 141872(%rsp)
	movq	48760(%rsp), %rax
	movq	%rax, 141880(%rsp)
	movq	48768(%rsp), %rax
	movq	%rax, 141888(%rsp)
	movq	48776(%rsp), %rax
	movq	%rax, 141896(%rsp)
	movq	48784(%rsp), %rax
	movq	%rax, 141904(%rsp)
	movq	48792(%rsp), %rax
	movq	%rax, 141912(%rsp)
	movq	48800(%rsp), %rax
	movq	%rax, 141920(%rsp)
	movq	48808(%rsp), %rax
	movq	%rax, 141928(%rsp)
	movq	48816(%rsp), %rax
	movq	%rax, 141936(%rsp)
	movq	48824(%rsp), %rax
	movq	%rax, 141944(%rsp)
	movq	48832(%rsp), %rax
	movq	%rax, 141952(%rsp)
	movq	48840(%rsp), %rax
	movq	%rax, 141960(%rsp)
	movq	48848(%rsp), %rax
	movq	%rax, 141968(%rsp)
	movq	48856(%rsp), %rax
	movq	%rax, 141976(%rsp)
	movq	48864(%rsp), %rax
	movq	%rax, 141984(%rsp)
	movq	48872(%rsp), %rax
	movq	%rax, 141992(%rsp)
	movq	48880(%rsp), %rax
	movq	%rax, 142000(%rsp)
	movq	48888(%rsp), %rax
	movq	%rax, 142008(%rsp)
	movq	48896(%rsp), %rax
	movq	%rax, 142016(%rsp)
	movq	48904(%rsp), %rax
	movq	%rax, 142024(%rsp)
	movq	48912(%rsp), %rax
	movq	%rax, 142032(%rsp)
	movq	48920(%rsp), %rax
	movq	%rax, 142040(%rsp)
	movq	48928(%rsp), %rax
	movq	%rax, 142048(%rsp)
	movq	48936(%rsp), %rax
	movq	%rax, 142056(%rsp)
	movq	48944(%rsp), %rax
	movq	%rax, 142064(%rsp)
	movq	48952(%rsp), %rax
	movq	%rax, 142072(%rsp)
	movq	48960(%rsp), %rax
	movq	%rax, 142080(%rsp)
	movq	48968(%rsp), %rax
	movq	%rax, 142088(%rsp)
	movq	48976(%rsp), %rax
	movq	%rax, 142096(%rsp)
	movq	48984(%rsp), %rax
	movq	%rax, 142104(%rsp)
	movq	48992(%rsp), %rax
	movq	%rax, 142112(%rsp)
	movq	49000(%rsp), %rax
	movq	%rax, 142120(%rsp)
	movq	49008(%rsp), %rax
	movq	%rax, 142128(%rsp)
	movq	49016(%rsp), %rax
	movq	%rax, 142136(%rsp)
	movq	49024(%rsp), %rax
	movq	%rax, 142144(%rsp)
	movq	49032(%rsp), %rax
	movq	%rax, 142152(%rsp)
	movq	49040(%rsp), %rax
	movq	%rax, 142160(%rsp)
	movq	49048(%rsp), %rax
	movq	%rax, 142168(%rsp)
	movq	49056(%rsp), %rax
	movq	%rax, 142176(%rsp)
	movq	49064(%rsp), %rax
	movq	%rax, 142184(%rsp)
	movq	49072(%rsp), %rax
	movq	%rax, 142192(%rsp)
	movq	49080(%rsp), %rax
	movq	%rax, 142200(%rsp)
	movq	49088(%rsp), %rax
	movq	%rax, 142208(%rsp)
	movq	49096(%rsp), %rax
	movq	%rax, 142216(%rsp)
	movq	49104(%rsp), %rax
	movq	%rax, 142224(%rsp)
	movq	49112(%rsp), %rax
	movq	%rax, 142232(%rsp)
	movq	49120(%rsp), %rax
	movq	%rax, 142240(%rsp)
	movq	49128(%rsp), %rax
	movq	%rax, 142248(%rsp)
	movq	49136(%rsp), %rax
	movq	%rax, 142256(%rsp)
	movq	49144(%rsp), %rax
	movq	%rax, 142264(%rsp)
	movq	49152(%rsp), %rax
	movq	%rax, 142272(%rsp)
	movq	49160(%rsp), %rax
	movq	%rax, 142280(%rsp)
	movq	49168(%rsp), %rax
	movq	%rax, 142288(%rsp)
	movq	49176(%rsp), %rax
	movq	%rax, 142296(%rsp)
	movq	49184(%rsp), %rax
	movq	%rax, 142304(%rsp)
	movq	49192(%rsp), %rax
	movq	%rax, 142312(%rsp)
	movq	49200(%rsp), %rax
	movq	%rax, 142320(%rsp)
	movq	49208(%rsp), %rax
	movq	%rax, 142328(%rsp)
	movq	49216(%rsp), %rax
	movq	%rax, 142336(%rsp)
	movq	49224(%rsp), %rax
	movq	%rax, 142344(%rsp)
	movq	49232(%rsp), %rax
	movq	%rax, 142352(%rsp)
	movq	49240(%rsp), %rax
	movq	%rax, 142360(%rsp)
	movq	49248(%rsp), %rax
	movq	%rax, 142368(%rsp)
	movq	49256(%rsp), %rax
	movq	%rax, 142376(%rsp)
	movq	49264(%rsp), %rax
	movq	%rax, 142384(%rsp)
	movq	49272(%rsp), %rax
	movq	%rax, 142392(%rsp)
	movq	49280(%rsp), %rax
	movq	%rax, 142400(%rsp)
	movq	49288(%rsp), %rax
	movq	%rax, 142408(%rsp)
	movq	49296(%rsp), %rax
	movq	%rax, 142416(%rsp)
	movq	49304(%rsp), %rax
	movq	%rax, 142424(%rsp)
	movq	49312(%rsp), %rax
	movq	%rax, 142432(%rsp)
	movq	49320(%rsp), %rax
	movq	%rax, 142440(%rsp)
	movq	49328(%rsp), %rax
	movq	%rax, 142448(%rsp)
	movq	49336(%rsp), %rax
	movq	%rax, 142456(%rsp)
	movq	49344(%rsp), %rax
	movq	%rax, 142464(%rsp)
	movq	49352(%rsp), %rax
	movq	%rax, 142472(%rsp)
	movq	49360(%rsp), %rax
	movq	%rax, 142480(%rsp)
	movq	49368(%rsp), %rax
	movq	%rax, 142488(%rsp)
	movq	49376(%rsp), %rax
	movq	%rax, 142496(%rsp)
	movq	49384(%rsp), %rax
	movq	%rax, 142504(%rsp)
	movq	49392(%rsp), %rax
	movq	%rax, 142512(%rsp)
	movq	49400(%rsp), %rax
	movq	%rax, 142520(%rsp)
	movq	49408(%rsp), %rax
	movq	%rax, 142528(%rsp)
	movq	49416(%rsp), %rax
	movq	%rax, 142536(%rsp)
	movq	49424(%rsp), %rax
	movq	%rax, 142544(%rsp)
	movq	49432(%rsp), %rax
	movq	%rax, 142552(%rsp)
	movq	49440(%rsp), %rax
	movq	%rax, 142560(%rsp)
	movq	49448(%rsp), %rax
	movq	%rax, 142568(%rsp)
	movq	49456(%rsp), %rax
	movq	%rax, 142576(%rsp)
	movq	49464(%rsp), %rax
	movq	%rax, 142584(%rsp)
	movq	49472(%rsp), %rax
	movq	%rax, 142592(%rsp)
	movq	49480(%rsp), %rax
	movq	%rax, 142600(%rsp)
	movq	49488(%rsp), %rax
	movq	%rax, 142608(%rsp)
	movq	49496(%rsp), %rax
	movq	%rax, 142616(%rsp)
	movq	49504(%rsp), %rax
	movq	%rax, 142624(%rsp)
	movq	49512(%rsp), %rax
	movq	%rax, 142632(%rsp)
	movq	49520(%rsp), %rax
	movq	%rax, 142640(%rsp)
	movq	49528(%rsp), %rax
	movq	%rax, 142648(%rsp)
	movq	49536(%rsp), %rax
	movq	%rax, 142656(%rsp)
	movq	49544(%rsp), %rax
	movq	%rax, 142664(%rsp)
	movq	49552(%rsp), %rax
	movq	%rax, 142672(%rsp)
	movq	49560(%rsp), %rax
	movq	%rax, 142680(%rsp)
	movq	49568(%rsp), %rax
	movq	%rax, 142688(%rsp)
	movq	49576(%rsp), %rax
	movq	%rax, 142696(%rsp)
	movq	49584(%rsp), %rax
	movq	%rax, 142704(%rsp)
	movq	49592(%rsp), %rax
	movq	%rax, 142712(%rsp)
	movq	49600(%rsp), %rax
	movq	%rax, 142720(%rsp)
	movq	49608(%rsp), %rax
	movq	%rax, 142728(%rsp)
	movq	49616(%rsp), %rax
	movq	%rax, 142736(%rsp)
	movq	49624(%rsp), %rax
	movq	%rax, 142744(%rsp)
	movq	49632(%rsp), %rax
	movq	%rax, 142752(%rsp)
	movq	49640(%rsp), %rax
	movq	%rax, 142760(%rsp)
	movq	49648(%rsp), %rax
	movq	%rax, 142768(%rsp)
	movq	49656(%rsp), %rax
	movq	%rax, 142776(%rsp)
	movq	49664(%rsp), %rax
	movq	%rax, 142784(%rsp)
	movq	49672(%rsp), %rax
	movq	%rax, 142792(%rsp)
	movq	49680(%rsp), %rax
	movq	%rax, 142800(%rsp)
	movq	49688(%rsp), %rax
	movq	%rax, 142808(%rsp)
	movq	49696(%rsp), %rax
	movq	%rax, 142816(%rsp)
	movq	49704(%rsp), %rax
	movq	%rax, 142824(%rsp)
	movq	49712(%rsp), %rax
	movq	%rax, 142832(%rsp)
	movq	49720(%rsp), %rax
	movq	%rax, 142840(%rsp)
	movq	49728(%rsp), %rax
	movq	%rax, 142848(%rsp)
	movq	49736(%rsp), %rax
	movq	%rax, 142856(%rsp)
	movq	49744(%rsp), %rax
	movq	%rax, 142864(%rsp)
	movq	49752(%rsp), %rax
	movq	%rax, 142872(%rsp)
	movq	49760(%rsp), %rax
	movq	%rax, 142880(%rsp)
	movq	49768(%rsp), %rax
	movq	%rax, 142888(%rsp)
	movq	49776(%rsp), %rax
	movq	%rax, 142896(%rsp)
	movq	49784(%rsp), %rax
	movq	%rax, 142904(%rsp)
	movq	49792(%rsp), %rax
	movq	%rax, 142912(%rsp)
	movq	49800(%rsp), %rax
	movq	%rax, 142920(%rsp)
	movq	49808(%rsp), %rax
	movq	%rax, 142928(%rsp)
	movq	49816(%rsp), %rax
	movq	%rax, 142936(%rsp)
	movq	49824(%rsp), %rax
	movq	%rax, 142944(%rsp)
	movq	49832(%rsp), %rax
	movq	%rax, 142952(%rsp)
	movq	49840(%rsp), %rax
	movq	%rax, 142960(%rsp)
	movq	49848(%rsp), %rax
	movq	%rax, 142968(%rsp)
	movq	49856(%rsp), %rax
	movq	%rax, 142976(%rsp)
	movq	49864(%rsp), %rax
	movq	%rax, 142984(%rsp)
	movq	49872(%rsp), %rax
	movq	%rax, 142992(%rsp)
	movq	49880(%rsp), %rax
	movq	%rax, 143000(%rsp)
	movq	49888(%rsp), %rax
	movq	%rax, 143008(%rsp)
	movq	49896(%rsp), %rax
	movq	%rax, 143016(%rsp)
	movq	49904(%rsp), %rax
	movq	%rax, 143024(%rsp)
	movq	49912(%rsp), %rax
	movq	%rax, 143032(%rsp)
	movq	49920(%rsp), %rax
	movq	%rax, 143040(%rsp)
	movq	49928(%rsp), %rax
	movq	%rax, 143048(%rsp)
	movq	49936(%rsp), %rax
	movq	%rax, 143056(%rsp)
	movq	49944(%rsp), %rax
	movq	%rax, 143064(%rsp)
	movq	49952(%rsp), %rax
	movq	%rax, 143072(%rsp)
	movq	49960(%rsp), %rax
	movq	%rax, 143080(%rsp)
	movq	49968(%rsp), %rax
	movq	%rax, 143088(%rsp)
	movq	49976(%rsp), %rax
	movq	%rax, 143096(%rsp)
	movq	49984(%rsp), %rax
	movq	%rax, 143104(%rsp)
	movq	49992(%rsp), %rax
	movq	%rax, 143112(%rsp)
	movq	50000(%rsp), %rax
	movq	%rax, 143120(%rsp)
	movq	50008(%rsp), %rax
	movq	%rax, 143128(%rsp)
	movq	50016(%rsp), %rax
	movq	%rax, 143136(%rsp)
	movq	50024(%rsp), %rax
	movq	%rax, 143144(%rsp)
	movq	50032(%rsp), %rax
	movq	%rax, 143152(%rsp)
	movq	50040(%rsp), %rax
	movq	%rax, 143160(%rsp)
	movq	50048(%rsp), %rax
	movq	%rax, 143168(%rsp)
	movq	50056(%rsp), %rax
	movq	%rax, 143176(%rsp)
	movq	50064(%rsp), %rax
	movq	%rax, 143184(%rsp)
	movq	50072(%rsp), %rax
	movq	%rax, 143192(%rsp)
	movq	50080(%rsp), %rax
	movq	%rax, 143200(%rsp)
	movq	50088(%rsp), %rax
	movq	%rax, 143208(%rsp)
	movq	50096(%rsp), %rax
	movq	%rax, 143216(%rsp)
	movq	50104(%rsp), %rax
	movq	%rax, 143224(%rsp)
	movq	50112(%rsp), %rax
	movq	%rax, 143232(%rsp)
	movq	50120(%rsp), %rax
	movq	%rax, 143240(%rsp)
	movq	50128(%rsp), %rax
	movq	%rax, 143248(%rsp)
	movq	50136(%rsp), %rax
	movq	%rax, 143256(%rsp)
	movq	50144(%rsp), %rax
	movq	%rax, 143264(%rsp)
	movq	50152(%rsp), %rax
	movq	%rax, 143272(%rsp)
	movq	50160(%rsp), %rax
	movq	%rax, 143280(%rsp)
	movq	50168(%rsp), %rax
	movq	%rax, 143288(%rsp)
	movq	50176(%rsp), %rax
	movq	%rax, 143296(%rsp)
	movq	50184(%rsp), %rax
	movq	%rax, 143304(%rsp)
	movq	50192(%rsp), %rax
	movq	%rax, 143312(%rsp)
	movq	50200(%rsp), %rax
	movq	%rax, 143320(%rsp)
	movq	50208(%rsp), %rax
	movq	%rax, 143328(%rsp)
	movq	50216(%rsp), %rax
	movq	%rax, 143336(%rsp)
	movq	50224(%rsp), %rax
	movq	%rax, 143344(%rsp)
	movq	50232(%rsp), %rax
	movq	%rax, 143352(%rsp)
	movq	50240(%rsp), %rax
	movq	%rax, 143360(%rsp)
	movq	50248(%rsp), %rax
	movq	%rax, 143368(%rsp)
	movq	50256(%rsp), %rax
	movq	%rax, 143376(%rsp)
	movq	50264(%rsp), %rax
	movq	%rax, 143384(%rsp)
	movq	50272(%rsp), %rax
	movq	%rax, 143392(%rsp)
	movq	50280(%rsp), %rax
	movq	%rax, 143400(%rsp)
	movq	50288(%rsp), %rax
	movq	%rax, 143408(%rsp)
	movq	50296(%rsp), %rax
	movq	%rax, 143416(%rsp)
	movq	50304(%rsp), %rax
	movq	%rax, 143424(%rsp)
	movq	50312(%rsp), %rax
	movq	%rax, 143432(%rsp)
	movq	50320(%rsp), %rax
	movq	%rax, 143440(%rsp)
	movq	50328(%rsp), %rax
	movq	%rax, 143448(%rsp)
	movq	50336(%rsp), %rax
	movq	%rax, 143456(%rsp)
	movq	50344(%rsp), %rax
	movq	%rax, 143464(%rsp)
	movq	50352(%rsp), %rax
	movq	%rax, 143472(%rsp)
	movq	50360(%rsp), %rax
	movq	%rax, 143480(%rsp)
	movq	50368(%rsp), %rax
	movq	%rax, 143488(%rsp)
	movq	50376(%rsp), %rax
	movq	%rax, 143496(%rsp)
	movq	50384(%rsp), %rax
	movq	%rax, 143504(%rsp)
	movq	50392(%rsp), %rax
	movq	%rax, 143512(%rsp)
	movq	50400(%rsp), %rax
	movq	%rax, 143520(%rsp)
	movq	50408(%rsp), %rax
	movq	%rax, 143528(%rsp)
	movq	50416(%rsp), %rax
	movq	%rax, 143536(%rsp)
	movq	50424(%rsp), %rax
	movq	%rax, 143544(%rsp)
	movq	50432(%rsp), %rax
	movq	%rax, 143552(%rsp)
	movq	50440(%rsp), %rax
	movq	%rax, 143560(%rsp)
	movq	50448(%rsp), %rax
	movq	%rax, 143568(%rsp)
	movq	50456(%rsp), %rax
	movq	%rax, 143576(%rsp)
	movq	50464(%rsp), %rax
	movq	%rax, 143584(%rsp)
	movq	50472(%rsp), %rax
	movq	%rax, 143592(%rsp)
	movq	50480(%rsp), %rax
	movq	%rax, 143600(%rsp)
	movq	50488(%rsp), %rax
	movq	%rax, 143608(%rsp)
	movq	50496(%rsp), %rax
	movq	%rax, 143616(%rsp)
	movq	50504(%rsp), %rax
	movq	%rax, 143624(%rsp)
	movq	50512(%rsp), %rax
	movq	%rax, 143632(%rsp)
	movq	50520(%rsp), %rax
	movq	%rax, 143640(%rsp)
	movq	50528(%rsp), %rax
	movq	%rax, 143648(%rsp)
	movq	50536(%rsp), %rax
	movq	%rax, 143656(%rsp)
	movq	50544(%rsp), %rax
	movq	%rax, 143664(%rsp)
	movq	50552(%rsp), %rax
	movq	%rax, 143672(%rsp)
	movq	50560(%rsp), %rax
	movq	%rax, 143680(%rsp)
	movq	50568(%rsp), %rax
	movq	%rax, 143688(%rsp)
	movq	50576(%rsp), %rax
	movq	%rax, 143696(%rsp)
	movq	50584(%rsp), %rax
	movq	%rax, 143704(%rsp)
	movq	50592(%rsp), %rax
	movq	%rax, 143712(%rsp)
	movq	50600(%rsp), %rax
	movq	%rax, 143720(%rsp)
	movq	50608(%rsp), %rax
	movq	%rax, 143728(%rsp)
	movq	50616(%rsp), %rax
	movq	%rax, 143736(%rsp)
	movq	50624(%rsp), %rax
	movq	%rax, 143744(%rsp)
	movq	50632(%rsp), %rax
	movq	%rax, 143752(%rsp)
	movq	50640(%rsp), %rax
	movq	%rax, 143760(%rsp)
	movq	50648(%rsp), %rax
	movq	%rax, 143768(%rsp)
	movq	50656(%rsp), %rax
	movq	%rax, 143776(%rsp)
	movq	50664(%rsp), %rax
	movq	%rax, 143784(%rsp)
	movq	50672(%rsp), %rax
	movq	%rax, 143792(%rsp)
	movq	50680(%rsp), %rax
	movq	%rax, 143800(%rsp)
	movq	50688(%rsp), %rax
	movq	%rax, 143808(%rsp)
	movq	50696(%rsp), %rax
	movq	%rax, 143816(%rsp)
	movq	50704(%rsp), %rax
	movq	%rax, 143824(%rsp)
	movq	50712(%rsp), %rax
	movq	%rax, 143832(%rsp)
	movq	50720(%rsp), %rax
	movq	%rax, 143840(%rsp)
	movq	50728(%rsp), %rax
	movq	%rax, 143848(%rsp)
	movq	50736(%rsp), %rax
	movq	%rax, 143856(%rsp)
	movq	50744(%rsp), %rax
	movq	%rax, 143864(%rsp)
	movq	50752(%rsp), %rax
	movq	%rax, 143872(%rsp)
	movq	50760(%rsp), %rax
	movq	%rax, 143880(%rsp)
	movq	50768(%rsp), %rax
	movq	%rax, 143888(%rsp)
	movq	50776(%rsp), %rax
	movq	%rax, 143896(%rsp)
	movq	50784(%rsp), %rax
	movq	%rax, 143904(%rsp)
	movq	50792(%rsp), %rax
	movq	%rax, 143912(%rsp)
	movq	50800(%rsp), %rax
	movq	%rax, 143920(%rsp)
	movq	50808(%rsp), %rax
	movq	%rax, 143928(%rsp)
	movq	50816(%rsp), %rax
	movq	%rax, 143936(%rsp)
	movq	50824(%rsp), %rax
	movq	%rax, 143944(%rsp)
	movq	50832(%rsp), %rax
	movq	%rax, 143952(%rsp)
	movq	50840(%rsp), %rax
	movq	%rax, 143960(%rsp)
	movq	50848(%rsp), %rax
	movq	%rax, 143968(%rsp)
	movq	50856(%rsp), %rax
	movq	%rax, 143976(%rsp)
	movq	50864(%rsp), %rax
	movq	%rax, 143984(%rsp)
	movq	50872(%rsp), %rax
	movq	%rax, 143992(%rsp)
	movq	50880(%rsp), %rax
	movq	%rax, 144000(%rsp)
	movq	50888(%rsp), %rax
	movq	%rax, 144008(%rsp)
	movq	50896(%rsp), %rax
	movq	%rax, 144016(%rsp)
	movq	50904(%rsp), %rax
	movq	%rax, 144024(%rsp)
	movq	50912(%rsp), %rax
	movq	%rax, 144032(%rsp)
	movq	50920(%rsp), %rax
	movq	%rax, 144040(%rsp)
	movq	50928(%rsp), %rax
	movq	%rax, 144048(%rsp)
	movq	50936(%rsp), %rax
	movq	%rax, 144056(%rsp)
	movq	50944(%rsp), %rax
	movq	%rax, 144064(%rsp)
	movq	50952(%rsp), %rax
	movq	%rax, 144072(%rsp)
	movq	50960(%rsp), %rax
	movq	%rax, 144080(%rsp)
	movq	50968(%rsp), %rax
	movq	%rax, 144088(%rsp)
	movq	50976(%rsp), %rax
	movq	%rax, 144096(%rsp)
	movq	50984(%rsp), %rax
	movq	%rax, 144104(%rsp)
	movq	50992(%rsp), %rax
	movq	%rax, 144112(%rsp)
	movq	51000(%rsp), %rax
	movq	%rax, 144120(%rsp)
	movq	51008(%rsp), %rax
	movq	%rax, 144128(%rsp)
	movq	51016(%rsp), %rax
	movq	%rax, 144136(%rsp)
	movq	51024(%rsp), %rax
	movq	%rax, 144144(%rsp)
	movq	51032(%rsp), %rax
	movq	%rax, 144152(%rsp)
	movq	51040(%rsp), %rax
	movq	%rax, 144160(%rsp)
	movq	51048(%rsp), %rax
	movq	%rax, 144168(%rsp)
	movq	51056(%rsp), %rax
	movq	%rax, 144176(%rsp)
	movq	51064(%rsp), %rax
	movq	%rax, 144184(%rsp)
	movq	51072(%rsp), %rax
	movq	%rax, 144192(%rsp)
	movq	51080(%rsp), %rax
	movq	%rax, 144200(%rsp)
	movq	51088(%rsp), %rax
	movq	%rax, 144208(%rsp)
	movq	51096(%rsp), %rax
	movq	%rax, 144216(%rsp)
	movq	51104(%rsp), %rax
	movq	%rax, 144224(%rsp)
	movq	51112(%rsp), %rax
	movq	%rax, 144232(%rsp)
	movq	51120(%rsp), %rax
	movq	%rax, 144240(%rsp)
	movq	51128(%rsp), %rax
	movq	%rax, 144248(%rsp)
	movq	51136(%rsp), %rax
	movq	%rax, 144256(%rsp)
	movq	51144(%rsp), %rax
	movq	%rax, 144264(%rsp)
	movq	51152(%rsp), %rax
	movq	%rax, 144272(%rsp)
	movq	51160(%rsp), %rax
	movq	%rax, 144280(%rsp)
	movq	51168(%rsp), %rax
	movq	%rax, 144288(%rsp)
	movq	51176(%rsp), %rax
	movq	%rax, 144296(%rsp)
	movq	51184(%rsp), %rax
	movq	%rax, 144304(%rsp)
	movq	51192(%rsp), %rax
	movq	%rax, 144312(%rsp)
	movq	51200(%rsp), %rax
	movq	%rax, 144320(%rsp)
	movq	51208(%rsp), %rax
	movq	%rax, 144328(%rsp)
	movq	51216(%rsp), %rax
	movq	%rax, 144336(%rsp)
	movq	51224(%rsp), %rax
	movq	%rax, 144344(%rsp)
	movq	51232(%rsp), %rax
	movq	%rax, 144352(%rsp)
	movq	51240(%rsp), %rax
	movq	%rax, 144360(%rsp)
	movq	51248(%rsp), %rax
	movq	%rax, 144368(%rsp)
	movq	51256(%rsp), %rax
	movq	%rax, 144376(%rsp)
	movq	51264(%rsp), %rax
	movq	%rax, 144384(%rsp)
	movq	51272(%rsp), %rax
	movq	%rax, 144392(%rsp)
	movq	51280(%rsp), %rax
	movq	%rax, 144400(%rsp)
	movq	51288(%rsp), %rax
	movq	%rax, 144408(%rsp)
	movq	51296(%rsp), %rax
	movq	%rax, 144416(%rsp)
	movq	51304(%rsp), %rax
	movq	%rax, 144424(%rsp)
	movq	51312(%rsp), %rax
	movq	%rax, 144432(%rsp)
	movq	51320(%rsp), %rax
	movq	%rax, 144440(%rsp)
	movq	51328(%rsp), %rax
	movq	%rax, 144448(%rsp)
	movq	51336(%rsp), %rax
	movq	%rax, 144456(%rsp)
	movq	51344(%rsp), %rax
	movq	%rax, 144464(%rsp)
	movq	51352(%rsp), %rax
	movq	%rax, 144472(%rsp)
	movq	51360(%rsp), %rax
	movq	%rax, 144480(%rsp)
	movq	51368(%rsp), %rax
	movq	%rax, 144488(%rsp)
	movq	51376(%rsp), %rax
	movq	%rax, 144496(%rsp)
	movq	51384(%rsp), %rax
	movq	%rax, 144504(%rsp)
	movq	51392(%rsp), %rax
	movq	%rax, 144512(%rsp)
	movq	51400(%rsp), %rax
	movq	%rax, 144520(%rsp)
	movq	51408(%rsp), %rax
	movq	%rax, 144528(%rsp)
	movq	51416(%rsp), %rax
	movq	%rax, 144536(%rsp)
	movq	51424(%rsp), %rax
	movq	%rax, 144544(%rsp)
	movq	51432(%rsp), %rax
	movq	%rax, 144552(%rsp)
	movq	51440(%rsp), %rax
	movq	%rax, 144560(%rsp)
	movq	51448(%rsp), %rax
	movq	%rax, 144568(%rsp)
	movq	51456(%rsp), %rax
	movq	%rax, 144576(%rsp)
	movq	51464(%rsp), %rax
	movq	%rax, 144584(%rsp)
	movq	51472(%rsp), %rax
	movq	%rax, 144592(%rsp)
	movq	51480(%rsp), %rax
	movq	%rax, 144600(%rsp)
	movq	51488(%rsp), %rax
	movq	%rax, 144608(%rsp)
	movq	51496(%rsp), %rax
	movq	%rax, 144616(%rsp)
	movq	51504(%rsp), %rax
	movq	%rax, 144624(%rsp)
	movq	51512(%rsp), %rax
	movq	%rax, 144632(%rsp)
	movq	51520(%rsp), %rax
	movq	%rax, 144640(%rsp)
	movq	51528(%rsp), %rax
	movq	%rax, 144648(%rsp)
	movq	51536(%rsp), %rax
	movq	%rax, 144656(%rsp)
	movq	51544(%rsp), %rax
	movq	%rax, 144664(%rsp)
	movq	51552(%rsp), %rax
	movq	%rax, 144672(%rsp)
	movq	51560(%rsp), %rax
	movq	%rax, 144680(%rsp)
	movq	51568(%rsp), %rax
	movq	%rax, 144688(%rsp)
	movq	51576(%rsp), %rax
	movq	%rax, 144696(%rsp)
	movq	51584(%rsp), %rax
	movq	%rax, 144704(%rsp)
	movq	51592(%rsp), %rax
	movq	%rax, 144712(%rsp)
	movq	51600(%rsp), %rax
	movq	%rax, 144720(%rsp)
	movq	51608(%rsp), %rax
	movq	%rax, 144728(%rsp)
	movq	51616(%rsp), %rax
	movq	%rax, 144736(%rsp)
	movq	51624(%rsp), %rax
	movq	%rax, 144744(%rsp)
	movq	51632(%rsp), %rax
	movq	%rax, 144752(%rsp)
	movq	51640(%rsp), %rax
	movq	%rax, 144760(%rsp)
	movq	51648(%rsp), %rax
	movq	%rax, 144768(%rsp)
	movq	51656(%rsp), %rax
	movq	%rax, 144776(%rsp)
	movq	51664(%rsp), %rax
	movq	%rax, 144784(%rsp)
	movq	51672(%rsp), %rax
	movq	%rax, 144792(%rsp)
	movq	51680(%rsp), %rax
	movq	%rax, 144800(%rsp)
	movq	51688(%rsp), %rax
	movq	%rax, 144808(%rsp)
	movq	51696(%rsp), %rax
	movq	%rax, 144816(%rsp)
	movq	51704(%rsp), %rax
	movq	%rax, 144824(%rsp)
	movq	51712(%rsp), %rax
	movq	%rax, 144832(%rsp)
	movq	51720(%rsp), %rax
	movq	%rax, 144840(%rsp)
	movq	51728(%rsp), %rax
	movq	%rax, 144848(%rsp)
	movq	51736(%rsp), %rax
	movq	%rax, 144856(%rsp)
	movq	51744(%rsp), %rax
	movq	%rax, 144864(%rsp)
	movq	51752(%rsp), %rax
	movq	%rax, 144872(%rsp)
	movq	51760(%rsp), %rax
	movq	%rax, 144880(%rsp)
	movq	51768(%rsp), %rax
	movq	%rax, 144888(%rsp)
	movq	51776(%rsp), %rax
	movq	%rax, 144896(%rsp)
	movq	51784(%rsp), %rax
	movq	%rax, 144904(%rsp)
	movq	51792(%rsp), %rax
	movq	%rax, 144912(%rsp)
	movq	51800(%rsp), %rax
	movq	%rax, 144920(%rsp)
	movq	51808(%rsp), %rax
	movq	%rax, 144928(%rsp)
	movq	51816(%rsp), %rax
	movq	%rax, 144936(%rsp)
	movq	51824(%rsp), %rax
	movq	%rax, 144944(%rsp)
	movq	51832(%rsp), %rax
	movq	%rax, 144952(%rsp)
	movq	51840(%rsp), %rax
	movq	%rax, 144960(%rsp)
	movq	51848(%rsp), %rax
	movq	%rax, 144968(%rsp)
	movq	51856(%rsp), %rax
	movq	%rax, 144976(%rsp)
	movq	51864(%rsp), %rax
	movq	%rax, 144984(%rsp)
	movq	51872(%rsp), %rax
	movq	%rax, 144992(%rsp)
	movq	51880(%rsp), %rax
	movq	%rax, 145000(%rsp)
	movq	51888(%rsp), %rax
	movq	%rax, 145008(%rsp)
	movq	51896(%rsp), %rax
	movq	%rax, 145016(%rsp)
	movq	51904(%rsp), %rax
	movq	%rax, 145024(%rsp)
	movq	51912(%rsp), %rax
	movq	%rax, 145032(%rsp)
	movq	51920(%rsp), %rax
	movq	%rax, 145040(%rsp)
	movq	51928(%rsp), %rax
	movq	%rax, 145048(%rsp)
	movq	51936(%rsp), %rax
	movq	%rax, 145056(%rsp)
	movq	51944(%rsp), %rax
	movq	%rax, 145064(%rsp)
	movq	51952(%rsp), %rax
	movq	%rax, 145072(%rsp)
	movq	51960(%rsp), %rax
	movq	%rax, 145080(%rsp)
	movq	51968(%rsp), %rax
	movq	%rax, 145088(%rsp)
	movq	51976(%rsp), %rax
	movq	%rax, 145096(%rsp)
	movq	51984(%rsp), %rax
	movq	%rax, 145104(%rsp)
	movq	51992(%rsp), %rax
	movq	%rax, 145112(%rsp)
	movq	52000(%rsp), %rax
	movq	%rax, 145120(%rsp)
	movq	52008(%rsp), %rax
	movq	%rax, 145128(%rsp)
	movq	52016(%rsp), %rax
	movq	%rax, 145136(%rsp)
	movq	52024(%rsp), %rax
	movq	%rax, 145144(%rsp)
	movq	52032(%rsp), %rax
	movq	%rax, 145152(%rsp)
	movq	52040(%rsp), %rax
	movq	%rax, 145160(%rsp)
	movq	52048(%rsp), %rax
	movq	%rax, 145168(%rsp)
	movq	52056(%rsp), %rax
	movq	%rax, 145176(%rsp)
	movq	52064(%rsp), %rax
	movq	%rax, 145184(%rsp)
	movq	52072(%rsp), %rax
	movq	%rax, 145192(%rsp)
	movq	52080(%rsp), %rax
	movq	%rax, 145200(%rsp)
	movq	52088(%rsp), %rax
	movq	%rax, 145208(%rsp)
	movq	52096(%rsp), %rax
	movq	%rax, 145216(%rsp)
	movq	52104(%rsp), %rax
	movq	%rax, 145224(%rsp)
	movq	52112(%rsp), %rax
	movq	%rax, 145232(%rsp)
	movq	52120(%rsp), %rax
	movq	%rax, 145240(%rsp)
	movq	52128(%rsp), %rax
	movq	%rax, 145248(%rsp)
	movq	52136(%rsp), %rax
	movq	%rax, 145256(%rsp)
	movq	52144(%rsp), %rax
	movq	%rax, 145264(%rsp)
	movq	52152(%rsp), %rax
	movq	%rax, 145272(%rsp)
	movq	52160(%rsp), %rax
	movq	%rax, 145280(%rsp)
	movq	52168(%rsp), %rax
	movq	%rax, 145288(%rsp)
	movq	52176(%rsp), %rax
	movq	%rax, 145296(%rsp)
	movq	52184(%rsp), %rax
	movq	%rax, 145304(%rsp)
	movq	52192(%rsp), %rax
	movq	%rax, 145312(%rsp)
	movq	52200(%rsp), %rax
	movq	%rax, 145320(%rsp)
	movq	52208(%rsp), %rax
	movq	%rax, 145328(%rsp)
	movq	52216(%rsp), %rax
	movq	%rax, 145336(%rsp)
	movq	52224(%rsp), %rax
	movq	%rax, 145344(%rsp)
	movq	52232(%rsp), %rax
	movq	%rax, 145352(%rsp)
	movq	52240(%rsp), %rax
	movq	%rax, 145360(%rsp)
	movq	52248(%rsp), %rax
	movq	%rax, 145368(%rsp)
	movq	52256(%rsp), %rax
	movq	%rax, 145376(%rsp)
	movq	52264(%rsp), %rax
	movq	%rax, 145384(%rsp)
	movq	52272(%rsp), %rax
	movq	%rax, 145392(%rsp)
	movq	52280(%rsp), %rax
	movq	%rax, 145400(%rsp)
	movq	52288(%rsp), %rax
	movq	%rax, 145408(%rsp)
	movq	52296(%rsp), %rax
	movq	%rax, 145416(%rsp)
	movq	52304(%rsp), %rax
	movq	%rax, 145424(%rsp)
	movq	52312(%rsp), %rax
	movq	%rax, 145432(%rsp)
	movq	52320(%rsp), %rax
	movq	%rax, 145440(%rsp)
	movq	52328(%rsp), %rax
	movq	%rax, 145448(%rsp)
	movq	52336(%rsp), %rax
	movq	%rax, 145456(%rsp)
	movq	52344(%rsp), %rax
	movq	%rax, 145464(%rsp)
	movq	52352(%rsp), %rax
	movq	%rax, 145472(%rsp)
	movq	52360(%rsp), %rax
	movq	%rax, 145480(%rsp)
	movq	52368(%rsp), %rax
	movq	%rax, 145488(%rsp)
	movq	52376(%rsp), %rax
	movq	%rax, 145496(%rsp)
	movq	52384(%rsp), %rax
	movq	%rax, 145504(%rsp)
	movq	52392(%rsp), %rax
	movq	%rax, 145512(%rsp)
	movq	52400(%rsp), %rax
	movq	%rax, 145520(%rsp)
	movq	52408(%rsp), %rax
	movq	%rax, 145528(%rsp)
	movq	52416(%rsp), %rax
	movq	%rax, 145536(%rsp)
	movq	52424(%rsp), %rax
	movq	%rax, 145544(%rsp)
	movq	52432(%rsp), %rax
	movq	%rax, 145552(%rsp)
	movq	52440(%rsp), %rax
	movq	%rax, 145560(%rsp)
	movq	52448(%rsp), %rax
	movq	%rax, 145568(%rsp)
	movq	52456(%rsp), %rax
	movq	%rax, 145576(%rsp)
	movq	52464(%rsp), %rax
	movq	%rax, 145584(%rsp)
	movq	52472(%rsp), %rax
	movq	%rax, 145592(%rsp)
	movq	52480(%rsp), %rax
	movq	%rax, 145600(%rsp)
	movq	52488(%rsp), %rax
	movq	%rax, 145608(%rsp)
	movq	52496(%rsp), %rax
	movq	%rax, 145616(%rsp)
	movq	52504(%rsp), %rax
	movq	%rax, 145624(%rsp)
	movq	52512(%rsp), %rax
	movq	%rax, 145632(%rsp)
	movq	52520(%rsp), %rax
	movq	%rax, 145640(%rsp)
	movq	52528(%rsp), %rax
	movq	%rax, 145648(%rsp)
	movq	52536(%rsp), %rax
	movq	%rax, 145656(%rsp)
	movq	52544(%rsp), %rax
	movq	%rax, 145664(%rsp)
	movq	52552(%rsp), %rax
	movq	%rax, 145672(%rsp)
	movq	52560(%rsp), %rax
	movq	%rax, 145680(%rsp)
	movq	52568(%rsp), %rax
	movq	%rax, 145688(%rsp)
	movq	52576(%rsp), %rax
	movq	%rax, 145696(%rsp)
	movq	52584(%rsp), %rax
	movq	%rax, 145704(%rsp)
	movq	52592(%rsp), %rax
	movq	%rax, 145712(%rsp)
	movq	52600(%rsp), %rax
	movq	%rax, 145720(%rsp)
	movq	52608(%rsp), %rax
	movq	%rax, 145728(%rsp)
	movq	52616(%rsp), %rax
	movq	%rax, 145736(%rsp)
	movq	52624(%rsp), %rax
	movq	%rax, 145744(%rsp)
	movq	52632(%rsp), %rax
	movq	%rax, 145752(%rsp)
	movq	52640(%rsp), %rax
	movq	%rax, 145760(%rsp)
	movq	52648(%rsp), %rax
	movq	%rax, 145768(%rsp)
	movq	52656(%rsp), %rax
	movq	%rax, 145776(%rsp)
	movq	52664(%rsp), %rax
	movq	%rax, 145784(%rsp)
	movq	52672(%rsp), %rax
	movq	%rax, 145792(%rsp)
	movq	52680(%rsp), %rax
	movq	%rax, 145800(%rsp)
	movq	52688(%rsp), %rax
	movq	%rax, 145808(%rsp)
	movq	52696(%rsp), %rax
	movq	%rax, 145816(%rsp)
	movq	52704(%rsp), %rax
	movq	%rax, 145824(%rsp)
	movq	52712(%rsp), %rax
	movq	%rax, 145832(%rsp)
	movq	52720(%rsp), %rax
	movq	%rax, 145840(%rsp)
	movq	52728(%rsp), %rax
	movq	%rax, 145848(%rsp)
	movq	52736(%rsp), %rax
	movq	%rax, 145856(%rsp)
	movq	52744(%rsp), %rax
	movq	%rax, 145864(%rsp)
	movq	52752(%rsp), %rax
	movq	%rax, 145872(%rsp)
	movq	52760(%rsp), %rax
	movq	%rax, 145880(%rsp)
	movq	52768(%rsp), %rax
	movq	%rax, 145888(%rsp)
	movq	52776(%rsp), %rax
	movq	%rax, 145896(%rsp)
	movq	52784(%rsp), %rax
	movq	%rax, 145904(%rsp)
	movq	52792(%rsp), %rax
	movq	%rax, 145912(%rsp)
	movq	52800(%rsp), %rax
	movq	%rax, 145920(%rsp)
	movq	52808(%rsp), %rax
	movq	%rax, 145928(%rsp)
	movq	52816(%rsp), %rax
	movq	%rax, 145936(%rsp)
	movq	52824(%rsp), %rax
	movq	%rax, 145944(%rsp)
	movq	52832(%rsp), %rax
	movq	%rax, 145952(%rsp)
	movq	52840(%rsp), %rax
	movq	%rax, 145960(%rsp)
	movq	52848(%rsp), %rax
	movq	%rax, 145968(%rsp)
	movq	52856(%rsp), %rax
	movq	%rax, 145976(%rsp)
	movq	52864(%rsp), %rax
	movq	%rax, 145984(%rsp)
	movq	52872(%rsp), %rax
	movq	%rax, 145992(%rsp)
	movq	52880(%rsp), %rax
	movq	%rax, 146000(%rsp)
	movq	52888(%rsp), %rax
	movq	%rax, 146008(%rsp)
	movq	52896(%rsp), %rax
	movq	%rax, 146016(%rsp)
	movq	52904(%rsp), %rax
	movq	%rax, 146024(%rsp)
	movq	52912(%rsp), %rax
	movq	%rax, 146032(%rsp)
	movq	52920(%rsp), %rax
	movq	%rax, 146040(%rsp)
	movq	52928(%rsp), %rax
	movq	%rax, 146048(%rsp)
	movq	52936(%rsp), %rax
	movq	%rax, 146056(%rsp)
	movq	52944(%rsp), %rax
	movq	%rax, 146064(%rsp)
	movq	52952(%rsp), %rax
	movq	%rax, 146072(%rsp)
	movq	52960(%rsp), %rax
	movq	%rax, 146080(%rsp)
	movq	52968(%rsp), %rax
	movq	%rax, 146088(%rsp)
	movq	52976(%rsp), %rax
	movq	%rax, 146096(%rsp)
	movq	52984(%rsp), %rax
	movq	%rax, 146104(%rsp)
	movq	52992(%rsp), %rax
	movq	%rax, 146112(%rsp)
	movq	53000(%rsp), %rax
	movq	%rax, 146120(%rsp)
	movq	53008(%rsp), %rax
	movq	%rax, 146128(%rsp)
	movq	53016(%rsp), %rax
	movq	%rax, 146136(%rsp)
	movq	53024(%rsp), %rax
	movq	%rax, 146144(%rsp)
	movq	53032(%rsp), %rax
	movq	%rax, 146152(%rsp)
	movq	53040(%rsp), %rax
	movq	%rax, 146160(%rsp)
	movq	53048(%rsp), %rax
	movq	%rax, 146168(%rsp)
	movq	53056(%rsp), %rax
	movq	%rax, 146176(%rsp)
	movq	53064(%rsp), %rax
	movq	%rax, 146184(%rsp)
	movq	53072(%rsp), %rax
	movq	%rax, 146192(%rsp)
	movq	53080(%rsp), %rax
	movq	%rax, 146200(%rsp)
	movq	53088(%rsp), %rax
	movq	%rax, 146208(%rsp)
	movq	53096(%rsp), %rax
	movq	%rax, 146216(%rsp)
	movq	53104(%rsp), %rax
	movq	%rax, 146224(%rsp)
	movq	53112(%rsp), %rax
	movq	%rax, 146232(%rsp)
	movq	53120(%rsp), %rax
	movq	%rax, 146240(%rsp)
	movq	53128(%rsp), %rax
	movq	%rax, 146248(%rsp)
	movq	53136(%rsp), %rax
	movq	%rax, 146256(%rsp)
	movq	53144(%rsp), %rax
	movq	%rax, 146264(%rsp)
	movq	53152(%rsp), %rax
	movq	%rax, 146272(%rsp)
	movq	53160(%rsp), %rax
	movq	%rax, 146280(%rsp)
	movq	53168(%rsp), %rax
	movq	%rax, 146288(%rsp)
	movq	53176(%rsp), %rax
	movq	%rax, 146296(%rsp)
	movq	53184(%rsp), %rax
	movq	%rax, 146304(%rsp)
	movq	53192(%rsp), %rax
	movq	%rax, 146312(%rsp)
	movq	53200(%rsp), %rax
	movq	%rax, 146320(%rsp)
	movq	53208(%rsp), %rax
	movq	%rax, 146328(%rsp)
	movq	53216(%rsp), %rax
	movq	%rax, 146336(%rsp)
	movq	53224(%rsp), %rax
	movq	%rax, 146344(%rsp)
	movq	53232(%rsp), %rax
	movq	%rax, 146352(%rsp)
	movq	53240(%rsp), %rax
	movq	%rax, 146360(%rsp)
	movq	53248(%rsp), %rax
	movq	%rax, 146368(%rsp)
	movq	53256(%rsp), %rax
	movq	%rax, 146376(%rsp)
	movq	53264(%rsp), %rax
	movq	%rax, 146384(%rsp)
	movq	53272(%rsp), %rax
	movq	%rax, 146392(%rsp)
	movq	53280(%rsp), %rax
	movq	%rax, 146400(%rsp)
	movq	53288(%rsp), %rax
	movq	%rax, 146408(%rsp)
	movq	53296(%rsp), %rax
	movq	%rax, 146416(%rsp)
	movq	53304(%rsp), %rax
	movq	%rax, 146424(%rsp)
	movq	53312(%rsp), %rax
	movq	%rax, 146432(%rsp)
	movq	53320(%rsp), %rax
	movq	%rax, 146440(%rsp)
	movq	53328(%rsp), %rax
	movq	%rax, 146448(%rsp)
	movq	53336(%rsp), %rax
	movq	%rax, 146456(%rsp)
	movq	53344(%rsp), %rax
	movq	%rax, 146464(%rsp)
	movq	53352(%rsp), %rax
	movq	%rax, 146472(%rsp)
	movq	53360(%rsp), %rax
	movq	%rax, 146480(%rsp)
	movq	53368(%rsp), %rax
	movq	%rax, 146488(%rsp)
	movq	53376(%rsp), %rax
	movq	%rax, 146496(%rsp)
	movq	53384(%rsp), %rax
	movq	%rax, 146504(%rsp)
	movq	53392(%rsp), %rax
	movq	%rax, 146512(%rsp)
	movq	53400(%rsp), %rax
	movq	%rax, 146520(%rsp)
	movq	53408(%rsp), %rax
	movq	%rax, 146528(%rsp)
	movq	53416(%rsp), %rax
	movq	%rax, 146536(%rsp)
	movq	53424(%rsp), %rax
	movq	%rax, 146544(%rsp)
	movq	53432(%rsp), %rax
	movq	%rax, 146552(%rsp)
	movq	53440(%rsp), %rax
	movq	%rax, 146560(%rsp)
	movq	53448(%rsp), %rax
	movq	%rax, 146568(%rsp)
	movq	53456(%rsp), %rax
	movq	%rax, 146576(%rsp)
	movq	53464(%rsp), %rax
	movq	%rax, 146584(%rsp)
	movq	53472(%rsp), %rax
	movq	%rax, 146592(%rsp)
	movq	53480(%rsp), %rax
	movq	%rax, 146600(%rsp)
	movq	53488(%rsp), %rax
	movq	%rax, 146608(%rsp)
	movq	53496(%rsp), %rax
	movq	%rax, 146616(%rsp)
	movq	53504(%rsp), %rax
	movq	%rax, 146624(%rsp)
	movq	53512(%rsp), %rax
	movq	%rax, 146632(%rsp)
	movq	53520(%rsp), %rax
	movq	%rax, 146640(%rsp)
	movq	53528(%rsp), %rax
	movq	%rax, 146648(%rsp)
	movq	53536(%rsp), %rax
	movq	%rax, 146656(%rsp)
	movq	53544(%rsp), %rax
	movq	%rax, 146664(%rsp)
	movq	53552(%rsp), %rax
	movq	%rax, 146672(%rsp)
	movq	53560(%rsp), %rax
	movq	%rax, 146680(%rsp)
	movq	53568(%rsp), %rax
	movq	%rax, 146688(%rsp)
	movq	53576(%rsp), %rax
	movq	%rax, 146696(%rsp)
	movq	53584(%rsp), %rax
	movq	%rax, 146704(%rsp)
	movq	53592(%rsp), %rax
	movq	%rax, 146712(%rsp)
	movq	53600(%rsp), %rax
	movq	%rax, 146720(%rsp)
	movq	53608(%rsp), %rax
	movq	%rax, 146728(%rsp)
	movq	53616(%rsp), %rax
	movq	%rax, 146736(%rsp)
	movq	53624(%rsp), %rax
	movq	%rax, 146744(%rsp)
	movq	53632(%rsp), %rax
	movq	%rax, 146752(%rsp)
	movq	53640(%rsp), %rax
	movq	%rax, 146760(%rsp)
	movq	53648(%rsp), %rax
	movq	%rax, 146768(%rsp)
	movq	53656(%rsp), %rax
	movq	%rax, 146776(%rsp)
	movq	53664(%rsp), %rax
	movq	%rax, 146784(%rsp)
	movq	53672(%rsp), %rax
	movq	%rax, 146792(%rsp)
	movq	53680(%rsp), %rax
	movq	%rax, 146800(%rsp)
	movq	53688(%rsp), %rax
	movq	%rax, 146808(%rsp)
	movq	53696(%rsp), %rax
	movq	%rax, 146816(%rsp)
	movq	53704(%rsp), %rax
	movq	%rax, 146824(%rsp)
	movq	53712(%rsp), %rax
	movq	%rax, 146832(%rsp)
	movq	53720(%rsp), %rax
	movq	%rax, 146840(%rsp)
	movq	53728(%rsp), %rax
	movq	%rax, 146848(%rsp)
	movq	53736(%rsp), %rax
	movq	%rax, 146856(%rsp)
	movq	53744(%rsp), %rax
	movq	%rax, 146864(%rsp)
	movq	53752(%rsp), %rax
	movq	%rax, 146872(%rsp)
	movq	53760(%rsp), %rax
	movq	%rax, 146880(%rsp)
	movq	53768(%rsp), %rax
	movq	%rax, 146888(%rsp)
	movq	53776(%rsp), %rax
	movq	%rax, 146896(%rsp)
	movq	53784(%rsp), %rax
	movq	%rax, 146904(%rsp)
	movq	53792(%rsp), %rax
	movq	%rax, 146912(%rsp)
	movq	53800(%rsp), %rax
	movq	%rax, 146920(%rsp)
	movq	53808(%rsp), %rax
	movq	%rax, 146928(%rsp)
	movq	53816(%rsp), %rax
	movq	%rax, 146936(%rsp)
	movq	53824(%rsp), %rax
	movq	%rax, 146944(%rsp)
	movq	53832(%rsp), %rax
	movq	%rax, 146952(%rsp)
	movq	53840(%rsp), %rax
	movq	%rax, 146960(%rsp)
	movq	53848(%rsp), %rax
	movq	%rax, 146968(%rsp)
	movq	53856(%rsp), %rax
	movq	%rax, 146976(%rsp)
	movq	53864(%rsp), %rax
	movq	%rax, 146984(%rsp)
	movq	53872(%rsp), %rax
	movq	%rax, 146992(%rsp)
	movq	53880(%rsp), %rax
	movq	%rax, 147000(%rsp)
	movq	53888(%rsp), %rax
	movq	%rax, 147008(%rsp)
	movq	53896(%rsp), %rax
	movq	%rax, 147016(%rsp)
	movq	53904(%rsp), %rax
	movq	%rax, 147024(%rsp)
	movq	53912(%rsp), %rax
	movq	%rax, 147032(%rsp)
	movq	53920(%rsp), %rax
	movq	%rax, 147040(%rsp)
	movq	53928(%rsp), %rax
	movq	%rax, 147048(%rsp)
	movq	53936(%rsp), %rax
	movq	%rax, 147056(%rsp)
	movq	53944(%rsp), %rax
	movq	%rax, 147064(%rsp)
	movq	53952(%rsp), %rax
	movq	%rax, 147072(%rsp)
	movq	53960(%rsp), %rax
	movq	%rax, 147080(%rsp)
	movq	53968(%rsp), %rax
	movq	%rax, 147088(%rsp)
	movq	53976(%rsp), %rax
	movq	%rax, 147096(%rsp)
	movq	53984(%rsp), %rax
	movq	%rax, 147104(%rsp)
	movq	53992(%rsp), %rax
	movq	%rax, 147112(%rsp)
	movq	54000(%rsp), %rax
	movq	%rax, 147120(%rsp)
	movq	54008(%rsp), %rax
	movq	%rax, 147128(%rsp)
	movq	54016(%rsp), %rax
	movq	%rax, 147136(%rsp)
	movq	54024(%rsp), %rax
	movq	%rax, 147144(%rsp)
	movq	54032(%rsp), %rax
	movq	%rax, 147152(%rsp)
	movq	54040(%rsp), %rax
	movq	%rax, 147160(%rsp)
	movq	54048(%rsp), %rax
	movq	%rax, 147168(%rsp)
	movq	54056(%rsp), %rax
	movq	%rax, 147176(%rsp)
	movq	54064(%rsp), %rax
	movq	%rax, 147184(%rsp)
	movq	54072(%rsp), %rax
	movq	%rax, 147192(%rsp)
	movq	54080(%rsp), %rax
	movq	%rax, 147200(%rsp)
	movq	54088(%rsp), %rax
	movq	%rax, 147208(%rsp)
	movq	54096(%rsp), %rax
	movq	%rax, 147216(%rsp)
	movq	54104(%rsp), %rax
	movq	%rax, 147224(%rsp)
	movq	54112(%rsp), %rax
	movq	%rax, 147232(%rsp)
	movq	54120(%rsp), %rax
	movq	%rax, 147240(%rsp)
	movq	54128(%rsp), %rax
	movq	%rax, 147248(%rsp)
	movq	54136(%rsp), %rax
	movq	%rax, 147256(%rsp)
	movq	54144(%rsp), %rax
	movq	%rax, 147264(%rsp)
	movq	54152(%rsp), %rax
	movq	%rax, 147272(%rsp)
	movq	54160(%rsp), %rax
	movq	%rax, 147280(%rsp)
	movq	54168(%rsp), %rax
	movq	%rax, 147288(%rsp)
	movq	54176(%rsp), %rax
	movq	%rax, 147296(%rsp)
	movq	54184(%rsp), %rax
	movq	%rax, 147304(%rsp)
	movq	54192(%rsp), %rax
	movq	%rax, 147312(%rsp)
	movq	54200(%rsp), %rax
	movq	%rax, 147320(%rsp)
	movq	54208(%rsp), %rax
	movq	%rax, 147328(%rsp)
	movq	54216(%rsp), %rax
	movq	%rax, 147336(%rsp)
	movq	54224(%rsp), %rax
	movq	%rax, 147344(%rsp)
	movq	54232(%rsp), %rax
	movq	%rax, 147352(%rsp)
	movq	54240(%rsp), %rax
	movq	%rax, 147360(%rsp)
	movq	54248(%rsp), %rax
	movq	%rax, 147368(%rsp)
	movq	54256(%rsp), %rax
	movq	%rax, 147376(%rsp)
	movq	54264(%rsp), %rax
	movq	%rax, 147384(%rsp)
	movq	54272(%rsp), %rax
	movq	%rax, 147392(%rsp)
	movq	54280(%rsp), %rax
	movq	%rax, 147400(%rsp)
	movq	54288(%rsp), %rax
	movq	%rax, 147408(%rsp)
	movq	54296(%rsp), %rax
	movq	%rax, 147416(%rsp)
	movq	54304(%rsp), %rax
	movq	%rax, 147424(%rsp)
	movq	54312(%rsp), %rax
	movq	%rax, 147432(%rsp)
	movq	54320(%rsp), %rax
	movq	%rax, 147440(%rsp)
	movq	54328(%rsp), %rax
	movq	%rax, 147448(%rsp)
	movq	54336(%rsp), %rax
	movq	%rax, 147456(%rsp)
	movq	54344(%rsp), %rax
	movq	%rax, 147464(%rsp)
	movq	54352(%rsp), %rax
	movq	%rax, 147472(%rsp)
	movq	54360(%rsp), %rax
	movq	%rax, 147480(%rsp)
	movq	54368(%rsp), %rax
	movq	%rax, 147488(%rsp)
	movq	54376(%rsp), %rax
	movq	%rax, 147496(%rsp)
	movq	54384(%rsp), %rax
	movq	%rax, 147504(%rsp)
	movq	54392(%rsp), %rax
	movq	%rax, 147512(%rsp)
	movq	54400(%rsp), %rax
	movq	%rax, 147520(%rsp)
	movq	54408(%rsp), %rax
	movq	%rax, 147528(%rsp)
	movq	54416(%rsp), %rax
	movq	%rax, 147536(%rsp)
	movq	54424(%rsp), %rax
	movq	%rax, 147544(%rsp)
	movq	54432(%rsp), %rax
	movq	%rax, 147552(%rsp)
	movq	54440(%rsp), %rax
	movq	%rax, 147560(%rsp)
	movq	54448(%rsp), %rax
	movq	%rax, 147568(%rsp)
	movq	54456(%rsp), %rax
	movq	%rax, 147576(%rsp)
	movq	54464(%rsp), %rax
	movq	%rax, 147584(%rsp)
	movq	54472(%rsp), %rax
	movq	%rax, 147592(%rsp)
	movq	54480(%rsp), %rax
	movq	%rax, 147600(%rsp)
	movq	54488(%rsp), %rax
	movq	%rax, 147608(%rsp)
	movq	54496(%rsp), %rax
	movq	%rax, 147616(%rsp)
	movq	54504(%rsp), %rax
	movq	%rax, 147624(%rsp)
	movq	54512(%rsp), %rax
	movq	%rax, 147632(%rsp)
	movq	54520(%rsp), %rax
	movq	%rax, 147640(%rsp)
	movq	54528(%rsp), %rax
	movq	%rax, 147648(%rsp)
	movq	54536(%rsp), %rax
	movq	%rax, 147656(%rsp)
	movq	54544(%rsp), %rax
	movq	%rax, 147664(%rsp)
	movq	54552(%rsp), %rax
	movq	%rax, 147672(%rsp)
	movq	54560(%rsp), %rax
	movq	%rax, 147680(%rsp)
	movq	54568(%rsp), %rax
	movq	%rax, 147688(%rsp)
	movq	54576(%rsp), %rax
	movq	%rax, 147696(%rsp)
	movq	54584(%rsp), %rax
	movq	%rax, 147704(%rsp)
	movq	54592(%rsp), %rax
	movq	%rax, 147712(%rsp)
	movq	54600(%rsp), %rax
	movq	%rax, 147720(%rsp)
	movq	54608(%rsp), %rax
	movq	%rax, 147728(%rsp)
	movq	54616(%rsp), %rax
	movq	%rax, 147736(%rsp)
	movq	54624(%rsp), %rax
	movq	%rax, 147744(%rsp)
	movq	54632(%rsp), %rax
	movq	%rax, 147752(%rsp)
	movq	54640(%rsp), %rax
	movq	%rax, 147760(%rsp)
	movq	54648(%rsp), %rax
	movq	%rax, 147768(%rsp)
	movq	54656(%rsp), %rax
	movq	%rax, 147776(%rsp)
	movq	54664(%rsp), %rax
	movq	%rax, 147784(%rsp)
	movq	54672(%rsp), %rax
	movq	%rax, 147792(%rsp)
	movq	54680(%rsp), %rax
	movq	%rax, 147800(%rsp)
	movq	54688(%rsp), %rax
	movq	%rax, 147808(%rsp)
	movq	54696(%rsp), %rax
	movq	%rax, 147816(%rsp)
	movq	54704(%rsp), %rax
	movq	%rax, 147824(%rsp)
	movq	54712(%rsp), %rax
	movq	%rax, 147832(%rsp)
	movq	54720(%rsp), %rax
	movq	%rax, 147840(%rsp)
	movq	54728(%rsp), %rax
	movq	%rax, 147848(%rsp)
	movq	54736(%rsp), %rax
	movq	%rax, 147856(%rsp)
	movq	54744(%rsp), %rax
	movq	%rax, 147864(%rsp)
	movq	54752(%rsp), %rax
	movq	%rax, 147872(%rsp)
	movq	54760(%rsp), %rax
	movq	%rax, 147880(%rsp)
	movq	54768(%rsp), %rax
	movq	%rax, 147888(%rsp)
	movq	54776(%rsp), %rax
	movq	%rax, 147896(%rsp)
	movq	54784(%rsp), %rax
	movq	%rax, 147904(%rsp)
	movq	54792(%rsp), %rax
	movq	%rax, 147912(%rsp)
	movq	54800(%rsp), %rax
	movq	%rax, 147920(%rsp)
	movq	54808(%rsp), %rax
	movq	%rax, 147928(%rsp)
	movq	54816(%rsp), %rax
	movq	%rax, 147936(%rsp)
	movq	54824(%rsp), %rax
	movq	%rax, 147944(%rsp)
	movq	54832(%rsp), %rax
	movq	%rax, 147952(%rsp)
	movq	54840(%rsp), %rax
	movq	%rax, 147960(%rsp)
	movq	54848(%rsp), %rax
	movq	%rax, 147968(%rsp)
	movq	54856(%rsp), %rax
	movq	%rax, 147976(%rsp)
	movq	54864(%rsp), %rax
	movq	%rax, 147984(%rsp)
	movq	54872(%rsp), %rax
	movq	%rax, 147992(%rsp)
	movq	54880(%rsp), %rax
	movq	%rax, 148000(%rsp)
	movq	54888(%rsp), %rax
	movq	%rax, 148008(%rsp)
	movq	54896(%rsp), %rax
	movq	%rax, 148016(%rsp)
	movq	54904(%rsp), %rax
	movq	%rax, 148024(%rsp)
	movq	54912(%rsp), %rax
	movq	%rax, 148032(%rsp)
	movq	54920(%rsp), %rax
	movq	%rax, 148040(%rsp)
	movq	54928(%rsp), %rax
	movq	%rax, 148048(%rsp)
	movq	54936(%rsp), %rax
	movq	%rax, 148056(%rsp)
	movq	54944(%rsp), %rax
	movq	%rax, 148064(%rsp)
	movq	54952(%rsp), %rax
	movq	%rax, 148072(%rsp)
	movq	54960(%rsp), %rax
	movq	%rax, 148080(%rsp)
	movq	54968(%rsp), %rax
	movq	%rax, 148088(%rsp)
	movq	54976(%rsp), %rax
	movq	%rax, 148096(%rsp)
	movq	54984(%rsp), %rax
	movq	%rax, 148104(%rsp)
	movq	54992(%rsp), %rax
	movq	%rax, 148112(%rsp)
	movq	55000(%rsp), %rax
	movq	%rax, 148120(%rsp)
	movq	55008(%rsp), %rax
	movq	%rax, 148128(%rsp)
	movq	55016(%rsp), %rax
	movq	%rax, 148136(%rsp)
	movq	55024(%rsp), %rax
	movq	%rax, 148144(%rsp)
	movq	55032(%rsp), %rax
	movq	%rax, 148152(%rsp)
	movq	55040(%rsp), %rax
	movq	%rax, 148160(%rsp)
	movq	55048(%rsp), %rax
	movq	%rax, 148168(%rsp)
	movq	55056(%rsp), %rax
	movq	%rax, 148176(%rsp)
	movq	55064(%rsp), %rax
	movq	%rax, 148184(%rsp)
	movq	55072(%rsp), %rax
	movq	%rax, 148192(%rsp)
	movq	55080(%rsp), %rax
	movq	%rax, 148200(%rsp)
	movq	55088(%rsp), %rax
	movq	%rax, 148208(%rsp)
	movq	55096(%rsp), %rax
	movq	%rax, 148216(%rsp)
	movq	55104(%rsp), %rax
	movq	%rax, 148224(%rsp)
	movq	55112(%rsp), %rax
	movq	%rax, 148232(%rsp)
	movq	55120(%rsp), %rax
	movq	%rax, 148240(%rsp)
	movq	55128(%rsp), %rax
	movq	%rax, 148248(%rsp)
	movq	55136(%rsp), %rax
	movq	%rax, 148256(%rsp)
	movq	55144(%rsp), %rax
	movq	%rax, 148264(%rsp)
	movq	55152(%rsp), %rax
	movq	%rax, 148272(%rsp)
	movq	55160(%rsp), %rax
	movq	%rax, 148280(%rsp)
	movq	55168(%rsp), %rax
	movq	%rax, 148288(%rsp)
	movq	55176(%rsp), %rax
	movq	%rax, 148296(%rsp)
	movq	55184(%rsp), %rax
	movq	%rax, 148304(%rsp)
	movq	55192(%rsp), %rax
	movq	%rax, 148312(%rsp)
	movq	55200(%rsp), %rax
	movq	%rax, 148320(%rsp)
	movq	55208(%rsp), %rax
	movq	%rax, 148328(%rsp)
	movq	55216(%rsp), %rax
	movq	%rax, 148336(%rsp)
	movq	55224(%rsp), %rax
	movq	%rax, 148344(%rsp)
	movq	55232(%rsp), %rax
	movq	%rax, 148352(%rsp)
	movq	55240(%rsp), %rax
	movq	%rax, 148360(%rsp)
	movq	55248(%rsp), %rax
	movq	%rax, 148368(%rsp)
	movq	55256(%rsp), %rax
	movq	%rax, 148376(%rsp)
	movq	55264(%rsp), %rax
	movq	%rax, 148384(%rsp)
	movq	55272(%rsp), %rax
	movq	%rax, 148392(%rsp)
	movq	55280(%rsp), %rax
	movq	%rax, 148400(%rsp)
	movq	55288(%rsp), %rax
	movq	%rax, 148408(%rsp)
	movq	55296(%rsp), %rax
	movq	%rax, 148416(%rsp)
	movq	55304(%rsp), %rax
	movq	%rax, 148424(%rsp)
	movq	55312(%rsp), %rax
	movq	%rax, 148432(%rsp)
	movq	55320(%rsp), %rax
	movq	%rax, 148440(%rsp)
	movq	55328(%rsp), %rax
	movq	%rax, 148448(%rsp)
	movq	55336(%rsp), %rax
	movq	%rax, 148456(%rsp)
	movq	55344(%rsp), %rax
	movq	%rax, 148464(%rsp)
	movq	55352(%rsp), %rax
	movq	%rax, 148472(%rsp)
	movq	55360(%rsp), %rax
	movq	%rax, 148480(%rsp)
	movq	55368(%rsp), %rax
	movq	%rax, 148488(%rsp)
	movq	55376(%rsp), %rax
	movq	%rax, 148496(%rsp)
	movq	55384(%rsp), %rax
	movq	%rax, 148504(%rsp)
	movq	55392(%rsp), %rax
	movq	%rax, 148512(%rsp)
	movq	55400(%rsp), %rax
	movq	%rax, 148520(%rsp)
	movq	55408(%rsp), %rax
	movq	%rax, 148528(%rsp)
	movq	55416(%rsp), %rax
	movq	%rax, 148536(%rsp)
	movq	55424(%rsp), %rax
	movq	%rax, 148544(%rsp)
	movq	55432(%rsp), %rax
	movq	%rax, 148552(%rsp)
	movq	55440(%rsp), %rax
	movq	%rax, 148560(%rsp)
	movq	55448(%rsp), %rax
	movq	%rax, 148568(%rsp)
	movq	55456(%rsp), %rax
	movq	%rax, 148576(%rsp)
	movq	55464(%rsp), %rax
	movq	%rax, 148584(%rsp)
	movq	55472(%rsp), %rax
	movq	%rax, 148592(%rsp)
	movq	55480(%rsp), %rax
	movq	%rax, 148600(%rsp)
	movq	55488(%rsp), %rax
	movq	%rax, 148608(%rsp)
	movq	55496(%rsp), %rax
	movq	%rax, 148616(%rsp)
	movq	55504(%rsp), %rax
	movq	%rax, 148624(%rsp)
	movq	55512(%rsp), %rax
	movq	%rax, 148632(%rsp)
	movq	55520(%rsp), %rax
	movq	%rax, 148640(%rsp)
	movq	55528(%rsp), %rax
	movq	%rax, 148648(%rsp)
	movq	55536(%rsp), %rax
	movq	%rax, 148656(%rsp)
	movq	55544(%rsp), %rax
	movq	%rax, 148664(%rsp)
	movq	55552(%rsp), %rax
	movq	%rax, 148672(%rsp)
	movq	55560(%rsp), %rax
	movq	%rax, 148680(%rsp)
	movq	55568(%rsp), %rax
	movq	%rax, 148688(%rsp)
	movq	55576(%rsp), %rax
	movq	%rax, 148696(%rsp)
	movq	55584(%rsp), %rax
	movq	%rax, 148704(%rsp)
	movq	55592(%rsp), %rax
	movq	%rax, 148712(%rsp)
	movq	55600(%rsp), %rax
	movq	%rax, 148720(%rsp)
	movq	55608(%rsp), %rax
	movq	%rax, 148728(%rsp)
	movq	55616(%rsp), %rax
	movq	%rax, 148736(%rsp)
	movq	55624(%rsp), %rax
	movq	%rax, 148744(%rsp)
	movq	55632(%rsp), %rax
	movq	%rax, 148752(%rsp)
	movq	55640(%rsp), %rax
	movq	%rax, 148760(%rsp)
	movq	55648(%rsp), %rax
	movq	%rax, 148768(%rsp)
	movq	55656(%rsp), %rax
	movq	%rax, 148776(%rsp)
	movq	55664(%rsp), %rax
	movq	%rax, 148784(%rsp)
	movq	55672(%rsp), %rax
	movq	%rax, 148792(%rsp)
	movq	55680(%rsp), %rax
	movq	%rax, 148800(%rsp)
	movq	55688(%rsp), %rax
	movq	%rax, 148808(%rsp)
	movq	55696(%rsp), %rax
	movq	%rax, 148816(%rsp)
	movq	55704(%rsp), %rax
	movq	%rax, 148824(%rsp)
	movq	55712(%rsp), %rax
	movq	%rax, 148832(%rsp)
	movq	55720(%rsp), %rax
	movq	%rax, 148840(%rsp)
	movq	55728(%rsp), %rax
	movq	%rax, 148848(%rsp)
	movq	55736(%rsp), %rax
	movq	%rax, 148856(%rsp)
	movq	55744(%rsp), %rax
	movq	%rax, 148864(%rsp)
	movq	55752(%rsp), %rax
	movq	%rax, 148872(%rsp)
	movq	55760(%rsp), %rax
	movq	%rax, 148880(%rsp)
	movq	55768(%rsp), %rax
	movq	%rax, 148888(%rsp)
	movq	55776(%rsp), %rax
	movq	%rax, 148896(%rsp)
	movq	55784(%rsp), %rax
	movq	%rax, 148904(%rsp)
	movq	55792(%rsp), %rax
	movq	%rax, 148912(%rsp)
	movq	55800(%rsp), %rax
	movq	%rax, 148920(%rsp)
	movq	55808(%rsp), %rax
	movq	%rax, 148928(%rsp)
	movq	55816(%rsp), %rax
	movq	%rax, 148936(%rsp)
	movq	55824(%rsp), %rax
	movq	%rax, 148944(%rsp)
	movq	55832(%rsp), %rax
	movq	%rax, 148952(%rsp)
	movq	55840(%rsp), %rax
	movq	%rax, 148960(%rsp)
	movq	55848(%rsp), %rax
	movq	%rax, 148968(%rsp)
	movq	55856(%rsp), %rax
	movq	%rax, 148976(%rsp)
	movq	55864(%rsp), %rax
	movq	%rax, 148984(%rsp)
	movq	55872(%rsp), %rax
	movq	%rax, 148992(%rsp)
	movq	55880(%rsp), %rax
	movq	%rax, 149000(%rsp)
	movq	55888(%rsp), %rax
	movq	%rax, 149008(%rsp)
	movq	55896(%rsp), %rax
	movq	%rax, 149016(%rsp)
	movq	55904(%rsp), %rax
	movq	%rax, 149024(%rsp)
	movq	55912(%rsp), %rax
	movq	%rax, 149032(%rsp)
	movq	55920(%rsp), %rax
	movq	%rax, 149040(%rsp)
	movq	55928(%rsp), %rax
	movq	%rax, 149048(%rsp)
	movq	55936(%rsp), %rax
	movq	%rax, 149056(%rsp)
	movq	55944(%rsp), %rax
	movq	%rax, 149064(%rsp)
	movq	55952(%rsp), %rax
	movq	%rax, 149072(%rsp)
	movq	55960(%rsp), %rax
	movq	%rax, 149080(%rsp)
	movq	55968(%rsp), %rax
	movq	%rax, 149088(%rsp)
	movq	55976(%rsp), %rax
	movq	%rax, 149096(%rsp)
	movq	55984(%rsp), %rax
	movq	%rax, 149104(%rsp)
	movq	55992(%rsp), %rax
	movq	%rax, 149112(%rsp)
	movq	56000(%rsp), %rax
	movq	%rax, 149120(%rsp)
	movq	56008(%rsp), %rax
	movq	%rax, 149128(%rsp)
	movq	56016(%rsp), %rax
	movq	%rax, 149136(%rsp)
	movq	56024(%rsp), %rax
	movq	%rax, 149144(%rsp)
	movq	56032(%rsp), %rax
	movq	%rax, 149152(%rsp)
	movq	56040(%rsp), %rax
	movq	%rax, 149160(%rsp)
	movq	56048(%rsp), %rax
	movq	%rax, 149168(%rsp)
	movq	56056(%rsp), %rax
	movq	%rax, 149176(%rsp)
	movq	56064(%rsp), %rax
	movq	%rax, 149184(%rsp)
	movq	56072(%rsp), %rax
	movq	%rax, 149192(%rsp)
	movq	56080(%rsp), %rax
	movq	%rax, 149200(%rsp)
	movq	56088(%rsp), %rax
	movq	%rax, 149208(%rsp)
	movq	56096(%rsp), %rax
	movq	%rax, 149216(%rsp)
	movq	56104(%rsp), %rax
	movq	%rax, 149224(%rsp)
	movq	56112(%rsp), %rax
	movq	%rax, 149232(%rsp)
	movq	56120(%rsp), %rax
	movq	%rax, 149240(%rsp)
	movq	56128(%rsp), %rax
	movq	%rax, 149248(%rsp)
	movq	56136(%rsp), %rax
	movq	%rax, 149256(%rsp)
	movq	56144(%rsp), %rax
	movq	%rax, 149264(%rsp)
	movq	56152(%rsp), %rax
	movq	%rax, 149272(%rsp)
	movq	56160(%rsp), %rax
	movq	%rax, 149280(%rsp)
	movq	56168(%rsp), %rax
	movq	%rax, 149288(%rsp)
	movq	56176(%rsp), %rax
	movq	%rax, 149296(%rsp)
	movq	56184(%rsp), %rax
	movq	%rax, 149304(%rsp)
	movq	56192(%rsp), %rax
	movq	%rax, 149312(%rsp)
	movq	56200(%rsp), %rax
	movq	%rax, 149320(%rsp)
	movq	56208(%rsp), %rax
	movq	%rax, 149328(%rsp)
	movq	56216(%rsp), %rax
	movq	%rax, 149336(%rsp)
	movq	56224(%rsp), %rax
	movq	%rax, 149344(%rsp)
	movq	56232(%rsp), %rax
	movq	%rax, 149352(%rsp)
	movq	56240(%rsp), %rax
	movq	%rax, 149360(%rsp)
	movq	56248(%rsp), %rax
	movq	%rax, 149368(%rsp)
	movq	56256(%rsp), %rax
	movq	%rax, 149376(%rsp)
	movq	56264(%rsp), %rax
	movq	%rax, 149384(%rsp)
	movq	56272(%rsp), %rax
	movq	%rax, 149392(%rsp)
	movq	56280(%rsp), %rax
	movq	%rax, 149400(%rsp)
	movq	56288(%rsp), %rax
	movq	%rax, 149408(%rsp)
	movq	56296(%rsp), %rax
	movq	%rax, 149416(%rsp)
	movq	56304(%rsp), %rax
	movq	%rax, 149424(%rsp)
	movq	56312(%rsp), %rax
	movq	%rax, 149432(%rsp)
	movq	56320(%rsp), %rax
	movq	%rax, 149440(%rsp)
	movq	56328(%rsp), %rax
	movq	%rax, 149448(%rsp)
	movq	56336(%rsp), %rax
	movq	%rax, 149456(%rsp)
	movq	56344(%rsp), %rax
	movq	%rax, 149464(%rsp)
	movq	56352(%rsp), %rax
	movq	%rax, 149472(%rsp)
	movq	56360(%rsp), %rax
	movq	%rax, 149480(%rsp)
	movq	56368(%rsp), %rax
	movq	%rax, 149488(%rsp)
	movq	56376(%rsp), %rax
	movq	%rax, 149496(%rsp)
	movq	56384(%rsp), %rax
	movq	%rax, 149504(%rsp)
	movq	56392(%rsp), %rax
	movq	%rax, 149512(%rsp)
	movq	56400(%rsp), %rax
	movq	%rax, 149520(%rsp)
	movq	56408(%rsp), %rax
	movq	%rax, 149528(%rsp)
	movq	56416(%rsp), %rax
	movq	%rax, 149536(%rsp)
	movq	56424(%rsp), %rax
	movq	%rax, 149544(%rsp)
	movq	56432(%rsp), %rax
	movq	%rax, 149552(%rsp)
	movq	56440(%rsp), %rax
	movq	%rax, 149560(%rsp)
	movq	56448(%rsp), %rax
	movq	%rax, 149568(%rsp)
	movq	56456(%rsp), %rax
	movq	%rax, 149576(%rsp)
	movq	56464(%rsp), %rax
	movq	%rax, 149584(%rsp)
	movq	56472(%rsp), %rax
	movq	%rax, 149592(%rsp)
	movq	56480(%rsp), %rax
	movq	%rax, 149600(%rsp)
	movq	56488(%rsp), %rax
	movq	%rax, 149608(%rsp)
	movq	56496(%rsp), %rax
	movq	%rax, 149616(%rsp)
	movq	56504(%rsp), %rax
	movq	%rax, 149624(%rsp)
	movq	56512(%rsp), %rax
	movq	%rax, 149632(%rsp)
	movq	56520(%rsp), %rax
	movq	%rax, 149640(%rsp)
	movq	56528(%rsp), %rax
	movq	%rax, 149648(%rsp)
	movq	56536(%rsp), %rax
	movq	%rax, 149656(%rsp)
	movq	56544(%rsp), %rax
	movq	%rax, 149664(%rsp)
	movq	56552(%rsp), %rax
	movq	%rax, 149672(%rsp)
	movq	56560(%rsp), %rax
	movq	%rax, 149680(%rsp)
	movq	56568(%rsp), %rax
	movq	%rax, 149688(%rsp)
	movq	56576(%rsp), %rax
	movq	%rax, 149696(%rsp)
	movq	56584(%rsp), %rax
	movq	%rax, 149704(%rsp)
	movq	56592(%rsp), %rax
	movq	%rax, 149712(%rsp)
	movq	56600(%rsp), %rax
	movq	%rax, 149720(%rsp)
	movq	56608(%rsp), %rax
	movq	%rax, 149728(%rsp)
	movq	56616(%rsp), %rax
	movq	%rax, 149736(%rsp)
	movq	56624(%rsp), %rax
	movq	%rax, 149744(%rsp)
	movq	56632(%rsp), %rax
	movq	%rax, 149752(%rsp)
	movq	56640(%rsp), %rax
	movq	%rax, 149760(%rsp)
	movq	56648(%rsp), %rax
	movq	%rax, 149768(%rsp)
	movq	56656(%rsp), %rax
	movq	%rax, 149776(%rsp)
	movq	56664(%rsp), %rax
	movq	%rax, 149784(%rsp)
	movq	56672(%rsp), %rax
	movq	%rax, 149792(%rsp)
	movq	56680(%rsp), %rax
	movq	%rax, 149800(%rsp)
	movq	56688(%rsp), %rax
	movq	%rax, 149808(%rsp)
	movq	56696(%rsp), %rax
	movq	%rax, 149816(%rsp)
	movq	56704(%rsp), %rax
	movq	%rax, 149824(%rsp)
	movq	56712(%rsp), %rax
	movq	%rax, 149832(%rsp)
	movq	56720(%rsp), %rax
	movq	%rax, 149840(%rsp)
	movq	56728(%rsp), %rax
	movq	%rax, 149848(%rsp)
	movq	56736(%rsp), %rax
	movq	%rax, 149856(%rsp)
	movq	56744(%rsp), %rax
	movq	%rax, 149864(%rsp)
	movq	56752(%rsp), %rax
	movq	%rax, 149872(%rsp)
	movq	56760(%rsp), %rax
	movq	%rax, 149880(%rsp)
	movq	56768(%rsp), %rax
	movq	%rax, 149888(%rsp)
	movq	56776(%rsp), %rax
	movq	%rax, 149896(%rsp)
	movq	56784(%rsp), %rax
	movq	%rax, 149904(%rsp)
	movq	56792(%rsp), %rax
	movq	%rax, 149912(%rsp)
	movq	56800(%rsp), %rax
	movq	%rax, 149920(%rsp)
	movq	56808(%rsp), %rax
	movq	%rax, 149928(%rsp)
	movq	56816(%rsp), %rax
	movq	%rax, 149936(%rsp)
	movq	56824(%rsp), %rax
	movq	%rax, 149944(%rsp)
	movq	56832(%rsp), %rax
	movq	%rax, 149952(%rsp)
	movq	56840(%rsp), %rax
	movq	%rax, 149960(%rsp)
	movq	56848(%rsp), %rax
	movq	%rax, 149968(%rsp)
	movq	56856(%rsp), %rax
	movq	%rax, 149976(%rsp)
	movq	56864(%rsp), %rax
	movq	%rax, 149984(%rsp)
	movq	56872(%rsp), %rax
	movq	%rax, 149992(%rsp)
	movq	56880(%rsp), %rax
	movq	%rax, 150000(%rsp)
	movq	56888(%rsp), %rax
	movq	%rax, 150008(%rsp)
	movq	56896(%rsp), %rax
	movq	%rax, 150016(%rsp)
	movq	56904(%rsp), %rax
	movq	%rax, 150024(%rsp)
	movq	56912(%rsp), %rax
	movq	%rax, 150032(%rsp)
	movq	56920(%rsp), %rax
	movq	%rax, 150040(%rsp)
	movq	56928(%rsp), %rax
	movq	%rax, 150048(%rsp)
	movq	56936(%rsp), %rax
	movq	%rax, 150056(%rsp)
	movq	56944(%rsp), %rax
	movq	%rax, 150064(%rsp)
	movq	56952(%rsp), %rax
	movq	%rax, 150072(%rsp)
	movq	56960(%rsp), %rax
	movq	%rax, 150080(%rsp)
	movq	56968(%rsp), %rax
	movq	%rax, 150088(%rsp)
	movq	56976(%rsp), %rax
	movq	%rax, 150096(%rsp)
	movq	56984(%rsp), %rax
	movq	%rax, 150104(%rsp)
	movq	56992(%rsp), %rax
	movq	%rax, 150112(%rsp)
	movq	57000(%rsp), %rax
	movq	%rax, 150120(%rsp)
	movq	57008(%rsp), %rax
	movq	%rax, 150128(%rsp)
	movq	57016(%rsp), %rax
	movq	%rax, 150136(%rsp)
	movq	57024(%rsp), %rax
	movq	%rax, 150144(%rsp)
	movq	57032(%rsp), %rax
	movq	%rax, 150152(%rsp)
	movq	57040(%rsp), %rax
	movq	%rax, 150160(%rsp)
	movq	57048(%rsp), %rax
	movq	%rax, 150168(%rsp)
	movq	57056(%rsp), %rax
	movq	%rax, 150176(%rsp)
	movq	57064(%rsp), %rax
	movq	%rax, 150184(%rsp)
	movq	57072(%rsp), %rax
	movq	%rax, 150192(%rsp)
	movq	57080(%rsp), %rax
	movq	%rax, 150200(%rsp)
	movq	57088(%rsp), %rax
	movq	%rax, 150208(%rsp)
	movq	57096(%rsp), %rax
	movq	%rax, 150216(%rsp)
	movq	57104(%rsp), %rax
	movq	%rax, 150224(%rsp)
	movq	57112(%rsp), %rax
	movq	%rax, 150232(%rsp)
	movq	57120(%rsp), %rax
	movq	%rax, 150240(%rsp)
	movq	57128(%rsp), %rax
	movq	%rax, 150248(%rsp)
	movq	57136(%rsp), %rax
	movq	%rax, 150256(%rsp)
	movq	57144(%rsp), %rax
	movq	%rax, 150264(%rsp)
	movq	57152(%rsp), %rax
	movq	%rax, 150272(%rsp)
	movq	57160(%rsp), %rax
	movq	%rax, 150280(%rsp)
	movq	57168(%rsp), %rax
	movq	%rax, 150288(%rsp)
	movq	57176(%rsp), %rax
	movq	%rax, 150296(%rsp)
	movq	57184(%rsp), %rax
	movq	%rax, 150304(%rsp)
	movq	57192(%rsp), %rax
	movq	%rax, 150312(%rsp)
	movq	57200(%rsp), %rax
	movq	%rax, 150320(%rsp)
	movq	57208(%rsp), %rax
	movq	%rax, 150328(%rsp)
	movq	57216(%rsp), %rax
	movq	%rax, 150336(%rsp)
	movq	57224(%rsp), %rax
	movq	%rax, 150344(%rsp)
	movq	57232(%rsp), %rax
	movq	%rax, 150352(%rsp)
	movq	57240(%rsp), %rax
	movq	%rax, 150360(%rsp)
	movq	57248(%rsp), %rax
	movq	%rax, 150368(%rsp)
	movq	57256(%rsp), %rax
	movq	%rax, 150376(%rsp)
	movq	57264(%rsp), %rax
	movq	%rax, 150384(%rsp)
	movq	57272(%rsp), %rax
	movq	%rax, 150392(%rsp)
	movq	57280(%rsp), %rax
	movq	%rax, 150400(%rsp)
	movq	57288(%rsp), %rax
	movq	%rax, 150408(%rsp)
	movq	57296(%rsp), %rax
	movq	%rax, 150416(%rsp)
	movq	57304(%rsp), %rax
	movq	%rax, 150424(%rsp)
	movq	57312(%rsp), %rax
	movq	%rax, 150432(%rsp)
	movq	57320(%rsp), %rax
	movq	%rax, 150440(%rsp)
	movq	57328(%rsp), %rax
	movq	%rax, 150448(%rsp)
	movq	57336(%rsp), %rax
	movq	%rax, 150456(%rsp)
	movq	57344(%rsp), %rax
	movq	%rax, 150464(%rsp)
	movq	57352(%rsp), %rax
	movq	%rax, 150472(%rsp)
	movq	57360(%rsp), %rax
	movq	%rax, 150480(%rsp)
	movq	57368(%rsp), %rax
	movq	%rax, 150488(%rsp)
	movq	57376(%rsp), %rax
	movq	%rax, 150496(%rsp)
	movq	57384(%rsp), %rax
	movq	%rax, 150504(%rsp)
	movq	57392(%rsp), %rax
	movq	%rax, 150512(%rsp)
	movq	57400(%rsp), %rax
	movq	%rax, 150520(%rsp)
	movq	57408(%rsp), %rax
	movq	%rax, 150528(%rsp)
	movq	57416(%rsp), %rax
	movq	%rax, 150536(%rsp)
	movq	57424(%rsp), %rax
	movq	%rax, 150544(%rsp)
	movq	57432(%rsp), %rax
	movq	%rax, 150552(%rsp)
	movq	57440(%rsp), %rax
	movq	%rax, 150560(%rsp)
	movq	57448(%rsp), %rax
	movq	%rax, 150568(%rsp)
	movq	57456(%rsp), %rax
	movq	%rax, 150576(%rsp)
	movq	57464(%rsp), %rax
	movq	%rax, 150584(%rsp)
	movq	57472(%rsp), %rax
	movq	%rax, 150592(%rsp)
	movq	57480(%rsp), %rax
	movq	%rax, 150600(%rsp)
	movq	57488(%rsp), %rax
	movq	%rax, 150608(%rsp)
	movq	57496(%rsp), %rax
	movq	%rax, 150616(%rsp)
	movq	57504(%rsp), %rax
	movq	%rax, 150624(%rsp)
	movq	57512(%rsp), %rax
	movq	%rax, 150632(%rsp)
	movq	57520(%rsp), %rax
	movq	%rax, 150640(%rsp)
	movq	57528(%rsp), %rax
	movq	%rax, 150648(%rsp)
	movq	57536(%rsp), %rax
	movq	%rax, 150656(%rsp)
	movq	57544(%rsp), %rax
	movq	%rax, 150664(%rsp)
	movq	57552(%rsp), %rax
	movq	%rax, 150672(%rsp)
	movq	57560(%rsp), %rax
	movq	%rax, 150680(%rsp)
	movq	57568(%rsp), %rax
	movq	%rax, 150688(%rsp)
	movq	57576(%rsp), %rax
	movq	%rax, 150696(%rsp)
	movq	57584(%rsp), %rax
	movq	%rax, 150704(%rsp)
	movq	57592(%rsp), %rax
	movq	%rax, 150712(%rsp)
	movq	57600(%rsp), %rax
	movq	%rax, 150720(%rsp)
	movq	57608(%rsp), %rax
	movq	%rax, 150728(%rsp)
	movq	57616(%rsp), %rax
	movq	%rax, 150736(%rsp)
	movq	57624(%rsp), %rax
	movq	%rax, 150744(%rsp)
	movq	57632(%rsp), %rax
	movq	%rax, 150752(%rsp)
	movq	57640(%rsp), %rax
	movq	%rax, 150760(%rsp)
	movq	57648(%rsp), %rax
	movq	%rax, 150768(%rsp)
	movq	57656(%rsp), %rax
	movq	%rax, 150776(%rsp)
	movq	57664(%rsp), %rax
	movq	%rax, 150784(%rsp)
	movq	57672(%rsp), %rax
	movq	%rax, 150792(%rsp)
	movq	57680(%rsp), %rax
	movq	%rax, 150800(%rsp)
	movq	57688(%rsp), %rax
	movq	%rax, 150808(%rsp)
	movq	57696(%rsp), %rax
	movq	%rax, 150816(%rsp)
	movq	57704(%rsp), %rax
	movq	%rax, 150824(%rsp)
	movq	57712(%rsp), %rax
	movq	%rax, 150832(%rsp)
	movq	57720(%rsp), %rax
	movq	%rax, 150840(%rsp)
	movq	57728(%rsp), %rax
	movq	%rax, 150848(%rsp)
	movq	57736(%rsp), %rax
	movq	%rax, 150856(%rsp)
	movq	57744(%rsp), %rax
	movq	%rax, 150864(%rsp)
	movq	57752(%rsp), %rax
	movq	%rax, 150872(%rsp)
	movq	57760(%rsp), %rax
	movq	%rax, 150880(%rsp)
	movq	57768(%rsp), %rax
	movq	%rax, 150888(%rsp)
	movq	57776(%rsp), %rax
	movq	%rax, 150896(%rsp)
	movq	57784(%rsp), %rax
	movq	%rax, 150904(%rsp)
	movq	57792(%rsp), %rax
	movq	%rax, 150912(%rsp)
	movq	57800(%rsp), %rax
	movq	%rax, 150920(%rsp)
	movq	57808(%rsp), %rax
	movq	%rax, 150928(%rsp)
	movq	57816(%rsp), %rax
	movq	%rax, 150936(%rsp)
	movq	57824(%rsp), %rax
	movq	%rax, 150944(%rsp)
	movq	57832(%rsp), %rax
	movq	%rax, 150952(%rsp)
	movq	57840(%rsp), %rax
	movq	%rax, 150960(%rsp)
	movq	57848(%rsp), %rax
	movq	%rax, 150968(%rsp)
	movq	57856(%rsp), %rax
	movq	%rax, 150976(%rsp)
	movq	57864(%rsp), %rax
	movq	%rax, 150984(%rsp)
	movq	57872(%rsp), %rax
	movq	%rax, 150992(%rsp)
	movq	57880(%rsp), %rax
	movq	%rax, 151000(%rsp)
	movq	57888(%rsp), %rax
	movq	%rax, 151008(%rsp)
	movq	57896(%rsp), %rax
	movq	%rax, 151016(%rsp)
	movq	57904(%rsp), %rax
	movq	%rax, 151024(%rsp)
	movq	57912(%rsp), %rax
	movq	%rax, 151032(%rsp)
	movq	57920(%rsp), %rax
	movq	%rax, 151040(%rsp)
	movq	57928(%rsp), %rax
	movq	%rax, 151048(%rsp)
	movq	57936(%rsp), %rax
	movq	%rax, 151056(%rsp)
	movq	57944(%rsp), %rax
	movq	%rax, 151064(%rsp)
	movq	57952(%rsp), %rax
	movq	%rax, 151072(%rsp)
	movq	57960(%rsp), %rax
	movq	%rax, 151080(%rsp)
	movq	57968(%rsp), %rax
	movq	%rax, 151088(%rsp)
	movq	57976(%rsp), %rax
	movq	%rax, 151096(%rsp)
	movq	57984(%rsp), %rax
	movq	%rax, 151104(%rsp)
	movq	57992(%rsp), %rax
	movq	%rax, 151112(%rsp)
	movq	58000(%rsp), %rax
	movq	%rax, 151120(%rsp)
	movq	58008(%rsp), %rax
	movq	%rax, 151128(%rsp)
	movq	58016(%rsp), %rax
	movq	%rax, 151136(%rsp)
	movq	58024(%rsp), %rax
	movq	%rax, 151144(%rsp)
	movq	58032(%rsp), %rax
	movq	%rax, 151152(%rsp)
	movq	58040(%rsp), %rax
	movq	%rax, 151160(%rsp)
	movq	58048(%rsp), %rax
	movq	%rax, 151168(%rsp)
	movq	58056(%rsp), %rax
	movq	%rax, 151176(%rsp)
	movq	58064(%rsp), %rax
	movq	%rax, 151184(%rsp)
	movq	58072(%rsp), %rax
	movq	%rax, 151192(%rsp)
	movq	58080(%rsp), %rax
	movq	%rax, 151200(%rsp)
	movq	58088(%rsp), %rax
	movq	%rax, 151208(%rsp)
	movq	58096(%rsp), %rax
	movq	%rax, 151216(%rsp)
	movq	58104(%rsp), %rax
	movq	%rax, 151224(%rsp)
	movq	58112(%rsp), %rax
	movq	%rax, 151232(%rsp)
	movq	58120(%rsp), %rax
	movq	%rax, 151240(%rsp)
	movq	58128(%rsp), %rax
	movq	%rax, 151248(%rsp)
	movq	58136(%rsp), %rax
	movq	%rax, 151256(%rsp)
	movq	58144(%rsp), %rax
	movq	%rax, 151264(%rsp)
	movq	58152(%rsp), %rax
	movq	%rax, 151272(%rsp)
	movq	58160(%rsp), %rax
	movq	%rax, 151280(%rsp)
	movq	58168(%rsp), %rax
	movq	%rax, 151288(%rsp)
	movq	58176(%rsp), %rax
	movq	%rax, 151296(%rsp)
	movq	58184(%rsp), %rax
	movq	%rax, 151304(%rsp)
	movq	58192(%rsp), %rax
	movq	%rax, 151312(%rsp)
	movq	58200(%rsp), %rax
	movq	%rax, 151320(%rsp)
	movq	58208(%rsp), %rax
	movq	%rax, 151328(%rsp)
	movq	58216(%rsp), %rax
	movq	%rax, 151336(%rsp)
	movq	58224(%rsp), %rax
	movq	%rax, 151344(%rsp)
	movq	58232(%rsp), %rax
	movq	%rax, 151352(%rsp)
	movq	58240(%rsp), %rax
	movq	%rax, 151360(%rsp)
	movq	58248(%rsp), %rax
	movq	%rax, 151368(%rsp)
	movq	58256(%rsp), %rax
	movq	%rax, 151376(%rsp)
	movq	58264(%rsp), %rax
	movq	%rax, 151384(%rsp)
	movq	58272(%rsp), %rax
	movq	%rax, 151392(%rsp)
	movq	58280(%rsp), %rax
	movq	%rax, 151400(%rsp)
	movq	58288(%rsp), %rax
	movq	%rax, 151408(%rsp)
	movq	58296(%rsp), %rax
	movq	%rax, 151416(%rsp)
	movq	58304(%rsp), %rax
	movq	%rax, 151424(%rsp)
	movq	58312(%rsp), %rax
	movq	%rax, 151432(%rsp)
	movq	58320(%rsp), %rax
	movq	%rax, 151440(%rsp)
	movq	58328(%rsp), %rax
	movq	%rax, 151448(%rsp)
	movq	58336(%rsp), %rax
	movq	%rax, 151456(%rsp)
	movq	58344(%rsp), %rax
	movq	%rax, 151464(%rsp)
	movq	58352(%rsp), %rax
	movq	%rax, 151472(%rsp)
	movq	58360(%rsp), %rax
	movq	%rax, 151480(%rsp)
	movq	58368(%rsp), %rax
	movq	%rax, 151488(%rsp)
	movq	58376(%rsp), %rax
	movq	%rax, 151496(%rsp)
	movq	58384(%rsp), %rax
	movq	%rax, 151504(%rsp)
	movq	58392(%rsp), %rax
	movq	%rax, 151512(%rsp)
	movq	58400(%rsp), %rax
	movq	%rax, 151520(%rsp)
	movq	58408(%rsp), %rax
	movq	%rax, 151528(%rsp)
	movq	58416(%rsp), %rax
	movq	%rax, 151536(%rsp)
	movq	58424(%rsp), %rax
	movq	%rax, 151544(%rsp)
	movq	58432(%rsp), %rax
	movq	%rax, 151552(%rsp)
	movq	58440(%rsp), %rax
	movq	%rax, 151560(%rsp)
	movq	58448(%rsp), %rax
	movq	%rax, 151568(%rsp)
	movq	58456(%rsp), %rax
	movq	%rax, 151576(%rsp)
	movq	58464(%rsp), %rax
	movq	%rax, 151584(%rsp)
	movq	58472(%rsp), %rax
	movq	%rax, 151592(%rsp)
	movq	58480(%rsp), %rax
	movq	%rax, 151600(%rsp)
	movq	58488(%rsp), %rax
	movq	%rax, 151608(%rsp)
	movq	58496(%rsp), %rax
	movq	%rax, 151616(%rsp)
	movq	58504(%rsp), %rax
	movq	%rax, 151624(%rsp)
	movq	58512(%rsp), %rax
	movq	%rax, 151632(%rsp)
	movq	58520(%rsp), %rax
	movq	%rax, 151640(%rsp)
	movq	58528(%rsp), %rax
	movq	%rax, 151648(%rsp)
	movq	58536(%rsp), %rax
	movq	%rax, 151656(%rsp)
	movq	58544(%rsp), %rax
	movq	%rax, 151664(%rsp)
	movq	58552(%rsp), %rax
	movq	%rax, 151672(%rsp)
	movq	58560(%rsp), %rax
	movq	%rax, 151680(%rsp)
	movq	58568(%rsp), %rax
	movq	%rax, 151688(%rsp)
	movq	58576(%rsp), %rax
	movq	%rax, 151696(%rsp)
	movq	58584(%rsp), %rax
	movq	%rax, 151704(%rsp)
	movq	58592(%rsp), %rax
	movq	%rax, 151712(%rsp)
	movq	58600(%rsp), %rax
	movq	%rax, 151720(%rsp)
	movq	58608(%rsp), %rax
	movq	%rax, 151728(%rsp)
	movq	58616(%rsp), %rax
	movq	%rax, 151736(%rsp)
	movq	58624(%rsp), %rax
	movq	%rax, 151744(%rsp)
	movq	58632(%rsp), %rax
	movq	%rax, 151752(%rsp)
	movq	58640(%rsp), %rax
	movq	%rax, 151760(%rsp)
	movq	58648(%rsp), %rax
	movq	%rax, 151768(%rsp)
	movq	58656(%rsp), %rax
	movq	%rax, 151776(%rsp)
	movq	58664(%rsp), %rax
	movq	%rax, 151784(%rsp)
	movq	58672(%rsp), %rax
	movq	%rax, 151792(%rsp)
	movq	58680(%rsp), %rax
	movq	%rax, 151800(%rsp)
	movq	58688(%rsp), %rax
	movq	%rax, 151808(%rsp)
	movq	58696(%rsp), %rax
	movq	%rax, 151816(%rsp)
	movq	58704(%rsp), %rax
	movq	%rax, 151824(%rsp)
	movq	58712(%rsp), %rax
	movq	%rax, 151832(%rsp)
	movq	58720(%rsp), %rax
	movq	%rax, 151840(%rsp)
	movq	58728(%rsp), %rax
	movq	%rax, 151848(%rsp)
	movq	58736(%rsp), %rax
	movq	%rax, 151856(%rsp)
	movq	58744(%rsp), %rax
	movq	%rax, 151864(%rsp)
	movq	58752(%rsp), %rax
	movq	%rax, 151872(%rsp)
	movq	58760(%rsp), %rax
	movq	%rax, 151880(%rsp)
	movq	58768(%rsp), %rax
	movq	%rax, 151888(%rsp)
	movq	58776(%rsp), %rax
	movq	%rax, 151896(%rsp)
	movq	58784(%rsp), %rax
	movq	%rax, 151904(%rsp)
	movq	58792(%rsp), %rax
	movq	%rax, 151912(%rsp)
	movq	58800(%rsp), %rax
	movq	%rax, 151920(%rsp)
	movq	58808(%rsp), %rax
	movq	%rax, 151928(%rsp)
	movq	58816(%rsp), %rax
	movq	%rax, 151936(%rsp)
	movq	58824(%rsp), %rax
	movq	%rax, 151944(%rsp)
	movq	58832(%rsp), %rax
	movq	%rax, 151952(%rsp)
	movq	58840(%rsp), %rax
	movq	%rax, 151960(%rsp)
	movq	58848(%rsp), %rax
	movq	%rax, 151968(%rsp)
	movq	58856(%rsp), %rax
	movq	%rax, 151976(%rsp)
	movq	58864(%rsp), %rax
	movq	%rax, 151984(%rsp)
	movq	58872(%rsp), %rax
	movq	%rax, 151992(%rsp)
	movq	58880(%rsp), %rax
	movq	%rax, 152000(%rsp)
	movq	58888(%rsp), %rax
	movq	%rax, 152008(%rsp)
	movq	58896(%rsp), %rax
	movq	%rax, 152016(%rsp)
	movq	58904(%rsp), %rax
	movq	%rax, 152024(%rsp)
	movq	58912(%rsp), %rax
	movq	%rax, 152032(%rsp)
	movq	58920(%rsp), %rax
	movq	%rax, 152040(%rsp)
	movq	58928(%rsp), %rax
	movq	%rax, 152048(%rsp)
	movq	58936(%rsp), %rax
	movq	%rax, 152056(%rsp)
	movq	58944(%rsp), %rax
	movq	%rax, 152064(%rsp)
	movq	58952(%rsp), %rax
	movq	%rax, 152072(%rsp)
	movq	58960(%rsp), %rax
	movq	%rax, 152080(%rsp)
	movq	58968(%rsp), %rax
	movq	%rax, 152088(%rsp)
	movq	58976(%rsp), %rax
	movq	%rax, 152096(%rsp)
	movq	58984(%rsp), %rax
	movq	%rax, 152104(%rsp)
	movq	58992(%rsp), %rax
	movq	%rax, 152112(%rsp)
	movq	59000(%rsp), %rax
	movq	%rax, 152120(%rsp)
	movq	59008(%rsp), %rax
	movq	%rax, 152128(%rsp)
	movq	59016(%rsp), %rax
	movq	%rax, 152136(%rsp)
	movq	59024(%rsp), %rax
	movq	%rax, 152144(%rsp)
	movq	59032(%rsp), %rax
	movq	%rax, 152152(%rsp)
	movq	59040(%rsp), %rax
	movq	%rax, 152160(%rsp)
	movq	59048(%rsp), %rax
	movq	%rax, 152168(%rsp)
	movq	59056(%rsp), %rax
	movq	%rax, 152176(%rsp)
	movq	59064(%rsp), %rax
	movq	%rax, 152184(%rsp)
	movq	59072(%rsp), %rax
	movq	%rax, 152192(%rsp)
	movq	59080(%rsp), %rax
	movq	%rax, 152200(%rsp)
	movq	59088(%rsp), %rax
	movq	%rax, 152208(%rsp)
	movq	59096(%rsp), %rax
	movq	%rax, 152216(%rsp)
	movq	59104(%rsp), %rax
	movq	%rax, 152224(%rsp)
	movq	59112(%rsp), %rax
	movq	%rax, 152232(%rsp)
	movq	59120(%rsp), %rax
	movq	%rax, 152240(%rsp)
	movq	59128(%rsp), %rax
	movq	%rax, 152248(%rsp)
	movq	59136(%rsp), %rax
	movq	%rax, 152256(%rsp)
	movq	59144(%rsp), %rax
	movq	%rax, 152264(%rsp)
	movq	59152(%rsp), %rax
	movq	%rax, 152272(%rsp)
	movq	59160(%rsp), %rax
	movq	%rax, 152280(%rsp)
	movq	59168(%rsp), %rax
	movq	%rax, 152288(%rsp)
	movq	59176(%rsp), %rax
	movq	%rax, 152296(%rsp)
	movq	59184(%rsp), %rax
	movq	%rax, 152304(%rsp)
	movq	59192(%rsp), %rax
	movq	%rax, 152312(%rsp)
	movq	59200(%rsp), %rax
	movq	%rax, 152320(%rsp)
	movq	59208(%rsp), %rax
	movq	%rax, 152328(%rsp)
	movq	59216(%rsp), %rax
	movq	%rax, 152336(%rsp)
	movq	59224(%rsp), %rax
	movq	%rax, 152344(%rsp)
	movq	59232(%rsp), %rax
	movq	%rax, 152352(%rsp)
	movq	59240(%rsp), %rax
	movq	%rax, 152360(%rsp)
	movq	59248(%rsp), %rax
	movq	%rax, 152368(%rsp)
	movq	59256(%rsp), %rax
	movq	%rax, 152376(%rsp)
	movq	59264(%rsp), %rax
	movq	%rax, 152384(%rsp)
	movq	59272(%rsp), %rax
	movq	%rax, 152392(%rsp)
	movq	59280(%rsp), %rax
	movq	%rax, 152400(%rsp)
	movq	59288(%rsp), %rax
	movq	%rax, 152408(%rsp)
	movq	59296(%rsp), %rax
	movq	%rax, 152416(%rsp)
	movq	59304(%rsp), %rax
	movq	%rax, 152424(%rsp)
	movq	59312(%rsp), %rax
	movq	%rax, 152432(%rsp)
	movq	59320(%rsp), %rax
	movq	%rax, 152440(%rsp)
	movq	59328(%rsp), %rax
	movq	%rax, 152448(%rsp)
	movq	59336(%rsp), %rax
	movq	%rax, 152456(%rsp)
	movq	59344(%rsp), %rax
	movq	%rax, 152464(%rsp)
	movq	59352(%rsp), %rax
	movq	%rax, 152472(%rsp)
	movq	59360(%rsp), %rax
	movq	%rax, 152480(%rsp)
	movq	59368(%rsp), %rax
	movq	%rax, 152488(%rsp)
	movq	59376(%rsp), %rax
	movq	%rax, 152496(%rsp)
	movq	59384(%rsp), %rax
	movq	%rax, 152504(%rsp)
	movq	59392(%rsp), %rax
	movq	%rax, 152512(%rsp)
	movq	59400(%rsp), %rax
	movq	%rax, 152520(%rsp)
	movq	59408(%rsp), %rax
	movq	%rax, 152528(%rsp)
	movq	59416(%rsp), %rax
	movq	%rax, 152536(%rsp)
	movq	59424(%rsp), %rax
	movq	%rax, 152544(%rsp)
	movq	59432(%rsp), %rax
	movq	%rax, 152552(%rsp)
	movq	59440(%rsp), %rax
	movq	%rax, 152560(%rsp)
	movq	59448(%rsp), %rax
	movq	%rax, 152568(%rsp)
	movq	59456(%rsp), %rax
	movq	%rax, 152576(%rsp)
	movq	59464(%rsp), %rax
	movq	%rax, 152584(%rsp)
	movq	59472(%rsp), %rax
	movq	%rax, 152592(%rsp)
	movq	59480(%rsp), %rax
	movq	%rax, 152600(%rsp)
	movq	59488(%rsp), %rax
	movq	%rax, 152608(%rsp)
	movq	59496(%rsp), %rax
	movq	%rax, 152616(%rsp)
	movq	59504(%rsp), %rax
	movq	%rax, 152624(%rsp)
	movq	59512(%rsp), %rax
	movq	%rax, 152632(%rsp)
	movq	59520(%rsp), %rax
	movq	%rax, 152640(%rsp)
	movq	59528(%rsp), %rax
	movq	%rax, 152648(%rsp)
	movq	59536(%rsp), %rax
	movq	%rax, 152656(%rsp)
	movq	59544(%rsp), %rax
	movq	%rax, 152664(%rsp)
	movq	59552(%rsp), %rax
	movq	%rax, 152672(%rsp)
	movq	59560(%rsp), %rax
	movq	%rax, 152680(%rsp)
	movq	59568(%rsp), %rax
	movq	%rax, 152688(%rsp)
	movq	59576(%rsp), %rax
	movq	%rax, 152696(%rsp)
	movq	59584(%rsp), %rax
	movq	%rax, 152704(%rsp)
	movq	59592(%rsp), %rax
	movq	%rax, 152712(%rsp)
	movq	59600(%rsp), %rax
	movq	%rax, 152720(%rsp)
	movq	59608(%rsp), %rax
	movq	%rax, 152728(%rsp)
	movq	59616(%rsp), %rax
	movq	%rax, 152736(%rsp)
	movq	59624(%rsp), %rax
	movq	%rax, 152744(%rsp)
	movq	59632(%rsp), %rax
	movq	%rax, 152752(%rsp)
	movq	59640(%rsp), %rax
	movq	%rax, 152760(%rsp)
	movq	59648(%rsp), %rax
	movq	%rax, 152768(%rsp)
	movq	59656(%rsp), %rax
	movq	%rax, 152776(%rsp)
	movq	59664(%rsp), %rax
	movq	%rax, 152784(%rsp)
	movq	59672(%rsp), %rax
	movq	%rax, 152792(%rsp)
	movq	59680(%rsp), %rax
	movq	%rax, 152800(%rsp)
	movq	59688(%rsp), %rax
	movq	%rax, 152808(%rsp)
	movq	59696(%rsp), %rax
	movq	%rax, 152816(%rsp)
	movq	59704(%rsp), %rax
	movq	%rax, 152824(%rsp)
	movq	59712(%rsp), %rax
	movq	%rax, 152832(%rsp)
	movq	59720(%rsp), %rax
	movq	%rax, 152840(%rsp)
	movq	59728(%rsp), %rax
	movq	%rax, 152848(%rsp)
	movq	59736(%rsp), %rax
	movq	%rax, 152856(%rsp)
	movq	59744(%rsp), %rax
	movq	%rax, 152864(%rsp)
	movq	59752(%rsp), %rax
	movq	%rax, 152872(%rsp)
	movq	59760(%rsp), %rax
	movq	%rax, 152880(%rsp)
	movq	59768(%rsp), %rax
	movq	%rax, 152888(%rsp)
	movq	59776(%rsp), %rax
	movq	%rax, 152896(%rsp)
	movq	59784(%rsp), %rax
	movq	%rax, 152904(%rsp)
	movq	59792(%rsp), %rax
	movq	%rax, 152912(%rsp)
	movq	59800(%rsp), %rax
	movq	%rax, 152920(%rsp)
	movq	59808(%rsp), %rax
	movq	%rax, 152928(%rsp)
	movq	59816(%rsp), %rax
	movq	%rax, 152936(%rsp)
	movq	59824(%rsp), %rax
	movq	%rax, 152944(%rsp)
	movq	59832(%rsp), %rax
	movq	%rax, 152952(%rsp)
	movq	59840(%rsp), %rax
	movq	%rax, 152960(%rsp)
	movq	59848(%rsp), %rax
	movq	%rax, 152968(%rsp)
	movq	59856(%rsp), %rax
	movq	%rax, 152976(%rsp)
	movq	59864(%rsp), %rax
	movq	%rax, 152984(%rsp)
	movq	59872(%rsp), %rax
	movq	%rax, 152992(%rsp)
	movq	59880(%rsp), %rax
	movq	%rax, 153000(%rsp)
	movq	59888(%rsp), %rax
	movq	%rax, 153008(%rsp)
	movq	59896(%rsp), %rax
	movq	%rax, 153016(%rsp)
	movq	59904(%rsp), %rax
	movq	%rax, 153024(%rsp)
	movq	59912(%rsp), %rax
	movq	%rax, 153032(%rsp)
	movq	59920(%rsp), %rax
	movq	%rax, 153040(%rsp)
	movq	59928(%rsp), %rax
	movq	%rax, 153048(%rsp)
	movq	59936(%rsp), %rax
	movq	%rax, 153056(%rsp)
	movq	59944(%rsp), %rax
	movq	%rax, 153064(%rsp)
	movq	59952(%rsp), %rax
	movq	%rax, 153072(%rsp)
	movq	59960(%rsp), %rax
	movq	%rax, 153080(%rsp)
	movq	59968(%rsp), %rax
	movq	%rax, 153088(%rsp)
	movq	59976(%rsp), %rax
	movq	%rax, 153096(%rsp)
	movq	59984(%rsp), %rax
	movq	%rax, 153104(%rsp)
	movq	59992(%rsp), %rax
	movq	%rax, 153112(%rsp)
	movq	60000(%rsp), %rax
	movq	%rax, 153120(%rsp)
	movq	60008(%rsp), %rax
	movq	%rax, 153128(%rsp)
	movq	60016(%rsp), %rax
	movq	%rax, 153136(%rsp)
	movq	60024(%rsp), %rax
	movq	%rax, 153144(%rsp)
	movq	60032(%rsp), %rax
	movq	%rax, 153152(%rsp)
	movq	60040(%rsp), %rax
	movq	%rax, 153160(%rsp)
	movq	60048(%rsp), %rax
	movq	%rax, 153168(%rsp)
	movq	60056(%rsp), %rax
	movq	%rax, 153176(%rsp)
	movq	60064(%rsp), %rax
	movq	%rax, 153184(%rsp)
	movq	60072(%rsp), %rax
	movq	%rax, 153192(%rsp)
	movq	60080(%rsp), %rax
	movq	%rax, 153200(%rsp)
	movq	60088(%rsp), %rax
	movq	%rax, 153208(%rsp)
	movq	60096(%rsp), %rax
	movq	%rax, 153216(%rsp)
	movq	60104(%rsp), %rax
	movq	%rax, 153224(%rsp)
	movq	60112(%rsp), %rax
	movq	%rax, 153232(%rsp)
	movq	60120(%rsp), %rax
	movq	%rax, 153240(%rsp)
	movq	60128(%rsp), %rax
	movq	%rax, 153248(%rsp)
	movq	60136(%rsp), %rax
	movq	%rax, 153256(%rsp)
	movq	60144(%rsp), %rax
	movq	%rax, 153264(%rsp)
	movq	60152(%rsp), %rax
	movq	%rax, 153272(%rsp)
	movq	60160(%rsp), %rax
	movq	%rax, 153280(%rsp)
	movq	60168(%rsp), %rax
	movq	%rax, 153288(%rsp)
	movq	60176(%rsp), %rax
	movq	%rax, 153296(%rsp)
	movq	60184(%rsp), %rax
	movq	%rax, 153304(%rsp)
	movq	60192(%rsp), %rax
	movq	%rax, 153312(%rsp)
	movq	60200(%rsp), %rax
	movq	%rax, 153320(%rsp)
	movq	60208(%rsp), %rax
	movq	%rax, 153328(%rsp)
	movq	60216(%rsp), %rax
	movq	%rax, 153336(%rsp)
	movq	60224(%rsp), %rax
	movq	%rax, 153344(%rsp)
	movq	60232(%rsp), %rax
	movq	%rax, 153352(%rsp)
	movq	60240(%rsp), %rax
	movq	%rax, 153360(%rsp)
	movq	60248(%rsp), %rax
	movq	%rax, 153368(%rsp)
	movq	60256(%rsp), %rax
	movq	%rax, 153376(%rsp)
	movq	60264(%rsp), %rax
	movq	%rax, 153384(%rsp)
	movq	60272(%rsp), %rax
	movq	%rax, 153392(%rsp)
	movq	60280(%rsp), %rax
	movq	%rax, 153400(%rsp)
	movq	60288(%rsp), %rax
	movq	%rax, 153408(%rsp)
	movq	60296(%rsp), %rax
	movq	%rax, 153416(%rsp)
	movq	60304(%rsp), %rax
	movq	%rax, 153424(%rsp)
	movq	60312(%rsp), %rax
	movq	%rax, 153432(%rsp)
	movq	60320(%rsp), %rax
	movq	%rax, 153440(%rsp)
	movq	60328(%rsp), %rax
	movq	%rax, 153448(%rsp)
	movq	60336(%rsp), %rax
	movq	%rax, 153456(%rsp)
	movq	60344(%rsp), %rax
	movq	%rax, 153464(%rsp)
	movq	60352(%rsp), %rax
	movq	%rax, 153472(%rsp)
	movq	60360(%rsp), %rax
	movq	%rax, 153480(%rsp)
	movq	60368(%rsp), %rax
	movq	%rax, 153488(%rsp)
	movq	60376(%rsp), %rax
	movq	%rax, 153496(%rsp)
	movq	60384(%rsp), %rax
	movq	%rax, 153504(%rsp)
	movq	60392(%rsp), %rax
	movq	%rax, 153512(%rsp)
	movq	60400(%rsp), %rax
	movq	%rax, 153520(%rsp)
	movq	60408(%rsp), %rax
	movq	%rax, 153528(%rsp)
	movq	60416(%rsp), %rax
	movq	%rax, 153536(%rsp)
	movq	60424(%rsp), %rax
	movq	%rax, 153544(%rsp)
	movq	60432(%rsp), %rax
	movq	%rax, 153552(%rsp)
	movq	60440(%rsp), %rax
	movq	%rax, 153560(%rsp)
	movq	60448(%rsp), %rax
	movq	%rax, 153568(%rsp)
	movq	60456(%rsp), %rax
	movq	%rax, 153576(%rsp)
	movq	60464(%rsp), %rax
	movq	%rax, 153584(%rsp)
	movq	60472(%rsp), %rax
	movq	%rax, 153592(%rsp)
	movq	60480(%rsp), %rax
	movq	%rax, 153600(%rsp)
	movq	60488(%rsp), %rax
	movq	%rax, 153608(%rsp)
	movq	60496(%rsp), %rax
	movq	%rax, 153616(%rsp)
	movq	60504(%rsp), %rax
	movq	%rax, 153624(%rsp)
	movq	60512(%rsp), %rax
	movq	%rax, 153632(%rsp)
	movq	60520(%rsp), %rax
	movq	%rax, 153640(%rsp)
	movq	60528(%rsp), %rax
	movq	%rax, 153648(%rsp)
	movq	60536(%rsp), %rax
	movq	%rax, 153656(%rsp)
	movq	60544(%rsp), %rax
	movq	%rax, 153664(%rsp)
	movq	60552(%rsp), %rax
	movq	%rax, 153672(%rsp)
	movq	60560(%rsp), %rax
	movq	%rax, 153680(%rsp)
	movq	60568(%rsp), %rax
	movq	%rax, 153688(%rsp)
	movq	60576(%rsp), %rax
	movq	%rax, 153696(%rsp)
	movq	60584(%rsp), %rax
	movq	%rax, 153704(%rsp)
	movq	60592(%rsp), %rax
	movq	%rax, 153712(%rsp)
	movq	60600(%rsp), %rax
	movq	%rax, 153720(%rsp)
	movq	60608(%rsp), %rax
	movq	%rax, 153728(%rsp)
	movq	60616(%rsp), %rax
	movq	%rax, 153736(%rsp)
	movq	60624(%rsp), %rax
	movq	%rax, 153744(%rsp)
	movq	60632(%rsp), %rax
	movq	%rax, 153752(%rsp)
	movq	60640(%rsp), %rax
	movq	%rax, 153760(%rsp)
	movq	60648(%rsp), %rax
	movq	%rax, 153768(%rsp)
	movq	60656(%rsp), %rax
	movq	%rax, 153776(%rsp)
	movq	60664(%rsp), %rax
	movq	%rax, 153784(%rsp)
	movq	60672(%rsp), %rax
	movq	%rax, 153792(%rsp)
	movq	60680(%rsp), %rax
	movq	%rax, 153800(%rsp)
	movq	60688(%rsp), %rax
	movq	%rax, 153808(%rsp)
	movq	60696(%rsp), %rax
	movq	%rax, 153816(%rsp)
	movq	60704(%rsp), %rax
	movq	%rax, 153824(%rsp)
	movq	60712(%rsp), %rax
	movq	%rax, 153832(%rsp)
	movq	60720(%rsp), %rax
	movq	%rax, 153840(%rsp)
	movq	60728(%rsp), %rax
	movq	%rax, 153848(%rsp)
	movq	60736(%rsp), %rax
	movq	%rax, 153856(%rsp)
	movq	60744(%rsp), %rax
	movq	%rax, 153864(%rsp)
	movq	60752(%rsp), %rax
	movq	%rax, 153872(%rsp)
	movq	60760(%rsp), %rax
	movq	%rax, 153880(%rsp)
	movq	60768(%rsp), %rax
	movq	%rax, 153888(%rsp)
	movq	60776(%rsp), %rax
	movq	%rax, 153896(%rsp)
	movq	60784(%rsp), %rax
	movq	%rax, 153904(%rsp)
	movq	60792(%rsp), %rax
	movq	%rax, 153912(%rsp)
	movq	60800(%rsp), %rax
	movq	%rax, 153920(%rsp)
	movq	60808(%rsp), %rax
	movq	%rax, 153928(%rsp)
	movq	60816(%rsp), %rax
	movq	%rax, 153936(%rsp)
	movq	60824(%rsp), %rax
	movq	%rax, 153944(%rsp)
	movq	60832(%rsp), %rax
	movq	%rax, 153952(%rsp)
	movq	60840(%rsp), %rax
	movq	%rax, 153960(%rsp)
	movq	60848(%rsp), %rax
	movq	%rax, 153968(%rsp)
	movq	60856(%rsp), %rax
	movq	%rax, 153976(%rsp)
	movq	60864(%rsp), %rax
	movq	%rax, 153984(%rsp)
	movq	60872(%rsp), %rax
	movq	%rax, 153992(%rsp)
	movq	60880(%rsp), %rax
	movq	%rax, 154000(%rsp)
	movq	60888(%rsp), %rax
	movq	%rax, 154008(%rsp)
	movq	60896(%rsp), %rax
	movq	%rax, 154016(%rsp)
	movq	60904(%rsp), %rax
	movq	%rax, 154024(%rsp)
	movq	60912(%rsp), %rax
	movq	%rax, 154032(%rsp)
	movq	60920(%rsp), %rax
	movq	%rax, 154040(%rsp)
	movq	60928(%rsp), %rax
	movq	%rax, 154048(%rsp)
	movq	60936(%rsp), %rax
	movq	%rax, 154056(%rsp)
	movq	60944(%rsp), %rax
	movq	%rax, 154064(%rsp)
	movq	60952(%rsp), %rax
	movq	%rax, 154072(%rsp)
	movq	60960(%rsp), %rax
	movq	%rax, 154080(%rsp)
	movq	60968(%rsp), %rax
	movq	%rax, 154088(%rsp)
	movq	60976(%rsp), %rax
	movq	%rax, 154096(%rsp)
	movq	60984(%rsp), %rax
	movq	%rax, 154104(%rsp)
	movq	60992(%rsp), %rax
	movq	%rax, 154112(%rsp)
	movq	61000(%rsp), %rax
	movq	%rax, 154120(%rsp)
	movq	61008(%rsp), %rax
	movq	%rax, 154128(%rsp)
	movq	61016(%rsp), %rax
	movq	%rax, 154136(%rsp)
	movq	61024(%rsp), %rax
	movq	%rax, 154144(%rsp)
	movq	61032(%rsp), %rax
	movq	%rax, 154152(%rsp)
	movq	61040(%rsp), %rax
	movq	%rax, 154160(%rsp)
	movq	61048(%rsp), %rax
	movq	%rax, 154168(%rsp)
	movq	61056(%rsp), %rax
	movq	%rax, 154176(%rsp)
	movq	61064(%rsp), %rax
	movq	%rax, 154184(%rsp)
	movq	61072(%rsp), %rax
	movq	%rax, 154192(%rsp)
	movq	61080(%rsp), %rax
	movq	%rax, 154200(%rsp)
	movq	61088(%rsp), %rax
	movq	%rax, 154208(%rsp)
	movq	61096(%rsp), %rax
	movq	%rax, 154216(%rsp)
	movq	61104(%rsp), %rax
	movq	%rax, 154224(%rsp)
	movq	61112(%rsp), %rax
	movq	%rax, 154232(%rsp)
	movq	61120(%rsp), %rax
	movq	%rax, 154240(%rsp)
	movq	61128(%rsp), %rax
	movq	%rax, 154248(%rsp)
	movq	61136(%rsp), %rax
	movq	%rax, 154256(%rsp)
	movq	61144(%rsp), %rax
	movq	%rax, 154264(%rsp)
	movq	61152(%rsp), %rax
	movq	%rax, 154272(%rsp)
	movq	61160(%rsp), %rax
	movq	%rax, 154280(%rsp)
	movq	61168(%rsp), %rax
	movq	%rax, 154288(%rsp)
	movq	61176(%rsp), %rax
	movq	%rax, 154296(%rsp)
	movq	61184(%rsp), %rax
	movq	%rax, 154304(%rsp)
	movq	61192(%rsp), %rax
	movq	%rax, 154312(%rsp)
	movq	61200(%rsp), %rax
	movq	%rax, 154320(%rsp)
	movq	61208(%rsp), %rax
	movq	%rax, 154328(%rsp)
	movq	61216(%rsp), %rax
	movq	%rax, 154336(%rsp)
	movq	61224(%rsp), %rax
	movq	%rax, 154344(%rsp)
	movq	61232(%rsp), %rax
	movq	%rax, 154352(%rsp)
	movq	61240(%rsp), %rax
	movq	%rax, 154360(%rsp)
	movq	61248(%rsp), %rax
	movq	%rax, 154368(%rsp)
	movq	61256(%rsp), %rax
	movq	%rax, 154376(%rsp)
	movq	61264(%rsp), %rax
	movq	%rax, 154384(%rsp)
	movq	61272(%rsp), %rax
	movq	%rax, 154392(%rsp)
	movq	61280(%rsp), %rax
	movq	%rax, 154400(%rsp)
	movq	61288(%rsp), %rax
	movq	%rax, 154408(%rsp)
	movq	61296(%rsp), %rax
	movq	%rax, 154416(%rsp)
	movq	61304(%rsp), %rax
	movq	%rax, 154424(%rsp)
	movq	61312(%rsp), %rax
	movq	%rax, 154432(%rsp)
	movq	61320(%rsp), %rax
	movq	%rax, 154440(%rsp)
	movq	61328(%rsp), %rax
	movq	%rax, 154448(%rsp)
	movq	61336(%rsp), %rax
	movq	%rax, 154456(%rsp)
	movq	61344(%rsp), %rax
	movq	%rax, 154464(%rsp)
	movq	61352(%rsp), %rax
	movq	%rax, 154472(%rsp)
	movq	61360(%rsp), %rax
	movq	%rax, 154480(%rsp)
	movq	61368(%rsp), %rax
	movq	%rax, 154488(%rsp)
	movq	61376(%rsp), %rax
	movq	%rax, 154496(%rsp)
	movq	61384(%rsp), %rax
	movq	%rax, 154504(%rsp)
	movq	61392(%rsp), %rax
	movq	%rax, 154512(%rsp)
	movq	61400(%rsp), %rax
	movq	%rax, 154520(%rsp)
	movq	61408(%rsp), %rax
	movq	%rax, 154528(%rsp)
	movq	61416(%rsp), %rax
	movq	%rax, 154536(%rsp)
	movq	61424(%rsp), %rax
	movq	%rax, 154544(%rsp)
	movq	61432(%rsp), %rax
	movq	%rax, 154552(%rsp)
	movq	61440(%rsp), %rax
	movq	%rax, 154560(%rsp)
	movq	61448(%rsp), %rax
	movq	%rax, 154568(%rsp)
	movq	61456(%rsp), %rax
	movq	%rax, 154576(%rsp)
	movq	61464(%rsp), %rax
	movq	%rax, 154584(%rsp)
	movq	61472(%rsp), %rax
	movq	%rax, 154592(%rsp)
	movq	61480(%rsp), %rax
	movq	%rax, 154600(%rsp)
	movq	61488(%rsp), %rax
	movq	%rax, 154608(%rsp)
	movq	61496(%rsp), %rax
	movq	%rax, 154616(%rsp)
	movq	61504(%rsp), %rax
	movq	%rax, 154624(%rsp)
	movq	61512(%rsp), %rax
	movq	%rax, 154632(%rsp)
	movq	61520(%rsp), %rax
	movq	%rax, 154640(%rsp)
	movq	61528(%rsp), %rax
	movq	%rax, 154648(%rsp)
	movq	61536(%rsp), %rax
	movq	%rax, 154656(%rsp)
	movq	61544(%rsp), %rax
	movq	%rax, 154664(%rsp)
	movq	61552(%rsp), %rax
	movq	%rax, 154672(%rsp)
	movq	61560(%rsp), %rax
	movq	%rax, 154680(%rsp)
	movq	61568(%rsp), %rax
	movq	%rax, 154688(%rsp)
	movq	61576(%rsp), %rax
	movq	%rax, 154696(%rsp)
	movq	61584(%rsp), %rax
	movq	%rax, 154704(%rsp)
	movq	61592(%rsp), %rax
	movq	%rax, 154712(%rsp)
	movq	61600(%rsp), %rax
	movq	%rax, 154720(%rsp)
	movq	61608(%rsp), %rax
	movq	%rax, 154728(%rsp)
	movq	61616(%rsp), %rax
	movq	%rax, 154736(%rsp)
	movq	61624(%rsp), %rax
	movq	%rax, 154744(%rsp)
	movq	61632(%rsp), %rax
	movq	%rax, 154752(%rsp)
	movq	61640(%rsp), %rax
	movq	%rax, 154760(%rsp)
	movq	61648(%rsp), %rax
	movq	%rax, 154768(%rsp)
	movq	61656(%rsp), %rax
	movq	%rax, 154776(%rsp)
	movq	61664(%rsp), %rax
	movq	%rax, 154784(%rsp)
	movq	61672(%rsp), %rax
	movq	%rax, 154792(%rsp)
	movq	61680(%rsp), %rax
	movq	%rax, 154800(%rsp)
	movq	61688(%rsp), %rax
	movq	%rax, 154808(%rsp)
	movq	61696(%rsp), %rax
	movq	%rax, 154816(%rsp)
	movq	61704(%rsp), %rax
	movq	%rax, 154824(%rsp)
	movq	61712(%rsp), %rax
	movq	%rax, 154832(%rsp)
	movq	61720(%rsp), %rax
	movq	%rax, 154840(%rsp)
	movq	61728(%rsp), %rax
	movq	%rax, 154848(%rsp)
	movq	61736(%rsp), %rax
	movq	%rax, 154856(%rsp)
	movq	61744(%rsp), %rax
	movq	%rax, 154864(%rsp)
	movq	61752(%rsp), %rax
	movq	%rax, 154872(%rsp)
	movq	61760(%rsp), %rax
	movq	%rax, 154880(%rsp)
	movq	61768(%rsp), %rax
	movq	%rax, 154888(%rsp)
	movq	61776(%rsp), %rax
	movq	%rax, 154896(%rsp)
	movq	61784(%rsp), %rax
	movq	%rax, 154904(%rsp)
	movq	61792(%rsp), %rax
	movq	%rax, 154912(%rsp)
	movq	61800(%rsp), %rax
	movq	%rax, 154920(%rsp)
	movq	61808(%rsp), %rax
	movq	%rax, 154928(%rsp)
	movq	61816(%rsp), %rax
	movq	%rax, 154936(%rsp)
	movq	61824(%rsp), %rax
	movq	%rax, 154944(%rsp)
	movq	61832(%rsp), %rax
	movq	%rax, 154952(%rsp)
	movq	61840(%rsp), %rax
	movq	%rax, 154960(%rsp)
	movq	61848(%rsp), %rax
	movq	%rax, 154968(%rsp)
	movq	61856(%rsp), %rax
	movq	%rax, 154976(%rsp)
	movq	61864(%rsp), %rax
	movq	%rax, 154984(%rsp)
	movq	61872(%rsp), %rax
	movq	%rax, 154992(%rsp)
	movq	61880(%rsp), %rax
	movq	%rax, 155000(%rsp)
	movq	61888(%rsp), %rax
	movq	%rax, 155008(%rsp)
	movq	61896(%rsp), %rax
	movq	%rax, 155016(%rsp)
	movq	61904(%rsp), %rax
	movq	%rax, 155024(%rsp)
	movq	61912(%rsp), %rax
	movq	%rax, 155032(%rsp)
	movq	61920(%rsp), %rax
	movq	%rax, 155040(%rsp)
	movq	61928(%rsp), %rax
	movq	%rax, 155048(%rsp)
	movq	61936(%rsp), %rax
	movq	%rax, 155056(%rsp)
	movq	61944(%rsp), %rax
	movq	%rax, 155064(%rsp)
	movq	61952(%rsp), %rax
	movq	%rax, 155072(%rsp)
	movq	61960(%rsp), %rax
	movq	%rax, 155080(%rsp)
	movq	61968(%rsp), %rax
	movq	%rax, 155088(%rsp)
	movq	61976(%rsp), %rax
	movq	%rax, 155096(%rsp)
	movq	61984(%rsp), %rax
	movq	%rax, 155104(%rsp)
	movq	61992(%rsp), %rax
	movq	%rax, 155112(%rsp)
	movq	62000(%rsp), %rax
	movq	%rax, 155120(%rsp)
	movq	62008(%rsp), %rax
	movq	%rax, 155128(%rsp)
	movq	62016(%rsp), %rax
	movq	%rax, 155136(%rsp)
	movq	62024(%rsp), %rax
	movq	%rax, 155144(%rsp)
	movq	62032(%rsp), %rax
	movq	%rax, 155152(%rsp)
	movq	62040(%rsp), %rax
	movq	%rax, 155160(%rsp)
	movq	62048(%rsp), %rax
	movq	%rax, 155168(%rsp)
	movq	62056(%rsp), %rax
	movq	%rax, 155176(%rsp)
	movq	62064(%rsp), %rax
	movq	%rax, 155184(%rsp)
	movq	62072(%rsp), %rax
	movq	%rax, 155192(%rsp)
	movq	62080(%rsp), %rax
	movq	%rax, 155200(%rsp)
	movq	62088(%rsp), %rax
	movq	%rax, 155208(%rsp)
	movq	62096(%rsp), %rax
	movq	%rax, 155216(%rsp)
	movq	62104(%rsp), %rax
	movq	%rax, 155224(%rsp)
	movq	62112(%rsp), %rax
	movq	%rax, 155232(%rsp)
	movq	62120(%rsp), %rax
	movq	%rax, 155240(%rsp)
	movq	62128(%rsp), %rax
	movq	%rax, 155248(%rsp)
	movq	62136(%rsp), %rax
	movq	%rax, 155256(%rsp)
	movq	62144(%rsp), %rax
	movq	%rax, 155264(%rsp)
	movq	62152(%rsp), %rax
	movq	%rax, 155272(%rsp)
	movq	62160(%rsp), %rax
	movq	%rax, 155280(%rsp)
	movq	62168(%rsp), %rax
	movq	%rax, 155288(%rsp)
	movq	62176(%rsp), %rax
	movq	%rax, 155296(%rsp)
	movq	62184(%rsp), %rax
	movq	%rax, 155304(%rsp)
	movq	62192(%rsp), %rax
	movq	%rax, 155312(%rsp)
	movq	62200(%rsp), %rax
	movq	%rax, 155320(%rsp)
	movq	62208(%rsp), %rax
	movq	%rax, 155328(%rsp)
	movq	62216(%rsp), %rax
	movq	%rax, 155336(%rsp)
	movq	62224(%rsp), %rax
	movq	%rax, 155344(%rsp)
	movq	62232(%rsp), %rax
	movq	%rax, 155352(%rsp)
	movq	62240(%rsp), %rax
	movq	%rax, 155360(%rsp)
	movq	62248(%rsp), %rax
	movq	%rax, 155368(%rsp)
	movq	62256(%rsp), %rax
	movq	%rax, 155376(%rsp)
	movq	62264(%rsp), %rax
	movq	%rax, 155384(%rsp)
	movq	62272(%rsp), %rax
	movq	%rax, 155392(%rsp)
	movq	62280(%rsp), %rax
	movq	%rax, 155400(%rsp)
	movq	62288(%rsp), %rax
	movq	%rax, 155408(%rsp)
	movq	62296(%rsp), %rax
	movq	%rax, 155416(%rsp)
	movq	62304(%rsp), %rax
	movq	%rax, 155424(%rsp)
	movq	62312(%rsp), %rax
	movq	%rax, 155432(%rsp)
	movq	62320(%rsp), %rax
	movq	%rax, 155440(%rsp)
	movq	62328(%rsp), %rax
	movq	%rax, 155448(%rsp)
	movq	62336(%rsp), %rax
	movq	%rax, 155456(%rsp)
	movq	62344(%rsp), %rax
	movq	%rax, 155464(%rsp)
	movq	62352(%rsp), %rax
	movq	%rax, 155472(%rsp)
	movq	62360(%rsp), %rax
	movq	%rax, 155480(%rsp)
	movq	62368(%rsp), %rax
	movq	%rax, 155488(%rsp)
	movq	62376(%rsp), %rax
	movq	%rax, 155496(%rsp)
	movq	62384(%rsp), %rax
	movq	%rax, 155504(%rsp)
	movq	62392(%rsp), %rax
	movq	%rax, 155512(%rsp)
	movq	62400(%rsp), %rax
	movq	%rax, 155520(%rsp)
	movq	62408(%rsp), %rax
	movq	%rax, 155528(%rsp)
	movq	62416(%rsp), %rax
	movq	%rax, 155536(%rsp)
	movq	62424(%rsp), %rax
	movq	%rax, 155544(%rsp)
	movq	62432(%rsp), %rax
	movq	%rax, 155552(%rsp)
	movq	62440(%rsp), %rax
	movq	%rax, 155560(%rsp)
	movq	62448(%rsp), %rax
	movq	%rax, 155568(%rsp)
	movq	62456(%rsp), %rax
	movq	%rax, 155576(%rsp)
	movq	62464(%rsp), %rax
	movq	%rax, 155584(%rsp)
	movq	62472(%rsp), %rax
	movq	%rax, 155592(%rsp)
	movq	62480(%rsp), %rax
	movq	%rax, 155600(%rsp)
	movq	62488(%rsp), %rax
	movq	%rax, 155608(%rsp)
	movq	62496(%rsp), %rax
	movq	%rax, 155616(%rsp)
	movq	62504(%rsp), %rax
	movq	%rax, 155624(%rsp)
	movq	62512(%rsp), %rax
	movq	%rax, 155632(%rsp)
	movq	62520(%rsp), %rax
	movq	%rax, 155640(%rsp)
	movq	62528(%rsp), %rax
	movq	%rax, 155648(%rsp)
	movq	62536(%rsp), %rax
	movq	%rax, 155656(%rsp)
	movq	62544(%rsp), %rax
	movq	%rax, 155664(%rsp)
	movq	62552(%rsp), %rax
	movq	%rax, 155672(%rsp)
	movq	62560(%rsp), %rax
	movq	%rax, 155680(%rsp)
	movq	62568(%rsp), %rax
	movq	%rax, 155688(%rsp)
	movq	62576(%rsp), %rax
	movq	%rax, 155696(%rsp)
	movq	62584(%rsp), %rax
	movq	%rax, 155704(%rsp)
	movq	62592(%rsp), %rax
	movq	%rax, 155712(%rsp)
	movq	62600(%rsp), %rax
	movq	%rax, 155720(%rsp)
	movq	62608(%rsp), %rax
	movq	%rax, 155728(%rsp)
	movq	62616(%rsp), %rax
	movq	%rax, 155736(%rsp)
	movq	62624(%rsp), %rax
	movq	%rax, 155744(%rsp)
	movq	62632(%rsp), %rax
	movq	%rax, 155752(%rsp)
	movq	62640(%rsp), %rax
	movq	%rax, 155760(%rsp)
	movq	62648(%rsp), %rax
	movq	%rax, 155768(%rsp)
	movq	62656(%rsp), %rax
	movq	%rax, 155776(%rsp)
	movq	62664(%rsp), %rax
	movq	%rax, 155784(%rsp)
	movq	62672(%rsp), %rax
	movq	%rax, 155792(%rsp)
	movq	62680(%rsp), %rax
	movq	%rax, 155800(%rsp)
	movq	62688(%rsp), %rax
	movq	%rax, 155808(%rsp)
	movq	62696(%rsp), %rax
	movq	%rax, 155816(%rsp)
	movq	62704(%rsp), %rax
	movq	%rax, 155824(%rsp)
	movq	62712(%rsp), %rax
	movq	%rax, 155832(%rsp)
	movq	62720(%rsp), %rax
	movq	%rax, 155840(%rsp)
	movq	62728(%rsp), %rax
	movq	%rax, 155848(%rsp)
	movq	62736(%rsp), %rax
	movq	%rax, 155856(%rsp)
	movq	62744(%rsp), %rax
	movq	%rax, 155864(%rsp)
	movq	62752(%rsp), %rax
	movq	%rax, 155872(%rsp)
	movq	62760(%rsp), %rax
	movq	%rax, 155880(%rsp)
	movq	62768(%rsp), %rax
	movq	%rax, 155888(%rsp)
	movq	62776(%rsp), %rax
	movq	%rax, 155896(%rsp)
	movq	62784(%rsp), %rax
	movq	%rax, 155904(%rsp)
	movq	62792(%rsp), %rax
	movq	%rax, 155912(%rsp)
	movq	62800(%rsp), %rax
	movq	%rax, 155920(%rsp)
	movq	62808(%rsp), %rax
	movq	%rax, 155928(%rsp)
	movq	62816(%rsp), %rax
	movq	%rax, 155936(%rsp)
	movq	62824(%rsp), %rax
	movq	%rax, 155944(%rsp)
	movq	62832(%rsp), %rax
	movq	%rax, 155952(%rsp)
	movq	62840(%rsp), %rax
	movq	%rax, 155960(%rsp)
	movq	62848(%rsp), %rax
	movq	%rax, 155968(%rsp)
	movq	62856(%rsp), %rax
	movq	%rax, 155976(%rsp)
	movq	62864(%rsp), %rax
	movq	%rax, 155984(%rsp)
	movq	62872(%rsp), %rax
	movq	%rax, 155992(%rsp)
	movq	62880(%rsp), %rax
	movq	%rax, 156000(%rsp)
	movq	62888(%rsp), %rax
	movq	%rax, 156008(%rsp)
	movq	62896(%rsp), %rax
	movq	%rax, 156016(%rsp)
	movq	62904(%rsp), %rax
	movq	%rax, 156024(%rsp)
	movq	62912(%rsp), %rax
	movq	%rax, 156032(%rsp)
	movq	62920(%rsp), %rax
	movq	%rax, 156040(%rsp)
	movq	62928(%rsp), %rax
	movq	%rax, 156048(%rsp)
	movq	62936(%rsp), %rax
	movq	%rax, 156056(%rsp)
	movq	62944(%rsp), %rax
	movq	%rax, 156064(%rsp)
	movq	62952(%rsp), %rax
	movq	%rax, 156072(%rsp)
	movq	62960(%rsp), %rax
	movq	%rax, 156080(%rsp)
	movq	62968(%rsp), %rax
	movq	%rax, 156088(%rsp)
	movq	62976(%rsp), %rax
	movq	%rax, 156096(%rsp)
	movq	62984(%rsp), %rax
	movq	%rax, 156104(%rsp)
	movq	62992(%rsp), %rax
	movq	%rax, 156112(%rsp)
	movq	63000(%rsp), %rax
	movq	%rax, 156120(%rsp)
	movq	63008(%rsp), %rax
	movq	%rax, 156128(%rsp)
	movq	63016(%rsp), %rax
	movq	%rax, 156136(%rsp)
	movq	63024(%rsp), %rax
	movq	%rax, 156144(%rsp)
	movq	63032(%rsp), %rax
	movq	%rax, 156152(%rsp)
	movq	63040(%rsp), %rax
	movq	%rax, 156160(%rsp)
	movq	63048(%rsp), %rax
	movq	%rax, 156168(%rsp)
	movq	63056(%rsp), %rax
	movq	%rax, 156176(%rsp)
	movq	63064(%rsp), %rax
	movq	%rax, 156184(%rsp)
	movq	63072(%rsp), %rax
	movq	%rax, 156192(%rsp)
	movq	63080(%rsp), %rax
	movq	%rax, 156200(%rsp)
	movq	63088(%rsp), %rax
	movq	%rax, 156208(%rsp)
	movq	63096(%rsp), %rax
	movq	%rax, 156216(%rsp)
	movq	63104(%rsp), %rax
	movq	%rax, 156224(%rsp)
	movq	63112(%rsp), %rax
	movq	%rax, 156232(%rsp)
	movq	63120(%rsp), %rax
	movq	%rax, 156240(%rsp)
	movq	63128(%rsp), %rax
	movq	%rax, 156248(%rsp)
	movq	63136(%rsp), %rax
	movq	%rax, 156256(%rsp)
	movq	63144(%rsp), %rax
	movq	%rax, 156264(%rsp)
	movq	63152(%rsp), %rax
	movq	%rax, 156272(%rsp)
	movq	63160(%rsp), %rax
	movq	%rax, 156280(%rsp)
	movq	63168(%rsp), %rax
	movq	%rax, 156288(%rsp)
	movq	63176(%rsp), %rax
	movq	%rax, 156296(%rsp)
	movq	63184(%rsp), %rax
	movq	%rax, 156304(%rsp)
	movq	63192(%rsp), %rax
	movq	%rax, 156312(%rsp)
	movq	63200(%rsp), %rax
	movq	%rax, 156320(%rsp)
	movq	63208(%rsp), %rax
	movq	%rax, 156328(%rsp)
	movq	63216(%rsp), %rax
	movq	%rax, 156336(%rsp)
	movq	63224(%rsp), %rax
	movq	%rax, 156344(%rsp)
	movq	63232(%rsp), %rax
	movq	%rax, 156352(%rsp)
	movq	63240(%rsp), %rax
	movq	%rax, 156360(%rsp)
	movq	63248(%rsp), %rax
	movq	%rax, 156368(%rsp)
	movq	63256(%rsp), %rax
	movq	%rax, 156376(%rsp)
	movq	63264(%rsp), %rax
	movq	%rax, 156384(%rsp)
	movq	63272(%rsp), %rax
	movq	%rax, 156392(%rsp)
	movq	63280(%rsp), %rax
	movq	%rax, 156400(%rsp)
	movq	63288(%rsp), %rax
	movq	%rax, 156408(%rsp)
	movq	63296(%rsp), %rax
	movq	%rax, 156416(%rsp)
	movq	63304(%rsp), %rax
	movq	%rax, 156424(%rsp)
	movq	63312(%rsp), %rax
	movq	%rax, 156432(%rsp)
	movq	63320(%rsp), %rax
	movq	%rax, 156440(%rsp)
	movq	63328(%rsp), %rax
	movq	%rax, 156448(%rsp)
	movq	63336(%rsp), %rax
	movq	%rax, 156456(%rsp)
	movq	63344(%rsp), %rax
	movq	%rax, 156464(%rsp)
	movq	63352(%rsp), %rax
	movq	%rax, 156472(%rsp)
	movq	63360(%rsp), %rax
	movq	%rax, 156480(%rsp)
	movq	63368(%rsp), %rax
	movq	%rax, 156488(%rsp)
	movq	63376(%rsp), %rax
	movq	%rax, 156496(%rsp)
	movq	63384(%rsp), %rax
	movq	%rax, 156504(%rsp)
	movq	63392(%rsp), %rax
	movq	%rax, 156512(%rsp)
	movq	63400(%rsp), %rax
	movq	%rax, 156520(%rsp)
	movq	63408(%rsp), %rax
	movq	%rax, 156528(%rsp)
	movq	63416(%rsp), %rax
	movq	%rax, 156536(%rsp)
	movq	63424(%rsp), %rax
	movq	%rax, 156544(%rsp)
	movq	63432(%rsp), %rax
	movq	%rax, 156552(%rsp)
	movq	63440(%rsp), %rax
	movq	%rax, 156560(%rsp)
	movq	63448(%rsp), %rax
	movq	%rax, 156568(%rsp)
	movq	63456(%rsp), %rax
	movq	%rax, 156576(%rsp)
	movq	63464(%rsp), %rax
	movq	%rax, 156584(%rsp)
	movq	63472(%rsp), %rax
	movq	%rax, 156592(%rsp)
	movq	63480(%rsp), %rax
	movq	%rax, 156600(%rsp)
	movq	63488(%rsp), %rax
	movq	%rax, 156608(%rsp)
	movq	63496(%rsp), %rax
	movq	%rax, 156616(%rsp)
	movq	63504(%rsp), %rax
	movq	%rax, 156624(%rsp)
	movq	63512(%rsp), %rax
	movq	%rax, 156632(%rsp)
	movq	63520(%rsp), %rax
	movq	%rax, 156640(%rsp)
	movq	63528(%rsp), %rax
	movq	%rax, 156648(%rsp)
	movq	63536(%rsp), %rax
	movq	%rax, 156656(%rsp)
	movq	63544(%rsp), %rax
	movq	%rax, 156664(%rsp)
	movq	63552(%rsp), %rax
	movq	%rax, 156672(%rsp)
	movq	63560(%rsp), %rax
	movq	%rax, 156680(%rsp)
	movq	63568(%rsp), %rax
	movq	%rax, 156688(%rsp)
	movq	63576(%rsp), %rax
	movq	%rax, 156696(%rsp)
	movq	63584(%rsp), %rax
	movq	%rax, 156704(%rsp)
	movq	63592(%rsp), %rax
	movq	%rax, 156712(%rsp)
	movq	63600(%rsp), %rax
	movq	%rax, 156720(%rsp)
	movq	63608(%rsp), %rax
	movq	%rax, 156728(%rsp)
	movq	63616(%rsp), %rax
	movq	%rax, 156736(%rsp)
	movq	63624(%rsp), %rax
	movq	%rax, 156744(%rsp)
	movq	63632(%rsp), %rax
	movq	%rax, 156752(%rsp)
	movq	63640(%rsp), %rax
	movq	%rax, 156760(%rsp)
	movq	63648(%rsp), %rax
	movq	%rax, 156768(%rsp)
	movq	63656(%rsp), %rax
	movq	%rax, 156776(%rsp)
	movq	63664(%rsp), %rax
	movq	%rax, 156784(%rsp)
	movq	63672(%rsp), %rax
	movq	%rax, 156792(%rsp)
	movq	63680(%rsp), %rax
	movq	%rax, 156800(%rsp)
	movq	63688(%rsp), %rax
	movq	%rax, 156808(%rsp)
	movq	63696(%rsp), %rax
	movq	%rax, 156816(%rsp)
	movq	63704(%rsp), %rax
	movq	%rax, 156824(%rsp)
	movq	63712(%rsp), %rax
	movq	%rax, 156832(%rsp)
	movq	63720(%rsp), %rax
	movq	%rax, 156840(%rsp)
	movq	63728(%rsp), %rax
	movq	%rax, 156848(%rsp)
	movq	63736(%rsp), %rax
	movq	%rax, 156856(%rsp)
	movq	63744(%rsp), %rax
	movq	%rax, 156864(%rsp)
	movq	63752(%rsp), %rax
	movq	%rax, 156872(%rsp)
	movq	63760(%rsp), %rax
	movq	%rax, 156880(%rsp)
	movq	63768(%rsp), %rax
	movq	%rax, 156888(%rsp)
	movq	63776(%rsp), %rax
	movq	%rax, 156896(%rsp)
	movq	63784(%rsp), %rax
	movq	%rax, 156904(%rsp)
	movq	63792(%rsp), %rax
	movq	%rax, 156912(%rsp)
	movq	63800(%rsp), %rax
	movq	%rax, 156920(%rsp)
	movq	63808(%rsp), %rax
	movq	%rax, 156928(%rsp)
	movq	63816(%rsp), %rax
	movq	%rax, 156936(%rsp)
	movq	63824(%rsp), %rax
	movq	%rax, 156944(%rsp)
	movq	63832(%rsp), %rax
	movq	%rax, 156952(%rsp)
	movq	63840(%rsp), %rax
	movq	%rax, 156960(%rsp)
	movq	63848(%rsp), %rax
	movq	%rax, 156968(%rsp)
	movq	63856(%rsp), %rax
	movq	%rax, 156976(%rsp)
	movq	63864(%rsp), %rax
	movq	%rax, 156984(%rsp)
	movq	63872(%rsp), %rax
	movq	%rax, 156992(%rsp)
	movq	63880(%rsp), %rax
	movq	%rax, 157000(%rsp)
	movq	63888(%rsp), %rax
	movq	%rax, 157008(%rsp)
	movq	63896(%rsp), %rax
	movq	%rax, 157016(%rsp)
	movq	63904(%rsp), %rax
	movq	%rax, 157024(%rsp)
	movq	63912(%rsp), %rax
	movq	%rax, 157032(%rsp)
	movq	63920(%rsp), %rax
	movq	%rax, 157040(%rsp)
	movq	63928(%rsp), %rax
	movq	%rax, 157048(%rsp)
	movq	63936(%rsp), %rax
	movq	%rax, 157056(%rsp)
	movq	63944(%rsp), %rax
	movq	%rax, 157064(%rsp)
	movq	63952(%rsp), %rax
	movq	%rax, 157072(%rsp)
	movq	63960(%rsp), %rax
	movq	%rax, 157080(%rsp)
	movq	63968(%rsp), %rax
	movq	%rax, 157088(%rsp)
	movq	63976(%rsp), %rax
	movq	%rax, 157096(%rsp)
	movq	63984(%rsp), %rax
	movq	%rax, 157104(%rsp)
	movq	63992(%rsp), %rax
	movq	%rax, 157112(%rsp)
	movq	64000(%rsp), %rax
	movq	%rax, 157120(%rsp)
	movq	64008(%rsp), %rax
	movq	%rax, 157128(%rsp)
	movq	64016(%rsp), %rax
	movq	%rax, 157136(%rsp)
	movq	64024(%rsp), %rax
	movq	%rax, 157144(%rsp)
	movq	64032(%rsp), %rax
	movq	%rax, 157152(%rsp)
	movq	64040(%rsp), %rax
	movq	%rax, 157160(%rsp)
	movq	64048(%rsp), %rax
	movq	%rax, 157168(%rsp)
	movq	64056(%rsp), %rax
	movq	%rax, 157176(%rsp)
	movq	64064(%rsp), %rax
	movq	%rax, 157184(%rsp)
	movq	64072(%rsp), %rax
	movq	%rax, 157192(%rsp)
	movq	64080(%rsp), %rax
	movq	%rax, 157200(%rsp)
	movq	64088(%rsp), %rax
	movq	%rax, 157208(%rsp)
	movq	64096(%rsp), %rax
	movq	%rax, 157216(%rsp)
	movq	64104(%rsp), %rax
	movq	%rax, 157224(%rsp)
	movq	64112(%rsp), %rax
	movq	%rax, 157232(%rsp)
	movq	64120(%rsp), %rax
	movq	%rax, 157240(%rsp)
	movq	64128(%rsp), %rax
	movq	%rax, 157248(%rsp)
	movq	64136(%rsp), %rax
	movq	%rax, 157256(%rsp)
	movq	64144(%rsp), %rax
	movq	%rax, 157264(%rsp)
	movq	64152(%rsp), %rax
	movq	%rax, 157272(%rsp)
	movq	64160(%rsp), %rax
	movq	%rax, 157280(%rsp)
	movq	64168(%rsp), %rax
	movq	%rax, 157288(%rsp)
	movq	64176(%rsp), %rax
	movq	%rax, 157296(%rsp)
	movq	64184(%rsp), %rax
	movq	%rax, 157304(%rsp)
	movq	64192(%rsp), %rax
	movq	%rax, 157312(%rsp)
	movq	64200(%rsp), %rax
	movq	%rax, 157320(%rsp)
	movq	64208(%rsp), %rax
	movq	%rax, 157328(%rsp)
	movq	64216(%rsp), %rax
	movq	%rax, 157336(%rsp)
	movq	64224(%rsp), %rax
	movq	%rax, 157344(%rsp)
	movq	64232(%rsp), %rax
	movq	%rax, 157352(%rsp)
	movq	64240(%rsp), %rax
	movq	%rax, 157360(%rsp)
	movq	64248(%rsp), %rax
	movq	%rax, 157368(%rsp)
	movq	64256(%rsp), %rax
	movq	%rax, 157376(%rsp)
	movq	64264(%rsp), %rax
	movq	%rax, 157384(%rsp)
	movq	64272(%rsp), %rax
	movq	%rax, 157392(%rsp)
	movq	64280(%rsp), %rax
	movq	%rax, 157400(%rsp)
	movq	64288(%rsp), %rax
	movq	%rax, 157408(%rsp)
	movq	64296(%rsp), %rax
	movq	%rax, 157416(%rsp)
	movq	64304(%rsp), %rax
	movq	%rax, 157424(%rsp)
	movq	64312(%rsp), %rax
	movq	%rax, 157432(%rsp)
	movq	64320(%rsp), %rax
	movq	%rax, 157440(%rsp)
	movq	64328(%rsp), %rax
	movq	%rax, 157448(%rsp)
	movq	64336(%rsp), %rax
	movq	%rax, 157456(%rsp)
	movq	64344(%rsp), %rax
	movq	%rax, 157464(%rsp)
	movq	64352(%rsp), %rax
	movq	%rax, 157472(%rsp)
	movq	64360(%rsp), %rax
	movq	%rax, 157480(%rsp)
	movq	64368(%rsp), %rax
	movq	%rax, 157488(%rsp)
	movq	64376(%rsp), %rax
	movq	%rax, 157496(%rsp)
	movq	64384(%rsp), %rax
	movq	%rax, 157504(%rsp)
	movq	64392(%rsp), %rax
	movq	%rax, 157512(%rsp)
	movq	64400(%rsp), %rax
	movq	%rax, 157520(%rsp)
	movq	64408(%rsp), %rax
	movq	%rax, 157528(%rsp)
	movq	64416(%rsp), %rax
	movq	%rax, 157536(%rsp)
	movq	64424(%rsp), %rax
	movq	%rax, 157544(%rsp)
	movq	64432(%rsp), %rax
	movq	%rax, 157552(%rsp)
	movq	64440(%rsp), %rax
	movq	%rax, 157560(%rsp)
	movq	64448(%rsp), %rax
	movq	%rax, 157568(%rsp)
	movq	64456(%rsp), %rax
	movq	%rax, 157576(%rsp)
	movq	64464(%rsp), %rax
	movq	%rax, 157584(%rsp)
	movq	64472(%rsp), %rax
	movq	%rax, 157592(%rsp)
	movq	64480(%rsp), %rax
	movq	%rax, 157600(%rsp)
	movq	64488(%rsp), %rax
	movq	%rax, 157608(%rsp)
	movq	64496(%rsp), %rax
	movq	%rax, 157616(%rsp)
	movq	64504(%rsp), %rax
	movq	%rax, 157624(%rsp)
	movq	64512(%rsp), %rax
	movq	%rax, 157632(%rsp)
	movq	64520(%rsp), %rax
	movq	%rax, 157640(%rsp)
	movq	64528(%rsp), %rax
	movq	%rax, 157648(%rsp)
	movq	64536(%rsp), %rax
	movq	%rax, 157656(%rsp)
	movq	64544(%rsp), %rax
	movq	%rax, 157664(%rsp)
	movq	64552(%rsp), %rax
	movq	%rax, 157672(%rsp)
	movq	64560(%rsp), %rax
	movq	%rax, 157680(%rsp)
	movq	64568(%rsp), %rax
	movq	%rax, 157688(%rsp)
	movq	64576(%rsp), %rax
	movq	%rax, 157696(%rsp)
	movq	64584(%rsp), %rax
	movq	%rax, 157704(%rsp)
	movq	64592(%rsp), %rax
	movq	%rax, 157712(%rsp)
	movq	64600(%rsp), %rax
	movq	%rax, 157720(%rsp)
	movq	64608(%rsp), %rax
	movq	%rax, 157728(%rsp)
	movq	64616(%rsp), %rax
	movq	%rax, 157736(%rsp)
	movq	64624(%rsp), %rax
	movq	%rax, 157744(%rsp)
	movq	64632(%rsp), %rax
	movq	%rax, 157752(%rsp)
	movq	64640(%rsp), %rax
	movq	%rax, 157760(%rsp)
	movq	64648(%rsp), %rax
	movq	%rax, 157768(%rsp)
	movq	64656(%rsp), %rax
	movq	%rax, 157776(%rsp)
	movq	64664(%rsp), %rax
	movq	%rax, 157784(%rsp)
	movq	64672(%rsp), %rax
	movq	%rax, 157792(%rsp)
	movq	64680(%rsp), %rax
	movq	%rax, 157800(%rsp)
	movq	64688(%rsp), %rax
	movq	%rax, 157808(%rsp)
	movq	64696(%rsp), %rax
	movq	%rax, 157816(%rsp)
	movq	64704(%rsp), %rax
	movq	%rax, 157824(%rsp)
	movq	64712(%rsp), %rax
	movq	%rax, 157832(%rsp)
	movq	64720(%rsp), %rax
	movq	%rax, 157840(%rsp)
	movq	64728(%rsp), %rax
	movq	%rax, 157848(%rsp)
	movq	64736(%rsp), %rax
	movq	%rax, 157856(%rsp)
	movq	64744(%rsp), %rax
	movq	%rax, 157864(%rsp)
	movq	64752(%rsp), %rax
	movq	%rax, 157872(%rsp)
	movq	64760(%rsp), %rax
	movq	%rax, 157880(%rsp)
	movq	64768(%rsp), %rax
	movq	%rax, 157888(%rsp)
	movq	64776(%rsp), %rax
	movq	%rax, 157896(%rsp)
	movq	64784(%rsp), %rax
	movq	%rax, 157904(%rsp)
	movq	64792(%rsp), %rax
	movq	%rax, 157912(%rsp)
	movq	64800(%rsp), %rax
	movq	%rax, 157920(%rsp)
	movq	64808(%rsp), %rax
	movq	%rax, 157928(%rsp)
	movq	64816(%rsp), %rax
	movq	%rax, 157936(%rsp)
	movq	64824(%rsp), %rax
	movq	%rax, 157944(%rsp)
	movq	64832(%rsp), %rax
	movq	%rax, 157952(%rsp)
	movq	64840(%rsp), %rax
	movq	%rax, 157960(%rsp)
	movq	64848(%rsp), %rax
	movq	%rax, 157968(%rsp)
	movq	64856(%rsp), %rax
	movq	%rax, 157976(%rsp)
	movq	64864(%rsp), %rax
	movq	%rax, 157984(%rsp)
	movq	64872(%rsp), %rax
	movq	%rax, 157992(%rsp)
	movq	64880(%rsp), %rax
	movq	%rax, 158000(%rsp)
	movq	64888(%rsp), %rax
	movq	%rax, 158008(%rsp)
	movq	64896(%rsp), %rax
	movq	%rax, 158016(%rsp)
	movq	64904(%rsp), %rax
	movq	%rax, 158024(%rsp)
	movq	64912(%rsp), %rax
	movq	%rax, 158032(%rsp)
	movq	64920(%rsp), %rax
	movq	%rax, 158040(%rsp)
	movq	64928(%rsp), %rax
	movq	%rax, 158048(%rsp)
	movq	64936(%rsp), %rax
	movq	%rax, 158056(%rsp)
	movq	64944(%rsp), %rax
	movq	%rax, 158064(%rsp)
	movq	64952(%rsp), %rax
	movq	%rax, 158072(%rsp)
	movq	64960(%rsp), %rax
	movq	%rax, 158080(%rsp)
	movq	64968(%rsp), %rax
	movq	%rax, 158088(%rsp)
	movq	64976(%rsp), %rax
	movq	%rax, 158096(%rsp)
	movq	64984(%rsp), %rax
	movq	%rax, 158104(%rsp)
	movq	64992(%rsp), %rax
	movq	%rax, 158112(%rsp)
	movq	65000(%rsp), %rax
	movq	%rax, 158120(%rsp)
	movq	65008(%rsp), %rax
	movq	%rax, 158128(%rsp)
	movq	65016(%rsp), %rax
	movq	%rax, 158136(%rsp)
	movq	65024(%rsp), %rax
	movq	%rax, 158144(%rsp)
	movq	65032(%rsp), %rax
	movq	%rax, 158152(%rsp)
	movq	65040(%rsp), %rax
	movq	%rax, 158160(%rsp)
	movq	65048(%rsp), %rax
	movq	%rax, 158168(%rsp)
	movq	65056(%rsp), %rax
	movq	%rax, 158176(%rsp)
	movq	65064(%rsp), %rax
	movq	%rax, 158184(%rsp)
	movq	65072(%rsp), %rax
	movq	%rax, 158192(%rsp)
	movq	65080(%rsp), %rax
	movq	%rax, 158200(%rsp)
	movq	65088(%rsp), %rax
	movq	%rax, 158208(%rsp)
	movq	65096(%rsp), %rax
	movq	%rax, 158216(%rsp)
	movq	65104(%rsp), %rax
	movq	%rax, 158224(%rsp)
	movq	65112(%rsp), %rax
	movq	%rax, 158232(%rsp)
	movq	65120(%rsp), %rax
	movq	%rax, 158240(%rsp)
	movq	65128(%rsp), %rax
	movq	%rax, 158248(%rsp)
	movq	65136(%rsp), %rax
	movq	%rax, 158256(%rsp)
	movq	65144(%rsp), %rax
	movq	%rax, 158264(%rsp)
	movq	65152(%rsp), %rax
	movq	%rax, 158272(%rsp)
	movq	65160(%rsp), %rax
	movq	%rax, 158280(%rsp)
	movq	65168(%rsp), %rax
	movq	%rax, 158288(%rsp)
	movq	65176(%rsp), %rax
	movq	%rax, 158296(%rsp)
	movq	65184(%rsp), %rax
	movq	%rax, 158304(%rsp)
	movq	65192(%rsp), %rax
	movq	%rax, 158312(%rsp)
	movq	65200(%rsp), %rax
	movq	%rax, 158320(%rsp)
	movq	65208(%rsp), %rax
	movq	%rax, 158328(%rsp)
	movq	65216(%rsp), %rax
	movq	%rax, 158336(%rsp)
	movq	65224(%rsp), %rax
	movq	%rax, 158344(%rsp)
	movq	65232(%rsp), %rax
	movq	%rax, 158352(%rsp)
	movq	65240(%rsp), %rax
	movq	%rax, 158360(%rsp)
	movq	65248(%rsp), %rax
	movq	%rax, 158368(%rsp)
	movq	65256(%rsp), %rax
	movq	%rax, 158376(%rsp)
	movq	65264(%rsp), %rax
	movq	%rax, 158384(%rsp)
	movq	65272(%rsp), %rax
	movq	%rax, 158392(%rsp)
	movq	65280(%rsp), %rax
	movq	%rax, 158400(%rsp)
	movq	65288(%rsp), %rax
	movq	%rax, 158408(%rsp)
	movq	65296(%rsp), %rax
	movq	%rax, 158416(%rsp)
	movq	65304(%rsp), %rax
	movq	%rax, 158424(%rsp)
	movq	65312(%rsp), %rax
	movq	%rax, 158432(%rsp)
	movq	65320(%rsp), %rax
	movq	%rax, 158440(%rsp)
	movq	65328(%rsp), %rax
	movq	%rax, 158448(%rsp)
	movq	65336(%rsp), %rax
	movq	%rax, 158456(%rsp)
	movq	65344(%rsp), %rax
	movq	%rax, 158464(%rsp)
	movq	65352(%rsp), %rax
	movq	%rax, 158472(%rsp)
	movq	65360(%rsp), %rax
	movq	%rax, 158480(%rsp)
	movq	65368(%rsp), %rax
	movq	%rax, 158488(%rsp)
	movq	65376(%rsp), %rax
	movq	%rax, 158496(%rsp)
	movq	65384(%rsp), %rax
	movq	%rax, 158504(%rsp)
	movq	65392(%rsp), %rax
	movq	%rax, 158512(%rsp)
	movq	65400(%rsp), %rax
	movq	%rax, 158520(%rsp)
	movq	65408(%rsp), %rax
	movq	%rax, 158528(%rsp)
	movq	65416(%rsp), %rax
	movq	%rax, 158536(%rsp)
	movq	65424(%rsp), %rax
	movq	%rax, 158544(%rsp)
	movq	65432(%rsp), %rax
	movq	%rax, 158552(%rsp)
	movq	65440(%rsp), %rax
	movq	%rax, 158560(%rsp)
	movq	65448(%rsp), %rax
	movq	%rax, 158568(%rsp)
	movq	65456(%rsp), %rax
	movq	%rax, 158576(%rsp)
	movq	65464(%rsp), %rax
	movq	%rax, 158584(%rsp)
	movq	65472(%rsp), %rax
	movq	%rax, 158592(%rsp)
	movq	65480(%rsp), %rax
	movq	%rax, 158600(%rsp)
	movq	65488(%rsp), %rax
	movq	%rax, 158608(%rsp)
	movq	65496(%rsp), %rax
	movq	%rax, 158616(%rsp)
	movq	65504(%rsp), %rax
	movq	%rax, 158624(%rsp)
	movq	65512(%rsp), %rax
	movq	%rax, 158632(%rsp)
	movq	65520(%rsp), %rax
	movq	%rax, 158640(%rsp)
	movq	65528(%rsp), %rax
	movq	%rax, 158648(%rsp)
	movq	65536(%rsp), %rax
	movq	%rax, 158656(%rsp)
	movq	65544(%rsp), %rax
	movq	%rax, 158664(%rsp)
	movq	65552(%rsp), %rax
	movq	%rax, 158672(%rsp)
	movq	65560(%rsp), %rax
	movq	%rax, 158680(%rsp)
	movq	65568(%rsp), %rax
	movq	%rax, 158688(%rsp)
	movq	65576(%rsp), %rax
	movq	%rax, 158696(%rsp)
	movq	65584(%rsp), %rax
	movq	%rax, 158704(%rsp)
	movq	65592(%rsp), %rax
	movq	%rax, 158712(%rsp)
	movq	65600(%rsp), %rax
	movq	%rax, 158720(%rsp)
	movq	65608(%rsp), %rax
	movq	%rax, 158728(%rsp)
	movq	65616(%rsp), %rax
	movq	%rax, 158736(%rsp)
	movq	65624(%rsp), %rax
	movq	%rax, 158744(%rsp)
	movq	65632(%rsp), %rax
	movq	%rax, 158752(%rsp)
	movq	65640(%rsp), %rax
	movq	%rax, 158760(%rsp)
	movq	65648(%rsp), %rax
	movq	%rax, 158768(%rsp)
	movq	65656(%rsp), %rax
	movq	%rax, 158776(%rsp)
	movq	65664(%rsp), %rax
	movq	%rax, 158784(%rsp)
	movq	65672(%rsp), %rax
	movq	%rax, 158792(%rsp)
	movq	65680(%rsp), %rax
	movq	%rax, 158800(%rsp)
	movq	65688(%rsp), %rax
	movq	%rax, 158808(%rsp)
	movq	65696(%rsp), %rax
	movq	%rax, 158816(%rsp)
	movq	65704(%rsp), %rax
	movq	%rax, 158824(%rsp)
	movq	65712(%rsp), %rax
	movq	%rax, 158832(%rsp)
	movq	65720(%rsp), %rax
	movq	%rax, 158840(%rsp)
	movq	65728(%rsp), %rax
	movq	%rax, 158848(%rsp)
	movq	65736(%rsp), %rax
	movq	%rax, 158856(%rsp)
	movq	65744(%rsp), %rax
	movq	%rax, 158864(%rsp)
	movq	65752(%rsp), %rax
	movq	%rax, 158872(%rsp)
	movq	65760(%rsp), %rax
	movq	%rax, 158880(%rsp)
	movq	65768(%rsp), %rax
	movq	%rax, 158888(%rsp)
	movq	65776(%rsp), %rax
	movq	%rax, 158896(%rsp)
	movq	65784(%rsp), %rax
	movq	%rax, 158904(%rsp)
	movq	65792(%rsp), %rax
	movq	%rax, 158912(%rsp)
	movq	65800(%rsp), %rax
	movq	%rax, 158920(%rsp)
	movq	65808(%rsp), %rax
	movq	%rax, 158928(%rsp)
	movq	65816(%rsp), %rax
	movq	%rax, 158936(%rsp)
	movq	65824(%rsp), %rax
	movq	%rax, 158944(%rsp)
	movq	65832(%rsp), %rax
	movq	%rax, 158952(%rsp)
	movq	65840(%rsp), %rax
	movq	%rax, 158960(%rsp)
	movq	65848(%rsp), %rax
	movq	%rax, 158968(%rsp)
	movq	65856(%rsp), %rax
	movq	%rax, 158976(%rsp)
	movq	65864(%rsp), %rax
	movq	%rax, 158984(%rsp)
	movq	65872(%rsp), %rax
	movq	%rax, 158992(%rsp)
	movq	65880(%rsp), %rax
	movq	%rax, 159000(%rsp)
	movq	65888(%rsp), %rax
	movq	%rax, 159008(%rsp)
	movq	65896(%rsp), %rax
	movq	%rax, 159016(%rsp)
	movq	65904(%rsp), %rax
	movq	%rax, 159024(%rsp)
	movq	65912(%rsp), %rax
	movq	%rax, 159032(%rsp)
	movq	65920(%rsp), %rax
	movq	%rax, 159040(%rsp)
	movq	65928(%rsp), %rax
	movq	%rax, 159048(%rsp)
	movq	65936(%rsp), %rax
	movq	%rax, 159056(%rsp)
	movq	65944(%rsp), %rax
	movq	%rax, 159064(%rsp)
	movq	65952(%rsp), %rax
	movq	%rax, 159072(%rsp)
	movq	65960(%rsp), %rax
	movq	%rax, 159080(%rsp)
	movq	65968(%rsp), %rax
	movq	%rax, 159088(%rsp)
	movq	65976(%rsp), %rax
	movq	%rax, 159096(%rsp)
	movq	65984(%rsp), %rax
	movq	%rax, 159104(%rsp)
	movq	65992(%rsp), %rax
	movq	%rax, 159112(%rsp)
	movq	66000(%rsp), %rax
	movq	%rax, 159120(%rsp)
	movq	66008(%rsp), %rax
	movq	%rax, 159128(%rsp)
	movq	66016(%rsp), %rax
	movq	%rax, 159136(%rsp)
	movq	66024(%rsp), %rax
	movq	%rax, 159144(%rsp)
	movq	66032(%rsp), %rax
	movq	%rax, 159152(%rsp)
	movq	66040(%rsp), %rax
	movq	%rax, 159160(%rsp)
	movq	66048(%rsp), %rax
	movq	%rax, 159168(%rsp)
	movq	66056(%rsp), %rax
	movq	%rax, 159176(%rsp)
	movq	66064(%rsp), %rax
	movq	%rax, 159184(%rsp)
	movq	66072(%rsp), %rax
	movq	%rax, 159192(%rsp)
	movq	66080(%rsp), %rax
	movq	%rax, 159200(%rsp)
	movq	66088(%rsp), %rax
	movq	%rax, 159208(%rsp)
	movq	66096(%rsp), %rax
	movq	%rax, 159216(%rsp)
	movq	66104(%rsp), %rax
	movq	%rax, 159224(%rsp)
	movq	66112(%rsp), %rax
	movq	%rax, 159232(%rsp)
	movq	66120(%rsp), %rax
	movq	%rax, 159240(%rsp)
	movq	66128(%rsp), %rax
	movq	%rax, 159248(%rsp)
	movq	66136(%rsp), %rax
	movq	%rax, 159256(%rsp)
	movq	66144(%rsp), %rax
	movq	%rax, 159264(%rsp)
	movq	66152(%rsp), %rax
	movq	%rax, 159272(%rsp)
	movq	66160(%rsp), %rax
	movq	%rax, 159280(%rsp)
	movq	66168(%rsp), %rax
	movq	%rax, 159288(%rsp)
	movq	66176(%rsp), %rax
	movq	%rax, 159296(%rsp)
	movq	66184(%rsp), %rax
	movq	%rax, 159304(%rsp)
	movq	66192(%rsp), %rax
	movq	%rax, 159312(%rsp)
	movq	66200(%rsp), %rax
	movq	%rax, 159320(%rsp)
	movq	66208(%rsp), %rax
	movq	%rax, 159328(%rsp)
	movq	66216(%rsp), %rax
	movq	%rax, 159336(%rsp)
	movq	66224(%rsp), %rax
	movq	%rax, 159344(%rsp)
	movq	66232(%rsp), %rax
	movq	%rax, 159352(%rsp)
	movq	66240(%rsp), %rax
	movq	%rax, 159360(%rsp)
	movq	66248(%rsp), %rax
	movq	%rax, 159368(%rsp)
	movq	66256(%rsp), %rax
	movq	%rax, 159376(%rsp)
	movq	66264(%rsp), %rax
	movq	%rax, 159384(%rsp)
	movq	66272(%rsp), %rax
	movq	%rax, 159392(%rsp)
	movq	66280(%rsp), %rax
	movq	%rax, 159400(%rsp)
	movq	66288(%rsp), %rax
	movq	%rax, 159408(%rsp)
	movq	66296(%rsp), %rax
	movq	%rax, 159416(%rsp)
	movq	66304(%rsp), %rax
	movq	%rax, 159424(%rsp)
	movq	66312(%rsp), %rax
	movq	%rax, 159432(%rsp)
	movq	66320(%rsp), %rax
	movq	%rax, 159440(%rsp)
	movq	66328(%rsp), %rax
	movq	%rax, 159448(%rsp)
	movq	66336(%rsp), %rax
	movq	%rax, 159456(%rsp)
	movq	66344(%rsp), %rax
	movq	%rax, 159464(%rsp)
	movq	66352(%rsp), %rax
	movq	%rax, 159472(%rsp)
	movq	66360(%rsp), %rax
	movq	%rax, 159480(%rsp)
	movq	66368(%rsp), %rax
	movq	%rax, 159488(%rsp)
	movq	66376(%rsp), %rax
	movq	%rax, 159496(%rsp)
	movq	66384(%rsp), %rax
	movq	%rax, 159504(%rsp)
	movq	66392(%rsp), %rax
	movq	%rax, 159512(%rsp)
	movq	66400(%rsp), %rax
	movq	%rax, 159520(%rsp)
	movq	66408(%rsp), %rax
	movq	%rax, 159528(%rsp)
	movq	66416(%rsp), %rax
	movq	%rax, 159536(%rsp)
	movq	66424(%rsp), %rax
	movq	%rax, 159544(%rsp)
	movq	66432(%rsp), %rax
	movq	%rax, 159552(%rsp)
	movq	66440(%rsp), %rax
	movq	%rax, 159560(%rsp)
	movq	66448(%rsp), %rax
	movq	%rax, 159568(%rsp)
	movq	66456(%rsp), %rax
	movq	%rax, 159576(%rsp)
	movq	66464(%rsp), %rax
	movq	%rax, 159584(%rsp)
	movq	66472(%rsp), %rax
	movq	%rax, 159592(%rsp)
	movq	66480(%rsp), %rax
	movq	%rax, 159600(%rsp)
	movq	66488(%rsp), %rax
	movq	%rax, 159608(%rsp)
	movq	66496(%rsp), %rax
	movq	%rax, 159616(%rsp)
	movq	66504(%rsp), %rax
	movq	%rax, 159624(%rsp)
	movq	66512(%rsp), %rax
	movq	%rax, 159632(%rsp)
	movq	66520(%rsp), %rax
	movq	%rax, 159640(%rsp)
	movq	66528(%rsp), %rax
	movq	%rax, 159648(%rsp)
	movq	66536(%rsp), %rax
	movq	%rax, 159656(%rsp)
	movq	66544(%rsp), %rax
	movq	%rax, 159664(%rsp)
	movq	66552(%rsp), %rax
	movq	%rax, 159672(%rsp)
	movq	66560(%rsp), %rax
	movq	%rax, 159680(%rsp)
	movq	66568(%rsp), %rax
	movq	%rax, 159688(%rsp)
	movq	66576(%rsp), %rax
	movq	%rax, 159696(%rsp)
	movq	66584(%rsp), %rax
	movq	%rax, 159704(%rsp)
	movq	66592(%rsp), %rax
	movq	%rax, 159712(%rsp)
	movq	66600(%rsp), %rax
	movq	%rax, 159720(%rsp)
	movq	66608(%rsp), %rax
	movq	%rax, 159728(%rsp)
	movq	66616(%rsp), %rax
	movq	%rax, 159736(%rsp)
	movq	66624(%rsp), %rax
	movq	%rax, 159744(%rsp)
	movq	66632(%rsp), %rax
	movq	%rax, 159752(%rsp)
	movq	66640(%rsp), %rax
	movq	%rax, 159760(%rsp)
	movq	66648(%rsp), %rax
	movq	%rax, 159768(%rsp)
	movq	66656(%rsp), %rax
	movq	%rax, 159776(%rsp)
	movq	66664(%rsp), %rax
	movq	%rax, 159784(%rsp)
	movq	66672(%rsp), %rax
	movq	%rax, 159792(%rsp)
	movq	66680(%rsp), %rax
	movq	%rax, 159800(%rsp)
	movq	66688(%rsp), %rax
	movq	%rax, 159808(%rsp)
	movq	66696(%rsp), %rax
	movq	%rax, 159816(%rsp)
	movq	66704(%rsp), %rax
	movq	%rax, 159824(%rsp)
	movq	66712(%rsp), %rax
	movq	%rax, 159832(%rsp)
	movq	66720(%rsp), %rax
	movq	%rax, 159840(%rsp)
	movq	66728(%rsp), %rax
	movq	%rax, 159848(%rsp)
	movq	66736(%rsp), %rax
	movq	%rax, 159856(%rsp)
	movq	66744(%rsp), %rax
	movq	%rax, 159864(%rsp)
	movq	66752(%rsp), %rax
	movq	%rax, 159872(%rsp)
	movq	66760(%rsp), %rax
	movq	%rax, 159880(%rsp)
	movq	66768(%rsp), %rax
	movq	%rax, 159888(%rsp)
	movq	66776(%rsp), %rax
	movq	%rax, 159896(%rsp)
	movq	66784(%rsp), %rax
	movq	%rax, 159904(%rsp)
	movq	66792(%rsp), %rax
	movq	%rax, 159912(%rsp)
	movq	66800(%rsp), %rax
	movq	%rax, 159920(%rsp)
	movq	66808(%rsp), %rax
	movq	%rax, 159928(%rsp)
	movq	66816(%rsp), %rax
	movq	%rax, 159936(%rsp)
	movq	66824(%rsp), %rax
	movq	%rax, 159944(%rsp)
	movq	66832(%rsp), %rax
	movq	%rax, 159952(%rsp)
	movq	66840(%rsp), %rax
	movq	%rax, 159960(%rsp)
	movq	66848(%rsp), %rax
	movq	%rax, 159968(%rsp)
	movq	66856(%rsp), %rax
	movq	%rax, 159976(%rsp)
	movq	66864(%rsp), %rax
	movq	%rax, 159984(%rsp)
	movq	66872(%rsp), %rax
	movq	%rax, 159992(%rsp)
	movq	66880(%rsp), %rax
	movq	%rax, 160000(%rsp)
	movq	66888(%rsp), %rax
	movq	%rax, 160008(%rsp)
	movq	66896(%rsp), %rax
	movq	%rax, 160016(%rsp)
	movq	66904(%rsp), %rax
	movq	%rax, 160024(%rsp)
	movq	66912(%rsp), %rax
	movq	%rax, 160032(%rsp)
	movq	66920(%rsp), %rax
	movq	%rax, 160040(%rsp)
	movq	66928(%rsp), %rax
	movq	%rax, 160048(%rsp)
	movq	66936(%rsp), %rax
	movq	%rax, 160056(%rsp)
	movq	66944(%rsp), %rax
	movq	%rax, 160064(%rsp)
	movq	66952(%rsp), %rax
	movq	%rax, 160072(%rsp)
	movq	66960(%rsp), %rax
	movq	%rax, 160080(%rsp)
	movq	66968(%rsp), %rax
	movq	%rax, 160088(%rsp)
	movq	66976(%rsp), %rax
	movq	%rax, 160096(%rsp)
	movq	66984(%rsp), %rax
	movq	%rax, 160104(%rsp)
	movq	66992(%rsp), %rax
	movq	%rax, 160112(%rsp)
	movq	67000(%rsp), %rax
	movq	%rax, 160120(%rsp)
	movq	67008(%rsp), %rax
	movq	%rax, 160128(%rsp)
	movq	67016(%rsp), %rax
	movq	%rax, 160136(%rsp)
	movq	67024(%rsp), %rax
	movq	%rax, 160144(%rsp)
	movq	67032(%rsp), %rax
	movq	%rax, 160152(%rsp)
	movq	67040(%rsp), %rax
	movq	%rax, 160160(%rsp)
	movq	67048(%rsp), %rax
	movq	%rax, 160168(%rsp)
	movq	67056(%rsp), %rax
	movq	%rax, 160176(%rsp)
	movq	67064(%rsp), %rax
	movq	%rax, 160184(%rsp)
	movq	67072(%rsp), %rax
	movq	%rax, 160192(%rsp)
	movq	67080(%rsp), %rax
	movq	%rax, 160200(%rsp)
	movq	67088(%rsp), %rax
	movq	%rax, 160208(%rsp)
	movq	67096(%rsp), %rax
	movq	%rax, 160216(%rsp)
	movq	67104(%rsp), %rax
	movq	%rax, 160224(%rsp)
	movq	67112(%rsp), %rax
	movq	%rax, 160232(%rsp)
	movq	67120(%rsp), %rax
	movq	%rax, 160240(%rsp)
	movq	67128(%rsp), %rax
	movq	%rax, 160248(%rsp)
	movq	67136(%rsp), %rax
	movq	%rax, 160256(%rsp)
	movq	67144(%rsp), %rax
	movq	%rax, 160264(%rsp)
	movq	67152(%rsp), %rax
	movq	%rax, 160272(%rsp)
	movq	67160(%rsp), %rax
	movq	%rax, 160280(%rsp)
	movq	67168(%rsp), %rax
	movq	%rax, 160288(%rsp)
	movq	67176(%rsp), %rax
	movq	%rax, 160296(%rsp)
	movq	67184(%rsp), %rax
	movq	%rax, 160304(%rsp)
	movq	67192(%rsp), %rax
	movq	%rax, 160312(%rsp)
	movq	67200(%rsp), %rax
	movq	%rax, 160320(%rsp)
	movq	67208(%rsp), %rax
	movq	%rax, 160328(%rsp)
	movq	67216(%rsp), %rax
	movq	%rax, 160336(%rsp)
	movq	67224(%rsp), %rax
	movq	%rax, 160344(%rsp)
	movq	67232(%rsp), %rax
	movq	%rax, 160352(%rsp)
	movq	67240(%rsp), %rax
	movq	%rax, 160360(%rsp)
	movq	67248(%rsp), %rax
	movq	%rax, 160368(%rsp)
	movq	67256(%rsp), %rax
	movq	%rax, 160376(%rsp)
	movq	67264(%rsp), %rax
	movq	%rax, 160384(%rsp)
	movq	67272(%rsp), %rax
	movq	%rax, 160392(%rsp)
	movq	67280(%rsp), %rax
	movq	%rax, 160400(%rsp)
	movq	67288(%rsp), %rax
	movq	%rax, 160408(%rsp)
	movq	67296(%rsp), %rax
	movq	%rax, 160416(%rsp)
	movq	67304(%rsp), %rax
	movq	%rax, 160424(%rsp)
	movq	67312(%rsp), %rax
	movq	%rax, 160432(%rsp)
	movq	67320(%rsp), %rax
	movq	%rax, 160440(%rsp)
	movq	67328(%rsp), %rax
	movq	%rax, 160448(%rsp)
	movq	67336(%rsp), %rax
	movq	%rax, 160456(%rsp)
	movq	67344(%rsp), %rax
	movq	%rax, 160464(%rsp)
	movq	67352(%rsp), %rax
	movq	%rax, 160472(%rsp)
	movq	67360(%rsp), %rax
	movq	%rax, 160480(%rsp)
	movq	67368(%rsp), %rax
	movq	%rax, 160488(%rsp)
	movq	67376(%rsp), %rax
	movq	%rax, 160496(%rsp)
	movq	67384(%rsp), %rax
	movq	%rax, 160504(%rsp)
	movq	67392(%rsp), %rax
	movq	%rax, 160512(%rsp)
	movq	67400(%rsp), %rax
	movq	%rax, 160520(%rsp)
	movq	67408(%rsp), %rax
	movq	%rax, 160528(%rsp)
	movq	67416(%rsp), %rax
	movq	%rax, 160536(%rsp)
	movq	67424(%rsp), %rax
	movq	%rax, 160544(%rsp)
	movq	67432(%rsp), %rax
	movq	%rax, 160552(%rsp)
	movq	67440(%rsp), %rax
	movq	%rax, 160560(%rsp)
	movq	67448(%rsp), %rax
	movq	%rax, 160568(%rsp)
	movq	67456(%rsp), %rax
	movq	%rax, 160576(%rsp)
	movq	67464(%rsp), %rax
	movq	%rax, 160584(%rsp)
	movq	67472(%rsp), %rax
	movq	%rax, 160592(%rsp)
	movq	67480(%rsp), %rax
	movq	%rax, 160600(%rsp)
	movq	67488(%rsp), %rax
	movq	%rax, 160608(%rsp)
	movq	67496(%rsp), %rax
	movq	%rax, 160616(%rsp)
	movq	67504(%rsp), %rax
	movq	%rax, 160624(%rsp)
	movq	67512(%rsp), %rax
	movq	%rax, 160632(%rsp)
	movq	67520(%rsp), %rax
	movq	%rax, 160640(%rsp)
	movq	67528(%rsp), %rax
	movq	%rax, 160648(%rsp)
	movq	67536(%rsp), %rax
	movq	%rax, 160656(%rsp)
	movq	67544(%rsp), %rax
	movq	%rax, 160664(%rsp)
	movq	67552(%rsp), %rax
	movq	%rax, 160672(%rsp)
	movq	67560(%rsp), %rax
	movq	%rax, 160680(%rsp)
	movq	67568(%rsp), %rax
	movq	%rax, 160688(%rsp)
	movq	67576(%rsp), %rax
	movq	%rax, 160696(%rsp)
	movq	67584(%rsp), %rax
	movq	%rax, 160704(%rsp)
	movq	67592(%rsp), %rax
	movq	%rax, 160712(%rsp)
	movq	67600(%rsp), %rax
	movq	%rax, 160720(%rsp)
	movq	67608(%rsp), %rax
	movq	%rax, 160728(%rsp)
	movq	67616(%rsp), %rax
	movq	%rax, 160736(%rsp)
	movq	67624(%rsp), %rax
	movq	%rax, 160744(%rsp)
	movq	67632(%rsp), %rax
	movq	%rax, 160752(%rsp)
	movq	67640(%rsp), %rax
	movq	%rax, 160760(%rsp)
	movq	67648(%rsp), %rax
	movq	%rax, 160768(%rsp)
	movq	67656(%rsp), %rax
	movq	%rax, 160776(%rsp)
	movq	67664(%rsp), %rax
	movq	%rax, 160784(%rsp)
	movq	67672(%rsp), %rax
	movq	%rax, 160792(%rsp)
	movq	67680(%rsp), %rax
	movq	%rax, 160800(%rsp)
	movq	67688(%rsp), %rax
	movq	%rax, 160808(%rsp)
	movq	67696(%rsp), %rax
	movq	%rax, 160816(%rsp)
	movq	67704(%rsp), %rax
	movq	%rax, 160824(%rsp)
	movq	67712(%rsp), %rax
	movq	%rax, 160832(%rsp)
	movq	67720(%rsp), %rax
	movq	%rax, 160840(%rsp)
	movq	67728(%rsp), %rax
	movq	%rax, 160848(%rsp)
	movq	67736(%rsp), %rax
	movq	%rax, 160856(%rsp)
	movq	67744(%rsp), %rax
	movq	%rax, 160864(%rsp)
	movq	67752(%rsp), %rax
	movq	%rax, 160872(%rsp)
	movq	67760(%rsp), %rax
	movq	%rax, 160880(%rsp)
	movq	67768(%rsp), %rax
	movq	%rax, 160888(%rsp)
	movq	67776(%rsp), %rax
	movq	%rax, 160896(%rsp)
	movq	67784(%rsp), %rax
	movq	%rax, 160904(%rsp)
	movq	67792(%rsp), %rax
	movq	%rax, 160912(%rsp)
	movq	67800(%rsp), %rax
	movq	%rax, 160920(%rsp)
	movq	67808(%rsp), %rax
	movq	%rax, 160928(%rsp)
	movq	67816(%rsp), %rax
	movq	%rax, 160936(%rsp)
	movq	67824(%rsp), %rax
	movq	%rax, 160944(%rsp)
	movq	67832(%rsp), %rax
	movq	%rax, 160952(%rsp)
	movq	67840(%rsp), %rax
	movq	%rax, 160960(%rsp)
	movq	67848(%rsp), %rax
	movq	%rax, 160968(%rsp)
	movq	67856(%rsp), %rax
	movq	%rax, 160976(%rsp)
	movq	67864(%rsp), %rax
	movq	%rax, 160984(%rsp)
	movq	67872(%rsp), %rax
	movq	%rax, 160992(%rsp)
	movq	67880(%rsp), %rax
	movq	%rax, 161000(%rsp)
	movq	67888(%rsp), %rax
	movq	%rax, 161008(%rsp)
	movq	67896(%rsp), %rax
	movq	%rax, 161016(%rsp)
	movq	67904(%rsp), %rax
	movq	%rax, 161024(%rsp)
	movq	67912(%rsp), %rax
	movq	%rax, 161032(%rsp)
	movq	67920(%rsp), %rax
	movq	%rax, 161040(%rsp)
	movq	67928(%rsp), %rax
	movq	%rax, 161048(%rsp)
	movq	67936(%rsp), %rax
	movq	%rax, 161056(%rsp)
	movq	67944(%rsp), %rax
	movq	%rax, 161064(%rsp)
	movq	67952(%rsp), %rax
	movq	%rax, 161072(%rsp)
	movq	67960(%rsp), %rax
	movq	%rax, 161080(%rsp)
	movq	67968(%rsp), %rax
	movq	%rax, 161088(%rsp)
	movq	67976(%rsp), %rax
	movq	%rax, 161096(%rsp)
	movq	67984(%rsp), %rax
	movq	%rax, 161104(%rsp)
	movq	67992(%rsp), %rax
	movq	%rax, 161112(%rsp)
	movq	68000(%rsp), %rax
	movq	%rax, 161120(%rsp)
	movq	68008(%rsp), %rax
	movq	%rax, 161128(%rsp)
	movq	68016(%rsp), %rax
	movq	%rax, 161136(%rsp)
	movq	68024(%rsp), %rax
	movq	%rax, 161144(%rsp)
	movq	68032(%rsp), %rax
	movq	%rax, 161152(%rsp)
	movq	68040(%rsp), %rax
	movq	%rax, 161160(%rsp)
	movq	68048(%rsp), %rax
	movq	%rax, 161168(%rsp)
	movq	68056(%rsp), %rax
	movq	%rax, 161176(%rsp)
	movq	68064(%rsp), %rax
	movq	%rax, 161184(%rsp)
	movq	68072(%rsp), %rax
	movq	%rax, 161192(%rsp)
	movq	68080(%rsp), %rax
	movq	%rax, 161200(%rsp)
	movq	68088(%rsp), %rax
	movq	%rax, 161208(%rsp)
	movq	68096(%rsp), %rax
	movq	%rax, 161216(%rsp)
	movq	68104(%rsp), %rax
	movq	%rax, 161224(%rsp)
	movq	68112(%rsp), %rax
	movq	%rax, 161232(%rsp)
	movq	68120(%rsp), %rax
	movq	%rax, 161240(%rsp)
	movq	68128(%rsp), %rax
	movq	%rax, 161248(%rsp)
	movq	68136(%rsp), %rax
	movq	%rax, 161256(%rsp)
	movq	68144(%rsp), %rax
	movq	%rax, 161264(%rsp)
	movq	68152(%rsp), %rax
	movq	%rax, 161272(%rsp)
	movq	68160(%rsp), %rax
	movq	%rax, 161280(%rsp)
	movq	68168(%rsp), %rax
	movq	%rax, 161288(%rsp)
	movq	68176(%rsp), %rax
	movq	%rax, 161296(%rsp)
	movq	68184(%rsp), %rax
	movq	%rax, 161304(%rsp)
	movq	68192(%rsp), %rax
	movq	%rax, 161312(%rsp)
	movq	68200(%rsp), %rax
	movq	%rax, 161320(%rsp)
	movq	68208(%rsp), %rax
	movq	%rax, 161328(%rsp)
	movq	68216(%rsp), %rax
	movq	%rax, 161336(%rsp)
	movq	68224(%rsp), %rax
	movq	%rax, 161344(%rsp)
	movq	68232(%rsp), %rax
	movq	%rax, 161352(%rsp)
	movq	68240(%rsp), %rax
	movq	%rax, 161360(%rsp)
	movq	68248(%rsp), %rax
	movq	%rax, 161368(%rsp)
	movq	68256(%rsp), %rax
	movq	%rax, 161376(%rsp)
	movq	68264(%rsp), %rax
	movq	%rax, 161384(%rsp)
	movq	68272(%rsp), %rax
	movq	%rax, 161392(%rsp)
	movq	68280(%rsp), %rax
	movq	%rax, 161400(%rsp)
	movq	68288(%rsp), %rax
	movq	%rax, 161408(%rsp)
	movq	68296(%rsp), %rax
	movq	%rax, 161416(%rsp)
	movq	68304(%rsp), %rax
	movq	%rax, 161424(%rsp)
	movq	68312(%rsp), %rax
	movq	%rax, 161432(%rsp)
	movq	68320(%rsp), %rax
	movq	%rax, 161440(%rsp)
	movq	68328(%rsp), %rax
	movq	%rax, 161448(%rsp)
	movq	68336(%rsp), %rax
	movq	%rax, 161456(%rsp)
	movq	68344(%rsp), %rax
	movq	%rax, 161464(%rsp)
	movq	68352(%rsp), %rax
	movq	%rax, 161472(%rsp)
	movq	68360(%rsp), %rax
	movq	%rax, 161480(%rsp)
	movq	68368(%rsp), %rax
	movq	%rax, 161488(%rsp)
	movq	68376(%rsp), %rax
	movq	%rax, 161496(%rsp)
	movq	68384(%rsp), %rax
	movq	%rax, 161504(%rsp)
	movq	68392(%rsp), %rax
	movq	%rax, 161512(%rsp)
	movq	68400(%rsp), %rax
	movq	%rax, 161520(%rsp)
	movq	68408(%rsp), %rax
	movq	%rax, 161528(%rsp)
	movq	68416(%rsp), %rax
	movq	%rax, 161536(%rsp)
	movq	68424(%rsp), %rax
	movq	%rax, 161544(%rsp)
	movq	68432(%rsp), %rax
	movq	%rax, 161552(%rsp)
	movq	68440(%rsp), %rax
	movq	%rax, 161560(%rsp)
	movq	68448(%rsp), %rax
	movq	%rax, 161568(%rsp)
	movq	68456(%rsp), %rax
	movq	%rax, 161576(%rsp)
	movq	68464(%rsp), %rax
	movq	%rax, 161584(%rsp)
	movq	68472(%rsp), %rax
	movq	%rax, 161592(%rsp)
	movq	68480(%rsp), %rax
	movq	%rax, 161600(%rsp)
	movq	68488(%rsp), %rax
	movq	%rax, 161608(%rsp)
	movq	68496(%rsp), %rax
	movq	%rax, 161616(%rsp)
	movq	68504(%rsp), %rax
	movq	%rax, 161624(%rsp)
	movq	68512(%rsp), %rax
	movq	%rax, 161632(%rsp)
	movq	68520(%rsp), %rax
	movq	%rax, 161640(%rsp)
	movq	68528(%rsp), %rax
	movq	%rax, 161648(%rsp)
	movq	68536(%rsp), %rax
	movq	%rax, 161656(%rsp)
	movq	68544(%rsp), %rax
	movq	%rax, 161664(%rsp)
	movq	68552(%rsp), %rax
	movq	%rax, 161672(%rsp)
	movq	68560(%rsp), %rax
	movq	%rax, 161680(%rsp)
	movq	68568(%rsp), %rax
	movq	%rax, 161688(%rsp)
	movq	68576(%rsp), %rax
	movq	%rax, 161696(%rsp)
	movq	68584(%rsp), %rax
	movq	%rax, 161704(%rsp)
	movq	68592(%rsp), %rax
	movq	%rax, 161712(%rsp)
	movq	68600(%rsp), %rax
	movq	%rax, 161720(%rsp)
	movq	68608(%rsp), %rax
	movq	%rax, 161728(%rsp)
	movq	68616(%rsp), %rax
	movq	%rax, 161736(%rsp)
	movq	68624(%rsp), %rax
	movq	%rax, 161744(%rsp)
	movq	68632(%rsp), %rax
	movq	%rax, 161752(%rsp)
	movq	68640(%rsp), %rax
	movq	%rax, 161760(%rsp)
	movq	68648(%rsp), %rax
	movq	%rax, 161768(%rsp)
	movq	68656(%rsp), %rax
	movq	%rax, 161776(%rsp)
	movq	68664(%rsp), %rax
	movq	%rax, 161784(%rsp)
	movq	68672(%rsp), %rax
	movq	%rax, 161792(%rsp)
	movq	68680(%rsp), %rax
	movq	%rax, 161800(%rsp)
	movq	68688(%rsp), %rax
	movq	%rax, 161808(%rsp)
	movq	68696(%rsp), %rax
	movq	%rax, 161816(%rsp)
	movq	68704(%rsp), %rax
	movq	%rax, 161824(%rsp)
	movq	68712(%rsp), %rax
	movq	%rax, 161832(%rsp)
	movq	68720(%rsp), %rax
	movq	%rax, 161840(%rsp)
	movq	68728(%rsp), %rax
	movq	%rax, 161848(%rsp)
	movq	68736(%rsp), %rax
	movq	%rax, 161856(%rsp)
	movq	68744(%rsp), %rax
	movq	%rax, 161864(%rsp)
	movq	68752(%rsp), %rax
	movq	%rax, 161872(%rsp)
	movq	68760(%rsp), %rax
	movq	%rax, 161880(%rsp)
	movq	68768(%rsp), %rax
	movq	%rax, 161888(%rsp)
	movq	68776(%rsp), %rax
	movq	%rax, 161896(%rsp)
	movq	68784(%rsp), %rax
	movq	%rax, 161904(%rsp)
	movq	68792(%rsp), %rax
	movq	%rax, 161912(%rsp)
	movq	68800(%rsp), %rax
	movq	%rax, 161920(%rsp)
	movq	68808(%rsp), %rax
	movq	%rax, 161928(%rsp)
	movq	68816(%rsp), %rax
	movq	%rax, 161936(%rsp)
	movq	68824(%rsp), %rax
	movq	%rax, 161944(%rsp)
	movq	68832(%rsp), %rax
	movq	%rax, 161952(%rsp)
	movq	68840(%rsp), %rax
	movq	%rax, 161960(%rsp)
	movq	68848(%rsp), %rax
	movq	%rax, 161968(%rsp)
	movq	68856(%rsp), %rax
	movq	%rax, 161976(%rsp)
	movq	68864(%rsp), %rax
	movq	%rax, 161984(%rsp)
	movq	68872(%rsp), %rax
	movq	%rax, 161992(%rsp)
	movq	68880(%rsp), %rax
	movq	%rax, 162000(%rsp)
	movq	68888(%rsp), %rax
	movq	%rax, 162008(%rsp)
	movq	68896(%rsp), %rax
	movq	%rax, 162016(%rsp)
	movq	68904(%rsp), %rax
	movq	%rax, 162024(%rsp)
	movq	68912(%rsp), %rax
	movq	%rax, 162032(%rsp)
	movq	68920(%rsp), %rax
	movq	%rax, 162040(%rsp)
	movq	68928(%rsp), %rax
	movq	%rax, 162048(%rsp)
	movq	68936(%rsp), %rax
	movq	%rax, 162056(%rsp)
	movq	68944(%rsp), %rax
	movq	%rax, 162064(%rsp)
	movq	68952(%rsp), %rax
	movq	%rax, 162072(%rsp)
	movq	68960(%rsp), %rax
	movq	%rax, 162080(%rsp)
	movq	68968(%rsp), %rax
	movq	%rax, 162088(%rsp)
	movq	68976(%rsp), %rax
	movq	%rax, 162096(%rsp)
	movq	68984(%rsp), %rax
	movq	%rax, 162104(%rsp)
	movq	68992(%rsp), %rax
	movq	%rax, 162112(%rsp)
	movq	69000(%rsp), %rax
	movq	%rax, 162120(%rsp)
	movq	69008(%rsp), %rax
	movq	%rax, 162128(%rsp)
	movq	69016(%rsp), %rax
	movq	%rax, 162136(%rsp)
	movq	69024(%rsp), %rax
	movq	%rax, 162144(%rsp)
	movq	69032(%rsp), %rax
	movq	%rax, 162152(%rsp)
	movq	69040(%rsp), %rax
	movq	%rax, 162160(%rsp)
	movq	69048(%rsp), %rax
	movq	%rax, 162168(%rsp)
	movq	69056(%rsp), %rax
	movq	%rax, 162176(%rsp)
	movq	69064(%rsp), %rax
	movq	%rax, 162184(%rsp)
	movq	69072(%rsp), %rax
	movq	%rax, 162192(%rsp)
	movq	69080(%rsp), %rax
	movq	%rax, 162200(%rsp)
	movq	69088(%rsp), %rax
	movq	%rax, 162208(%rsp)
	movq	69096(%rsp), %rax
	movq	%rax, 162216(%rsp)
	movq	69104(%rsp), %rax
	movq	%rax, 162224(%rsp)
	movq	69112(%rsp), %rax
	movq	%rax, 162232(%rsp)
	movq	69120(%rsp), %rax
	movq	%rax, 162240(%rsp)
	movq	69128(%rsp), %rax
	movq	%rax, 162248(%rsp)
	movq	69136(%rsp), %rax
	movq	%rax, 162256(%rsp)
	movq	69144(%rsp), %rax
	movq	%rax, 162264(%rsp)
	movq	69152(%rsp), %rax
	movq	%rax, 162272(%rsp)
	movq	69160(%rsp), %rax
	movq	%rax, 162280(%rsp)
	movq	69168(%rsp), %rax
	movq	%rax, 162288(%rsp)
	movq	69176(%rsp), %rax
	movq	%rax, 162296(%rsp)
	movq	69184(%rsp), %rax
	movq	%rax, 162304(%rsp)
	movq	69192(%rsp), %rax
	movq	%rax, 162312(%rsp)
	movq	69200(%rsp), %rax
	movq	%rax, 162320(%rsp)
	movq	69208(%rsp), %rax
	movq	%rax, 162328(%rsp)
	movq	69216(%rsp), %rax
	movq	%rax, 162336(%rsp)
	movq	69224(%rsp), %rax
	movq	%rax, 162344(%rsp)
	movq	69232(%rsp), %rax
	movq	%rax, 162352(%rsp)
	movq	69240(%rsp), %rax
	movq	%rax, 162360(%rsp)
	movq	69248(%rsp), %rax
	movq	%rax, 162368(%rsp)
	movq	69256(%rsp), %rax
	movq	%rax, 162376(%rsp)
	movq	69264(%rsp), %rax
	movq	%rax, 162384(%rsp)
	movq	69272(%rsp), %rax
	movq	%rax, 162392(%rsp)
	movq	69280(%rsp), %rax
	movq	%rax, 162400(%rsp)
	movq	69288(%rsp), %rax
	movq	%rax, 162408(%rsp)
	movq	69296(%rsp), %rax
	movq	%rax, 162416(%rsp)
	movq	69304(%rsp), %rax
	movq	%rax, 162424(%rsp)
	movq	69312(%rsp), %rax
	movq	%rax, 162432(%rsp)
	movq	69320(%rsp), %rax
	movq	%rax, 162440(%rsp)
	movq	69328(%rsp), %rax
	movq	%rax, 162448(%rsp)
	movq	69336(%rsp), %rax
	movq	%rax, 162456(%rsp)
	movq	69344(%rsp), %rax
	movq	%rax, 162464(%rsp)
	movq	69352(%rsp), %rax
	movq	%rax, 162472(%rsp)
	movq	69360(%rsp), %rax
	movq	%rax, 162480(%rsp)
	movq	69368(%rsp), %rax
	movq	%rax, 162488(%rsp)
	movq	69376(%rsp), %rax
	movq	%rax, 162496(%rsp)
	movq	69384(%rsp), %rax
	movq	%rax, 162504(%rsp)
	movq	69392(%rsp), %rax
	movq	%rax, 162512(%rsp)
	movq	69400(%rsp), %rax
	movq	%rax, 162520(%rsp)
	movq	69408(%rsp), %rax
	movq	%rax, 162528(%rsp)
	movq	69416(%rsp), %rax
	movq	%rax, 162536(%rsp)
	movq	69424(%rsp), %rax
	movq	%rax, 162544(%rsp)
	movq	69432(%rsp), %rax
	movq	%rax, 162552(%rsp)
	movq	69440(%rsp), %rax
	movq	%rax, 162560(%rsp)
	movq	69448(%rsp), %rax
	movq	%rax, 162568(%rsp)
	movq	69456(%rsp), %rax
	movq	%rax, 162576(%rsp)
	movq	69464(%rsp), %rax
	movq	%rax, 162584(%rsp)
	movq	69472(%rsp), %rax
	movq	%rax, 162592(%rsp)
	movq	69480(%rsp), %rax
	movq	%rax, 162600(%rsp)
	movq	69488(%rsp), %rax
	movq	%rax, 162608(%rsp)
	movq	69496(%rsp), %rax
	movq	%rax, 162616(%rsp)
	movq	69504(%rsp), %rax
	movq	%rax, 162624(%rsp)
	movq	69512(%rsp), %rax
	movq	%rax, 162632(%rsp)
	movq	69520(%rsp), %rax
	movq	%rax, 162640(%rsp)
	movq	69528(%rsp), %rax
	movq	%rax, 162648(%rsp)
	movq	69536(%rsp), %rax
	movq	%rax, 162656(%rsp)
	movq	69544(%rsp), %rax
	movq	%rax, 162664(%rsp)
	movq	69552(%rsp), %rax
	movq	%rax, 162672(%rsp)
	movq	69560(%rsp), %rax
	movq	%rax, 162680(%rsp)
	movq	69568(%rsp), %rax
	movq	%rax, 162688(%rsp)
	movq	69576(%rsp), %rax
	movq	%rax, 162696(%rsp)
	movq	69584(%rsp), %rax
	movq	%rax, 162704(%rsp)
	movq	69592(%rsp), %rax
	movq	%rax, 162712(%rsp)
	movq	69600(%rsp), %rax
	movq	%rax, 162720(%rsp)
	movq	69608(%rsp), %rax
	movq	%rax, 162728(%rsp)
	movq	69616(%rsp), %rax
	movq	%rax, 162736(%rsp)
	movq	69624(%rsp), %rax
	movq	%rax, 162744(%rsp)
	movq	69632(%rsp), %rax
	movq	%rax, 162752(%rsp)
	movq	69640(%rsp), %rax
	movq	%rax, 162760(%rsp)
	movq	69648(%rsp), %rax
	movq	%rax, 162768(%rsp)
	movq	69656(%rsp), %rax
	movq	%rax, 162776(%rsp)
	movq	69664(%rsp), %rax
	movq	%rax, 162784(%rsp)
	movq	69672(%rsp), %rax
	movq	%rax, 162792(%rsp)
	movq	69680(%rsp), %rax
	movq	%rax, 162800(%rsp)
	movq	69688(%rsp), %rax
	movq	%rax, 162808(%rsp)
	movq	69696(%rsp), %rax
	movq	%rax, 162816(%rsp)
	movq	69704(%rsp), %rax
	movq	%rax, 162824(%rsp)
	movq	69712(%rsp), %rax
	movq	%rax, 162832(%rsp)
	movq	69720(%rsp), %rax
	movq	%rax, 162840(%rsp)
	movq	69728(%rsp), %rax
	movq	%rax, 162848(%rsp)
	movq	69736(%rsp), %rax
	movq	%rax, 162856(%rsp)
	movq	69744(%rsp), %rax
	movq	%rax, 162864(%rsp)
	movq	69752(%rsp), %rax
	movq	%rax, 162872(%rsp)
	movq	69760(%rsp), %rax
	movq	%rax, 162880(%rsp)
	movq	69768(%rsp), %rax
	movq	%rax, 162888(%rsp)
	movq	69776(%rsp), %rax
	movq	%rax, 162896(%rsp)
	movq	69784(%rsp), %rax
	movq	%rax, 162904(%rsp)
	movq	69792(%rsp), %rax
	movq	%rax, 162912(%rsp)
	movq	69800(%rsp), %rax
	movq	%rax, 162920(%rsp)
	movq	69808(%rsp), %rax
	movq	%rax, 162928(%rsp)
	movq	69816(%rsp), %rax
	movq	%rax, 162936(%rsp)
	movq	69824(%rsp), %rax
	movq	%rax, 162944(%rsp)
	movq	69832(%rsp), %rax
	movq	%rax, 162952(%rsp)
	movq	69840(%rsp), %rax
	movq	%rax, 162960(%rsp)
	movq	69848(%rsp), %rax
	movq	%rax, 162968(%rsp)
	movq	69856(%rsp), %rax
	movq	%rax, 162976(%rsp)
	movq	69864(%rsp), %rax
	movq	%rax, 162984(%rsp)
	movq	69872(%rsp), %rax
	movq	%rax, 162992(%rsp)
	movq	69880(%rsp), %rax
	movq	%rax, 163000(%rsp)
	movq	69888(%rsp), %rax
	movq	%rax, 163008(%rsp)
	movq	69896(%rsp), %rax
	movq	%rax, 163016(%rsp)
	movq	69904(%rsp), %rax
	movq	%rax, 163024(%rsp)
	movq	69912(%rsp), %rax
	movq	%rax, 163032(%rsp)
	movq	69920(%rsp), %rax
	movq	%rax, 163040(%rsp)
	movq	69928(%rsp), %rax
	movq	%rax, 163048(%rsp)
	movq	69936(%rsp), %rax
	movq	%rax, 163056(%rsp)
	movq	69944(%rsp), %rax
	movq	%rax, 163064(%rsp)
	movq	69952(%rsp), %rax
	movq	%rax, 163072(%rsp)
	movq	69960(%rsp), %rax
	movq	%rax, 163080(%rsp)
	movq	69968(%rsp), %rax
	movq	%rax, 163088(%rsp)
	movq	69976(%rsp), %rax
	movq	%rax, 163096(%rsp)
	movq	69984(%rsp), %rax
	movq	%rax, 163104(%rsp)
	movq	69992(%rsp), %rax
	movq	%rax, 163112(%rsp)
	movq	70000(%rsp), %rax
	movq	%rax, 163120(%rsp)
	movq	70008(%rsp), %rax
	movq	%rax, 163128(%rsp)
	movq	70016(%rsp), %rax
	movq	%rax, 163136(%rsp)
	movq	70024(%rsp), %rax
	movq	%rax, 163144(%rsp)
	movq	70032(%rsp), %rax
	movq	%rax, 163152(%rsp)
	movq	70040(%rsp), %rax
	movq	%rax, 163160(%rsp)
	movq	70048(%rsp), %rax
	movq	%rax, 163168(%rsp)
	movq	70056(%rsp), %rax
	movq	%rax, 163176(%rsp)
	movq	70064(%rsp), %rax
	movq	%rax, 163184(%rsp)
	movq	70072(%rsp), %rax
	movq	%rax, 163192(%rsp)
	movq	70080(%rsp), %rax
	movq	%rax, 163200(%rsp)
	movq	70088(%rsp), %rax
	movq	%rax, 163208(%rsp)
	movq	70096(%rsp), %rax
	movq	%rax, 163216(%rsp)
	movq	70104(%rsp), %rax
	movq	%rax, 163224(%rsp)
	movq	70112(%rsp), %rax
	movq	%rax, 163232(%rsp)
	movq	70120(%rsp), %rax
	movq	%rax, 163240(%rsp)
	movq	70128(%rsp), %rax
	movq	%rax, 163248(%rsp)
	movq	70136(%rsp), %rax
	movq	%rax, 163256(%rsp)
	movq	70144(%rsp), %rax
	movq	%rax, 163264(%rsp)
	movq	70152(%rsp), %rax
	movq	%rax, 163272(%rsp)
	movq	70160(%rsp), %rax
	movq	%rax, 163280(%rsp)
	movq	70168(%rsp), %rax
	movq	%rax, 163288(%rsp)
	movq	70176(%rsp), %rax
	movq	%rax, 163296(%rsp)
	movq	70184(%rsp), %rax
	movq	%rax, 163304(%rsp)
	movq	70192(%rsp), %rax
	movq	%rax, 163312(%rsp)
	movq	70200(%rsp), %rax
	movq	%rax, 163320(%rsp)
	movq	70208(%rsp), %rax
	movq	%rax, 163328(%rsp)
	movq	70216(%rsp), %rax
	movq	%rax, 163336(%rsp)
	movq	70224(%rsp), %rax
	movq	%rax, 163344(%rsp)
	movq	70232(%rsp), %rax
	movq	%rax, 163352(%rsp)
	movq	70240(%rsp), %rax
	movq	%rax, 163360(%rsp)
	movq	70248(%rsp), %rax
	movq	%rax, 163368(%rsp)
	movq	70256(%rsp), %rax
	movq	%rax, 163376(%rsp)
	movq	70264(%rsp), %rax
	movq	%rax, 163384(%rsp)
	movq	70272(%rsp), %rax
	movq	%rax, 163392(%rsp)
	movq	70280(%rsp), %rax
	movq	%rax, 163400(%rsp)
	movq	70288(%rsp), %rax
	movq	%rax, 163408(%rsp)
	movq	70296(%rsp), %rax
	movq	%rax, 163416(%rsp)
	movq	70304(%rsp), %rax
	movq	%rax, 163424(%rsp)
	movq	70312(%rsp), %rax
	movq	%rax, 163432(%rsp)
	movq	70320(%rsp), %rax
	movq	%rax, 163440(%rsp)
	movq	70328(%rsp), %rax
	movq	%rax, 163448(%rsp)
	movq	70336(%rsp), %rax
	movq	%rax, 163456(%rsp)
	movq	70344(%rsp), %rax
	movq	%rax, 163464(%rsp)
	movq	70352(%rsp), %rax
	movq	%rax, 163472(%rsp)
	movq	70360(%rsp), %rax
	movq	%rax, 163480(%rsp)
	movq	70368(%rsp), %rax
	movq	%rax, 163488(%rsp)
	movq	70376(%rsp), %rax
	movq	%rax, 163496(%rsp)
	movq	70384(%rsp), %rax
	movq	%rax, 163504(%rsp)
	movq	70392(%rsp), %rax
	movq	%rax, 163512(%rsp)
	movq	70400(%rsp), %rax
	movq	%rax, 163520(%rsp)
	movq	70408(%rsp), %rax
	movq	%rax, 163528(%rsp)
	movq	70416(%rsp), %rax
	movq	%rax, 163536(%rsp)
	movq	70424(%rsp), %rax
	movq	%rax, 163544(%rsp)
	movq	70432(%rsp), %rax
	movq	%rax, 163552(%rsp)
	movq	70440(%rsp), %rax
	movq	%rax, 163560(%rsp)
	movq	70448(%rsp), %rax
	movq	%rax, 163568(%rsp)
	movq	70456(%rsp), %rax
	movq	%rax, 163576(%rsp)
	movq	70464(%rsp), %rax
	movq	%rax, 163584(%rsp)
	movq	70472(%rsp), %rax
	movq	%rax, 163592(%rsp)
	movq	70480(%rsp), %rax
	movq	%rax, 163600(%rsp)
	movq	70488(%rsp), %rax
	movq	%rax, 163608(%rsp)
	movq	70496(%rsp), %rax
	movq	%rax, 163616(%rsp)
	movq	70504(%rsp), %rax
	movq	%rax, 163624(%rsp)
	movq	70512(%rsp), %rax
	movq	%rax, 163632(%rsp)
	movq	70520(%rsp), %rax
	movq	%rax, 163640(%rsp)
	movq	70528(%rsp), %rax
	movq	%rax, 163648(%rsp)
	movq	70536(%rsp), %rax
	movq	%rax, 163656(%rsp)
	movq	70544(%rsp), %rax
	movq	%rax, 163664(%rsp)
	movq	70552(%rsp), %rax
	movq	%rax, 163672(%rsp)
	movq	70560(%rsp), %rax
	movq	%rax, 163680(%rsp)
	movq	70568(%rsp), %rax
	movq	%rax, 163688(%rsp)
	movq	70576(%rsp), %rax
	movq	%rax, 163696(%rsp)
	movq	70584(%rsp), %rax
	movq	%rax, 163704(%rsp)
	movq	70592(%rsp), %rax
	movq	%rax, 163712(%rsp)
	movq	70600(%rsp), %rax
	movq	%rax, 163720(%rsp)
	movq	70608(%rsp), %rax
	movq	%rax, 163728(%rsp)
	movq	70616(%rsp), %rax
	movq	%rax, 163736(%rsp)
	movq	70624(%rsp), %rax
	movq	%rax, 163744(%rsp)
	movq	70632(%rsp), %rax
	movq	%rax, 163752(%rsp)
	movq	70640(%rsp), %rax
	movq	%rax, 163760(%rsp)
	movq	70648(%rsp), %rax
	movq	%rax, 163768(%rsp)
	movq	70656(%rsp), %rax
	movq	%rax, 163776(%rsp)
	movq	70664(%rsp), %rax
	movq	%rax, 163784(%rsp)
	movq	70672(%rsp), %rax
	movq	%rax, 163792(%rsp)
	movq	70680(%rsp), %rax
	movq	%rax, 163800(%rsp)
	movq	70688(%rsp), %rax
	movq	%rax, 163808(%rsp)
	movq	70696(%rsp), %rax
	movq	%rax, 163816(%rsp)
	movq	70704(%rsp), %rax
	movq	%rax, 163824(%rsp)
	movq	70712(%rsp), %rax
	movq	%rax, 163832(%rsp)
	movq	70720(%rsp), %rax
	movq	%rax, 163840(%rsp)
	movq	70728(%rsp), %rax
	movq	%rax, 163848(%rsp)
	movq	70736(%rsp), %rax
	movq	%rax, 163856(%rsp)
	movq	70744(%rsp), %rax
	movq	%rax, 163864(%rsp)
	movq	70752(%rsp), %rax
	movq	%rax, 163872(%rsp)
	movq	70760(%rsp), %rax
	movq	%rax, 163880(%rsp)
	movq	70768(%rsp), %rax
	movq	%rax, 163888(%rsp)
	movq	70776(%rsp), %rax
	movq	%rax, 163896(%rsp)
	movq	70784(%rsp), %rax
	movq	%rax, 163904(%rsp)
	movq	70792(%rsp), %rax
	movq	%rax, 163912(%rsp)
	movq	70800(%rsp), %rax
	movq	%rax, 163920(%rsp)
	movq	70808(%rsp), %rax
	movq	%rax, 163928(%rsp)
	movq	70816(%rsp), %rax
	movq	%rax, 163936(%rsp)
	movq	70824(%rsp), %rax
	movq	%rax, 163944(%rsp)
	movq	70832(%rsp), %rax
	movq	%rax, 163952(%rsp)
	movq	70840(%rsp), %rax
	movq	%rax, 163960(%rsp)
	movq	70848(%rsp), %rax
	movq	%rax, 163968(%rsp)
	movq	70856(%rsp), %rax
	movq	%rax, 163976(%rsp)
	movq	70864(%rsp), %rax
	movq	%rax, 163984(%rsp)
	movq	70872(%rsp), %rax
	movq	%rax, 163992(%rsp)
	movq	70880(%rsp), %rax
	movq	%rax, 164000(%rsp)
	movq	70888(%rsp), %rax
	movq	%rax, 164008(%rsp)
	movq	70896(%rsp), %rax
	movq	%rax, 164016(%rsp)
	movq	70904(%rsp), %rax
	movq	%rax, 164024(%rsp)
	movq	70912(%rsp), %rax
	movq	%rax, 164032(%rsp)
	movq	70920(%rsp), %rax
	movq	%rax, 164040(%rsp)
	movq	70928(%rsp), %rax
	movq	%rax, 164048(%rsp)
	movq	70936(%rsp), %rax
	movq	%rax, 164056(%rsp)
	movq	70944(%rsp), %rax
	movq	%rax, 164064(%rsp)
	movq	70952(%rsp), %rax
	movq	%rax, 164072(%rsp)
	movq	70960(%rsp), %rax
	movq	%rax, 164080(%rsp)
	movq	70968(%rsp), %rax
	movq	%rax, 164088(%rsp)
	movq	70976(%rsp), %rax
	movq	%rax, 164096(%rsp)
	movq	70984(%rsp), %rax
	movq	%rax, 164104(%rsp)
	movq	70992(%rsp), %rax
	movq	%rax, 164112(%rsp)
	movq	71000(%rsp), %rax
	movq	%rax, 164120(%rsp)
	movq	71008(%rsp), %rax
	movq	%rax, 164128(%rsp)
	movq	71016(%rsp), %rax
	movq	%rax, 164136(%rsp)
	movq	71024(%rsp), %rax
	movq	%rax, 164144(%rsp)
	movq	71032(%rsp), %rax
	movq	%rax, 164152(%rsp)
	movq	71040(%rsp), %rax
	movq	%rax, 164160(%rsp)
	movq	71048(%rsp), %rax
	movq	%rax, 164168(%rsp)
	movq	71056(%rsp), %rax
	movq	%rax, 164176(%rsp)
	movq	71064(%rsp), %rax
	movq	%rax, 164184(%rsp)
	movq	71072(%rsp), %rax
	movq	%rax, 164192(%rsp)
	movq	71080(%rsp), %rax
	movq	%rax, 164200(%rsp)
	movq	71088(%rsp), %rax
	movq	%rax, 164208(%rsp)
	movq	71096(%rsp), %rax
	movq	%rax, 164216(%rsp)
	movq	71104(%rsp), %rax
	movq	%rax, 164224(%rsp)
	movq	71112(%rsp), %rax
	movq	%rax, 164232(%rsp)
	movq	71120(%rsp), %rax
	movq	%rax, 164240(%rsp)
	movq	71128(%rsp), %rax
	movq	%rax, 164248(%rsp)
	movq	71136(%rsp), %rax
	movq	%rax, 164256(%rsp)
	movq	71144(%rsp), %rax
	movq	%rax, 164264(%rsp)
	movq	71152(%rsp), %rax
	movq	%rax, 164272(%rsp)
	movq	71160(%rsp), %rax
	movq	%rax, 164280(%rsp)
	movq	71168(%rsp), %rax
	movq	%rax, 164288(%rsp)
	movq	71176(%rsp), %rax
	movq	%rax, 164296(%rsp)
	movq	71184(%rsp), %rax
	movq	%rax, 164304(%rsp)
	movq	71192(%rsp), %rax
	movq	%rax, 164312(%rsp)
	movq	71200(%rsp), %rax
	movq	%rax, 164320(%rsp)
	movq	71208(%rsp), %rax
	movq	%rax, 164328(%rsp)
	movq	71216(%rsp), %rax
	movq	%rax, 164336(%rsp)
	movq	71224(%rsp), %rax
	movq	%rax, 164344(%rsp)
	movq	71232(%rsp), %rax
	movq	%rax, 164352(%rsp)
	movq	71240(%rsp), %rax
	movq	%rax, 164360(%rsp)
	movq	71248(%rsp), %rax
	movq	%rax, 164368(%rsp)
	movq	71256(%rsp), %rax
	movq	%rax, 164376(%rsp)
	movq	71264(%rsp), %rax
	movq	%rax, 164384(%rsp)
	movq	71272(%rsp), %rax
	movq	%rax, 164392(%rsp)
	movq	71280(%rsp), %rax
	movq	%rax, 164400(%rsp)
	movq	71288(%rsp), %rax
	movq	%rax, 164408(%rsp)
	movq	71296(%rsp), %rax
	movq	%rax, 164416(%rsp)
	movq	71304(%rsp), %rax
	movq	%rax, 164424(%rsp)
	movq	71312(%rsp), %rax
	movq	%rax, 164432(%rsp)
	movq	71320(%rsp), %rax
	movq	%rax, 164440(%rsp)
	movq	71328(%rsp), %rax
	movq	%rax, 164448(%rsp)
	movq	71336(%rsp), %rax
	movq	%rax, 164456(%rsp)
	movq	71344(%rsp), %rax
	movq	%rax, 164464(%rsp)
	movq	71352(%rsp), %rax
	movq	%rax, 164472(%rsp)
	movq	71360(%rsp), %rax
	movq	%rax, 164480(%rsp)
	movq	71368(%rsp), %rax
	movq	%rax, 164488(%rsp)
	movq	71376(%rsp), %rax
	movq	%rax, 164496(%rsp)
	movq	71384(%rsp), %rax
	movq	%rax, 164504(%rsp)
	movq	71392(%rsp), %rax
	movq	%rax, 164512(%rsp)
	movq	71400(%rsp), %rax
	movq	%rax, 164520(%rsp)
	movq	71408(%rsp), %rax
	movq	%rax, 164528(%rsp)
	movq	71416(%rsp), %rax
	movq	%rax, 164536(%rsp)
	movq	71424(%rsp), %rax
	movq	%rax, 164544(%rsp)
	movq	71432(%rsp), %rax
	movq	%rax, 164552(%rsp)
	movq	71440(%rsp), %rax
	movq	%rax, 164560(%rsp)
	movq	71448(%rsp), %rax
	movq	%rax, 164568(%rsp)
	movq	71456(%rsp), %rax
	movq	%rax, 164576(%rsp)
	movq	71464(%rsp), %rax
	movq	%rax, 164584(%rsp)
	movq	71472(%rsp), %rax
	movq	%rax, 164592(%rsp)
	movq	71480(%rsp), %rax
	movq	%rax, 164600(%rsp)
	movq	71488(%rsp), %rax
	movq	%rax, 164608(%rsp)
	movq	71496(%rsp), %rax
	movq	%rax, 164616(%rsp)
	movq	71504(%rsp), %rax
	movq	%rax, 164624(%rsp)
	movq	71512(%rsp), %rax
	movq	%rax, 164632(%rsp)
	movq	71520(%rsp), %rax
	movq	%rax, 164640(%rsp)
	movq	71528(%rsp), %rax
	movq	%rax, 164648(%rsp)
	movq	71536(%rsp), %rax
	movq	%rax, 164656(%rsp)
	movq	71544(%rsp), %rax
	movq	%rax, 164664(%rsp)
	movq	71552(%rsp), %rax
	movq	%rax, 164672(%rsp)
	movq	71560(%rsp), %rax
	movq	%rax, 164680(%rsp)
	movq	71568(%rsp), %rax
	movq	%rax, 164688(%rsp)
	movq	71576(%rsp), %rax
	movq	%rax, 164696(%rsp)
	movq	71584(%rsp), %rax
	movq	%rax, 164704(%rsp)
	movq	71592(%rsp), %rax
	movq	%rax, 164712(%rsp)
	movq	71600(%rsp), %rax
	movq	%rax, 164720(%rsp)
	movq	71608(%rsp), %rax
	movq	%rax, 164728(%rsp)
	movq	71616(%rsp), %rax
	movq	%rax, 164736(%rsp)
	movq	71624(%rsp), %rax
	movq	%rax, 164744(%rsp)
	movq	71632(%rsp), %rax
	movq	%rax, 164752(%rsp)
	movq	71640(%rsp), %rax
	movq	%rax, 164760(%rsp)
	movq	71648(%rsp), %rax
	movq	%rax, 164768(%rsp)
	movq	71656(%rsp), %rax
	movq	%rax, 164776(%rsp)
	movq	71664(%rsp), %rax
	movq	%rax, 164784(%rsp)
	movq	71672(%rsp), %rax
	movq	%rax, 164792(%rsp)
	movq	71680(%rsp), %rax
	movq	%rax, 164800(%rsp)
	movq	71688(%rsp), %rax
	movq	%rax, 164808(%rsp)
	movq	71696(%rsp), %rax
	movq	%rax, 164816(%rsp)
	movq	71704(%rsp), %rax
	movq	%rax, 164824(%rsp)
	movq	71712(%rsp), %rax
	movq	%rax, 164832(%rsp)
	movq	71720(%rsp), %rax
	movq	%rax, 164840(%rsp)
	movq	71728(%rsp), %rax
	movq	%rax, 164848(%rsp)
	movq	71736(%rsp), %rax
	movq	%rax, 164856(%rsp)
	movq	71744(%rsp), %rax
	movq	%rax, 164864(%rsp)
	movq	71752(%rsp), %rax
	movq	%rax, 164872(%rsp)
	movq	71760(%rsp), %rax
	movq	%rax, 164880(%rsp)
	movq	71768(%rsp), %rax
	movq	%rax, 164888(%rsp)
	movq	71776(%rsp), %rax
	movq	%rax, 164896(%rsp)
	movq	71784(%rsp), %rax
	movq	%rax, 164904(%rsp)
	movq	71792(%rsp), %rax
	movq	%rax, 164912(%rsp)
	movq	71800(%rsp), %rax
	movq	%rax, 164920(%rsp)
	movq	71808(%rsp), %rax
	movq	%rax, 164928(%rsp)
	movq	71816(%rsp), %rax
	movq	%rax, 164936(%rsp)
	movq	71824(%rsp), %rax
	movq	%rax, 164944(%rsp)
	movq	71832(%rsp), %rax
	movq	%rax, 164952(%rsp)
	movq	71840(%rsp), %rax
	movq	%rax, 164960(%rsp)
	movq	71848(%rsp), %rax
	movq	%rax, 164968(%rsp)
	movq	71856(%rsp), %rax
	movq	%rax, 164976(%rsp)
	movq	71864(%rsp), %rax
	movq	%rax, 164984(%rsp)
	movq	71872(%rsp), %rax
	movq	%rax, 164992(%rsp)
	movq	71880(%rsp), %rax
	movq	%rax, 165000(%rsp)
	movq	71888(%rsp), %rax
	movq	%rax, 165008(%rsp)
	movq	71896(%rsp), %rax
	movq	%rax, 165016(%rsp)
	movq	71904(%rsp), %rax
	movq	%rax, 165024(%rsp)
	movq	71912(%rsp), %rax
	movq	%rax, 165032(%rsp)
	movq	71920(%rsp), %rax
	movq	%rax, 165040(%rsp)
	movq	71928(%rsp), %rax
	movq	%rax, 165048(%rsp)
	movq	71936(%rsp), %rax
	movq	%rax, 165056(%rsp)
	movq	71944(%rsp), %rax
	movq	%rax, 165064(%rsp)
	movq	71952(%rsp), %rax
	movq	%rax, 165072(%rsp)
	movq	71960(%rsp), %rax
	movq	%rax, 165080(%rsp)
	movq	71968(%rsp), %rax
	movq	%rax, 165088(%rsp)
	movq	71976(%rsp), %rax
	movq	%rax, 165096(%rsp)
	movq	71984(%rsp), %rax
	movq	%rax, 165104(%rsp)
	movq	71992(%rsp), %rax
	movq	%rax, 165112(%rsp)
	movq	72000(%rsp), %rax
	movq	%rax, 165120(%rsp)
	movq	72008(%rsp), %rax
	movq	%rax, 165128(%rsp)
	movq	72016(%rsp), %rax
	movq	%rax, 165136(%rsp)
	movq	72024(%rsp), %rax
	movq	%rax, 165144(%rsp)
	movq	72032(%rsp), %rax
	movq	%rax, 165152(%rsp)
	movq	72040(%rsp), %rax
	movq	%rax, 165160(%rsp)
	movq	72048(%rsp), %rax
	movq	%rax, 165168(%rsp)
	movq	72056(%rsp), %rax
	movq	%rax, 165176(%rsp)
	movq	72064(%rsp), %rax
	movq	%rax, 165184(%rsp)
	movq	72072(%rsp), %rax
	movq	%rax, 165192(%rsp)
	movq	72080(%rsp), %rax
	movq	%rax, 165200(%rsp)
	movq	72088(%rsp), %rax
	movq	%rax, 165208(%rsp)
	movq	72096(%rsp), %rax
	movq	%rax, 165216(%rsp)
	movq	72104(%rsp), %rax
	movq	%rax, 165224(%rsp)
	movq	72112(%rsp), %rax
	movq	%rax, 165232(%rsp)
	movq	72120(%rsp), %rax
	movq	%rax, 165240(%rsp)
	movq	72128(%rsp), %rax
	movq	%rax, 165248(%rsp)
	movq	72136(%rsp), %rax
	movq	%rax, 165256(%rsp)
	movq	72144(%rsp), %rax
	movq	%rax, 165264(%rsp)
	movq	72152(%rsp), %rax
	movq	%rax, 165272(%rsp)
	movq	72160(%rsp), %rax
	movq	%rax, 165280(%rsp)
	movq	72168(%rsp), %rax
	movq	%rax, 165288(%rsp)
	movq	72176(%rsp), %rax
	movq	%rax, 165296(%rsp)
	movq	72184(%rsp), %rax
	movq	%rax, 165304(%rsp)
	movq	72192(%rsp), %rax
	movq	%rax, 165312(%rsp)
	movq	72200(%rsp), %rax
	movq	%rax, 165320(%rsp)
	movq	72208(%rsp), %rax
	movq	%rax, 165328(%rsp)
	movq	72216(%rsp), %rax
	movq	%rax, 165336(%rsp)
	movq	72224(%rsp), %rax
	movq	%rax, 165344(%rsp)
	movq	72232(%rsp), %rax
	movq	%rax, 165352(%rsp)
	movq	72240(%rsp), %rax
	movq	%rax, 165360(%rsp)
	movq	72248(%rsp), %rax
	movq	%rax, 165368(%rsp)
	movq	72256(%rsp), %rax
	movq	%rax, 165376(%rsp)
	movq	72264(%rsp), %rax
	movq	%rax, 165384(%rsp)
	movq	72272(%rsp), %rax
	movq	%rax, 165392(%rsp)
	movq	72280(%rsp), %rax
	movq	%rax, 165400(%rsp)
	movq	72288(%rsp), %rax
	movq	%rax, 165408(%rsp)
	movq	72296(%rsp), %rax
	movq	%rax, 165416(%rsp)
	movq	72304(%rsp), %rax
	movq	%rax, 165424(%rsp)
	movq	72312(%rsp), %rax
	movq	%rax, 165432(%rsp)
	movq	72320(%rsp), %rax
	movq	%rax, 165440(%rsp)
	movq	72328(%rsp), %rax
	movq	%rax, 165448(%rsp)
	movq	72336(%rsp), %rax
	movq	%rax, 165456(%rsp)
	movq	72344(%rsp), %rax
	movq	%rax, 165464(%rsp)
	movq	72352(%rsp), %rax
	movq	%rax, 165472(%rsp)
	movq	72360(%rsp), %rax
	movq	%rax, 165480(%rsp)
	movq	72368(%rsp), %rax
	movq	%rax, 165488(%rsp)
	movq	72376(%rsp), %rax
	movq	%rax, 165496(%rsp)
	movq	72384(%rsp), %rax
	movq	%rax, 165504(%rsp)
	movq	72392(%rsp), %rax
	movq	%rax, 165512(%rsp)
	movq	72400(%rsp), %rax
	movq	%rax, 165520(%rsp)
	movq	72408(%rsp), %rax
	movq	%rax, 165528(%rsp)
	movq	72416(%rsp), %rax
	movq	%rax, 165536(%rsp)
	movq	72424(%rsp), %rax
	movq	%rax, 165544(%rsp)
	movq	72432(%rsp), %rax
	movq	%rax, 165552(%rsp)
	movq	72440(%rsp), %rax
	movq	%rax, 165560(%rsp)
	movq	72448(%rsp), %rax
	movq	%rax, 165568(%rsp)
	movq	72456(%rsp), %rax
	movq	%rax, 165576(%rsp)
	movq	72464(%rsp), %rax
	movq	%rax, 165584(%rsp)
	movq	72472(%rsp), %rax
	movq	%rax, 165592(%rsp)
	movq	72480(%rsp), %rax
	movq	%rax, 165600(%rsp)
	movq	72488(%rsp), %rax
	movq	%rax, 165608(%rsp)
	movq	72496(%rsp), %rax
	movq	%rax, 165616(%rsp)
	movq	72504(%rsp), %rax
	movq	%rax, 165624(%rsp)
	movq	72512(%rsp), %rax
	movq	%rax, 165632(%rsp)
	movq	72520(%rsp), %rax
	movq	%rax, 165640(%rsp)
	movq	72528(%rsp), %rax
	movq	%rax, 165648(%rsp)
	movq	72536(%rsp), %rax
	movq	%rax, 165656(%rsp)
	movq	72544(%rsp), %rax
	movq	%rax, 165664(%rsp)
	movq	72552(%rsp), %rax
	movq	%rax, 165672(%rsp)
	movq	72560(%rsp), %rax
	movq	%rax, 165680(%rsp)
	movq	72568(%rsp), %rax
	movq	%rax, 165688(%rsp)
	movq	72576(%rsp), %rax
	movq	%rax, 165696(%rsp)
	movq	72584(%rsp), %rax
	movq	%rax, 165704(%rsp)
	movq	72592(%rsp), %rax
	movq	%rax, 165712(%rsp)
	movq	72600(%rsp), %rax
	movq	%rax, 165720(%rsp)
	movq	72608(%rsp), %rax
	movq	%rax, 165728(%rsp)
	movq	72616(%rsp), %rax
	movq	%rax, 165736(%rsp)
	movq	72624(%rsp), %rax
	movq	%rax, 165744(%rsp)
	movq	72632(%rsp), %rax
	movq	%rax, 165752(%rsp)
	movq	72640(%rsp), %rax
	movq	%rax, 165760(%rsp)
	movq	72648(%rsp), %rax
	movq	%rax, 165768(%rsp)
	movq	72656(%rsp), %rax
	movq	%rax, 165776(%rsp)
	movq	72664(%rsp), %rax
	movq	%rax, 165784(%rsp)
	movq	72672(%rsp), %rax
	movq	%rax, 165792(%rsp)
	movq	72680(%rsp), %rax
	movq	%rax, 165800(%rsp)
	movq	72688(%rsp), %rax
	movq	%rax, 165808(%rsp)
	movq	72696(%rsp), %rax
	movq	%rax, 165816(%rsp)
	movq	72704(%rsp), %rax
	movq	%rax, 165824(%rsp)
	movq	72712(%rsp), %rax
	movq	%rax, 165832(%rsp)
	movq	72720(%rsp), %rax
	movq	%rax, 165840(%rsp)
	movq	72728(%rsp), %rax
	movq	%rax, 165848(%rsp)
	movq	72736(%rsp), %rax
	movq	%rax, 165856(%rsp)
	movq	72744(%rsp), %rax
	movq	%rax, 165864(%rsp)
	movq	72752(%rsp), %rax
	movq	%rax, 165872(%rsp)
	movq	72760(%rsp), %rax
	movq	%rax, 165880(%rsp)
	movq	72768(%rsp), %rax
	movq	%rax, 165888(%rsp)
	movq	72776(%rsp), %rax
	movq	%rax, 165896(%rsp)
	movq	72784(%rsp), %rax
	movq	%rax, 165904(%rsp)
	movq	72792(%rsp), %rax
	movq	%rax, 165912(%rsp)
	movq	72800(%rsp), %rax
	movq	%rax, 165920(%rsp)
	movq	72808(%rsp), %rax
	movq	%rax, 165928(%rsp)
	movq	72816(%rsp), %rax
	movq	%rax, 165936(%rsp)
	movq	72824(%rsp), %rax
	movq	%rax, 165944(%rsp)
	movq	72832(%rsp), %rax
	movq	%rax, 165952(%rsp)
	movq	72840(%rsp), %rax
	movq	%rax, 165960(%rsp)
	movq	72848(%rsp), %rax
	movq	%rax, 165968(%rsp)
	movq	72856(%rsp), %rax
	movq	%rax, 165976(%rsp)
	movq	72864(%rsp), %rax
	movq	%rax, 165984(%rsp)
	movq	72872(%rsp), %rax
	movq	%rax, 165992(%rsp)
	movq	72880(%rsp), %rax
	movq	%rax, 166000(%rsp)
	movq	72888(%rsp), %rax
	movq	%rax, 166008(%rsp)
	movq	72896(%rsp), %rax
	movq	%rax, 166016(%rsp)
	movq	72904(%rsp), %rax
	movq	%rax, 166024(%rsp)
	movq	72912(%rsp), %rax
	movq	%rax, 166032(%rsp)
	movq	72920(%rsp), %rax
	movq	%rax, 166040(%rsp)
	movq	72928(%rsp), %rax
	movq	%rax, 166048(%rsp)
	movq	72936(%rsp), %rax
	movq	%rax, 166056(%rsp)
	movq	72944(%rsp), %rax
	movq	%rax, 166064(%rsp)
	movq	72952(%rsp), %rax
	movq	%rax, 166072(%rsp)
	movq	72960(%rsp), %rax
	movq	%rax, 166080(%rsp)
	movq	72968(%rsp), %rax
	movq	%rax, 166088(%rsp)
	movq	72976(%rsp), %rax
	movq	%rax, 166096(%rsp)
	movq	72984(%rsp), %rax
	movq	%rax, 166104(%rsp)
	movq	72992(%rsp), %rax
	movq	%rax, 166112(%rsp)
	movq	73000(%rsp), %rax
	movq	%rax, 166120(%rsp)
	movq	73008(%rsp), %rax
	movq	%rax, 166128(%rsp)
	movq	73016(%rsp), %rax
	movq	%rax, 166136(%rsp)
	movq	73024(%rsp), %rax
	movq	%rax, 166144(%rsp)
	movq	73032(%rsp), %rax
	movq	%rax, 166152(%rsp)
	movq	73040(%rsp), %rax
	movq	%rax, 166160(%rsp)
	movq	73048(%rsp), %rax
	movq	%rax, 166168(%rsp)
	movq	73056(%rsp), %rax
	movq	%rax, 166176(%rsp)
	movq	73064(%rsp), %rax
	movq	%rax, 166184(%rsp)
	movq	73072(%rsp), %rax
	movq	%rax, 166192(%rsp)
	movq	73080(%rsp), %rax
	movq	%rax, 166200(%rsp)
	movq	73088(%rsp), %rax
	movq	%rax, 166208(%rsp)
	movq	73096(%rsp), %rax
	movq	%rax, 166216(%rsp)
	movq	73104(%rsp), %rax
	movq	%rax, 166224(%rsp)
	movq	73112(%rsp), %rax
	movq	%rax, 166232(%rsp)
	movq	73120(%rsp), %rax
	movq	%rax, 166240(%rsp)
	movq	73128(%rsp), %rax
	movq	%rax, 166248(%rsp)
	movq	73136(%rsp), %rax
	movq	%rax, 166256(%rsp)
	movq	73144(%rsp), %rax
	movq	%rax, 166264(%rsp)
	movq	73152(%rsp), %rax
	movq	%rax, 166272(%rsp)
	movq	73160(%rsp), %rax
	movq	%rax, 166280(%rsp)
	movq	73168(%rsp), %rax
	movq	%rax, 166288(%rsp)
	movq	73176(%rsp), %rax
	movq	%rax, 166296(%rsp)
	movq	73184(%rsp), %rax
	movq	%rax, 166304(%rsp)
	movq	73192(%rsp), %rax
	movq	%rax, 166312(%rsp)
	movq	73200(%rsp), %rax
	movq	%rax, 166320(%rsp)
	movq	73208(%rsp), %rax
	movq	%rax, 166328(%rsp)
	movq	73216(%rsp), %rax
	movq	%rax, 166336(%rsp)
	movq	73224(%rsp), %rax
	movq	%rax, 166344(%rsp)
	movq	73232(%rsp), %rax
	movq	%rax, 166352(%rsp)
	movq	73240(%rsp), %rax
	movq	%rax, 166360(%rsp)
	movq	73248(%rsp), %rax
	movq	%rax, 166368(%rsp)
	movq	73256(%rsp), %rax
	movq	%rax, 166376(%rsp)
	movq	73264(%rsp), %rax
	movq	%rax, 166384(%rsp)
	movq	73272(%rsp), %rax
	movq	%rax, 166392(%rsp)
	movq	73280(%rsp), %rax
	movq	%rax, 166400(%rsp)
	movq	73288(%rsp), %rax
	movq	%rax, 166408(%rsp)
	movq	73296(%rsp), %rax
	movq	%rax, 166416(%rsp)
	movq	73304(%rsp), %rax
	movq	%rax, 166424(%rsp)
	movq	73312(%rsp), %rax
	movq	%rax, 166432(%rsp)
	movq	73320(%rsp), %rax
	movq	%rax, 166440(%rsp)
	movq	73328(%rsp), %rax
	movq	%rax, 166448(%rsp)
	movq	73336(%rsp), %rax
	movq	%rax, 166456(%rsp)
	movq	73344(%rsp), %rax
	movq	%rax, 166464(%rsp)
	movq	73352(%rsp), %rax
	movq	%rax, 166472(%rsp)
	movq	73360(%rsp), %rax
	movq	%rax, 166480(%rsp)
	movq	73368(%rsp), %rax
	movq	%rax, 166488(%rsp)
	movq	73376(%rsp), %rax
	movq	%rax, 166496(%rsp)
	movq	73384(%rsp), %rax
	movq	%rax, 166504(%rsp)
	movq	73392(%rsp), %rax
	movq	%rax, 166512(%rsp)
	movq	73400(%rsp), %rax
	movq	%rax, 166520(%rsp)
	movq	73408(%rsp), %rax
	movq	%rax, 166528(%rsp)
	movq	73416(%rsp), %rax
	movq	%rax, 166536(%rsp)
	movq	73424(%rsp), %rax
	movq	%rax, 166544(%rsp)
	movq	73432(%rsp), %rax
	movq	%rax, 166552(%rsp)
	movq	73440(%rsp), %rax
	movq	%rax, 166560(%rsp)
	movq	73448(%rsp), %rax
	movq	%rax, 166568(%rsp)
	movq	73456(%rsp), %rax
	movq	%rax, 166576(%rsp)
	movq	73464(%rsp), %rax
	movq	%rax, 166584(%rsp)
	movq	73472(%rsp), %rax
	movq	%rax, 166592(%rsp)
	movq	73480(%rsp), %rax
	movq	%rax, 166600(%rsp)
	movq	73488(%rsp), %rax
	movq	%rax, 166608(%rsp)
	movq	73496(%rsp), %rax
	movq	%rax, 166616(%rsp)
	movq	73504(%rsp), %rax
	movq	%rax, 166624(%rsp)
	movq	73512(%rsp), %rax
	movq	%rax, 166632(%rsp)
	movq	73520(%rsp), %rax
	movq	%rax, 166640(%rsp)
	movq	73528(%rsp), %rax
	movq	%rax, 166648(%rsp)
	movq	73536(%rsp), %rax
	movq	%rax, 166656(%rsp)
	movq	73544(%rsp), %rax
	movq	%rax, 166664(%rsp)
	movq	73552(%rsp), %rax
	movq	%rax, 166672(%rsp)
	movq	73560(%rsp), %rax
	movq	%rax, 166680(%rsp)
	movq	73568(%rsp), %rax
	movq	%rax, 166688(%rsp)
	movq	73576(%rsp), %rax
	movq	%rax, 166696(%rsp)
	movq	73584(%rsp), %rax
	movq	%rax, 166704(%rsp)
	movq	73592(%rsp), %rax
	movq	%rax, 166712(%rsp)
	movq	73600(%rsp), %rax
	movq	%rax, 166720(%rsp)
	movq	73608(%rsp), %rax
	movq	%rax, 166728(%rsp)
	movq	73616(%rsp), %rax
	movq	%rax, 166736(%rsp)
	movq	73624(%rsp), %rax
	movq	%rax, 166744(%rsp)
	movq	73632(%rsp), %rax
	movq	%rax, 166752(%rsp)
	movq	73640(%rsp), %rax
	movq	%rax, 166760(%rsp)
	movq	73648(%rsp), %rax
	movq	%rax, 166768(%rsp)
	movq	73656(%rsp), %rax
	movq	%rax, 166776(%rsp)
	movq	73664(%rsp), %rax
	movq	%rax, 166784(%rsp)
	movq	73672(%rsp), %rax
	movq	%rax, 166792(%rsp)
	movq	73680(%rsp), %rax
	movq	%rax, 166800(%rsp)
	movq	73688(%rsp), %rax
	movq	%rax, 166808(%rsp)
	movq	73696(%rsp), %rax
	movq	%rax, 166816(%rsp)
	movq	73704(%rsp), %rax
	movq	%rax, 166824(%rsp)
	movq	73712(%rsp), %rax
	movq	%rax, 166832(%rsp)
	movq	73720(%rsp), %rax
	movq	%rax, 166840(%rsp)
	movq	73728(%rsp), %rax
	movq	%rax, 166848(%rsp)
	movq	73736(%rsp), %rax
	movq	%rax, 166856(%rsp)
	movq	73744(%rsp), %rax
	movq	%rax, 166864(%rsp)
	movq	73752(%rsp), %rax
	movq	%rax, 166872(%rsp)
	movq	73760(%rsp), %rax
	movq	%rax, 166880(%rsp)
	movq	73768(%rsp), %rax
	movq	%rax, 166888(%rsp)
	movq	73776(%rsp), %rax
	movq	%rax, 166896(%rsp)
	movq	73784(%rsp), %rax
	movq	%rax, 166904(%rsp)
	movq	73792(%rsp), %rax
	movq	%rax, 166912(%rsp)
	movq	73800(%rsp), %rax
	movq	%rax, 166920(%rsp)
	movq	73808(%rsp), %rax
	movq	%rax, 166928(%rsp)
	movq	73816(%rsp), %rax
	movq	%rax, 166936(%rsp)
	movq	73824(%rsp), %rax
	movq	%rax, 166944(%rsp)
	movq	73832(%rsp), %rax
	movq	%rax, 166952(%rsp)
	movq	73840(%rsp), %rax
	movq	%rax, 166960(%rsp)
	movq	73848(%rsp), %rax
	movq	%rax, 166968(%rsp)
	movq	73856(%rsp), %rax
	movq	%rax, 166976(%rsp)
	movq	73864(%rsp), %rax
	movq	%rax, 166984(%rsp)
	movq	73872(%rsp), %rax
	movq	%rax, 166992(%rsp)
	movq	73880(%rsp), %rax
	movq	%rax, 167000(%rsp)
	movq	73888(%rsp), %rax
	movq	%rax, 167008(%rsp)
	movq	73896(%rsp), %rax
	movq	%rax, 167016(%rsp)
	movq	73904(%rsp), %rax
	movq	%rax, 167024(%rsp)
	movq	73912(%rsp), %rax
	movq	%rax, 167032(%rsp)
	movq	73920(%rsp), %rax
	movq	%rax, 167040(%rsp)
	movq	73928(%rsp), %rax
	movq	%rax, 167048(%rsp)
	movq	73936(%rsp), %rax
	movq	%rax, 167056(%rsp)
	movq	73944(%rsp), %rax
	movq	%rax, 167064(%rsp)
	movq	73952(%rsp), %rax
	movq	%rax, 167072(%rsp)
	movq	73960(%rsp), %rax
	movq	%rax, 167080(%rsp)
	movq	73968(%rsp), %rax
	movq	%rax, 167088(%rsp)
	movq	73976(%rsp), %rax
	movq	%rax, 167096(%rsp)
	movq	73984(%rsp), %rax
	movq	%rax, 167104(%rsp)
	movq	73992(%rsp), %rax
	movq	%rax, 167112(%rsp)
	movq	74000(%rsp), %rax
	movq	%rax, 167120(%rsp)
	movq	74008(%rsp), %rax
	movq	%rax, 167128(%rsp)
	movq	74016(%rsp), %rax
	movq	%rax, 167136(%rsp)
	movq	74024(%rsp), %rax
	movq	%rax, 167144(%rsp)
	movq	74032(%rsp), %rax
	movq	%rax, 167152(%rsp)
	movq	74040(%rsp), %rax
	movq	%rax, 167160(%rsp)
	movq	74048(%rsp), %rax
	movq	%rax, 167168(%rsp)
	movq	74056(%rsp), %rax
	movq	%rax, 167176(%rsp)
	movq	74064(%rsp), %rax
	movq	%rax, 167184(%rsp)
	movq	74072(%rsp), %rax
	movq	%rax, 167192(%rsp)
	movq	74080(%rsp), %rax
	movq	%rax, 167200(%rsp)
	movq	74088(%rsp), %rax
	movq	%rax, 167208(%rsp)
	movq	74096(%rsp), %rax
	movq	%rax, 167216(%rsp)
	movq	74104(%rsp), %rax
	movq	%rax, 167224(%rsp)
	movq	74112(%rsp), %rax
	movq	%rax, 167232(%rsp)
	movq	74120(%rsp), %rax
	movq	%rax, 167240(%rsp)
	movq	74128(%rsp), %rax
	movq	%rax, 167248(%rsp)
	movq	74136(%rsp), %rax
	movq	%rax, 167256(%rsp)
	movq	74144(%rsp), %rax
	movq	%rax, 167264(%rsp)
	movq	74152(%rsp), %rax
	movq	%rax, 167272(%rsp)
	movq	74160(%rsp), %rax
	movq	%rax, 167280(%rsp)
	movq	74168(%rsp), %rax
	movq	%rax, 167288(%rsp)
	movq	74176(%rsp), %rax
	movq	%rax, 167296(%rsp)
	movq	74184(%rsp), %rax
	movq	%rax, 167304(%rsp)
	movq	74192(%rsp), %rax
	movq	%rax, 167312(%rsp)
	movq	74200(%rsp), %rax
	movq	%rax, 167320(%rsp)
	movq	74208(%rsp), %rax
	movq	%rax, 167328(%rsp)
	movq	74216(%rsp), %rax
	movq	%rax, 167336(%rsp)
	movq	74224(%rsp), %rax
	movq	%rax, 167344(%rsp)
	movq	74232(%rsp), %rax
	movq	%rax, 167352(%rsp)
	movq	74240(%rsp), %rax
	movq	%rax, 167360(%rsp)
	movq	74248(%rsp), %rax
	movq	%rax, 167368(%rsp)
	movq	74256(%rsp), %rax
	movq	%rax, 167376(%rsp)
	movq	74264(%rsp), %rax
	movq	%rax, 167384(%rsp)
	movq	74272(%rsp), %rax
	movq	%rax, 167392(%rsp)
	movq	74280(%rsp), %rax
	movq	%rax, 167400(%rsp)
	movq	74288(%rsp), %rax
	movq	%rax, 167408(%rsp)
	movq	74296(%rsp), %rax
	movq	%rax, 167416(%rsp)
	movq	74304(%rsp), %rax
	movq	%rax, 167424(%rsp)
	movq	74312(%rsp), %rax
	movq	%rax, 167432(%rsp)
	movq	74320(%rsp), %rax
	movq	%rax, 167440(%rsp)
	movq	74328(%rsp), %rax
	movq	%rax, 167448(%rsp)
	movq	74336(%rsp), %rax
	movq	%rax, 167456(%rsp)
	movq	74344(%rsp), %rax
	movq	%rax, 167464(%rsp)
	movq	74352(%rsp), %rax
	movq	%rax, 167472(%rsp)
	movq	74360(%rsp), %rax
	movq	%rax, 167480(%rsp)
	movq	74368(%rsp), %rax
	movq	%rax, 167488(%rsp)
	movq	74376(%rsp), %rax
	movq	%rax, 167496(%rsp)
	movq	74384(%rsp), %rax
	movq	%rax, 167504(%rsp)
	movq	74392(%rsp), %rax
	movq	%rax, 167512(%rsp)
	movq	74400(%rsp), %rax
	movq	%rax, 167520(%rsp)
	movq	74408(%rsp), %rax
	movq	%rax, 167528(%rsp)
	movq	74416(%rsp), %rax
	movq	%rax, 167536(%rsp)
	movq	74424(%rsp), %rax
	movq	%rax, 167544(%rsp)
	movq	74432(%rsp), %rax
	movq	%rax, 167552(%rsp)
	movq	74440(%rsp), %rax
	movq	%rax, 167560(%rsp)
	movq	74448(%rsp), %rax
	movq	%rax, 167568(%rsp)
	movq	74456(%rsp), %rax
	movq	%rax, 167576(%rsp)
	movq	74464(%rsp), %rax
	movq	%rax, 167584(%rsp)
	movq	74472(%rsp), %rax
	movq	%rax, 167592(%rsp)
	movq	74480(%rsp), %rax
	movq	%rax, 167600(%rsp)
	movq	74488(%rsp), %rax
	movq	%rax, 167608(%rsp)
	movq	74496(%rsp), %rax
	movq	%rax, 167616(%rsp)
	movq	74504(%rsp), %rax
	movq	%rax, 167624(%rsp)
	movq	74512(%rsp), %rax
	movq	%rax, 167632(%rsp)
	movq	74520(%rsp), %rax
	movq	%rax, 167640(%rsp)
	movq	74528(%rsp), %rax
	movq	%rax, 167648(%rsp)
	movq	74536(%rsp), %rax
	movq	%rax, 167656(%rsp)
	movq	74544(%rsp), %rax
	movq	%rax, 167664(%rsp)
	movq	74552(%rsp), %rax
	movq	%rax, 167672(%rsp)
	movq	74560(%rsp), %rax
	movq	%rax, 167680(%rsp)
	movq	74568(%rsp), %rax
	movq	%rax, 167688(%rsp)
	movq	74576(%rsp), %rax
	movq	%rax, 167696(%rsp)
	movq	74584(%rsp), %rax
	movq	%rax, 167704(%rsp)
	movq	74592(%rsp), %rax
	movq	%rax, 167712(%rsp)
	movq	74600(%rsp), %rax
	movq	%rax, 167720(%rsp)
	movq	74608(%rsp), %rax
	movq	%rax, 167728(%rsp)
	movq	74616(%rsp), %rax
	movq	%rax, 167736(%rsp)
	movq	74624(%rsp), %rax
	movq	%rax, 167744(%rsp)
	movq	74632(%rsp), %rax
	movq	%rax, 167752(%rsp)
	movq	74640(%rsp), %rax
	movq	%rax, 167760(%rsp)
	movq	74648(%rsp), %rax
	movq	%rax, 167768(%rsp)
	movq	74656(%rsp), %rax
	movq	%rax, 167776(%rsp)
	movq	74664(%rsp), %rax
	movq	%rax, 167784(%rsp)
	movq	74672(%rsp), %rax
	movq	%rax, 167792(%rsp)
	movq	74680(%rsp), %rax
	movq	%rax, 167800(%rsp)
	movq	74688(%rsp), %rax
	movq	%rax, 167808(%rsp)
	movq	74696(%rsp), %rax
	movq	%rax, 167816(%rsp)
	movq	74704(%rsp), %rax
	movq	%rax, 167824(%rsp)
	movq	74712(%rsp), %rax
	movq	%rax, 167832(%rsp)
	movq	74720(%rsp), %rax
	movq	%rax, 167840(%rsp)
	movq	74728(%rsp), %rax
	movq	%rax, 167848(%rsp)
	movq	74736(%rsp), %rax
	movq	%rax, 167856(%rsp)
	movq	74744(%rsp), %rax
	movq	%rax, 167864(%rsp)
	movq	74752(%rsp), %rax
	movq	%rax, 167872(%rsp)
	movq	74760(%rsp), %rax
	movq	%rax, 167880(%rsp)
	movq	74768(%rsp), %rax
	movq	%rax, 167888(%rsp)
	movq	74776(%rsp), %rax
	movq	%rax, 167896(%rsp)
	movq	74784(%rsp), %rax
	movq	%rax, 167904(%rsp)
	movq	74792(%rsp), %rax
	movq	%rax, 167912(%rsp)
	movq	74800(%rsp), %rax
	movq	%rax, 167920(%rsp)
	movq	74808(%rsp), %rax
	movq	%rax, 167928(%rsp)
	movq	74816(%rsp), %rax
	movq	%rax, 167936(%rsp)
	movq	74824(%rsp), %rax
	movq	%rax, 167944(%rsp)
	movq	74832(%rsp), %rax
	movq	%rax, 167952(%rsp)
	movq	74840(%rsp), %rax
	movq	%rax, 167960(%rsp)
	movq	74848(%rsp), %rax
	movq	%rax, 167968(%rsp)
	movq	74856(%rsp), %rax
	movq	%rax, 167976(%rsp)
	movq	74864(%rsp), %rax
	movq	%rax, 167984(%rsp)
	movq	74872(%rsp), %rax
	movq	%rax, 167992(%rsp)
	movq	74880(%rsp), %rax
	movq	%rax, 168000(%rsp)
	movq	74888(%rsp), %rax
	movq	%rax, 168008(%rsp)
	movq	74896(%rsp), %rax
	movq	%rax, 168016(%rsp)
	movq	74904(%rsp), %rax
	movq	%rax, 168024(%rsp)
	movq	74912(%rsp), %rax
	movq	%rax, 168032(%rsp)
	movq	74920(%rsp), %rax
	movq	%rax, 168040(%rsp)
	movq	74928(%rsp), %rax
	movq	%rax, 168048(%rsp)
	movq	74936(%rsp), %rax
	movq	%rax, 168056(%rsp)
	movq	74944(%rsp), %rax
	movq	%rax, 168064(%rsp)
	movq	74952(%rsp), %rax
	movq	%rax, 168072(%rsp)
	movq	74960(%rsp), %rax
	movq	%rax, 168080(%rsp)
	movq	74968(%rsp), %rax
	movq	%rax, 168088(%rsp)
	movq	74976(%rsp), %rax
	movq	%rax, 168096(%rsp)
	movq	74984(%rsp), %rax
	movq	%rax, 168104(%rsp)
	movq	74992(%rsp), %rax
	movq	%rax, 168112(%rsp)
	movq	75000(%rsp), %rax
	movq	%rax, 168120(%rsp)
	movq	75008(%rsp), %rax
	movq	%rax, 168128(%rsp)
	movq	75016(%rsp), %rax
	movq	%rax, 168136(%rsp)
	movq	75024(%rsp), %rax
	movq	%rax, 168144(%rsp)
	movq	75032(%rsp), %rax
	movq	%rax, 168152(%rsp)
	movq	75040(%rsp), %rax
	movq	%rax, 168160(%rsp)
	movq	75048(%rsp), %rax
	movq	%rax, 168168(%rsp)
	movq	75056(%rsp), %rax
	movq	%rax, 168176(%rsp)
	movq	75064(%rsp), %rax
	movq	%rax, 168184(%rsp)
	movq	75072(%rsp), %rax
	movq	%rax, 168192(%rsp)
	movq	75080(%rsp), %rax
	movq	%rax, 168200(%rsp)
	movq	75088(%rsp), %rax
	movq	%rax, 168208(%rsp)
	movq	75096(%rsp), %rax
	movq	%rax, 168216(%rsp)
	movq	75104(%rsp), %rax
	movq	%rax, 168224(%rsp)
	movq	75112(%rsp), %rax
	movq	%rax, 168232(%rsp)
	movq	75120(%rsp), %rax
	movq	%rax, 168240(%rsp)
	movq	75128(%rsp), %rax
	movq	%rax, 168248(%rsp)
	movq	75136(%rsp), %rax
	movq	%rax, 168256(%rsp)
	movq	75144(%rsp), %rax
	movq	%rax, 168264(%rsp)
	movq	75152(%rsp), %rax
	movq	%rax, 168272(%rsp)
	movq	75160(%rsp), %rax
	movq	%rax, 168280(%rsp)
	movq	75168(%rsp), %rax
	movq	%rax, 168288(%rsp)
	movq	75176(%rsp), %rax
	movq	%rax, 168296(%rsp)
	movq	75184(%rsp), %rax
	movq	%rax, 168304(%rsp)
	movq	75192(%rsp), %rax
	movq	%rax, 168312(%rsp)
	movq	75200(%rsp), %rax
	movq	%rax, 168320(%rsp)
	movq	75208(%rsp), %rax
	movq	%rax, 168328(%rsp)
	movq	75216(%rsp), %rax
	movq	%rax, 168336(%rsp)
	movq	75224(%rsp), %rax
	movq	%rax, 168344(%rsp)
	movq	75232(%rsp), %rax
	movq	%rax, 168352(%rsp)
	movq	75240(%rsp), %rax
	movq	%rax, 168360(%rsp)
	movq	75248(%rsp), %rax
	movq	%rax, 168368(%rsp)
	movq	75256(%rsp), %rax
	movq	%rax, 168376(%rsp)
	movq	75264(%rsp), %rax
	movq	%rax, 168384(%rsp)
	movq	75272(%rsp), %rax
	movq	%rax, 168392(%rsp)
	movq	75280(%rsp), %rax
	movq	%rax, 168400(%rsp)
	movq	75288(%rsp), %rax
	movq	%rax, 168408(%rsp)
	movq	75296(%rsp), %rax
	movq	%rax, 168416(%rsp)
	movq	75304(%rsp), %rax
	movq	%rax, 168424(%rsp)
	movq	75312(%rsp), %rax
	movq	%rax, 168432(%rsp)
	movq	75320(%rsp), %rax
	movq	%rax, 168440(%rsp)
	movq	75328(%rsp), %rax
	movq	%rax, 168448(%rsp)
	movq	75336(%rsp), %rax
	movq	%rax, 168456(%rsp)
	movq	75344(%rsp), %rax
	movq	%rax, 168464(%rsp)
	movq	75352(%rsp), %rax
	movq	%rax, 168472(%rsp)
	movq	75360(%rsp), %rax
	movq	%rax, 168480(%rsp)
	movq	75368(%rsp), %rax
	movq	%rax, 168488(%rsp)
	movq	75376(%rsp), %rax
	movq	%rax, 168496(%rsp)
	movq	75384(%rsp), %rax
	movq	%rax, 168504(%rsp)
	movq	75392(%rsp), %rax
	movq	%rax, 168512(%rsp)
	movq	75400(%rsp), %rax
	movq	%rax, 168520(%rsp)
	movq	75408(%rsp), %rax
	movq	%rax, 168528(%rsp)
	movq	75416(%rsp), %rax
	movq	%rax, 168536(%rsp)
	movq	75424(%rsp), %rax
	movq	%rax, 168544(%rsp)
	movq	75432(%rsp), %rax
	movq	%rax, 168552(%rsp)
	movq	75440(%rsp), %rax
	movq	%rax, 168560(%rsp)
	movq	75448(%rsp), %rax
	movq	%rax, 168568(%rsp)
	movq	75456(%rsp), %rax
	movq	%rax, 168576(%rsp)
	movq	75464(%rsp), %rax
	movq	%rax, 168584(%rsp)
	movq	75472(%rsp), %rax
	movq	%rax, 168592(%rsp)
	movq	75480(%rsp), %rax
	movq	%rax, 168600(%rsp)
	movq	75488(%rsp), %rax
	movq	%rax, 168608(%rsp)
	movq	75496(%rsp), %rax
	movq	%rax, 168616(%rsp)
	movq	75504(%rsp), %rax
	movq	%rax, 168624(%rsp)
	movq	75512(%rsp), %rax
	movq	%rax, 168632(%rsp)
	movq	75520(%rsp), %rax
	movq	%rax, 168640(%rsp)
	movq	75528(%rsp), %rax
	movq	%rax, 168648(%rsp)
	movq	75536(%rsp), %rax
	movq	%rax, 168656(%rsp)
	movq	75544(%rsp), %rax
	movq	%rax, 168664(%rsp)
	movq	75552(%rsp), %rax
	movq	%rax, 168672(%rsp)
	movq	75560(%rsp), %rax
	movq	%rax, 168680(%rsp)
	movq	75568(%rsp), %rax
	movq	%rax, 168688(%rsp)
	movq	75576(%rsp), %rax
	movq	%rax, 168696(%rsp)
	movq	75584(%rsp), %rax
	movq	%rax, 168704(%rsp)
	movq	75592(%rsp), %rax
	movq	%rax, 168712(%rsp)
	movq	75600(%rsp), %rax
	movq	%rax, 168720(%rsp)
	movq	75608(%rsp), %rax
	movq	%rax, 168728(%rsp)
	movq	75616(%rsp), %rax
	movq	%rax, 168736(%rsp)
	movq	75624(%rsp), %rax
	movq	%rax, 168744(%rsp)
	movq	75632(%rsp), %rax
	movq	%rax, 168752(%rsp)
	movq	75640(%rsp), %rax
	movq	%rax, 168760(%rsp)
	movq	75648(%rsp), %rax
	movq	%rax, 168768(%rsp)
	movq	75656(%rsp), %rax
	movq	%rax, 168776(%rsp)
	movq	75664(%rsp), %rax
	movq	%rax, 168784(%rsp)
	movq	75672(%rsp), %rax
	movq	%rax, 168792(%rsp)
	movq	75680(%rsp), %rax
	movq	%rax, 168800(%rsp)
	movq	75688(%rsp), %rax
	movq	%rax, 168808(%rsp)
	movq	75696(%rsp), %rax
	movq	%rax, 168816(%rsp)
	movq	75704(%rsp), %rax
	movq	%rax, 168824(%rsp)
	movq	75712(%rsp), %rax
	movq	%rax, 168832(%rsp)
	movq	75720(%rsp), %rax
	movq	%rax, 168840(%rsp)
	movq	75728(%rsp), %rax
	movq	%rax, 168848(%rsp)
	movq	75736(%rsp), %rax
	movq	%rax, 168856(%rsp)
	movq	75744(%rsp), %rax
	movq	%rax, 168864(%rsp)
	movq	75752(%rsp), %rax
	movq	%rax, 168872(%rsp)
	movq	75760(%rsp), %rax
	movq	%rax, 168880(%rsp)
	movq	75768(%rsp), %rax
	movq	%rax, 168888(%rsp)
	movq	75776(%rsp), %rax
	movq	%rax, 168896(%rsp)
	movq	75784(%rsp), %rax
	movq	%rax, 168904(%rsp)
	movq	75792(%rsp), %rax
	movq	%rax, 168912(%rsp)
	movq	75800(%rsp), %rax
	movq	%rax, 168920(%rsp)
	movq	75808(%rsp), %rax
	movq	%rax, 168928(%rsp)
	movq	75816(%rsp), %rax
	movq	%rax, 168936(%rsp)
	movq	75824(%rsp), %rax
	movq	%rax, 168944(%rsp)
	movq	75832(%rsp), %rax
	movq	%rax, 168952(%rsp)
	movq	75840(%rsp), %rax
	movq	%rax, 168960(%rsp)
	movq	75848(%rsp), %rax
	movq	%rax, 168968(%rsp)
	movq	75856(%rsp), %rax
	movq	%rax, 168976(%rsp)
	movq	75864(%rsp), %rax
	movq	%rax, 168984(%rsp)
	movq	75872(%rsp), %rax
	movq	%rax, 168992(%rsp)
	movq	75880(%rsp), %rax
	movq	%rax, 169000(%rsp)
	movq	75888(%rsp), %rax
	movq	%rax, 169008(%rsp)
	movq	75896(%rsp), %rax
	movq	%rax, 169016(%rsp)
	movq	75904(%rsp), %rax
	movq	%rax, 169024(%rsp)
	movq	75912(%rsp), %rax
	movq	%rax, 169032(%rsp)
	movq	75920(%rsp), %rax
	movq	%rax, 169040(%rsp)
	movq	75928(%rsp), %rax
	movq	%rax, 169048(%rsp)
	movq	75936(%rsp), %rax
	movq	%rax, 169056(%rsp)
	movq	75944(%rsp), %rax
	movq	%rax, 169064(%rsp)
	movq	75952(%rsp), %rax
	movq	%rax, 169072(%rsp)
	movq	75960(%rsp), %rax
	movq	%rax, 169080(%rsp)
	movq	75968(%rsp), %rax
	movq	%rax, 169088(%rsp)
	movq	75976(%rsp), %rax
	movq	%rax, 169096(%rsp)
	movq	75984(%rsp), %rax
	movq	%rax, 169104(%rsp)
	movq	75992(%rsp), %rax
	movq	%rax, 169112(%rsp)
	movq	76000(%rsp), %rax
	movq	%rax, 169120(%rsp)
	movq	76008(%rsp), %rax
	movq	%rax, 169128(%rsp)
	movq	76016(%rsp), %rax
	movq	%rax, 169136(%rsp)
	movq	76024(%rsp), %rax
	movq	%rax, 169144(%rsp)
	movq	76032(%rsp), %rax
	movq	%rax, 169152(%rsp)
	movq	76040(%rsp), %rax
	movq	%rax, 169160(%rsp)
	movq	76048(%rsp), %rax
	movq	%rax, 169168(%rsp)
	movq	76056(%rsp), %rax
	movq	%rax, 169176(%rsp)
	movq	76064(%rsp), %rax
	movq	%rax, 169184(%rsp)
	movq	76072(%rsp), %rax
	movq	%rax, 169192(%rsp)
	movq	76080(%rsp), %rax
	movq	%rax, 169200(%rsp)
	movq	76088(%rsp), %rax
	movq	%rax, 169208(%rsp)
	movq	76096(%rsp), %rax
	movq	%rax, 169216(%rsp)
	movq	76104(%rsp), %rax
	movq	%rax, 169224(%rsp)
	movq	76112(%rsp), %rax
	movq	%rax, 169232(%rsp)
	movq	76120(%rsp), %rax
	movq	%rax, 169240(%rsp)
	movq	76128(%rsp), %rax
	movq	%rax, 169248(%rsp)
	movq	76136(%rsp), %rax
	movq	%rax, 169256(%rsp)
	movq	76144(%rsp), %rax
	movq	%rax, 169264(%rsp)
	movq	76152(%rsp), %rax
	movq	%rax, 169272(%rsp)
	movq	76160(%rsp), %rax
	movq	%rax, 169280(%rsp)
	movq	76168(%rsp), %rax
	movq	%rax, 169288(%rsp)
	movq	76176(%rsp), %rax
	movq	%rax, 169296(%rsp)
	movq	76184(%rsp), %rax
	movq	%rax, 169304(%rsp)
	movq	76192(%rsp), %rax
	movq	%rax, 169312(%rsp)
	movq	76200(%rsp), %rax
	movq	%rax, 169320(%rsp)
	movq	76208(%rsp), %rax
	movq	%rax, 169328(%rsp)
	movq	76216(%rsp), %rax
	movq	%rax, 169336(%rsp)
	movq	76224(%rsp), %rax
	movq	%rax, 169344(%rsp)
	movq	76232(%rsp), %rax
	movq	%rax, 169352(%rsp)
	movq	76240(%rsp), %rax
	movq	%rax, 169360(%rsp)
	movq	76248(%rsp), %rax
	movq	%rax, 169368(%rsp)
	movq	76256(%rsp), %rax
	movq	%rax, 169376(%rsp)
	movq	76264(%rsp), %rax
	movq	%rax, 169384(%rsp)
	movq	76272(%rsp), %rax
	movq	%rax, 169392(%rsp)
	movq	76280(%rsp), %rax
	movq	%rax, 169400(%rsp)
	movq	76288(%rsp), %rax
	movq	%rax, 169408(%rsp)
	movq	76296(%rsp), %rax
	movq	%rax, 169416(%rsp)
	movq	76304(%rsp), %rax
	movq	%rax, 169424(%rsp)
	movq	76312(%rsp), %rax
	movq	%rax, 169432(%rsp)
	movq	76320(%rsp), %rax
	movq	%rax, 169440(%rsp)
	movq	76328(%rsp), %rax
	movq	%rax, 169448(%rsp)
	movq	76336(%rsp), %rax
	movq	%rax, 169456(%rsp)
	movq	76344(%rsp), %rax
	movq	%rax, 169464(%rsp)
	movq	76352(%rsp), %rax
	movq	%rax, 169472(%rsp)
	movq	76360(%rsp), %rax
	movq	%rax, 169480(%rsp)
	movq	76368(%rsp), %rax
	movq	%rax, 169488(%rsp)
	movq	76376(%rsp), %rax
	movq	%rax, 169496(%rsp)
	movq	76384(%rsp), %rax
	movq	%rax, 169504(%rsp)
	movq	76392(%rsp), %rax
	movq	%rax, 169512(%rsp)
	movq	76400(%rsp), %rax
	movq	%rax, 169520(%rsp)
	movq	76408(%rsp), %rax
	movq	%rax, 169528(%rsp)
	movq	76416(%rsp), %rax
	movq	%rax, 169536(%rsp)
	movq	76424(%rsp), %rax
	movq	%rax, 169544(%rsp)
	movq	76432(%rsp), %rax
	movq	%rax, 169552(%rsp)
	movq	76440(%rsp), %rax
	movq	%rax, 169560(%rsp)
	movq	76448(%rsp), %rax
	movq	%rax, 169568(%rsp)
	movq	76456(%rsp), %rax
	movq	%rax, 169576(%rsp)
	movq	76464(%rsp), %rax
	movq	%rax, 169584(%rsp)
	movq	76472(%rsp), %rax
	movq	%rax, 169592(%rsp)
	movq	76480(%rsp), %rax
	movq	%rax, 169600(%rsp)
	movq	76488(%rsp), %rax
	movq	%rax, 169608(%rsp)
	movq	76496(%rsp), %rax
	movq	%rax, 169616(%rsp)
	movq	76504(%rsp), %rax
	movq	%rax, 169624(%rsp)
	movq	76512(%rsp), %rax
	movq	%rax, 169632(%rsp)
	movq	76520(%rsp), %rax
	movq	%rax, 169640(%rsp)
	movq	76528(%rsp), %rax
	movq	%rax, 169648(%rsp)
	movq	76536(%rsp), %rax
	movq	%rax, 169656(%rsp)
	movq	76544(%rsp), %rax
	movq	%rax, 169664(%rsp)
	movq	76552(%rsp), %rax
	movq	%rax, 169672(%rsp)
	movq	76560(%rsp), %rax
	movq	%rax, 169680(%rsp)
	movq	76568(%rsp), %rax
	movq	%rax, 169688(%rsp)
	movq	76576(%rsp), %rax
	movq	%rax, 169696(%rsp)
	movq	76584(%rsp), %rax
	movq	%rax, 169704(%rsp)
	movq	76592(%rsp), %rax
	movq	%rax, 169712(%rsp)
	movq	76600(%rsp), %rax
	movq	%rax, 169720(%rsp)
	movq	76608(%rsp), %rax
	movq	%rax, 169728(%rsp)
	movq	76616(%rsp), %rax
	movq	%rax, 169736(%rsp)
	movq	76624(%rsp), %rax
	movq	%rax, 169744(%rsp)
	movq	76632(%rsp), %rax
	movq	%rax, 169752(%rsp)
	movq	76640(%rsp), %rax
	movq	%rax, 169760(%rsp)
	movq	76648(%rsp), %rax
	movq	%rax, 169768(%rsp)
	movq	76656(%rsp), %rax
	movq	%rax, 169776(%rsp)
	movq	76664(%rsp), %rax
	movq	%rax, 169784(%rsp)
	movq	76672(%rsp), %rax
	movq	%rax, 169792(%rsp)
	movq	76680(%rsp), %rax
	movq	%rax, 169800(%rsp)
	movq	76688(%rsp), %rax
	movq	%rax, 169808(%rsp)
	movq	76696(%rsp), %rax
	movq	%rax, 169816(%rsp)
	movq	76704(%rsp), %rax
	movq	%rax, 169824(%rsp)
	movq	76712(%rsp), %rax
	movq	%rax, 169832(%rsp)
	movq	76720(%rsp), %rax
	movq	%rax, 169840(%rsp)
	movq	76728(%rsp), %rax
	movq	%rax, 169848(%rsp)
	movq	76736(%rsp), %rax
	movq	%rax, 169856(%rsp)
	movq	76744(%rsp), %rax
	movq	%rax, 169864(%rsp)
	movq	76752(%rsp), %rax
	movq	%rax, 169872(%rsp)
	movq	76760(%rsp), %rax
	movq	%rax, 169880(%rsp)
	movq	76768(%rsp), %rax
	movq	%rax, 169888(%rsp)
	movq	76776(%rsp), %rax
	movq	%rax, 169896(%rsp)
	movq	76784(%rsp), %rax
	movq	%rax, 169904(%rsp)
	movq	76792(%rsp), %rax
	movq	%rax, 169912(%rsp)
	movq	76800(%rsp), %rax
	movq	%rax, 169920(%rsp)
	movq	76808(%rsp), %rax
	movq	%rax, 169928(%rsp)
	movq	76816(%rsp), %rax
	movq	%rax, 169936(%rsp)
	movq	76824(%rsp), %rax
	movq	%rax, 169944(%rsp)
	movq	76832(%rsp), %rax
	movq	%rax, 169952(%rsp)
	movq	76840(%rsp), %rax
	movq	%rax, 169960(%rsp)
	movq	76848(%rsp), %rax
	movq	%rax, 169968(%rsp)
	movq	76856(%rsp), %rax
	movq	%rax, 169976(%rsp)
	movq	76864(%rsp), %rax
	movq	%rax, 169984(%rsp)
	movq	76872(%rsp), %rax
	movq	%rax, 169992(%rsp)
	movq	76880(%rsp), %rax
	movq	%rax, 170000(%rsp)
	movq	76888(%rsp), %rax
	movq	%rax, 170008(%rsp)
	movq	76896(%rsp), %rax
	movq	%rax, 170016(%rsp)
	movq	76904(%rsp), %rax
	movq	%rax, 170024(%rsp)
	movq	76912(%rsp), %rax
	movq	%rax, 170032(%rsp)
	movq	76920(%rsp), %rax
	movq	%rax, 170040(%rsp)
	movq	76928(%rsp), %rax
	movq	%rax, 170048(%rsp)
	movq	76936(%rsp), %rax
	movq	%rax, 170056(%rsp)
	movq	76944(%rsp), %rax
	movq	%rax, 170064(%rsp)
	movq	76952(%rsp), %rax
	movq	%rax, 170072(%rsp)
	movq	76960(%rsp), %rax
	movq	%rax, 170080(%rsp)
	movq	76968(%rsp), %rax
	movq	%rax, 170088(%rsp)
	movq	76976(%rsp), %rax
	movq	%rax, 170096(%rsp)
	movq	76984(%rsp), %rax
	movq	%rax, 170104(%rsp)
	movq	76992(%rsp), %rax
	movq	%rax, 170112(%rsp)
	movq	77000(%rsp), %rax
	movq	%rax, 170120(%rsp)
	movq	77008(%rsp), %rax
	movq	%rax, 170128(%rsp)
	movq	77016(%rsp), %rax
	movq	%rax, 170136(%rsp)
	movq	77024(%rsp), %rax
	movq	%rax, 170144(%rsp)
	movq	77032(%rsp), %rax
	movq	%rax, 170152(%rsp)
	movq	77040(%rsp), %rax
	movq	%rax, 170160(%rsp)
	movq	77048(%rsp), %rax
	movq	%rax, 170168(%rsp)
	movq	77056(%rsp), %rax
	movq	%rax, 170176(%rsp)
	movq	77064(%rsp), %rax
	movq	%rax, 170184(%rsp)
	movq	77072(%rsp), %rax
	movq	%rax, 170192(%rsp)
	movq	77080(%rsp), %rax
	movq	%rax, 170200(%rsp)
	movq	77088(%rsp), %rax
	movq	%rax, 170208(%rsp)
	movq	77096(%rsp), %rax
	movq	%rax, 170216(%rsp)
	movq	77104(%rsp), %rax
	movq	%rax, 170224(%rsp)
	movq	77112(%rsp), %rax
	movq	%rax, 170232(%rsp)
	movq	77120(%rsp), %rax
	movq	%rax, 170240(%rsp)
	movq	77128(%rsp), %rax
	movq	%rax, 170248(%rsp)
	movq	77136(%rsp), %rax
	movq	%rax, 170256(%rsp)
	movq	77144(%rsp), %rax
	movq	%rax, 170264(%rsp)
	movq	77152(%rsp), %rax
	movq	%rax, 170272(%rsp)
	movq	77160(%rsp), %rax
	movq	%rax, 170280(%rsp)
	movq	77168(%rsp), %rax
	movq	%rax, 170288(%rsp)
	movq	77176(%rsp), %rax
	movq	%rax, 170296(%rsp)
	movq	77184(%rsp), %rax
	movq	%rax, 170304(%rsp)
	movq	77192(%rsp), %rax
	movq	%rax, 170312(%rsp)
	movq	77200(%rsp), %rax
	movq	%rax, 170320(%rsp)
	movq	77208(%rsp), %rax
	movq	%rax, 170328(%rsp)
	movq	77216(%rsp), %rax
	movq	%rax, 170336(%rsp)
	movq	77224(%rsp), %rax
	movq	%rax, 170344(%rsp)
	movq	77232(%rsp), %rax
	movq	%rax, 170352(%rsp)
	movq	77240(%rsp), %rax
	movq	%rax, 170360(%rsp)
	movq	77248(%rsp), %rax
	movq	%rax, 170368(%rsp)
	movq	77256(%rsp), %rax
	movq	%rax, 170376(%rsp)
	movq	77264(%rsp), %rax
	movq	%rax, 170384(%rsp)
	movq	77272(%rsp), %rax
	movq	%rax, 170392(%rsp)
	movq	77280(%rsp), %rax
	movq	%rax, 170400(%rsp)
	movq	77288(%rsp), %rax
	movq	%rax, 170408(%rsp)
	movq	77296(%rsp), %rax
	movq	%rax, 170416(%rsp)
	movq	77304(%rsp), %rax
	movq	%rax, 170424(%rsp)
	movq	77312(%rsp), %rax
	movq	%rax, 170432(%rsp)
	movq	77320(%rsp), %rax
	movq	%rax, 170440(%rsp)
	movq	77328(%rsp), %rax
	movq	%rax, 170448(%rsp)
	movq	77336(%rsp), %rax
	movq	%rax, 170456(%rsp)
	movq	77344(%rsp), %rax
	movq	%rax, 170464(%rsp)
	movq	77352(%rsp), %rax
	movq	%rax, 170472(%rsp)
	movq	77360(%rsp), %rax
	movq	%rax, 170480(%rsp)
	movq	77368(%rsp), %rax
	movq	%rax, 170488(%rsp)
	movq	77376(%rsp), %rax
	movq	%rax, 170496(%rsp)
	movq	77384(%rsp), %rax
	movq	%rax, 170504(%rsp)
	movq	77392(%rsp), %rax
	movq	%rax, 170512(%rsp)
	movq	77400(%rsp), %rax
	movq	%rax, 170520(%rsp)
	movq	77408(%rsp), %rax
	movq	%rax, 170528(%rsp)
	movq	77416(%rsp), %rax
	movq	%rax, 170536(%rsp)
	movq	77424(%rsp), %rax
	movq	%rax, 170544(%rsp)
	movq	77432(%rsp), %rax
	movq	%rax, 170552(%rsp)
	movq	77440(%rsp), %rax
	movq	%rax, 170560(%rsp)
	movq	77448(%rsp), %rax
	movq	%rax, 170568(%rsp)
	movq	77456(%rsp), %rax
	movq	%rax, 170576(%rsp)
	movq	77464(%rsp), %rax
	movq	%rax, 170584(%rsp)
	movq	77472(%rsp), %rax
	movq	%rax, 170592(%rsp)
	movq	77480(%rsp), %rax
	movq	%rax, 170600(%rsp)
	movq	77488(%rsp), %rax
	movq	%rax, 170608(%rsp)
	movq	77496(%rsp), %rax
	movq	%rax, 170616(%rsp)
	movq	77504(%rsp), %rax
	movq	%rax, 170624(%rsp)
	movq	77512(%rsp), %rax
	movq	%rax, 170632(%rsp)
	movq	77520(%rsp), %rax
	movq	%rax, 170640(%rsp)
	movq	77528(%rsp), %rax
	movq	%rax, 170648(%rsp)
	movq	77536(%rsp), %rax
	movq	%rax, 170656(%rsp)
	movq	77544(%rsp), %rax
	movq	%rax, 170664(%rsp)
	movq	77552(%rsp), %rax
	movq	%rax, 170672(%rsp)
	movq	77560(%rsp), %rax
	movq	%rax, 170680(%rsp)
	movq	77568(%rsp), %rax
	movq	%rax, 170688(%rsp)
	movq	77576(%rsp), %rax
	movq	%rax, 170696(%rsp)
	movq	77584(%rsp), %rax
	movq	%rax, 170704(%rsp)
	movq	77592(%rsp), %rax
	movq	%rax, 170712(%rsp)
	movq	77600(%rsp), %rax
	movq	%rax, 170720(%rsp)
	movq	77608(%rsp), %rax
	movq	%rax, 170728(%rsp)
	movq	77616(%rsp), %rax
	movq	%rax, 170736(%rsp)
	movq	77624(%rsp), %rax
	movq	%rax, 170744(%rsp)
	movq	77632(%rsp), %rax
	movq	%rax, 170752(%rsp)
	movq	77640(%rsp), %rax
	movq	%rax, 170760(%rsp)
	movq	77648(%rsp), %rax
	movq	%rax, 170768(%rsp)
	movq	77656(%rsp), %rax
	movq	%rax, 170776(%rsp)
	movq	77664(%rsp), %rax
	movq	%rax, 170784(%rsp)
	movq	77672(%rsp), %rax
	movq	%rax, 170792(%rsp)
	movq	77680(%rsp), %rax
	movq	%rax, 170800(%rsp)
	movq	77688(%rsp), %rax
	movq	%rax, 170808(%rsp)
	movq	77696(%rsp), %rax
	movq	%rax, 170816(%rsp)
	movq	77704(%rsp), %rax
	movq	%rax, 170824(%rsp)
	movq	77712(%rsp), %rax
	movq	%rax, 170832(%rsp)
	movq	77720(%rsp), %rax
	movq	%rax, 170840(%rsp)
	movq	77728(%rsp), %rax
	movq	%rax, 170848(%rsp)
	movq	77736(%rsp), %rax
	movq	%rax, 170856(%rsp)
	movq	77744(%rsp), %rax
	movq	%rax, 170864(%rsp)
	movq	77752(%rsp), %rax
	movq	%rax, 170872(%rsp)
	movq	77760(%rsp), %rax
	movq	%rax, 170880(%rsp)
	movq	77768(%rsp), %rax
	movq	%rax, 170888(%rsp)
	movq	77776(%rsp), %rax
	movq	%rax, 170896(%rsp)
	movq	77784(%rsp), %rax
	movq	%rax, 170904(%rsp)
	movq	77792(%rsp), %rax
	movq	%rax, 170912(%rsp)
	movq	77800(%rsp), %rax
	movq	%rax, 170920(%rsp)
	movq	77808(%rsp), %rax
	movq	%rax, 170928(%rsp)
	movq	77816(%rsp), %rax
	movq	%rax, 170936(%rsp)
	movq	77824(%rsp), %rax
	movq	%rax, 170944(%rsp)
	movq	77832(%rsp), %rax
	movq	%rax, 170952(%rsp)
	movq	77840(%rsp), %rax
	movq	%rax, 170960(%rsp)
	movq	77848(%rsp), %rax
	movq	%rax, 170968(%rsp)
	movq	77856(%rsp), %rax
	movq	%rax, 170976(%rsp)
	movq	77864(%rsp), %rax
	movq	%rax, 170984(%rsp)
	movq	77872(%rsp), %rax
	movq	%rax, 170992(%rsp)
	movq	77880(%rsp), %rax
	movq	%rax, 171000(%rsp)
	movq	77888(%rsp), %rax
	movq	%rax, 171008(%rsp)
	movq	77896(%rsp), %rax
	movq	%rax, 171016(%rsp)
	movq	77904(%rsp), %rax
	movq	%rax, 171024(%rsp)
	movq	77912(%rsp), %rax
	movq	%rax, 171032(%rsp)
	movq	77920(%rsp), %rax
	movq	%rax, 171040(%rsp)
	movq	77928(%rsp), %rax
	movq	%rax, 171048(%rsp)
	movq	77936(%rsp), %rax
	movq	%rax, 171056(%rsp)
	movq	77944(%rsp), %rax
	movq	%rax, 171064(%rsp)
	movq	77952(%rsp), %rax
	movq	%rax, 171072(%rsp)
	movq	77960(%rsp), %rax
	movq	%rax, 171080(%rsp)
	movq	77968(%rsp), %rax
	movq	%rax, 171088(%rsp)
	movq	77976(%rsp), %rax
	movq	%rax, 171096(%rsp)
	movq	77984(%rsp), %rax
	movq	%rax, 171104(%rsp)
	movq	77992(%rsp), %rax
	movq	%rax, 171112(%rsp)
	movq	78000(%rsp), %rax
	movq	%rax, 171120(%rsp)
	movq	78008(%rsp), %rax
	movq	%rax, 171128(%rsp)
	movq	78016(%rsp), %rax
	movq	%rax, 171136(%rsp)
	movq	78024(%rsp), %rax
	movq	%rax, 171144(%rsp)
	movq	78032(%rsp), %rax
	movq	%rax, 171152(%rsp)
	movq	78040(%rsp), %rax
	movq	%rax, 171160(%rsp)
	movq	78048(%rsp), %rax
	movq	%rax, 171168(%rsp)
	movq	78056(%rsp), %rax
	movq	%rax, 171176(%rsp)
	movq	78064(%rsp), %rax
	movq	%rax, 171184(%rsp)
	movq	78072(%rsp), %rax
	movq	%rax, 171192(%rsp)
	movq	78080(%rsp), %rax
	movq	%rax, 171200(%rsp)
	movq	78088(%rsp), %rax
	movq	%rax, 171208(%rsp)
	movq	78096(%rsp), %rax
	movq	%rax, 171216(%rsp)
	movq	78104(%rsp), %rax
	movq	%rax, 171224(%rsp)
	movq	78112(%rsp), %rax
	movq	%rax, 171232(%rsp)
	movq	78120(%rsp), %rax
	movq	%rax, 171240(%rsp)
	movq	78128(%rsp), %rax
	movq	%rax, 171248(%rsp)
	movq	78136(%rsp), %rax
	movq	%rax, 171256(%rsp)
	movq	78144(%rsp), %rax
	movq	%rax, 171264(%rsp)
	movq	78152(%rsp), %rax
	movq	%rax, 171272(%rsp)
	movq	78160(%rsp), %rax
	movq	%rax, 171280(%rsp)
	movq	78168(%rsp), %rax
	movq	%rax, 171288(%rsp)
	movq	78176(%rsp), %rax
	movq	%rax, 171296(%rsp)
	movq	78184(%rsp), %rax
	movq	%rax, 171304(%rsp)
	movq	78192(%rsp), %rax
	movq	%rax, 171312(%rsp)
	movq	78200(%rsp), %rax
	movq	%rax, 171320(%rsp)
	movq	78208(%rsp), %rax
	movq	%rax, 171328(%rsp)
	movq	78216(%rsp), %rax
	movq	%rax, 171336(%rsp)
	movq	78224(%rsp), %rax
	movq	%rax, 171344(%rsp)
	movq	78232(%rsp), %rax
	movq	%rax, 171352(%rsp)
	movq	78240(%rsp), %rax
	movq	%rax, 171360(%rsp)
	movq	78248(%rsp), %rax
	movq	%rax, 171368(%rsp)
	movq	78256(%rsp), %rax
	movq	%rax, 171376(%rsp)
	movq	78264(%rsp), %rax
	movq	%rax, 171384(%rsp)
	movq	78272(%rsp), %rax
	movq	%rax, 171392(%rsp)
	movq	78280(%rsp), %rax
	movq	%rax, 171400(%rsp)
	movq	78288(%rsp), %rax
	movq	%rax, 171408(%rsp)
	movq	78296(%rsp), %rax
	movq	%rax, 171416(%rsp)
	movq	78304(%rsp), %rax
	movq	%rax, 171424(%rsp)
	movq	78312(%rsp), %rax
	movq	%rax, 171432(%rsp)
	movq	78320(%rsp), %rax
	movq	%rax, 171440(%rsp)
	movq	78328(%rsp), %rax
	movq	%rax, 171448(%rsp)
	movq	78336(%rsp), %rax
	movq	%rax, 171456(%rsp)
	movq	78344(%rsp), %rax
	movq	%rax, 171464(%rsp)
	movq	78352(%rsp), %rax
	movq	%rax, 171472(%rsp)
	movq	78360(%rsp), %rax
	movq	%rax, 171480(%rsp)
	movq	78368(%rsp), %rax
	movq	%rax, 171488(%rsp)
	movq	78376(%rsp), %rax
	movq	%rax, 171496(%rsp)
	movq	78384(%rsp), %rax
	movq	%rax, 171504(%rsp)
	movq	78392(%rsp), %rax
	movq	%rax, 171512(%rsp)
	movq	78400(%rsp), %rax
	movq	%rax, 171520(%rsp)
	movq	78408(%rsp), %rax
	movq	%rax, 171528(%rsp)
	movq	78416(%rsp), %rax
	movq	%rax, 171536(%rsp)
	movq	78424(%rsp), %rax
	movq	%rax, 171544(%rsp)
	movq	78432(%rsp), %rax
	movq	%rax, 171552(%rsp)
	movq	78440(%rsp), %rax
	movq	%rax, 171560(%rsp)
	movq	78448(%rsp), %rax
	movq	%rax, 171568(%rsp)
	movq	78456(%rsp), %rax
	movq	%rax, 171576(%rsp)
	movq	78464(%rsp), %rax
	movq	%rax, 171584(%rsp)
	movq	78472(%rsp), %rax
	movq	%rax, 171592(%rsp)
	movq	78480(%rsp), %rax
	movq	%rax, 171600(%rsp)
	movq	78488(%rsp), %rax
	movq	%rax, 171608(%rsp)
	movq	78496(%rsp), %rax
	movq	%rax, 171616(%rsp)
	movq	78504(%rsp), %rax
	movq	%rax, 171624(%rsp)
	movq	78512(%rsp), %rax
	movq	%rax, 171632(%rsp)
	movq	78520(%rsp), %rax
	movq	%rax, 171640(%rsp)
	movq	78528(%rsp), %rax
	movq	%rax, 171648(%rsp)
	movq	78536(%rsp), %rax
	movq	%rax, 171656(%rsp)
	movq	78544(%rsp), %rax
	movq	%rax, 171664(%rsp)
	movq	78552(%rsp), %rax
	movq	%rax, 171672(%rsp)
	movq	78560(%rsp), %rax
	movq	%rax, 171680(%rsp)
	movq	78568(%rsp), %rax
	movq	%rax, 171688(%rsp)
	movq	78576(%rsp), %rax
	movq	%rax, 171696(%rsp)
	movq	78584(%rsp), %rax
	movq	%rax, 171704(%rsp)
	movq	78592(%rsp), %rax
	movq	%rax, 171712(%rsp)
	movq	78600(%rsp), %rax
	movq	%rax, 171720(%rsp)
	movq	78608(%rsp), %rax
	movq	%rax, 171728(%rsp)
	movq	78616(%rsp), %rax
	movq	%rax, 171736(%rsp)
	movq	78624(%rsp), %rax
	movq	%rax, 171744(%rsp)
	movq	78632(%rsp), %rax
	movq	%rax, 171752(%rsp)
	movq	78640(%rsp), %rax
	movq	%rax, 171760(%rsp)
	movq	78648(%rsp), %rax
	movq	%rax, 171768(%rsp)
	movq	78656(%rsp), %rax
	movq	%rax, 171776(%rsp)
	movq	78664(%rsp), %rax
	movq	%rax, 171784(%rsp)
	movq	78672(%rsp), %rax
	movq	%rax, 171792(%rsp)
	movq	78680(%rsp), %rax
	movq	%rax, 171800(%rsp)
	movq	78688(%rsp), %rax
	movq	%rax, 171808(%rsp)
	movq	78696(%rsp), %rax
	movq	%rax, 171816(%rsp)
	movq	78704(%rsp), %rax
	movq	%rax, 171824(%rsp)
	movq	78712(%rsp), %rax
	movq	%rax, 171832(%rsp)
	movq	78720(%rsp), %rax
	movq	%rax, 171840(%rsp)
	movq	78728(%rsp), %rax
	movq	%rax, 171848(%rsp)
	movq	78736(%rsp), %rax
	movq	%rax, 171856(%rsp)
	movq	78744(%rsp), %rax
	movq	%rax, 171864(%rsp)
	movq	78752(%rsp), %rax
	movq	%rax, 171872(%rsp)
	movq	78760(%rsp), %rax
	movq	%rax, 171880(%rsp)
	movq	78768(%rsp), %rax
	movq	%rax, 171888(%rsp)
	movq	78776(%rsp), %rax
	movq	%rax, 171896(%rsp)
	movq	78784(%rsp), %rax
	movq	%rax, 171904(%rsp)
	movq	78792(%rsp), %rax
	movq	%rax, 171912(%rsp)
	movq	78800(%rsp), %rax
	movq	%rax, 171920(%rsp)
	movq	78808(%rsp), %rax
	movq	%rax, 171928(%rsp)
	movq	78816(%rsp), %rax
	movq	%rax, 171936(%rsp)
	movq	78824(%rsp), %rax
	movq	%rax, 171944(%rsp)
	movq	78832(%rsp), %rax
	movq	%rax, 171952(%rsp)
	movq	78840(%rsp), %rax
	movq	%rax, 171960(%rsp)
	movq	78848(%rsp), %rax
	movq	%rax, 171968(%rsp)
	movq	78856(%rsp), %rax
	movq	%rax, 171976(%rsp)
	movq	78864(%rsp), %rax
	movq	%rax, 171984(%rsp)
	movq	78872(%rsp), %rax
	movq	%rax, 171992(%rsp)
	movq	78880(%rsp), %rax
	movq	%rax, 172000(%rsp)
	movq	78888(%rsp), %rax
	movq	%rax, 172008(%rsp)
	movq	78896(%rsp), %rax
	movq	%rax, 172016(%rsp)
	movq	78904(%rsp), %rax
	movq	%rax, 172024(%rsp)
	movq	78912(%rsp), %rax
	movq	%rax, 172032(%rsp)
	movq	78920(%rsp), %rax
	movq	%rax, 172040(%rsp)
	movq	78928(%rsp), %rax
	movq	%rax, 172048(%rsp)
	movq	78936(%rsp), %rax
	movq	%rax, 172056(%rsp)
	movq	78944(%rsp), %rax
	movq	%rax, 172064(%rsp)
	movq	78952(%rsp), %rax
	movq	%rax, 172072(%rsp)
	movq	78960(%rsp), %rax
	movq	%rax, 172080(%rsp)
	movq	78968(%rsp), %rax
	movq	%rax, 172088(%rsp)
	movq	78976(%rsp), %rax
	movq	%rax, 172096(%rsp)
	movq	78984(%rsp), %rax
	movq	%rax, 172104(%rsp)
	movq	78992(%rsp), %rax
	movq	%rax, 172112(%rsp)
	movq	79000(%rsp), %rax
	movq	%rax, 172120(%rsp)
	movq	79008(%rsp), %rax
	movq	%rax, 172128(%rsp)
	movq	79016(%rsp), %rax
	movq	%rax, 172136(%rsp)
	movq	79024(%rsp), %rax
	movq	%rax, 172144(%rsp)
	movq	79032(%rsp), %rax
	movq	%rax, 172152(%rsp)
	movq	79040(%rsp), %rax
	movq	%rax, 172160(%rsp)
	movq	79048(%rsp), %rax
	movq	%rax, 172168(%rsp)
	movq	79056(%rsp), %rax
	movq	%rax, 172176(%rsp)
	movq	79064(%rsp), %rax
	movq	%rax, 172184(%rsp)
	movq	79072(%rsp), %rax
	movq	%rax, 172192(%rsp)
	movq	79080(%rsp), %rax
	movq	%rax, 172200(%rsp)
	movq	79088(%rsp), %rax
	movq	%rax, 172208(%rsp)
	movq	79096(%rsp), %rax
	movq	%rax, 172216(%rsp)
	movq	79104(%rsp), %rax
	movq	%rax, 172224(%rsp)
	movq	79112(%rsp), %rax
	movq	%rax, 172232(%rsp)
	movq	79120(%rsp), %rax
	movq	%rax, 172240(%rsp)
	movq	79128(%rsp), %rax
	movq	%rax, 172248(%rsp)
	movq	79136(%rsp), %rax
	movq	%rax, 172256(%rsp)
	movq	79144(%rsp), %rax
	movq	%rax, 172264(%rsp)
	movq	79152(%rsp), %rax
	movq	%rax, 172272(%rsp)
	movq	79160(%rsp), %rax
	movq	%rax, 172280(%rsp)
	movq	79168(%rsp), %rax
	movq	%rax, 172288(%rsp)
	movq	79176(%rsp), %rax
	movq	%rax, 172296(%rsp)
	movq	79184(%rsp), %rax
	movq	%rax, 172304(%rsp)
	movq	79192(%rsp), %rax
	movq	%rax, 172312(%rsp)
	movq	79200(%rsp), %rax
	movq	%rax, 172320(%rsp)
	movq	79208(%rsp), %rax
	movq	%rax, 172328(%rsp)
	movq	79216(%rsp), %rax
	movq	%rax, 172336(%rsp)
	movq	79224(%rsp), %rax
	movq	%rax, 172344(%rsp)
	movq	79232(%rsp), %rax
	movq	%rax, 172352(%rsp)
	movq	79240(%rsp), %rax
	movq	%rax, 172360(%rsp)
	movq	79248(%rsp), %rax
	movq	%rax, 172368(%rsp)
	movq	79256(%rsp), %rax
	movq	%rax, 172376(%rsp)
	movq	79264(%rsp), %rax
	movq	%rax, 172384(%rsp)
	movq	79272(%rsp), %rax
	movq	%rax, 172392(%rsp)
	movq	79280(%rsp), %rax
	movq	%rax, 172400(%rsp)
	movq	79288(%rsp), %rax
	movq	%rax, 172408(%rsp)
	movq	79296(%rsp), %rax
	movq	%rax, 172416(%rsp)
	movq	79304(%rsp), %rax
	movq	%rax, 172424(%rsp)
	movq	79312(%rsp), %rax
	movq	%rax, 172432(%rsp)
	movq	79320(%rsp), %rax
	movq	%rax, 172440(%rsp)
	movq	79328(%rsp), %rax
	movq	%rax, 172448(%rsp)
	movq	79336(%rsp), %rax
	movq	%rax, 172456(%rsp)
	movq	79344(%rsp), %rax
	movq	%rax, 172464(%rsp)
	movq	79352(%rsp), %rax
	movq	%rax, 172472(%rsp)
	movq	79360(%rsp), %rax
	movq	%rax, 172480(%rsp)
	movq	79368(%rsp), %rax
	movq	%rax, 172488(%rsp)
	movq	79376(%rsp), %rax
	movq	%rax, 172496(%rsp)
	movq	79384(%rsp), %rax
	movq	%rax, 172504(%rsp)
	movq	79392(%rsp), %rax
	movq	%rax, 172512(%rsp)
	movq	79400(%rsp), %rax
	movq	%rax, 172520(%rsp)
	movq	79408(%rsp), %rax
	movq	%rax, 172528(%rsp)
	movq	79416(%rsp), %rax
	movq	%rax, 172536(%rsp)
	movq	79424(%rsp), %rax
	movq	%rax, 172544(%rsp)
	movq	79432(%rsp), %rax
	movq	%rax, 172552(%rsp)
	movq	79440(%rsp), %rax
	movq	%rax, 172560(%rsp)
	movq	79448(%rsp), %rax
	movq	%rax, 172568(%rsp)
	movq	79456(%rsp), %rax
	movq	%rax, 172576(%rsp)
	movq	79464(%rsp), %rax
	movq	%rax, 172584(%rsp)
	movq	79472(%rsp), %rax
	movq	%rax, 172592(%rsp)
	movq	79480(%rsp), %rax
	movq	%rax, 172600(%rsp)
	movq	79488(%rsp), %rax
	movq	%rax, 172608(%rsp)
	movq	79496(%rsp), %rax
	movq	%rax, 172616(%rsp)
	movq	79504(%rsp), %rax
	movq	%rax, 172624(%rsp)
	movq	79512(%rsp), %rax
	movq	%rax, 172632(%rsp)
	movq	79520(%rsp), %rax
	movq	%rax, 172640(%rsp)
	movq	79528(%rsp), %rax
	movq	%rax, 172648(%rsp)
	movq	79536(%rsp), %rax
	movq	%rax, 172656(%rsp)
	movq	79544(%rsp), %rax
	movq	%rax, 172664(%rsp)
	movq	79552(%rsp), %rax
	movq	%rax, 172672(%rsp)
	movq	79560(%rsp), %rax
	movq	%rax, 172680(%rsp)
	movq	79568(%rsp), %rax
	movq	%rax, 172688(%rsp)
	movq	79576(%rsp), %rax
	movq	%rax, 172696(%rsp)
	movq	79584(%rsp), %rax
	movq	%rax, 172704(%rsp)
	movq	79592(%rsp), %rax
	movq	%rax, 172712(%rsp)
	movq	79600(%rsp), %rax
	movq	%rax, 172720(%rsp)
	movq	79608(%rsp), %rax
	movq	%rax, 172728(%rsp)
	movq	79616(%rsp), %rax
	movq	%rax, 172736(%rsp)
	movq	79624(%rsp), %rax
	movq	%rax, 172744(%rsp)
	movq	79632(%rsp), %rax
	movq	%rax, 172752(%rsp)
	movq	79640(%rsp), %rax
	movq	%rax, 172760(%rsp)
	movq	79648(%rsp), %rax
	movq	%rax, 172768(%rsp)
	movq	79656(%rsp), %rax
	movq	%rax, 172776(%rsp)
	movq	79664(%rsp), %rax
	movq	%rax, 172784(%rsp)
	movq	79672(%rsp), %rax
	movq	%rax, 172792(%rsp)
	movq	79680(%rsp), %rax
	movq	%rax, 172800(%rsp)
	movq	79688(%rsp), %rax
	movq	%rax, 172808(%rsp)
	movq	79696(%rsp), %rax
	movq	%rax, 172816(%rsp)
	movq	79704(%rsp), %rax
	movq	%rax, 172824(%rsp)
	movq	79712(%rsp), %rax
	movq	%rax, 172832(%rsp)
	movq	79720(%rsp), %rax
	movq	%rax, 172840(%rsp)
	movq	79728(%rsp), %rax
	movq	%rax, 172848(%rsp)
	movq	79736(%rsp), %rax
	movq	%rax, 172856(%rsp)
	movq	79744(%rsp), %rax
	movq	%rax, 172864(%rsp)
	movq	79752(%rsp), %rax
	movq	%rax, 172872(%rsp)
	movq	79760(%rsp), %rax
	movq	%rax, 172880(%rsp)
	movq	79768(%rsp), %rax
	movq	%rax, 172888(%rsp)
	movq	79776(%rsp), %rax
	movq	%rax, 172896(%rsp)
	movq	79784(%rsp), %rax
	movq	%rax, 172904(%rsp)
	movq	79792(%rsp), %rax
	movq	%rax, 172912(%rsp)
	movq	79800(%rsp), %rax
	movq	%rax, 172920(%rsp)
	movq	79808(%rsp), %rax
	movq	%rax, 172928(%rsp)
	movq	79816(%rsp), %rax
	movq	%rax, 172936(%rsp)
	movq	79824(%rsp), %rax
	movq	%rax, 172944(%rsp)
	movq	79832(%rsp), %rax
	movq	%rax, 172952(%rsp)
	movq	79840(%rsp), %rax
	movq	%rax, 172960(%rsp)
	movq	79848(%rsp), %rax
	movq	%rax, 172968(%rsp)
	movq	79856(%rsp), %rax
	movq	%rax, 172976(%rsp)
	movq	79864(%rsp), %rax
	movq	%rax, 172984(%rsp)
	movq	79872(%rsp), %rax
	movq	%rax, 172992(%rsp)
	movq	79880(%rsp), %rax
	movq	%rax, 173000(%rsp)
	movq	79888(%rsp), %rax
	movq	%rax, 173008(%rsp)
	movq	79896(%rsp), %rax
	movq	%rax, 173016(%rsp)
	movq	79904(%rsp), %rax
	movq	%rax, 173024(%rsp)
	movq	79912(%rsp), %rax
	movq	%rax, 173032(%rsp)
	movq	79920(%rsp), %rax
	movq	%rax, 173040(%rsp)
	movq	79928(%rsp), %rax
	movq	%rax, 173048(%rsp)
	movq	79936(%rsp), %rax
	movq	%rax, 173056(%rsp)
	movq	79944(%rsp), %rax
	movq	%rax, 173064(%rsp)
	movq	79952(%rsp), %rax
	movq	%rax, 173072(%rsp)
	movq	79960(%rsp), %rax
	movq	%rax, 173080(%rsp)
	movq	79968(%rsp), %rax
	movq	%rax, 173088(%rsp)
	movq	79976(%rsp), %rax
	movq	%rax, 173096(%rsp)
	movq	79984(%rsp), %rax
	movq	%rax, 173104(%rsp)
	movq	79992(%rsp), %rax
	movq	%rax, 173112(%rsp)
	movq	80000(%rsp), %rax
	movq	%rax, 173120(%rsp)
	movq	80008(%rsp), %rax
	movq	%rax, 173128(%rsp)
	movq	80016(%rsp), %rax
	movq	%rax, 173136(%rsp)
	movq	80024(%rsp), %rax
	movq	%rax, 173144(%rsp)
	movq	80032(%rsp), %rax
	movq	%rax, 173152(%rsp)
	movq	80040(%rsp), %rax
	movq	%rax, 173160(%rsp)
	movq	80048(%rsp), %rax
	movq	%rax, 173168(%rsp)
	movq	80056(%rsp), %rax
	movq	%rax, 173176(%rsp)
	movq	80064(%rsp), %rax
	movq	%rax, 173184(%rsp)
	movq	80072(%rsp), %rax
	movq	%rax, 173192(%rsp)
	movq	80080(%rsp), %rax
	movq	%rax, 173200(%rsp)
	movq	80088(%rsp), %rax
	movq	%rax, 173208(%rsp)
	movq	80096(%rsp), %rax
	movq	%rax, 173216(%rsp)
	movq	80104(%rsp), %rax
	movq	%rax, 173224(%rsp)
	movq	80112(%rsp), %rax
	movq	%rax, 173232(%rsp)
	movq	80120(%rsp), %rax
	movq	%rax, 173240(%rsp)
	movq	80128(%rsp), %rax
	movq	%rax, 173248(%rsp)
	movq	80136(%rsp), %rax
	movq	%rax, 173256(%rsp)
	movq	80144(%rsp), %rax
	movq	%rax, 173264(%rsp)
	movq	80152(%rsp), %rax
	movq	%rax, 173272(%rsp)
	movq	80160(%rsp), %rax
	movq	%rax, 173280(%rsp)
	movq	80168(%rsp), %rax
	movq	%rax, 173288(%rsp)
	movq	80176(%rsp), %rax
	movq	%rax, 173296(%rsp)
	movq	80184(%rsp), %rax
	movq	%rax, 173304(%rsp)
	movq	80192(%rsp), %rax
	movq	%rax, 173312(%rsp)
	movq	80200(%rsp), %rax
	movq	%rax, 173320(%rsp)
	movq	80208(%rsp), %rax
	movq	%rax, 173328(%rsp)
	movq	80216(%rsp), %rax
	movq	%rax, 173336(%rsp)
	movq	80224(%rsp), %rax
	movq	%rax, 173344(%rsp)
	movq	80232(%rsp), %rax
	movq	%rax, 173352(%rsp)
	movq	80240(%rsp), %rax
	movq	%rax, 173360(%rsp)
	movq	80248(%rsp), %rax
	movq	%rax, 173368(%rsp)
	movq	80256(%rsp), %rax
	movq	%rax, 173376(%rsp)
	movq	80264(%rsp), %rax
	movq	%rax, 173384(%rsp)
	movq	80272(%rsp), %rax
	movq	%rax, 173392(%rsp)
	movq	80280(%rsp), %rax
	movq	%rax, 173400(%rsp)
	movq	80288(%rsp), %rax
	movq	%rax, 173408(%rsp)
	movq	80296(%rsp), %rax
	movq	%rax, 173416(%rsp)
	movq	80304(%rsp), %rax
	movq	%rax, 173424(%rsp)
	movq	80312(%rsp), %rax
	movq	%rax, 173432(%rsp)
	movq	80320(%rsp), %rax
	movq	%rax, 173440(%rsp)
	movq	80328(%rsp), %rax
	movq	%rax, 173448(%rsp)
	movq	80336(%rsp), %rax
	movq	%rax, 173456(%rsp)
	movq	80344(%rsp), %rax
	movq	%rax, 173464(%rsp)
	movq	80352(%rsp), %rax
	movq	%rax, 173472(%rsp)
	movq	80360(%rsp), %rax
	movq	%rax, 173480(%rsp)
	movq	80368(%rsp), %rax
	movq	%rax, 173488(%rsp)
	movq	80376(%rsp), %rax
	movq	%rax, 173496(%rsp)
	movq	80384(%rsp), %rax
	movq	%rax, 173504(%rsp)
	movq	80392(%rsp), %rax
	movq	%rax, 173512(%rsp)
	movq	80400(%rsp), %rax
	movq	%rax, 173520(%rsp)
	movq	80408(%rsp), %rax
	movq	%rax, 173528(%rsp)
	movq	80416(%rsp), %rax
	movq	%rax, 173536(%rsp)
	movq	80424(%rsp), %rax
	movq	%rax, 173544(%rsp)
	movq	80432(%rsp), %rax
	movq	%rax, 173552(%rsp)
	movq	80440(%rsp), %rax
	movq	%rax, 173560(%rsp)
	movq	80448(%rsp), %rax
	movq	%rax, 173568(%rsp)
	movq	80456(%rsp), %rax
	movq	%rax, 173576(%rsp)
	movq	80464(%rsp), %rax
	movq	%rax, 173584(%rsp)
	movq	80472(%rsp), %rax
	movq	%rax, 173592(%rsp)
	movq	80480(%rsp), %rax
	movq	%rax, 173600(%rsp)
	movq	80488(%rsp), %rax
	movq	%rax, 173608(%rsp)
	movq	80496(%rsp), %rax
	movq	%rax, 173616(%rsp)
	movq	80504(%rsp), %rax
	movq	%rax, 173624(%rsp)
	movq	80512(%rsp), %rax
	movq	%rax, 173632(%rsp)
	movq	80520(%rsp), %rax
	movq	%rax, 173640(%rsp)
	movq	80528(%rsp), %rax
	movq	%rax, 173648(%rsp)
	movq	80536(%rsp), %rax
	movq	%rax, 173656(%rsp)
	movq	80544(%rsp), %rax
	movq	%rax, 173664(%rsp)
	movq	80552(%rsp), %rax
	movq	%rax, 173672(%rsp)
	movq	80560(%rsp), %rax
	movq	%rax, 173680(%rsp)
	movq	80568(%rsp), %rax
	movq	%rax, 173688(%rsp)
	movq	80576(%rsp), %rax
	movq	%rax, 173696(%rsp)
	movq	80584(%rsp), %rax
	movq	%rax, 173704(%rsp)
	movq	80592(%rsp), %rax
	movq	%rax, 173712(%rsp)
	movq	80600(%rsp), %rax
	movq	%rax, 173720(%rsp)
	movq	80608(%rsp), %rax
	movq	%rax, 173728(%rsp)
	movq	80616(%rsp), %rax
	movq	%rax, 173736(%rsp)
	movq	80624(%rsp), %rax
	movq	%rax, 173744(%rsp)
	movq	80632(%rsp), %rax
	movq	%rax, 173752(%rsp)
	movq	80640(%rsp), %rax
	movq	%rax, 173760(%rsp)
	movq	80648(%rsp), %rax
	movq	%rax, 173768(%rsp)
	movq	80656(%rsp), %rax
	movq	%rax, 173776(%rsp)
	movq	80664(%rsp), %rax
	movq	%rax, 173784(%rsp)
	movq	80672(%rsp), %rax
	movq	%rax, 173792(%rsp)
	movq	80680(%rsp), %rax
	movq	%rax, 173800(%rsp)
	movq	80688(%rsp), %rax
	movq	%rax, 173808(%rsp)
	movq	80696(%rsp), %rax
	movq	%rax, 173816(%rsp)
	movq	80704(%rsp), %rax
	movq	%rax, 173824(%rsp)
	movq	80712(%rsp), %rax
	movq	%rax, 173832(%rsp)
	movq	80720(%rsp), %rax
	movq	%rax, 173840(%rsp)
	movq	80728(%rsp), %rax
	movq	%rax, 173848(%rsp)
	movq	80736(%rsp), %rax
	movq	%rax, 173856(%rsp)
	movq	80744(%rsp), %rax
	movq	%rax, 173864(%rsp)
	movq	80752(%rsp), %rax
	movq	%rax, 173872(%rsp)
	movq	80760(%rsp), %rax
	movq	%rax, 173880(%rsp)
	movq	80768(%rsp), %rax
	movq	%rax, 173888(%rsp)
	movq	80776(%rsp), %rax
	movq	%rax, 173896(%rsp)
	movq	80784(%rsp), %rax
	movq	%rax, 173904(%rsp)
	movq	80792(%rsp), %rax
	movq	%rax, 173912(%rsp)
	movq	80800(%rsp), %rax
	movq	%rax, 173920(%rsp)
	movq	80808(%rsp), %rax
	movq	%rax, 173928(%rsp)
	movq	80816(%rsp), %rax
	movq	%rax, 173936(%rsp)
	movq	80824(%rsp), %rax
	movq	%rax, 173944(%rsp)
	movq	80832(%rsp), %rax
	movq	%rax, 173952(%rsp)
	movq	80840(%rsp), %rax
	movq	%rax, 173960(%rsp)
	movq	80848(%rsp), %rax
	movq	%rax, 173968(%rsp)
	movq	80856(%rsp), %rax
	movq	%rax, 173976(%rsp)
	movq	80864(%rsp), %rax
	movq	%rax, 173984(%rsp)
	movq	80872(%rsp), %rax
	movq	%rax, 173992(%rsp)
	movq	80880(%rsp), %rax
	movq	%rax, 174000(%rsp)
	movq	80888(%rsp), %rax
	movq	%rax, 174008(%rsp)
	movq	80896(%rsp), %rax
	movq	%rax, 174016(%rsp)
	movq	80904(%rsp), %rax
	movq	%rax, 174024(%rsp)
	movq	80912(%rsp), %rax
	movq	%rax, 174032(%rsp)
	movq	80920(%rsp), %rax
	movq	%rax, 174040(%rsp)
	movq	80928(%rsp), %rax
	movq	%rax, 174048(%rsp)
	movq	80936(%rsp), %rax
	movq	%rax, 174056(%rsp)
	movq	80944(%rsp), %rax
	movq	%rax, 174064(%rsp)
	movq	80952(%rsp), %rax
	movq	%rax, 174072(%rsp)
	movq	80960(%rsp), %rax
	movq	%rax, 174080(%rsp)
	movq	80968(%rsp), %rax
	movq	%rax, 174088(%rsp)
	movq	80976(%rsp), %rax
	movq	%rax, 174096(%rsp)
	movq	80984(%rsp), %rax
	movq	%rax, 174104(%rsp)
	movq	80992(%rsp), %rax
	movq	%rax, 174112(%rsp)
	movq	81000(%rsp), %rax
	movq	%rax, 174120(%rsp)
	movq	81008(%rsp), %rax
	movq	%rax, 174128(%rsp)
	movq	81016(%rsp), %rax
	movq	%rax, 174136(%rsp)
	movq	81024(%rsp), %rax
	movq	%rax, 174144(%rsp)
	movq	81032(%rsp), %rax
	movq	%rax, 174152(%rsp)
	movq	81040(%rsp), %rax
	movq	%rax, 174160(%rsp)
	movq	81048(%rsp), %rax
	movq	%rax, 174168(%rsp)
	movq	81056(%rsp), %rax
	movq	%rax, 174176(%rsp)
	movq	81064(%rsp), %rax
	movq	%rax, 174184(%rsp)
	movq	81072(%rsp), %rax
	movq	%rax, 174192(%rsp)
	movq	81080(%rsp), %rax
	movq	%rax, 174200(%rsp)
	movq	81088(%rsp), %rax
	movq	%rax, 174208(%rsp)
	movq	81096(%rsp), %rax
	movq	%rax, 174216(%rsp)
	movq	81104(%rsp), %rax
	movq	%rax, 174224(%rsp)
	movq	81112(%rsp), %rax
	movq	%rax, 174232(%rsp)
	movq	81120(%rsp), %rax
	movq	%rax, 174240(%rsp)
	movq	81128(%rsp), %rax
	movq	%rax, 174248(%rsp)
	movq	81136(%rsp), %rax
	movq	%rax, 174256(%rsp)
	movq	81144(%rsp), %rax
	movq	%rax, 174264(%rsp)
	movq	81152(%rsp), %rax
	movq	%rax, 174272(%rsp)
	movq	81160(%rsp), %rax
	movq	%rax, 174280(%rsp)
	movq	81168(%rsp), %rax
	movq	%rax, 174288(%rsp)
	movq	81176(%rsp), %rax
	movq	%rax, 174296(%rsp)
	movq	81184(%rsp), %rax
	movq	%rax, 174304(%rsp)
	movq	81192(%rsp), %rax
	movq	%rax, 174312(%rsp)
	movq	81200(%rsp), %rax
	movq	%rax, 174320(%rsp)
	movq	81208(%rsp), %rax
	movq	%rax, 174328(%rsp)
	movq	81216(%rsp), %rax
	movq	%rax, 174336(%rsp)
	movq	81224(%rsp), %rax
	movq	%rax, 174344(%rsp)
	movq	81232(%rsp), %rax
	movq	%rax, 174352(%rsp)
	movq	81240(%rsp), %rax
	movq	%rax, 174360(%rsp)
	movq	81248(%rsp), %rax
	movq	%rax, 174368(%rsp)
	movq	81256(%rsp), %rax
	movq	%rax, 174376(%rsp)
	movq	81264(%rsp), %rax
	movq	%rax, 174384(%rsp)
	movq	81272(%rsp), %rax
	movq	%rax, 174392(%rsp)
	movq	81280(%rsp), %rax
	movq	%rax, 174400(%rsp)
	movq	81288(%rsp), %rax
	movq	%rax, 174408(%rsp)
	movq	81296(%rsp), %rax
	movq	%rax, 174416(%rsp)
	movq	81304(%rsp), %rax
	movq	%rax, 174424(%rsp)
	movq	81312(%rsp), %rax
	movq	%rax, 174432(%rsp)
	movq	81320(%rsp), %rax
	movq	%rax, 174440(%rsp)
	movq	81328(%rsp), %rax
	movq	%rax, 174448(%rsp)
	movq	81336(%rsp), %rax
	movq	%rax, 174456(%rsp)
	movq	81344(%rsp), %rax
	movq	%rax, 174464(%rsp)
	movq	81352(%rsp), %rax
	movq	%rax, 174472(%rsp)
	movq	81360(%rsp), %rax
	movq	%rax, 174480(%rsp)
	movq	81368(%rsp), %rax
	movq	%rax, 174488(%rsp)
	movq	81376(%rsp), %rax
	movq	%rax, 174496(%rsp)
	movq	81384(%rsp), %rax
	movq	%rax, 174504(%rsp)
	movq	81392(%rsp), %rax
	movq	%rax, 174512(%rsp)
	movq	81400(%rsp), %rax
	movq	%rax, 174520(%rsp)
	movq	81408(%rsp), %rax
	movq	%rax, 174528(%rsp)
	movq	81416(%rsp), %rax
	movq	%rax, 174536(%rsp)
	movq	81424(%rsp), %rax
	movq	%rax, 174544(%rsp)
	movq	81432(%rsp), %rax
	movq	%rax, 174552(%rsp)
	movq	81440(%rsp), %rax
	movq	%rax, 174560(%rsp)
	movq	81448(%rsp), %rax
	movq	%rax, 174568(%rsp)
	movq	81456(%rsp), %rax
	movq	%rax, 174576(%rsp)
	movq	81464(%rsp), %rax
	movq	%rax, 174584(%rsp)
	movq	81472(%rsp), %rax
	movq	%rax, 174592(%rsp)
	movq	81480(%rsp), %rax
	movq	%rax, 174600(%rsp)
	movq	81488(%rsp), %rax
	movq	%rax, 174608(%rsp)
	movq	81496(%rsp), %rax
	movq	%rax, 174616(%rsp)
	movq	81504(%rsp), %rax
	movq	%rax, 174624(%rsp)
	movq	81512(%rsp), %rax
	movq	%rax, 174632(%rsp)
	movq	81520(%rsp), %rax
	movq	%rax, 174640(%rsp)
	movq	81528(%rsp), %rax
	movq	%rax, 174648(%rsp)
	movq	81536(%rsp), %rax
	movq	%rax, 174656(%rsp)
	movq	81544(%rsp), %rax
	movq	%rax, 174664(%rsp)
	movq	81552(%rsp), %rax
	movq	%rax, 174672(%rsp)
	movq	81560(%rsp), %rax
	movq	%rax, 174680(%rsp)
	movq	81568(%rsp), %rax
	movq	%rax, 174688(%rsp)
	movq	81576(%rsp), %rax
	movq	%rax, 174696(%rsp)
	movq	81584(%rsp), %rax
	movq	%rax, 174704(%rsp)
	movq	81592(%rsp), %rax
	movq	%rax, 174712(%rsp)
	movq	81600(%rsp), %rax
	movq	%rax, 174720(%rsp)
	movq	81608(%rsp), %rax
	movq	%rax, 174728(%rsp)
	movq	81616(%rsp), %rax
	movq	%rax, 174736(%rsp)
	movq	81624(%rsp), %rax
	movq	%rax, 174744(%rsp)
	movq	81632(%rsp), %rax
	movq	%rax, 174752(%rsp)
	movq	81640(%rsp), %rax
	movq	%rax, 174760(%rsp)
	movq	81648(%rsp), %rax
	movq	%rax, 174768(%rsp)
	movq	81656(%rsp), %rax
	movq	%rax, 174776(%rsp)
	movq	81664(%rsp), %rax
	movq	%rax, 174784(%rsp)
	movq	81672(%rsp), %rax
	movq	%rax, 174792(%rsp)
	movq	81680(%rsp), %rax
	movq	%rax, 174800(%rsp)
	movq	81688(%rsp), %rax
	movq	%rax, 174808(%rsp)
	movq	81696(%rsp), %rax
	movq	%rax, 174816(%rsp)
	movq	81704(%rsp), %rax
	movq	%rax, 174824(%rsp)
	movq	81712(%rsp), %rax
	movq	%rax, 174832(%rsp)
	movq	81720(%rsp), %rax
	movq	%rax, 174840(%rsp)
	movq	81728(%rsp), %rax
	movq	%rax, 174848(%rsp)
	movq	81736(%rsp), %rax
	movq	%rax, 174856(%rsp)
	movq	81744(%rsp), %rax
	movq	%rax, 174864(%rsp)
	movq	81752(%rsp), %rax
	movq	%rax, 174872(%rsp)
	movq	81760(%rsp), %rax
	movq	%rax, 174880(%rsp)
	movq	81768(%rsp), %rax
	movq	%rax, 174888(%rsp)
	movq	81776(%rsp), %rax
	movq	%rax, 174896(%rsp)
	movq	81784(%rsp), %rax
	movq	%rax, 174904(%rsp)
	movq	81792(%rsp), %rax
	movq	%rax, 174912(%rsp)
	movq	81800(%rsp), %rax
	movq	%rax, 174920(%rsp)
	movq	81808(%rsp), %rax
	movq	%rax, 174928(%rsp)
	movq	81816(%rsp), %rax
	movq	%rax, 174936(%rsp)
	movq	81824(%rsp), %rax
	movq	%rax, 174944(%rsp)
	movq	81832(%rsp), %rax
	movq	%rax, 174952(%rsp)
	movq	81840(%rsp), %rax
	movq	%rax, 174960(%rsp)
	movq	81848(%rsp), %rax
	movq	%rax, 174968(%rsp)
	movq	81856(%rsp), %rax
	movq	%rax, 174976(%rsp)
	movq	81864(%rsp), %rax
	movq	%rax, 174984(%rsp)
	movq	81872(%rsp), %rax
	movq	%rax, 174992(%rsp)
	movq	81880(%rsp), %rax
	movq	%rax, 175000(%rsp)
	movq	81888(%rsp), %rax
	movq	%rax, 175008(%rsp)
	movq	81896(%rsp), %rax
	movq	%rax, 175016(%rsp)
	movq	81904(%rsp), %rax
	movq	%rax, 175024(%rsp)
	movq	81912(%rsp), %rax
	movq	%rax, 175032(%rsp)
	movq	81920(%rsp), %rax
	movq	%rax, 175040(%rsp)
	movq	81928(%rsp), %rax
	movq	%rax, 175048(%rsp)
	movq	81936(%rsp), %rax
	movq	%rax, 175056(%rsp)
	movq	81944(%rsp), %rax
	movq	%rax, 175064(%rsp)
	movq	81952(%rsp), %rax
	movq	%rax, 175072(%rsp)
	movq	81960(%rsp), %rax
	movq	%rax, 175080(%rsp)
	movq	81968(%rsp), %rax
	movq	%rax, 175088(%rsp)
	movq	81976(%rsp), %rax
	movq	%rax, 175096(%rsp)
	movq	81984(%rsp), %rax
	movq	%rax, 175104(%rsp)
	movq	81992(%rsp), %rax
	movq	%rax, 175112(%rsp)
	movq	82000(%rsp), %rax
	movq	%rax, 175120(%rsp)
	movq	82008(%rsp), %rax
	movq	%rax, 175128(%rsp)
	movq	82016(%rsp), %rax
	movq	%rax, 175136(%rsp)
	movq	82024(%rsp), %rax
	movq	%rax, 175144(%rsp)
	movq	82032(%rsp), %rax
	movq	%rax, 175152(%rsp)
	movq	82040(%rsp), %rax
	movq	%rax, 175160(%rsp)
	movq	82048(%rsp), %rax
	movq	%rax, 175168(%rsp)
	movq	82056(%rsp), %rax
	movq	%rax, 175176(%rsp)
	movq	82064(%rsp), %rax
	movq	%rax, 175184(%rsp)
	movq	82072(%rsp), %rax
	movq	%rax, 175192(%rsp)
	movq	82080(%rsp), %rax
	movq	%rax, 175200(%rsp)
	movq	82088(%rsp), %rax
	movq	%rax, 175208(%rsp)
	movq	82096(%rsp), %rax
	movq	%rax, 175216(%rsp)
	movq	82104(%rsp), %rax
	movq	%rax, 175224(%rsp)
	movq	82112(%rsp), %rax
	movq	%rax, 175232(%rsp)
	movq	82120(%rsp), %rax
	movq	%rax, 175240(%rsp)
	movq	82128(%rsp), %rax
	movq	%rax, 175248(%rsp)
	movq	82136(%rsp), %rax
	movq	%rax, 175256(%rsp)
	movq	82144(%rsp), %rax
	movq	%rax, 175264(%rsp)
	movq	82152(%rsp), %rax
	movq	%rax, 175272(%rsp)
	movq	82160(%rsp), %rax
	movq	%rax, 175280(%rsp)
	movq	82168(%rsp), %rax
	movq	%rax, 175288(%rsp)
	movq	82176(%rsp), %rax
	movq	%rax, 175296(%rsp)
	movq	82184(%rsp), %rax
	movq	%rax, 175304(%rsp)
	movq	82192(%rsp), %rax
	movq	%rax, 175312(%rsp)
	movq	82200(%rsp), %rax
	movq	%rax, 175320(%rsp)
	movq	82208(%rsp), %rax
	movq	%rax, 175328(%rsp)
	movq	82216(%rsp), %rax
	movq	%rax, 175336(%rsp)
	movq	82224(%rsp), %rax
	movq	%rax, 175344(%rsp)
	movq	82232(%rsp), %rax
	movq	%rax, 175352(%rsp)
	movq	82240(%rsp), %rax
	movq	%rax, 175360(%rsp)
	movq	82248(%rsp), %rax
	movq	%rax, 175368(%rsp)
	movq	82256(%rsp), %rax
	movq	%rax, 175376(%rsp)
	movq	82264(%rsp), %rax
	movq	%rax, 175384(%rsp)
	movq	82272(%rsp), %rax
	movq	%rax, 175392(%rsp)
	movq	82280(%rsp), %rax
	movq	%rax, 175400(%rsp)
	movq	82288(%rsp), %rax
	movq	%rax, 175408(%rsp)
	movq	82296(%rsp), %rax
	movq	%rax, 175416(%rsp)
	movq	82304(%rsp), %rax
	movq	%rax, 175424(%rsp)
	movq	82312(%rsp), %rax
	movq	%rax, 175432(%rsp)
	movq	82320(%rsp), %rax
	movq	%rax, 175440(%rsp)
	movq	82328(%rsp), %rax
	movq	%rax, 175448(%rsp)
	movq	82336(%rsp), %rax
	movq	%rax, 175456(%rsp)
	movq	82344(%rsp), %rax
	movq	%rax, 175464(%rsp)
	movq	82352(%rsp), %rax
	movq	%rax, 175472(%rsp)
	movq	82360(%rsp), %rax
	movq	%rax, 175480(%rsp)
	movq	82368(%rsp), %rax
	movq	%rax, 175488(%rsp)
	movq	82376(%rsp), %rax
	movq	%rax, 175496(%rsp)
	movq	82384(%rsp), %rax
	movq	%rax, 175504(%rsp)
	movq	82392(%rsp), %rax
	movq	%rax, 175512(%rsp)
	movq	82400(%rsp), %rax
	movq	%rax, 175520(%rsp)
	movq	82408(%rsp), %rax
	movq	%rax, 175528(%rsp)
	movq	82416(%rsp), %rax
	movq	%rax, 175536(%rsp)
	movq	82424(%rsp), %rax
	movq	%rax, 175544(%rsp)
	movq	82432(%rsp), %rax
	movq	%rax, 175552(%rsp)
	movq	82440(%rsp), %rax
	movq	%rax, 175560(%rsp)
	movq	82448(%rsp), %rax
	movq	%rax, 175568(%rsp)
	movq	82456(%rsp), %rax
	movq	%rax, 175576(%rsp)
	movq	82464(%rsp), %rax
	movq	%rax, 175584(%rsp)
	movq	82472(%rsp), %rax
	movq	%rax, 175592(%rsp)
	movq	82480(%rsp), %rax
	movq	%rax, 175600(%rsp)
	movq	82488(%rsp), %rax
	movq	%rax, 175608(%rsp)
	movq	82496(%rsp), %rax
	movq	%rax, 175616(%rsp)
	movq	82504(%rsp), %rax
	movq	%rax, 175624(%rsp)
	movq	82512(%rsp), %rax
	movq	%rax, 175632(%rsp)
	movq	82520(%rsp), %rax
	movq	%rax, 175640(%rsp)
	movq	82528(%rsp), %rax
	movq	%rax, 175648(%rsp)
	movq	82536(%rsp), %rax
	movq	%rax, 175656(%rsp)
	movq	82544(%rsp), %rax
	movq	%rax, 175664(%rsp)
	movq	82552(%rsp), %rax
	movq	%rax, 175672(%rsp)
	movq	82560(%rsp), %rax
	movq	%rax, 175680(%rsp)
	movq	82568(%rsp), %rax
	movq	%rax, 175688(%rsp)
	movq	82576(%rsp), %rax
	movq	%rax, 175696(%rsp)
	movq	82584(%rsp), %rax
	movq	%rax, 175704(%rsp)
	movq	82592(%rsp), %rax
	movq	%rax, 175712(%rsp)
	movq	82600(%rsp), %rax
	movq	%rax, 175720(%rsp)
	movq	82608(%rsp), %rax
	movq	%rax, 175728(%rsp)
	movq	82616(%rsp), %rax
	movq	%rax, 175736(%rsp)
	movq	82624(%rsp), %rax
	movq	%rax, 175744(%rsp)
	movq	82632(%rsp), %rax
	movq	%rax, 175752(%rsp)
	movq	82640(%rsp), %rax
	movq	%rax, 175760(%rsp)
	movq	82648(%rsp), %rax
	movq	%rax, 175768(%rsp)
	movq	82656(%rsp), %rax
	movq	%rax, 175776(%rsp)
	movq	82664(%rsp), %rax
	movq	%rax, 175784(%rsp)
	movq	82672(%rsp), %rax
	movq	%rax, 175792(%rsp)
	movq	82680(%rsp), %rax
	movq	%rax, 175800(%rsp)
	movq	82688(%rsp), %rax
	movq	%rax, 175808(%rsp)
	movq	82696(%rsp), %rax
	movq	%rax, 175816(%rsp)
	movq	82704(%rsp), %rax
	movq	%rax, 175824(%rsp)
	movq	82712(%rsp), %rax
	movq	%rax, 175832(%rsp)
	movq	82720(%rsp), %rax
	movq	%rax, 175840(%rsp)
	movq	82728(%rsp), %rax
	movq	%rax, 175848(%rsp)
	movq	82736(%rsp), %rax
	movq	%rax, 175856(%rsp)
	movq	82744(%rsp), %rax
	movq	%rax, 175864(%rsp)
	movq	82752(%rsp), %rax
	movq	%rax, 175872(%rsp)
	movq	82760(%rsp), %rax
	movq	%rax, 175880(%rsp)
	movq	82768(%rsp), %rax
	movq	%rax, 175888(%rsp)
	movq	82776(%rsp), %rax
	movq	%rax, 175896(%rsp)
	movq	82784(%rsp), %rax
	movq	%rax, 175904(%rsp)
	movq	82792(%rsp), %rax
	movq	%rax, 175912(%rsp)
	movq	82800(%rsp), %rax
	movq	%rax, 175920(%rsp)
	movq	82808(%rsp), %rax
	movq	%rax, 175928(%rsp)
	movq	82816(%rsp), %rax
	movq	%rax, 175936(%rsp)
	movq	82824(%rsp), %rax
	movq	%rax, 175944(%rsp)
	movq	82832(%rsp), %rax
	movq	%rax, 175952(%rsp)
	movq	82840(%rsp), %rax
	movq	%rax, 175960(%rsp)
	movq	82848(%rsp), %rax
	movq	%rax, 175968(%rsp)
	movq	82856(%rsp), %rax
	movq	%rax, 175976(%rsp)
	movq	82864(%rsp), %rax
	movq	%rax, 175984(%rsp)
	movq	82872(%rsp), %rax
	movq	%rax, 175992(%rsp)
	movq	82880(%rsp), %rax
	movq	%rax, 176000(%rsp)
	movq	82888(%rsp), %rax
	movq	%rax, 176008(%rsp)
	movq	82896(%rsp), %rax
	movq	%rax, 176016(%rsp)
	movq	82904(%rsp), %rax
	movq	%rax, 176024(%rsp)
	movq	82912(%rsp), %rax
	movq	%rax, 176032(%rsp)
	movq	82920(%rsp), %rax
	movq	%rax, 176040(%rsp)
	movq	82928(%rsp), %rax
	movq	%rax, 176048(%rsp)
	movq	82936(%rsp), %rax
	movq	%rax, 176056(%rsp)
	movq	82944(%rsp), %rax
	movq	%rax, 176064(%rsp)
	movq	82952(%rsp), %rax
	movq	%rax, 176072(%rsp)
	movq	82960(%rsp), %rax
	movq	%rax, 176080(%rsp)
	movq	82968(%rsp), %rax
	movq	%rax, 176088(%rsp)
	movq	82976(%rsp), %rax
	movq	%rax, 176096(%rsp)
	movq	82984(%rsp), %rax
	movq	%rax, 176104(%rsp)
	movq	82992(%rsp), %rax
	movq	%rax, 176112(%rsp)
	movq	83000(%rsp), %rax
	movq	%rax, 176120(%rsp)
	movq	83008(%rsp), %rax
	movq	%rax, 176128(%rsp)
	movq	83016(%rsp), %rax
	movq	%rax, 176136(%rsp)
	movq	83024(%rsp), %rax
	movq	%rax, 176144(%rsp)
	movq	83032(%rsp), %rax
	movq	%rax, 176152(%rsp)
	movq	83040(%rsp), %rax
	movq	%rax, 176160(%rsp)
	movq	83048(%rsp), %rax
	movq	%rax, 176168(%rsp)
	movq	83056(%rsp), %rax
	movq	%rax, 176176(%rsp)
	movq	83064(%rsp), %rax
	movq	%rax, 176184(%rsp)
	movq	83072(%rsp), %rax
	movq	%rax, 176192(%rsp)
	movq	83080(%rsp), %rax
	movq	%rax, 176200(%rsp)
	movq	83088(%rsp), %rax
	movq	%rax, 176208(%rsp)
	movq	83096(%rsp), %rax
	movq	%rax, 176216(%rsp)
	movq	83104(%rsp), %rax
	movq	%rax, 176224(%rsp)
	movq	83112(%rsp), %rax
	movq	%rax, 176232(%rsp)
	movq	83120(%rsp), %rax
	movq	%rax, 176240(%rsp)
	movq	83128(%rsp), %rax
	movq	%rax, 176248(%rsp)
	movq	83136(%rsp), %rax
	movq	%rax, 176256(%rsp)
	movq	83144(%rsp), %rax
	movq	%rax, 176264(%rsp)
	movq	83152(%rsp), %rax
	movq	%rax, 176272(%rsp)
	movq	83160(%rsp), %rax
	movq	%rax, 176280(%rsp)
	movq	83168(%rsp), %rax
	movq	%rax, 176288(%rsp)
	movq	83176(%rsp), %rax
	movq	%rax, 176296(%rsp)
	movq	83184(%rsp), %rax
	movq	%rax, 176304(%rsp)
	movq	83192(%rsp), %rax
	movq	%rax, 176312(%rsp)
	movq	83200(%rsp), %rax
	movq	%rax, 176320(%rsp)
	movq	83208(%rsp), %rax
	movq	%rax, 176328(%rsp)
	movq	83216(%rsp), %rax
	movq	%rax, 176336(%rsp)
	movq	83224(%rsp), %rax
	movq	%rax, 176344(%rsp)
	movq	83232(%rsp), %rax
	movq	%rax, 176352(%rsp)
	movq	83240(%rsp), %rax
	movq	%rax, 176360(%rsp)
	movq	83248(%rsp), %rax
	movq	%rax, 176368(%rsp)
	movq	83256(%rsp), %rax
	movq	%rax, 176376(%rsp)
	movq	83264(%rsp), %rax
	movq	%rax, 176384(%rsp)
	movq	83272(%rsp), %rax
	movq	%rax, 176392(%rsp)
	movq	83280(%rsp), %rax
	movq	%rax, 176400(%rsp)
	movq	83288(%rsp), %rax
	movq	%rax, 176408(%rsp)
	movq	83296(%rsp), %rax
	movq	%rax, 176416(%rsp)
	movq	83304(%rsp), %rax
	movq	%rax, 176424(%rsp)
	movq	83312(%rsp), %rax
	movq	%rax, 176432(%rsp)
	movq	83320(%rsp), %rax
	movq	%rax, 176440(%rsp)
	movq	83328(%rsp), %rax
	movq	%rax, 176448(%rsp)
	movq	83336(%rsp), %rax
	movq	%rax, 176456(%rsp)
	movq	83344(%rsp), %rax
	movq	%rax, 176464(%rsp)
	movq	83352(%rsp), %rax
	movq	%rax, 176472(%rsp)
	movq	83360(%rsp), %rax
	movq	%rax, 176480(%rsp)
	movq	83368(%rsp), %rax
	movq	%rax, 176488(%rsp)
	movq	83376(%rsp), %rax
	movq	%rax, 176496(%rsp)
	movq	83384(%rsp), %rax
	movq	%rax, 176504(%rsp)
	movq	83392(%rsp), %rax
	movq	%rax, 176512(%rsp)
	movq	83400(%rsp), %rax
	movq	%rax, 176520(%rsp)
	movq	83408(%rsp), %rax
	movq	%rax, 176528(%rsp)
	movq	83416(%rsp), %rax
	movq	%rax, 176536(%rsp)
	movq	83424(%rsp), %rax
	movq	%rax, 176544(%rsp)
	movq	83432(%rsp), %rax
	movq	%rax, 176552(%rsp)
	movq	83440(%rsp), %rax
	movq	%rax, 176560(%rsp)
	movq	83448(%rsp), %rax
	movq	%rax, 176568(%rsp)
	movq	83456(%rsp), %rax
	movq	%rax, 176576(%rsp)
	movq	83464(%rsp), %rax
	movq	%rax, 176584(%rsp)
	movq	83472(%rsp), %rax
	movq	%rax, 176592(%rsp)
	movq	83480(%rsp), %rax
	movq	%rax, 176600(%rsp)
	movq	83488(%rsp), %rax
	movq	%rax, 176608(%rsp)
	movq	83496(%rsp), %rax
	movq	%rax, 176616(%rsp)
	movq	83504(%rsp), %rax
	movq	%rax, 176624(%rsp)
	movq	83512(%rsp), %rax
	movq	%rax, 176632(%rsp)
	movq	83520(%rsp), %rax
	movq	%rax, 176640(%rsp)
	movq	83528(%rsp), %rax
	movq	%rax, 176648(%rsp)
	movq	83536(%rsp), %rax
	movq	%rax, 176656(%rsp)
	movq	83544(%rsp), %rax
	movq	%rax, 176664(%rsp)
	movq	83552(%rsp), %rax
	movq	%rax, 176672(%rsp)
	movq	83560(%rsp), %rax
	movq	%rax, 176680(%rsp)
	movq	83568(%rsp), %rax
	movq	%rax, 176688(%rsp)
	movq	83576(%rsp), %rax
	movq	%rax, 176696(%rsp)
	movq	83584(%rsp), %rax
	movq	%rax, 176704(%rsp)
	movq	83592(%rsp), %rax
	movq	%rax, 176712(%rsp)
	movq	83600(%rsp), %rax
	movq	%rax, 176720(%rsp)
	movq	83608(%rsp), %rax
	movq	%rax, 176728(%rsp)
	movq	83616(%rsp), %rax
	movq	%rax, 176736(%rsp)
	movq	83624(%rsp), %rax
	movq	%rax, 176744(%rsp)
	movq	83632(%rsp), %rax
	movq	%rax, 176752(%rsp)
	movq	83640(%rsp), %rax
	movq	%rax, 176760(%rsp)
	movq	83648(%rsp), %rax
	movq	%rax, 176768(%rsp)
	movq	83656(%rsp), %rax
	movq	%rax, 176776(%rsp)
	movq	83664(%rsp), %rax
	movq	%rax, 176784(%rsp)
	movq	83672(%rsp), %rax
	movq	%rax, 176792(%rsp)
	movq	83680(%rsp), %rax
	movq	%rax, 176800(%rsp)
	movq	83688(%rsp), %rax
	movq	%rax, 176808(%rsp)
	movq	83696(%rsp), %rax
	movq	%rax, 176816(%rsp)
	movq	83704(%rsp), %rax
	movq	%rax, 176824(%rsp)
	movq	83712(%rsp), %rax
	movq	%rax, 176832(%rsp)
	movq	83720(%rsp), %rax
	movq	%rax, 176840(%rsp)
	movq	83728(%rsp), %rax
	movq	%rax, 176848(%rsp)
	movq	83736(%rsp), %rax
	movq	%rax, 176856(%rsp)
	movq	83744(%rsp), %rax
	movq	%rax, 176864(%rsp)
	movq	83752(%rsp), %rax
	movq	%rax, 176872(%rsp)
	movq	83760(%rsp), %rax
	movq	%rax, 176880(%rsp)
	movq	83768(%rsp), %rax
	movq	%rax, 176888(%rsp)
	movq	83776(%rsp), %rax
	movq	%rax, 176896(%rsp)
	movq	83784(%rsp), %rax
	movq	%rax, 176904(%rsp)
	movq	83792(%rsp), %rax
	movq	%rax, 176912(%rsp)
	movq	83800(%rsp), %rax
	movq	%rax, 176920(%rsp)
	movq	83808(%rsp), %rax
	movq	%rax, 176928(%rsp)
	movq	83816(%rsp), %rax
	movq	%rax, 176936(%rsp)
	movq	83824(%rsp), %rax
	movq	%rax, 176944(%rsp)
	movq	83832(%rsp), %rax
	movq	%rax, 176952(%rsp)
	movq	83840(%rsp), %rax
	movq	%rax, 176960(%rsp)
	movq	83848(%rsp), %rax
	movq	%rax, 176968(%rsp)
	movq	83856(%rsp), %rax
	movq	%rax, 176976(%rsp)
	movq	83864(%rsp), %rax
	movq	%rax, 176984(%rsp)
	movq	83872(%rsp), %rax
	movq	%rax, 176992(%rsp)
	movq	83880(%rsp), %rax
	movq	%rax, 177000(%rsp)
	movq	83888(%rsp), %rax
	movq	%rax, 177008(%rsp)
	movq	83896(%rsp), %rax
	movq	%rax, 177016(%rsp)
	movq	83904(%rsp), %rax
	movq	%rax, 177024(%rsp)
	movq	83912(%rsp), %rax
	movq	%rax, 177032(%rsp)
	movq	83920(%rsp), %rax
	movq	%rax, 177040(%rsp)
	movq	83928(%rsp), %rax
	movq	%rax, 177048(%rsp)
	movq	83936(%rsp), %rax
	movq	%rax, 177056(%rsp)
	movq	83944(%rsp), %rax
	movq	%rax, 177064(%rsp)
	movq	83952(%rsp), %rax
	movq	%rax, 177072(%rsp)
	movq	83960(%rsp), %rax
	movq	%rax, 177080(%rsp)
	movq	83968(%rsp), %rax
	movq	%rax, 177088(%rsp)
	movq	83976(%rsp), %rax
	movq	%rax, 177096(%rsp)
	movq	83984(%rsp), %rax
	movq	%rax, 177104(%rsp)
	movq	83992(%rsp), %rax
	movq	%rax, 177112(%rsp)
	movq	84000(%rsp), %rax
	movq	%rax, 177120(%rsp)
	movq	84008(%rsp), %rax
	movq	%rax, 177128(%rsp)
	movq	84016(%rsp), %rax
	movq	%rax, 177136(%rsp)
	movq	84024(%rsp), %rax
	movq	%rax, 177144(%rsp)
	movq	84032(%rsp), %rax
	movq	%rax, 177152(%rsp)
	movq	84040(%rsp), %rax
	movq	%rax, 177160(%rsp)
	movq	84048(%rsp), %rax
	movq	%rax, 177168(%rsp)
	movq	84056(%rsp), %rax
	movq	%rax, 177176(%rsp)
	movq	84064(%rsp), %rax
	movq	%rax, 177184(%rsp)
	movq	84072(%rsp), %rax
	movq	%rax, 177192(%rsp)
	movq	84080(%rsp), %rax
	movq	%rax, 177200(%rsp)
	movq	84088(%rsp), %rax
	movq	%rax, 177208(%rsp)
	movq	84096(%rsp), %rax
	movq	%rax, 177216(%rsp)
	movq	84104(%rsp), %rax
	movq	%rax, 177224(%rsp)
	movq	84112(%rsp), %rax
	movq	%rax, 177232(%rsp)
	movq	84120(%rsp), %rax
	movq	%rax, 177240(%rsp)
	movq	84128(%rsp), %rax
	movq	%rax, 177248(%rsp)
	movq	84136(%rsp), %rax
	movq	%rax, 177256(%rsp)
	movq	84144(%rsp), %rax
	movq	%rax, 177264(%rsp)
	movq	84152(%rsp), %rax
	movq	%rax, 177272(%rsp)
	movq	84160(%rsp), %rax
	movq	%rax, 177280(%rsp)
	movq	84168(%rsp), %rax
	movq	%rax, 177288(%rsp)
	movq	84176(%rsp), %rax
	movq	%rax, 177296(%rsp)
	movq	84184(%rsp), %rax
	movq	%rax, 177304(%rsp)
	movq	84192(%rsp), %rax
	movq	%rax, 177312(%rsp)
	movq	84200(%rsp), %rax
	movq	%rax, 177320(%rsp)
	movq	84208(%rsp), %rax
	movq	%rax, 177328(%rsp)
	movq	84216(%rsp), %rax
	movq	%rax, 177336(%rsp)
	movq	84224(%rsp), %rax
	movq	%rax, 177344(%rsp)
	movq	84232(%rsp), %rax
	movq	%rax, 177352(%rsp)
	movq	84240(%rsp), %rax
	movq	%rax, 177360(%rsp)
	movq	84248(%rsp), %rax
	movq	%rax, 177368(%rsp)
	movq	84256(%rsp), %rax
	movq	%rax, 177376(%rsp)
	movq	84264(%rsp), %rax
	movq	%rax, 177384(%rsp)
	movq	84272(%rsp), %rax
	movq	%rax, 177392(%rsp)
	movq	84280(%rsp), %rax
	movq	%rax, 177400(%rsp)
	movq	84288(%rsp), %rax
	movq	%rax, 177408(%rsp)
	movq	84296(%rsp), %rax
	movq	%rax, 177416(%rsp)
	movq	84304(%rsp), %rax
	movq	%rax, 177424(%rsp)
	movq	84312(%rsp), %rax
	movq	%rax, 177432(%rsp)
	movq	84320(%rsp), %rax
	movq	%rax, 177440(%rsp)
	movq	84328(%rsp), %rax
	movq	%rax, 177448(%rsp)
	movq	84336(%rsp), %rax
	movq	%rax, 177456(%rsp)
	movq	84344(%rsp), %rax
	movq	%rax, 177464(%rsp)
	movq	84352(%rsp), %rax
	movq	%rax, 177472(%rsp)
	movq	84360(%rsp), %rax
	movq	%rax, 177480(%rsp)
	movq	84368(%rsp), %rax
	movq	%rax, 177488(%rsp)
	movq	84376(%rsp), %rax
	movq	%rax, 177496(%rsp)
	movq	84384(%rsp), %rax
	movq	%rax, 177504(%rsp)
	movq	84392(%rsp), %rax
	movq	%rax, 177512(%rsp)
	movq	84400(%rsp), %rax
	movq	%rax, 177520(%rsp)
	movq	84408(%rsp), %rax
	movq	%rax, 177528(%rsp)
	movq	84416(%rsp), %rax
	movq	%rax, 177536(%rsp)
	movq	84424(%rsp), %rax
	movq	%rax, 177544(%rsp)
	movq	84432(%rsp), %rax
	movq	%rax, 177552(%rsp)
	movq	84440(%rsp), %rax
	movq	%rax, 177560(%rsp)
	movq	84448(%rsp), %rax
	movq	%rax, 177568(%rsp)
	movq	84456(%rsp), %rax
	movq	%rax, 177576(%rsp)
	movq	84464(%rsp), %rax
	movq	%rax, 177584(%rsp)
	movq	84472(%rsp), %rax
	movq	%rax, 177592(%rsp)
	movq	84480(%rsp), %rax
	movq	%rax, 177600(%rsp)
	movq	84488(%rsp), %rax
	movq	%rax, 177608(%rsp)
	movq	84496(%rsp), %rax
	movq	%rax, 177616(%rsp)
	movq	84504(%rsp), %rax
	movq	%rax, 177624(%rsp)
	movq	84512(%rsp), %rax
	movq	%rax, 177632(%rsp)
	movq	84520(%rsp), %rax
	movq	%rax, 177640(%rsp)
	movq	84528(%rsp), %rax
	movq	%rax, 177648(%rsp)
	movq	84536(%rsp), %rax
	movq	%rax, 177656(%rsp)
	movq	84544(%rsp), %rax
	movq	%rax, 177664(%rsp)
	movq	84552(%rsp), %rax
	movq	%rax, 177672(%rsp)
	movq	84560(%rsp), %rax
	movq	%rax, 177680(%rsp)
	movq	84568(%rsp), %rax
	movq	%rax, 177688(%rsp)
	movq	84576(%rsp), %rax
	movq	%rax, 177696(%rsp)
	movq	84584(%rsp), %rax
	movq	%rax, 177704(%rsp)
	movq	84592(%rsp), %rax
	movq	%rax, 177712(%rsp)
	movq	84600(%rsp), %rax
	movq	%rax, 177720(%rsp)
	movq	84608(%rsp), %rax
	movq	%rax, 177728(%rsp)
	movq	84616(%rsp), %rax
	movq	%rax, 177736(%rsp)
	movq	84624(%rsp), %rax
	movq	%rax, 177744(%rsp)
	movq	84632(%rsp), %rax
	movq	%rax, 177752(%rsp)
	movq	84640(%rsp), %rax
	movq	%rax, 177760(%rsp)
	movq	84648(%rsp), %rax
	movq	%rax, 177768(%rsp)
	movq	84656(%rsp), %rax
	movq	%rax, 177776(%rsp)
	movq	84664(%rsp), %rax
	movq	%rax, 177784(%rsp)
	movq	84672(%rsp), %rax
	movq	%rax, 177792(%rsp)
	movq	84680(%rsp), %rax
	movq	%rax, 177800(%rsp)
	movq	84688(%rsp), %rax
	movq	%rax, 177808(%rsp)
	movq	84696(%rsp), %rax
	movq	%rax, 177816(%rsp)
	movq	84704(%rsp), %rax
	movq	%rax, 177824(%rsp)
	movq	84712(%rsp), %rax
	movq	%rax, 177832(%rsp)
	movq	84720(%rsp), %rax
	movq	%rax, 177840(%rsp)
	movq	84728(%rsp), %rax
	movq	%rax, 177848(%rsp)
	movq	84736(%rsp), %rax
	movq	%rax, 177856(%rsp)
	movq	84744(%rsp), %rax
	movq	%rax, 177864(%rsp)
	movq	84752(%rsp), %rax
	movq	%rax, 177872(%rsp)
	movq	84760(%rsp), %rax
	movq	%rax, 177880(%rsp)
	movq	84768(%rsp), %rax
	movq	%rax, 177888(%rsp)
	movq	84776(%rsp), %rax
	movq	%rax, 177896(%rsp)
	movq	84784(%rsp), %rax
	movq	%rax, 177904(%rsp)
	movq	84792(%rsp), %rax
	movq	%rax, 177912(%rsp)
	movq	84800(%rsp), %rax
	movq	%rax, 177920(%rsp)
	movq	84808(%rsp), %rax
	movq	%rax, 177928(%rsp)
	movq	84816(%rsp), %rax
	movq	%rax, 177936(%rsp)
	movq	84824(%rsp), %rax
	movq	%rax, 177944(%rsp)
	movq	84832(%rsp), %rax
	movq	%rax, 177952(%rsp)
	movq	84840(%rsp), %rax
	movq	%rax, 177960(%rsp)
	movq	84848(%rsp), %rax
	movq	%rax, 177968(%rsp)
	movq	84856(%rsp), %rax
	movq	%rax, 177976(%rsp)
	movq	84864(%rsp), %rax
	movq	%rax, 177984(%rsp)
	movq	84872(%rsp), %rax
	movq	%rax, 177992(%rsp)
	movq	84880(%rsp), %rax
	movq	%rax, 178000(%rsp)
	movq	84888(%rsp), %rax
	movq	%rax, 178008(%rsp)
	movq	84896(%rsp), %rax
	movq	%rax, 178016(%rsp)
	movq	84904(%rsp), %rax
	movq	%rax, 178024(%rsp)
	movq	84912(%rsp), %rax
	movq	%rax, 178032(%rsp)
	movq	84920(%rsp), %rax
	movq	%rax, 178040(%rsp)
	movq	84928(%rsp), %rax
	movq	%rax, 178048(%rsp)
	movq	84936(%rsp), %rax
	movq	%rax, 178056(%rsp)
	movq	84944(%rsp), %rax
	movq	%rax, 178064(%rsp)
	movq	84952(%rsp), %rax
	movq	%rax, 178072(%rsp)
	movq	84960(%rsp), %rax
	movq	%rax, 178080(%rsp)
	movq	84968(%rsp), %rax
	movq	%rax, 178088(%rsp)
	movq	84976(%rsp), %rax
	movq	%rax, 178096(%rsp)
	movq	84984(%rsp), %rax
	movq	%rax, 178104(%rsp)
	movq	84992(%rsp), %rax
	movq	%rax, 178112(%rsp)
	movq	85000(%rsp), %rax
	movq	%rax, 178120(%rsp)
	movq	85008(%rsp), %rax
	movq	%rax, 178128(%rsp)
	movq	85016(%rsp), %rax
	movq	%rax, 178136(%rsp)
	movq	85024(%rsp), %rax
	movq	%rax, 178144(%rsp)
	movq	85032(%rsp), %rax
	movq	%rax, 178152(%rsp)
	movq	85040(%rsp), %rax
	movq	%rax, 178160(%rsp)
	movq	85048(%rsp), %rax
	movq	%rax, 178168(%rsp)
	movq	85056(%rsp), %rax
	movq	%rax, 178176(%rsp)
	movq	85064(%rsp), %rax
	movq	%rax, 178184(%rsp)
	movq	85072(%rsp), %rax
	movq	%rax, 178192(%rsp)
	movq	85080(%rsp), %rax
	movq	%rax, 178200(%rsp)
	movq	85088(%rsp), %rax
	movq	%rax, 178208(%rsp)
	movq	85096(%rsp), %rax
	movq	%rax, 178216(%rsp)
	movq	85104(%rsp), %rax
	movq	%rax, 178224(%rsp)
	movq	85112(%rsp), %rax
	movq	%rax, 178232(%rsp)
	movq	85120(%rsp), %rax
	movq	%rax, 178240(%rsp)
	movq	85128(%rsp), %rax
	movq	%rax, 178248(%rsp)
	movq	85136(%rsp), %rax
	movq	%rax, 178256(%rsp)
	movq	85144(%rsp), %rax
	movq	%rax, 178264(%rsp)
	movq	85152(%rsp), %rax
	movq	%rax, 178272(%rsp)
	movq	85160(%rsp), %rax
	movq	%rax, 178280(%rsp)
	movq	85168(%rsp), %rax
	movq	%rax, 178288(%rsp)
	movq	85176(%rsp), %rax
	movq	%rax, 178296(%rsp)
	movq	85184(%rsp), %rax
	movq	%rax, 178304(%rsp)
	movq	85192(%rsp), %rax
	movq	%rax, 178312(%rsp)
	movq	85200(%rsp), %rax
	movq	%rax, 178320(%rsp)
	movq	85208(%rsp), %rax
	movq	%rax, 178328(%rsp)
	movq	85216(%rsp), %rax
	movq	%rax, 178336(%rsp)
	movq	85224(%rsp), %rax
	movq	%rax, 178344(%rsp)
	movq	85232(%rsp), %rax
	movq	%rax, 178352(%rsp)
	movq	85240(%rsp), %rax
	movq	%rax, 178360(%rsp)
	movq	85248(%rsp), %rax
	movq	%rax, 178368(%rsp)
	movq	85256(%rsp), %rax
	movq	%rax, 178376(%rsp)
	movq	85264(%rsp), %rax
	movq	%rax, 178384(%rsp)
	movq	85272(%rsp), %rax
	movq	%rax, 178392(%rsp)
	movq	85280(%rsp), %rax
	movq	%rax, 178400(%rsp)
	movq	85288(%rsp), %rax
	movq	%rax, 178408(%rsp)
	movq	85296(%rsp), %rax
	movq	%rax, 178416(%rsp)
	movq	85304(%rsp), %rax
	movq	%rax, 178424(%rsp)
	movq	85312(%rsp), %rax
	movq	%rax, 178432(%rsp)
	movq	85320(%rsp), %rax
	movq	%rax, 178440(%rsp)
	movq	85328(%rsp), %rax
	movq	%rax, 178448(%rsp)
	movq	85336(%rsp), %rax
	movq	%rax, 178456(%rsp)
	movq	85344(%rsp), %rax
	movq	%rax, 178464(%rsp)
	movq	85352(%rsp), %rax
	movq	%rax, 178472(%rsp)
	movq	85360(%rsp), %rax
	movq	%rax, 178480(%rsp)
	movq	85368(%rsp), %rax
	movq	%rax, 178488(%rsp)
	movq	85376(%rsp), %rax
	movq	%rax, 178496(%rsp)
	movq	85384(%rsp), %rax
	movq	%rax, 178504(%rsp)
	movq	85392(%rsp), %rax
	movq	%rax, 178512(%rsp)
	movq	85400(%rsp), %rax
	movq	%rax, 178520(%rsp)
	movq	85408(%rsp), %rax
	movq	%rax, 178528(%rsp)
	movq	85416(%rsp), %rax
	movq	%rax, 178536(%rsp)
	movq	85424(%rsp), %rax
	movq	%rax, 178544(%rsp)
	movq	85432(%rsp), %rax
	movq	%rax, 178552(%rsp)
	movq	85440(%rsp), %rax
	movq	%rax, 178560(%rsp)
	movq	85448(%rsp), %rax
	movq	%rax, 178568(%rsp)
	movq	85456(%rsp), %rax
	movq	%rax, 178576(%rsp)
	movq	85464(%rsp), %rax
	movq	%rax, 178584(%rsp)
	movq	85472(%rsp), %rax
	movq	%rax, 178592(%rsp)
	movq	85480(%rsp), %rax
	movq	%rax, 178600(%rsp)
	movq	85488(%rsp), %rax
	movq	%rax, 178608(%rsp)
	movq	85496(%rsp), %rax
	movq	%rax, 178616(%rsp)
	movq	85504(%rsp), %rax
	movq	%rax, 178624(%rsp)
	movq	85512(%rsp), %rax
	movq	%rax, 178632(%rsp)
	movq	85520(%rsp), %rax
	movq	%rax, 178640(%rsp)
	movq	85528(%rsp), %rax
	movq	%rax, 178648(%rsp)
	movq	85536(%rsp), %rax
	movq	%rax, 178656(%rsp)
	movq	85544(%rsp), %rax
	movq	%rax, 178664(%rsp)
	movq	85552(%rsp), %rax
	movq	%rax, 178672(%rsp)
	movq	85560(%rsp), %rax
	movq	%rax, 178680(%rsp)
	movq	85568(%rsp), %rax
	movq	%rax, 178688(%rsp)
	movq	85576(%rsp), %rax
	movq	%rax, 178696(%rsp)
	movq	85584(%rsp), %rax
	movq	%rax, 178704(%rsp)
	movq	85592(%rsp), %rax
	movq	%rax, 178712(%rsp)
	movq	85600(%rsp), %rax
	movq	%rax, 178720(%rsp)
	movq	85608(%rsp), %rax
	movq	%rax, 178728(%rsp)
	movq	85616(%rsp), %rax
	movq	%rax, 178736(%rsp)
	movq	85624(%rsp), %rax
	movq	%rax, 178744(%rsp)
	movq	85632(%rsp), %rax
	movq	%rax, 178752(%rsp)
	movq	85640(%rsp), %rax
	movq	%rax, 178760(%rsp)
	movq	85648(%rsp), %rax
	movq	%rax, 178768(%rsp)
	movq	85656(%rsp), %rax
	movq	%rax, 178776(%rsp)
	movq	85664(%rsp), %rax
	movq	%rax, 178784(%rsp)
	movq	85672(%rsp), %rax
	movq	%rax, 178792(%rsp)
	movq	85680(%rsp), %rax
	movq	%rax, 178800(%rsp)
	movq	85688(%rsp), %rax
	movq	%rax, 178808(%rsp)
	movq	85696(%rsp), %rax
	movq	%rax, 178816(%rsp)
	movq	85704(%rsp), %rax
	movq	%rax, 178824(%rsp)
	movq	85712(%rsp), %rax
	movq	%rax, 178832(%rsp)
	movq	85720(%rsp), %rax
	movq	%rax, 178840(%rsp)
	movq	85728(%rsp), %rax
	movq	%rax, 178848(%rsp)
	movq	85736(%rsp), %rax
	movq	%rax, 178856(%rsp)
	movq	85744(%rsp), %rax
	movq	%rax, 178864(%rsp)
	movq	85752(%rsp), %rax
	movq	%rax, 178872(%rsp)
	movq	85760(%rsp), %rax
	movq	%rax, 178880(%rsp)
	movq	85768(%rsp), %rax
	movq	%rax, 178888(%rsp)
	movq	85776(%rsp), %rax
	movq	%rax, 178896(%rsp)
	movq	85784(%rsp), %rax
	movq	%rax, 178904(%rsp)
	movq	85792(%rsp), %rax
	movq	%rax, 178912(%rsp)
	movq	85800(%rsp), %rax
	movq	%rax, 178920(%rsp)
	movq	85808(%rsp), %rax
	movq	%rax, 178928(%rsp)
	movq	85816(%rsp), %rax
	movq	%rax, 178936(%rsp)
	movq	85824(%rsp), %rax
	movq	%rax, 178944(%rsp)
	movq	85832(%rsp), %rax
	movq	%rax, 178952(%rsp)
	movq	85840(%rsp), %rax
	movq	%rax, 178960(%rsp)
	movq	85848(%rsp), %rax
	movq	%rax, 178968(%rsp)
	movq	85856(%rsp), %rax
	movq	%rax, 178976(%rsp)
	movq	85864(%rsp), %rax
	movq	%rax, 178984(%rsp)
	movq	85872(%rsp), %rax
	movq	%rax, 178992(%rsp)
	movq	85880(%rsp), %rax
	movq	%rax, 179000(%rsp)
	movq	85888(%rsp), %rax
	movq	%rax, 179008(%rsp)
	movq	85896(%rsp), %rax
	movq	%rax, 179016(%rsp)
	movq	85904(%rsp), %rax
	movq	%rax, 179024(%rsp)
	movq	85912(%rsp), %rax
	movq	%rax, 179032(%rsp)
	movq	85920(%rsp), %rax
	movq	%rax, 179040(%rsp)
	movq	85928(%rsp), %rax
	movq	%rax, 179048(%rsp)
	movq	85936(%rsp), %rax
	movq	%rax, 179056(%rsp)
	movq	85944(%rsp), %rax
	movq	%rax, 179064(%rsp)
	movq	85952(%rsp), %rax
	movq	%rax, 179072(%rsp)
	movq	85960(%rsp), %rax
	movq	%rax, 179080(%rsp)
	movq	85968(%rsp), %rax
	movq	%rax, 179088(%rsp)
	movq	85976(%rsp), %rax
	movq	%rax, 179096(%rsp)
	movq	85984(%rsp), %rax
	movq	%rax, 179104(%rsp)
	movq	85992(%rsp), %rax
	movq	%rax, 179112(%rsp)
	movq	86000(%rsp), %rax
	movq	%rax, 179120(%rsp)
	movq	86008(%rsp), %rax
	movq	%rax, 179128(%rsp)
	movq	86016(%rsp), %rax
	movq	%rax, 179136(%rsp)
	movq	86024(%rsp), %rax
	movq	%rax, 179144(%rsp)
	movq	86032(%rsp), %rax
	movq	%rax, 179152(%rsp)
	movq	86040(%rsp), %rax
	movq	%rax, 179160(%rsp)
	movq	86048(%rsp), %rax
	movq	%rax, 179168(%rsp)
	movq	86056(%rsp), %rax
	movq	%rax, 179176(%rsp)
	movq	86064(%rsp), %rax
	movq	%rax, 179184(%rsp)
	movq	86072(%rsp), %rax
	movq	%rax, 179192(%rsp)
	movq	86080(%rsp), %rax
	movq	%rax, 179200(%rsp)
	movq	86088(%rsp), %rax
	movq	%rax, 179208(%rsp)
	movq	86096(%rsp), %rax
	movq	%rax, 179216(%rsp)
	movq	86104(%rsp), %rax
	movq	%rax, 179224(%rsp)
	movq	86112(%rsp), %rax
	movq	%rax, 179232(%rsp)
	movq	86120(%rsp), %rax
	movq	%rax, 179240(%rsp)
	movq	86128(%rsp), %rax
	movq	%rax, 179248(%rsp)
	movq	86136(%rsp), %rax
	movq	%rax, 179256(%rsp)
	movq	86144(%rsp), %rax
	movq	%rax, 179264(%rsp)
	movq	86152(%rsp), %rax
	movq	%rax, 179272(%rsp)
	movq	86160(%rsp), %rax
	movq	%rax, 179280(%rsp)
	movq	86168(%rsp), %rax
	movq	%rax, 179288(%rsp)
	movq	86176(%rsp), %rax
	movq	%rax, 179296(%rsp)
	movq	86184(%rsp), %rax
	movq	%rax, 179304(%rsp)
	movq	86192(%rsp), %rax
	movq	%rax, 179312(%rsp)
	movq	86200(%rsp), %rax
	movq	%rax, 179320(%rsp)
	movq	86208(%rsp), %rax
	movq	%rax, 179328(%rsp)
	movq	86216(%rsp), %rax
	movq	%rax, 179336(%rsp)
	movq	86224(%rsp), %rax
	movq	%rax, 179344(%rsp)
	movq	86232(%rsp), %rax
	movq	%rax, 179352(%rsp)
	movq	86240(%rsp), %rax
	movq	%rax, 179360(%rsp)
	movq	86248(%rsp), %rax
	movq	%rax, 179368(%rsp)
	movq	86256(%rsp), %rax
	movq	%rax, 179376(%rsp)
	movq	86264(%rsp), %rax
	movq	%rax, 179384(%rsp)
	movq	86272(%rsp), %rax
	movq	%rax, 179392(%rsp)
	movq	86280(%rsp), %rax
	movq	%rax, 179400(%rsp)
	movq	86288(%rsp), %rax
	movq	%rax, 179408(%rsp)
	movq	86296(%rsp), %rax
	movq	%rax, 179416(%rsp)
	movq	86304(%rsp), %rax
	movq	%rax, 179424(%rsp)
	movq	86312(%rsp), %rax
	movq	%rax, 179432(%rsp)
	movq	86320(%rsp), %rax
	movq	%rax, 179440(%rsp)
	movq	86328(%rsp), %rax
	movq	%rax, 179448(%rsp)
	movq	86336(%rsp), %rax
	movq	%rax, 179456(%rsp)
	movq	86344(%rsp), %rax
	movq	%rax, 179464(%rsp)
	movq	86352(%rsp), %rax
	movq	%rax, 179472(%rsp)
	movq	86360(%rsp), %rax
	movq	%rax, 179480(%rsp)
	movq	86368(%rsp), %rax
	movq	%rax, 179488(%rsp)
	movq	86376(%rsp), %rax
	movq	%rax, 179496(%rsp)
	movq	86384(%rsp), %rax
	movq	%rax, 179504(%rsp)
	movq	86392(%rsp), %rax
	movq	%rax, 179512(%rsp)
	movq	86400(%rsp), %rax
	movq	%rax, 179520(%rsp)
	movq	86408(%rsp), %rax
	movq	%rax, 179528(%rsp)
	movq	86416(%rsp), %rax
	movq	%rax, 179536(%rsp)
	movq	86424(%rsp), %rax
	movq	%rax, 179544(%rsp)
	movq	86432(%rsp), %rax
	movq	%rax, 179552(%rsp)
	movq	86440(%rsp), %rax
	movq	%rax, 179560(%rsp)
	movq	86448(%rsp), %rax
	movq	%rax, 179568(%rsp)
	movq	86456(%rsp), %rax
	movq	%rax, 179576(%rsp)
	movq	86464(%rsp), %rax
	movq	%rax, 179584(%rsp)
	movq	86472(%rsp), %rax
	movq	%rax, 179592(%rsp)
	movq	86480(%rsp), %rax
	movq	%rax, 179600(%rsp)
	movq	86488(%rsp), %rax
	movq	%rax, 179608(%rsp)
	movq	86496(%rsp), %rax
	movq	%rax, 179616(%rsp)
	movq	86504(%rsp), %rax
	movq	%rax, 179624(%rsp)
	movq	86512(%rsp), %rax
	movq	%rax, 179632(%rsp)
	movq	86520(%rsp), %rax
	movq	%rax, 179640(%rsp)
	movq	86528(%rsp), %rax
	movq	%rax, 179648(%rsp)
	movq	86536(%rsp), %rax
	movq	%rax, 179656(%rsp)
	movq	86544(%rsp), %rax
	movq	%rax, 179664(%rsp)
	movq	86552(%rsp), %rax
	movq	%rax, 179672(%rsp)
	movq	86560(%rsp), %rax
	movq	%rax, 179680(%rsp)
	movq	86568(%rsp), %rax
	movq	%rax, 179688(%rsp)
	movq	86576(%rsp), %rax
	movq	%rax, 179696(%rsp)
	movq	86584(%rsp), %rax
	movq	%rax, 179704(%rsp)
	movq	86592(%rsp), %rax
	movq	%rax, 179712(%rsp)
	movq	86600(%rsp), %rax
	movq	%rax, 179720(%rsp)
	movq	86608(%rsp), %rax
	movq	%rax, 179728(%rsp)
	movq	86616(%rsp), %rax
	movq	%rax, 179736(%rsp)
	movq	86624(%rsp), %rax
	movq	%rax, 179744(%rsp)
	movq	86632(%rsp), %rax
	movq	%rax, 179752(%rsp)
	movq	86640(%rsp), %rax
	movq	%rax, 179760(%rsp)
	movq	86648(%rsp), %rax
	movq	%rax, 179768(%rsp)
	movq	86656(%rsp), %rax
	movq	%rax, 179776(%rsp)
	movq	86664(%rsp), %rax
	movq	%rax, 179784(%rsp)
	movq	86672(%rsp), %rax
	movq	%rax, 179792(%rsp)
	movq	86680(%rsp), %rax
	movq	%rax, 179800(%rsp)
	movq	86688(%rsp), %rax
	movq	%rax, 179808(%rsp)
	movq	86696(%rsp), %rax
	movq	%rax, 179816(%rsp)
	movq	86704(%rsp), %rax
	movq	%rax, 179824(%rsp)
	movq	86712(%rsp), %rax
	movq	%rax, 179832(%rsp)
	movq	86720(%rsp), %rax
	movq	%rax, 179840(%rsp)
	movq	86728(%rsp), %rax
	movq	%rax, 179848(%rsp)
	movq	86736(%rsp), %rax
	movq	%rax, 179856(%rsp)
	movq	86744(%rsp), %rax
	movq	%rax, 179864(%rsp)
	movq	86752(%rsp), %rax
	movq	%rax, 179872(%rsp)
	movq	86760(%rsp), %rax
	movq	%rax, 179880(%rsp)
	movq	86768(%rsp), %rax
	movq	%rax, 179888(%rsp)
	movq	86776(%rsp), %rax
	movq	%rax, 179896(%rsp)
	movq	86784(%rsp), %rax
	movq	%rax, 179904(%rsp)
	movq	86792(%rsp), %rax
	movq	%rax, 179912(%rsp)
	movq	86800(%rsp), %rax
	movq	%rax, 179920(%rsp)
	movq	86808(%rsp), %rax
	movq	%rax, 179928(%rsp)
	movq	86816(%rsp), %rax
	movq	%rax, 179936(%rsp)
	movq	86824(%rsp), %rax
	movq	%rax, 179944(%rsp)
	movq	86832(%rsp), %rax
	movq	%rax, 179952(%rsp)
	movq	86840(%rsp), %rax
	movq	%rax, 179960(%rsp)
	movq	86848(%rsp), %rax
	movq	%rax, 179968(%rsp)
	movq	86856(%rsp), %rax
	movq	%rax, 179976(%rsp)
	movq	86864(%rsp), %rax
	movq	%rax, 179984(%rsp)
	movq	86872(%rsp), %rax
	movq	%rax, 179992(%rsp)
	movq	86880(%rsp), %rax
	movq	%rax, 180000(%rsp)
	movq	86888(%rsp), %rax
	movq	%rax, 180008(%rsp)
	movq	86896(%rsp), %rax
	movq	%rax, 180016(%rsp)
	movq	86904(%rsp), %rax
	movq	%rax, 180024(%rsp)
	movq	86912(%rsp), %rax
	movq	%rax, 180032(%rsp)
	movq	86920(%rsp), %rax
	movq	%rax, 180040(%rsp)
	movq	86928(%rsp), %rax
	movq	%rax, 180048(%rsp)
	movq	86936(%rsp), %rax
	movq	%rax, 180056(%rsp)
	movq	86944(%rsp), %rax
	movq	%rax, 180064(%rsp)
	movq	86952(%rsp), %rax
	movq	%rax, 180072(%rsp)
	movq	86960(%rsp), %rax
	movq	%rax, 180080(%rsp)
	movq	86968(%rsp), %rax
	movq	%rax, 180088(%rsp)
	movq	86976(%rsp), %rax
	movq	%rax, 180096(%rsp)
	movq	86984(%rsp), %rax
	movq	%rax, 180104(%rsp)
	movq	86992(%rsp), %rax
	movq	%rax, 180112(%rsp)
	movq	87000(%rsp), %rax
	movq	%rax, 180120(%rsp)
	movq	87008(%rsp), %rax
	movq	%rax, 180128(%rsp)
	movq	87016(%rsp), %rax
	movq	%rax, 180136(%rsp)
	movq	87024(%rsp), %rax
	movq	%rax, 180144(%rsp)
	movq	87032(%rsp), %rax
	movq	%rax, 180152(%rsp)
	movq	87040(%rsp), %rax
	movq	%rax, 180160(%rsp)
	movq	87048(%rsp), %rax
	movq	%rax, 180168(%rsp)
	movq	87056(%rsp), %rax
	movq	%rax, 180176(%rsp)
	movq	87064(%rsp), %rax
	movq	%rax, 180184(%rsp)
	movq	87072(%rsp), %rax
	movq	%rax, 180192(%rsp)
	movq	87080(%rsp), %rax
	movq	%rax, 180200(%rsp)
	movq	87088(%rsp), %rax
	movq	%rax, 180208(%rsp)
	movq	87096(%rsp), %rax
	movq	%rax, 180216(%rsp)
	movq	87104(%rsp), %rax
	movq	%rax, 180224(%rsp)
	movq	87112(%rsp), %rax
	movq	%rax, 180232(%rsp)
	movq	87120(%rsp), %rax
	movq	%rax, 180240(%rsp)
	movq	87128(%rsp), %rax
	movq	%rax, 180248(%rsp)
	movq	87136(%rsp), %rax
	movq	%rax, 180256(%rsp)
	movq	87144(%rsp), %rax
	movq	%rax, 180264(%rsp)
	movq	87152(%rsp), %rax
	movq	%rax, 180272(%rsp)
	movq	87160(%rsp), %rax
	movq	%rax, 180280(%rsp)
	movq	87168(%rsp), %rax
	movq	%rax, 180288(%rsp)
	movq	87176(%rsp), %rax
	movq	%rax, 180296(%rsp)
	movq	87184(%rsp), %rax
	movq	%rax, 180304(%rsp)
	movq	87192(%rsp), %rax
	movq	%rax, 180312(%rsp)
	movq	87200(%rsp), %rax
	movq	%rax, 180320(%rsp)
	movq	87208(%rsp), %rax
	movq	%rax, 180328(%rsp)
	movq	87216(%rsp), %rax
	movq	%rax, 180336(%rsp)
	movq	87224(%rsp), %rax
	movq	%rax, 180344(%rsp)
	movq	87232(%rsp), %rax
	movq	%rax, 180352(%rsp)
	movq	87240(%rsp), %rax
	movq	%rax, 180360(%rsp)
	movq	87248(%rsp), %rax
	movq	%rax, 180368(%rsp)
	movq	87256(%rsp), %rax
	movq	%rax, 180376(%rsp)
	movq	87264(%rsp), %rax
	movq	%rax, 180384(%rsp)
	movq	87272(%rsp), %rax
	movq	%rax, 180392(%rsp)
	movq	87280(%rsp), %rax
	movq	%rax, 180400(%rsp)
	movq	87288(%rsp), %rax
	movq	%rax, 180408(%rsp)
	movq	87296(%rsp), %rax
	movq	%rax, 180416(%rsp)
	movq	87304(%rsp), %rax
	movq	%rax, 180424(%rsp)
	movq	87312(%rsp), %rax
	movq	%rax, 180432(%rsp)
	movq	87320(%rsp), %rax
	movq	%rax, 180440(%rsp)
	movq	87328(%rsp), %rax
	movq	%rax, 180448(%rsp)
	movq	87336(%rsp), %rax
	movq	%rax, 180456(%rsp)
	movq	87344(%rsp), %rax
	movq	%rax, 180464(%rsp)
	movq	87352(%rsp), %rax
	movq	%rax, 180472(%rsp)
	movq	87360(%rsp), %rax
	movq	%rax, 180480(%rsp)
	movq	87368(%rsp), %rax
	movq	%rax, 180488(%rsp)
	movq	87376(%rsp), %rax
	movq	%rax, 180496(%rsp)
	movq	87384(%rsp), %rax
	movq	%rax, 180504(%rsp)
	movq	87392(%rsp), %rax
	movq	%rax, 180512(%rsp)
	movq	87400(%rsp), %rax
	movq	%rax, 180520(%rsp)
	movq	87408(%rsp), %rax
	movq	%rax, 180528(%rsp)
	movq	87416(%rsp), %rax
	movq	%rax, 180536(%rsp)
	movq	87424(%rsp), %rax
	movq	%rax, 180544(%rsp)
	movq	87432(%rsp), %rax
	movq	%rax, 180552(%rsp)
	movq	87440(%rsp), %rax
	movq	%rax, 180560(%rsp)
	movq	87448(%rsp), %rax
	movq	%rax, 180568(%rsp)
	movq	87456(%rsp), %rax
	movq	%rax, 180576(%rsp)
	movq	87464(%rsp), %rax
	movq	%rax, 180584(%rsp)
	movq	87472(%rsp), %rax
	movq	%rax, 180592(%rsp)
	movq	87480(%rsp), %rax
	movq	%rax, 180600(%rsp)
	movq	87488(%rsp), %rax
	movq	%rax, 180608(%rsp)
	movq	87496(%rsp), %rax
	movq	%rax, 180616(%rsp)
	movq	87504(%rsp), %rax
	movq	%rax, 180624(%rsp)
	movq	87512(%rsp), %rax
	movq	%rax, 180632(%rsp)
	movq	87520(%rsp), %rax
	movq	%rax, 180640(%rsp)
	movq	87528(%rsp), %rax
	movq	%rax, 180648(%rsp)
	movq	87536(%rsp), %rax
	movq	%rax, 180656(%rsp)
	movq	87544(%rsp), %rax
	movq	%rax, 180664(%rsp)
	movq	87552(%rsp), %rax
	movq	%rax, 180672(%rsp)
	movq	87560(%rsp), %rax
	movq	%rax, 180680(%rsp)
	movq	87568(%rsp), %rax
	movq	%rax, 180688(%rsp)
	movq	87576(%rsp), %rax
	movq	%rax, 180696(%rsp)
	movq	87584(%rsp), %rax
	movq	%rax, 180704(%rsp)
	movq	87592(%rsp), %rax
	movq	%rax, 180712(%rsp)
	movq	87600(%rsp), %rax
	movq	%rax, 180720(%rsp)
	movq	87608(%rsp), %rax
	movq	%rax, 180728(%rsp)
	movq	87616(%rsp), %rax
	movq	%rax, 180736(%rsp)
	movq	87624(%rsp), %rax
	movq	%rax, 180744(%rsp)
	movq	87632(%rsp), %rax
	movq	%rax, 180752(%rsp)
	movq	87640(%rsp), %rax
	movq	%rax, 180760(%rsp)
	movq	87648(%rsp), %rax
	movq	%rax, 180768(%rsp)
	movq	87656(%rsp), %rax
	movq	%rax, 180776(%rsp)
	movq	87664(%rsp), %rax
	movq	%rax, 180784(%rsp)
	movq	87672(%rsp), %rax
	movq	%rax, 180792(%rsp)
	movq	87680(%rsp), %rax
	movq	%rax, 180800(%rsp)
	movq	87688(%rsp), %rax
	movq	%rax, 180808(%rsp)
	movq	87696(%rsp), %rax
	movq	%rax, 180816(%rsp)
	movq	87704(%rsp), %rax
	movq	%rax, 180824(%rsp)
	movq	87712(%rsp), %rax
	movq	%rax, 180832(%rsp)
	movq	87720(%rsp), %rax
	movq	%rax, 180840(%rsp)
	movq	87728(%rsp), %rax
	movq	%rax, 180848(%rsp)
	movq	87736(%rsp), %rax
	movq	%rax, 180856(%rsp)
	movq	87744(%rsp), %rax
	movq	%rax, 180864(%rsp)
	movq	87752(%rsp), %rax
	movq	%rax, 180872(%rsp)
	movq	87760(%rsp), %rax
	movq	%rax, 180880(%rsp)
	movq	87768(%rsp), %rax
	movq	%rax, 180888(%rsp)
	movq	87776(%rsp), %rax
	movq	%rax, 180896(%rsp)
	movq	87784(%rsp), %rax
	movq	%rax, 180904(%rsp)
	movq	87792(%rsp), %rax
	movq	%rax, 180912(%rsp)
	movq	87800(%rsp), %rax
	movq	%rax, 180920(%rsp)
	movq	87808(%rsp), %rax
	movq	%rax, 180928(%rsp)
	movq	87816(%rsp), %rax
	movq	%rax, 180936(%rsp)
	movq	87824(%rsp), %rax
	movq	%rax, 180944(%rsp)
	movq	87832(%rsp), %rax
	movq	%rax, 180952(%rsp)
	movq	87840(%rsp), %rax
	movq	%rax, 180960(%rsp)
	movq	87848(%rsp), %rax
	movq	%rax, 180968(%rsp)
	movq	87856(%rsp), %rax
	movq	%rax, 180976(%rsp)
	movq	87864(%rsp), %rax
	movq	%rax, 180984(%rsp)
	movq	87872(%rsp), %rax
	movq	%rax, 180992(%rsp)
	movq	87880(%rsp), %rax
	movq	%rax, 181000(%rsp)
	movq	87888(%rsp), %rax
	movq	%rax, 181008(%rsp)
	movq	87896(%rsp), %rax
	movq	%rax, 181016(%rsp)
	movq	87904(%rsp), %rax
	movq	%rax, 181024(%rsp)
	movq	87912(%rsp), %rax
	movq	%rax, 181032(%rsp)
	movq	87920(%rsp), %rax
	movq	%rax, 181040(%rsp)
	movq	87928(%rsp), %rax
	movq	%rax, 181048(%rsp)
	movq	87936(%rsp), %rax
	movq	%rax, 181056(%rsp)
	movq	87944(%rsp), %rax
	movq	%rax, 181064(%rsp)
	movq	87952(%rsp), %rax
	movq	%rax, 181072(%rsp)
	movq	87960(%rsp), %rax
	movq	%rax, 181080(%rsp)
	movq	87968(%rsp), %rax
	movq	%rax, 181088(%rsp)
	movq	87976(%rsp), %rax
	movq	%rax, 181096(%rsp)
	movq	87984(%rsp), %rax
	movq	%rax, 181104(%rsp)
	movq	87992(%rsp), %rax
	movq	%rax, 181112(%rsp)
	movq	88000(%rsp), %rax
	movq	%rax, 181120(%rsp)
	movq	88008(%rsp), %rax
	movq	%rax, 181128(%rsp)
	movq	88016(%rsp), %rax
	movq	%rax, 181136(%rsp)
	movq	88024(%rsp), %rax
	movq	%rax, 181144(%rsp)
	movq	88032(%rsp), %rax
	movq	%rax, 181152(%rsp)
	movq	88040(%rsp), %rax
	movq	%rax, 181160(%rsp)
	movq	88048(%rsp), %rax
	movq	%rax, 181168(%rsp)
	movq	88056(%rsp), %rax
	movq	%rax, 181176(%rsp)
	movq	88064(%rsp), %rax
	movq	%rax, 181184(%rsp)
	movq	88072(%rsp), %rax
	movq	%rax, 181192(%rsp)
	movq	88080(%rsp), %rax
	movq	%rax, 181200(%rsp)
	movq	88088(%rsp), %rax
	movq	%rax, 181208(%rsp)
	movq	88096(%rsp), %rax
	movq	%rax, 181216(%rsp)
	movq	88104(%rsp), %rax
	movq	%rax, 181224(%rsp)
	movq	88112(%rsp), %rax
	movq	%rax, 181232(%rsp)
	movq	88120(%rsp), %rax
	movq	%rax, 181240(%rsp)
	movq	88128(%rsp), %rax
	movq	%rax, 181248(%rsp)
	movq	88136(%rsp), %rax
	movq	%rax, 181256(%rsp)
	movq	88144(%rsp), %rax
	movq	%rax, 181264(%rsp)
	movq	88152(%rsp), %rax
	movq	%rax, 181272(%rsp)
	movq	88160(%rsp), %rax
	movq	%rax, 181280(%rsp)
	movq	88168(%rsp), %rax
	movq	%rax, 181288(%rsp)
	movq	88176(%rsp), %rax
	movq	%rax, 181296(%rsp)
	movq	88184(%rsp), %rax
	movq	%rax, 181304(%rsp)
	movq	88192(%rsp), %rax
	movq	%rax, 181312(%rsp)
	movq	88200(%rsp), %rax
	movq	%rax, 181320(%rsp)
	movq	88208(%rsp), %rax
	movq	%rax, 181328(%rsp)
	movq	88216(%rsp), %rax
	movq	%rax, 181336(%rsp)
	movq	88224(%rsp), %rax
	movq	%rax, 181344(%rsp)
	movq	88232(%rsp), %rax
	movq	%rax, 181352(%rsp)
	movq	88240(%rsp), %rax
	movq	%rax, 181360(%rsp)
	movq	88248(%rsp), %rax
	movq	%rax, 181368(%rsp)
	movq	88256(%rsp), %rax
	movq	%rax, 181376(%rsp)
	movq	88264(%rsp), %rax
	movq	%rax, 181384(%rsp)
	movq	88272(%rsp), %rax
	movq	%rax, 181392(%rsp)
	movq	88280(%rsp), %rax
	movq	%rax, 181400(%rsp)
	movq	88288(%rsp), %rax
	movq	%rax, 181408(%rsp)
	movq	88296(%rsp), %rax
	movq	%rax, 181416(%rsp)
	movq	88304(%rsp), %rax
	movq	%rax, 181424(%rsp)
	movq	88312(%rsp), %rax
	movq	%rax, 181432(%rsp)
	movq	88320(%rsp), %rax
	movq	%rax, 181440(%rsp)
	movq	88328(%rsp), %rax
	movq	%rax, 181448(%rsp)
	movq	88336(%rsp), %rax
	movq	%rax, 181456(%rsp)
	movq	88344(%rsp), %rax
	movq	%rax, 181464(%rsp)
	movq	88352(%rsp), %rax
	movq	%rax, 181472(%rsp)
	movq	88360(%rsp), %rax
	movq	%rax, 181480(%rsp)
	movq	88368(%rsp), %rax
	movq	%rax, 181488(%rsp)
	movq	88376(%rsp), %rax
	movq	%rax, 181496(%rsp)
	movq	88384(%rsp), %rax
	movq	%rax, 181504(%rsp)
	movq	88392(%rsp), %rax
	movq	%rax, 181512(%rsp)
	movq	88400(%rsp), %rax
	movq	%rax, 181520(%rsp)
	movq	88408(%rsp), %rax
	movq	%rax, 181528(%rsp)
	movq	88416(%rsp), %rax
	movq	%rax, 181536(%rsp)
	movq	88424(%rsp), %rax
	movq	%rax, 181544(%rsp)
	movq	88432(%rsp), %rax
	movq	%rax, 181552(%rsp)
	movq	88440(%rsp), %rax
	movq	%rax, 181560(%rsp)
	movq	88448(%rsp), %rax
	movq	%rax, 181568(%rsp)
	movq	88456(%rsp), %rax
	movq	%rax, 181576(%rsp)
	movq	88464(%rsp), %rax
	movq	%rax, 181584(%rsp)
	movq	88472(%rsp), %rax
	movq	%rax, 181592(%rsp)
	movq	88480(%rsp), %rax
	movq	%rax, 181600(%rsp)
	movq	88488(%rsp), %rax
	movq	%rax, 181608(%rsp)
	movq	88496(%rsp), %rax
	movq	%rax, 181616(%rsp)
	movq	88504(%rsp), %rax
	movq	%rax, 181624(%rsp)
	movq	88512(%rsp), %rax
	movq	%rax, 181632(%rsp)
	movq	88520(%rsp), %rax
	movq	%rax, 181640(%rsp)
	movq	88528(%rsp), %rax
	movq	%rax, 181648(%rsp)
	movq	88536(%rsp), %rax
	movq	%rax, 181656(%rsp)
	movq	88544(%rsp), %rax
	movq	%rax, 181664(%rsp)
	movq	88552(%rsp), %rax
	movq	%rax, 181672(%rsp)
	movq	88560(%rsp), %rax
	movq	%rax, 181680(%rsp)
	movq	88568(%rsp), %rax
	movq	%rax, 181688(%rsp)
	movq	88576(%rsp), %rax
	movq	%rax, 181696(%rsp)
	movq	88584(%rsp), %rax
	movq	%rax, 181704(%rsp)
	movq	88592(%rsp), %rax
	movq	%rax, 181712(%rsp)
	movq	88600(%rsp), %rax
	movq	%rax, 181720(%rsp)
	movq	88608(%rsp), %rax
	movq	%rax, 181728(%rsp)
	movq	88616(%rsp), %rax
	movq	%rax, 181736(%rsp)
	movq	88624(%rsp), %rax
	movq	%rax, 181744(%rsp)
	movq	88632(%rsp), %rax
	movq	%rax, 181752(%rsp)
	movq	88640(%rsp), %rax
	movq	%rax, 181760(%rsp)
	movq	88648(%rsp), %rax
	movq	%rax, 181768(%rsp)
	movq	88656(%rsp), %rax
	movq	%rax, 181776(%rsp)
	movq	88664(%rsp), %rax
	movq	%rax, 181784(%rsp)
	movq	88672(%rsp), %rax
	movq	%rax, 181792(%rsp)
	movq	88680(%rsp), %rax
	movq	%rax, 181800(%rsp)
	movq	88688(%rsp), %rax
	movq	%rax, 181808(%rsp)
	movq	88696(%rsp), %rax
	movq	%rax, 181816(%rsp)
	movq	88704(%rsp), %rax
	movq	%rax, 181824(%rsp)
	movq	88712(%rsp), %rax
	movq	%rax, 181832(%rsp)
	movq	88720(%rsp), %rax
	movq	%rax, 181840(%rsp)
	movq	88728(%rsp), %rax
	movq	%rax, 181848(%rsp)
	movq	88736(%rsp), %rax
	movq	%rax, 181856(%rsp)
	movq	88744(%rsp), %rax
	movq	%rax, 181864(%rsp)
	movq	88752(%rsp), %rax
	movq	%rax, 181872(%rsp)
	movq	88760(%rsp), %rax
	movq	%rax, 181880(%rsp)
	movq	88768(%rsp), %rax
	movq	%rax, 181888(%rsp)
	movq	88776(%rsp), %rax
	movq	%rax, 181896(%rsp)
	movq	88784(%rsp), %rax
	movq	%rax, 181904(%rsp)
	movq	88792(%rsp), %rax
	movq	%rax, 181912(%rsp)
	movq	88800(%rsp), %rax
	movq	%rax, 181920(%rsp)
	movq	88808(%rsp), %rax
	movq	%rax, 181928(%rsp)
	movq	88816(%rsp), %rax
	movq	%rax, 181936(%rsp)
	movq	88824(%rsp), %rax
	movq	%rax, 181944(%rsp)
	movq	88832(%rsp), %rax
	movq	%rax, 181952(%rsp)
	movq	88840(%rsp), %rax
	movq	%rax, 181960(%rsp)
	movq	88848(%rsp), %rax
	movq	%rax, 181968(%rsp)
	movq	88856(%rsp), %rax
	movq	%rax, 181976(%rsp)
	movq	88864(%rsp), %rax
	movq	%rax, 181984(%rsp)
	movq	88872(%rsp), %rax
	movq	%rax, 181992(%rsp)
	movq	88880(%rsp), %rax
	movq	%rax, 182000(%rsp)
	movq	88888(%rsp), %rax
	movq	%rax, 182008(%rsp)
	movq	88896(%rsp), %rax
	movq	%rax, 182016(%rsp)
	movq	88904(%rsp), %rax
	movq	%rax, 182024(%rsp)
	movq	88912(%rsp), %rax
	movq	%rax, 182032(%rsp)
	movq	88920(%rsp), %rax
	movq	%rax, 182040(%rsp)
	movq	88928(%rsp), %rax
	movq	%rax, 182048(%rsp)
	movq	88936(%rsp), %rax
	movq	%rax, 182056(%rsp)
	movq	88944(%rsp), %rax
	movq	%rax, 182064(%rsp)
	movq	88952(%rsp), %rax
	movq	%rax, 182072(%rsp)
	movq	88960(%rsp), %rax
	movq	%rax, 182080(%rsp)
	movq	88968(%rsp), %rax
	movq	%rax, 182088(%rsp)
	movq	88976(%rsp), %rax
	movq	%rax, 182096(%rsp)
	movq	88984(%rsp), %rax
	movq	%rax, 182104(%rsp)
	movq	88992(%rsp), %rax
	movq	%rax, 182112(%rsp)
	movq	89000(%rsp), %rax
	movq	%rax, 182120(%rsp)
	movq	89008(%rsp), %rax
	movq	%rax, 182128(%rsp)
	movq	89016(%rsp), %rax
	movq	%rax, 182136(%rsp)
	movq	89024(%rsp), %rax
	movq	%rax, 182144(%rsp)
	movq	89032(%rsp), %rax
	movq	%rax, 182152(%rsp)
	movq	89040(%rsp), %rax
	movq	%rax, 182160(%rsp)
	movq	89048(%rsp), %rax
	movq	%rax, 182168(%rsp)
	movq	89056(%rsp), %rax
	movq	%rax, 182176(%rsp)
	movq	89064(%rsp), %rax
	movq	%rax, 182184(%rsp)
	movq	89072(%rsp), %rax
	movq	%rax, 182192(%rsp)
	movq	89080(%rsp), %rax
	movq	%rax, 182200(%rsp)
	movq	89088(%rsp), %rax
	movq	%rax, 182208(%rsp)
	movq	89096(%rsp), %rax
	movq	%rax, 182216(%rsp)
	movq	89104(%rsp), %rax
	movq	%rax, 182224(%rsp)
	movq	89112(%rsp), %rax
	movq	%rax, 182232(%rsp)
	movq	89120(%rsp), %rax
	movq	%rax, 182240(%rsp)
	movq	89128(%rsp), %rax
	movq	%rax, 182248(%rsp)
	movq	89136(%rsp), %rax
	movq	%rax, 182256(%rsp)
	movq	89144(%rsp), %rax
	movq	%rax, 182264(%rsp)
	movq	89152(%rsp), %rax
	movq	%rax, 182272(%rsp)
	movq	89160(%rsp), %rax
	movq	%rax, 182280(%rsp)
	movq	89168(%rsp), %rax
	movq	%rax, 182288(%rsp)
	movq	89176(%rsp), %rax
	movq	%rax, 182296(%rsp)
	movq	89184(%rsp), %rax
	movq	%rax, 182304(%rsp)
	movq	89192(%rsp), %rax
	movq	%rax, 182312(%rsp)
	movq	89200(%rsp), %rax
	movq	%rax, 182320(%rsp)
	movq	89208(%rsp), %rax
	movq	%rax, 182328(%rsp)
	movq	89216(%rsp), %rax
	movq	%rax, 182336(%rsp)
	movq	89224(%rsp), %rax
	movq	%rax, 182344(%rsp)
	movq	89232(%rsp), %rax
	movq	%rax, 182352(%rsp)
	movq	89240(%rsp), %rax
	movq	%rax, 182360(%rsp)
	movq	89248(%rsp), %rax
	movq	%rax, 182368(%rsp)
	movq	89256(%rsp), %rax
	movq	%rax, 182376(%rsp)
	movq	89264(%rsp), %rax
	movq	%rax, 182384(%rsp)
	movq	89272(%rsp), %rax
	movq	%rax, 182392(%rsp)
	movq	89280(%rsp), %rax
	movq	%rax, 182400(%rsp)
	movq	89288(%rsp), %rax
	movq	%rax, 182408(%rsp)
	movq	89296(%rsp), %rax
	movq	%rax, 182416(%rsp)
	movq	89304(%rsp), %rax
	movq	%rax, 182424(%rsp)
	movq	89312(%rsp), %rax
	movq	%rax, 182432(%rsp)
	movq	89320(%rsp), %rax
	movq	%rax, 182440(%rsp)
	movq	89328(%rsp), %rax
	movq	%rax, 182448(%rsp)
	movq	89336(%rsp), %rax
	movq	%rax, 182456(%rsp)
	movq	89344(%rsp), %rax
	movq	%rax, 182464(%rsp)
	movq	89352(%rsp), %rax
	movq	%rax, 182472(%rsp)
	movq	89360(%rsp), %rax
	movq	%rax, 182480(%rsp)
	movq	89368(%rsp), %rax
	movq	%rax, 182488(%rsp)
	movq	89376(%rsp), %rax
	movq	%rax, 182496(%rsp)
	movq	89384(%rsp), %rax
	movq	%rax, 182504(%rsp)
	movq	89392(%rsp), %rax
	movq	%rax, 182512(%rsp)
	movq	89400(%rsp), %rax
	movq	%rax, 182520(%rsp)
	movq	89408(%rsp), %rax
	movq	%rax, 182528(%rsp)
	movq	89416(%rsp), %rax
	movq	%rax, 182536(%rsp)
	movq	89424(%rsp), %rax
	movq	%rax, 182544(%rsp)
	movq	89432(%rsp), %rax
	movq	%rax, 182552(%rsp)
	movq	89440(%rsp), %rax
	movq	%rax, 182560(%rsp)
	movq	89448(%rsp), %rax
	movq	%rax, 182568(%rsp)
	movq	89456(%rsp), %rax
	movq	%rax, 182576(%rsp)
	movq	89464(%rsp), %rax
	movq	%rax, 182584(%rsp)
	movq	89472(%rsp), %rax
	movq	%rax, 182592(%rsp)
	movq	89480(%rsp), %rax
	movq	%rax, 182600(%rsp)
	movq	89488(%rsp), %rax
	movq	%rax, 182608(%rsp)
	movq	89496(%rsp), %rax
	movq	%rax, 182616(%rsp)
	movq	89504(%rsp), %rax
	movq	%rax, 182624(%rsp)
	movq	89512(%rsp), %rax
	movq	%rax, 182632(%rsp)
	movq	89520(%rsp), %rax
	movq	%rax, 182640(%rsp)
	movq	89528(%rsp), %rax
	movq	%rax, 182648(%rsp)
	movq	89536(%rsp), %rax
	movq	%rax, 182656(%rsp)
	movq	89544(%rsp), %rax
	movq	%rax, 182664(%rsp)
	movq	89552(%rsp), %rax
	movq	%rax, 182672(%rsp)
	movq	89560(%rsp), %rax
	movq	%rax, 182680(%rsp)
	movq	89568(%rsp), %rax
	movq	%rax, 182688(%rsp)
	movq	89576(%rsp), %rax
	movq	%rax, 182696(%rsp)
	movq	89584(%rsp), %rax
	movq	%rax, 182704(%rsp)
	movq	89592(%rsp), %rax
	movq	%rax, 182712(%rsp)
	movq	89600(%rsp), %rax
	movq	%rax, 182720(%rsp)
	movq	89608(%rsp), %rax
	movq	%rax, 182728(%rsp)
	movq	89616(%rsp), %rax
	movq	%rax, 182736(%rsp)
	movq	89624(%rsp), %rax
	movq	%rax, 182744(%rsp)
	movq	89632(%rsp), %rax
	movq	%rax, 182752(%rsp)
	movq	89640(%rsp), %rax
	movq	%rax, 182760(%rsp)
	movq	89648(%rsp), %rax
	movq	%rax, 182768(%rsp)
	movq	89656(%rsp), %rax
	movq	%rax, 182776(%rsp)
	movq	89664(%rsp), %rax
	movq	%rax, 182784(%rsp)
	movq	89672(%rsp), %rax
	movq	%rax, 182792(%rsp)
	movq	89680(%rsp), %rax
	movq	%rax, 182800(%rsp)
	movq	89688(%rsp), %rax
	movq	%rax, 182808(%rsp)
	movq	89696(%rsp), %rax
	movq	%rax, 182816(%rsp)
	movq	89704(%rsp), %rax
	movq	%rax, 182824(%rsp)
	movq	89712(%rsp), %rax
	movq	%rax, 182832(%rsp)
	movq	89720(%rsp), %rax
	movq	%rax, 182840(%rsp)
	movq	89728(%rsp), %rax
	movq	%rax, 182848(%rsp)
	movq	89736(%rsp), %rax
	movq	%rax, 182856(%rsp)
	movq	89744(%rsp), %rax
	movq	%rax, 182864(%rsp)
	movq	89752(%rsp), %rax
	movq	%rax, 182872(%rsp)
	movq	89760(%rsp), %rax
	movq	%rax, 182880(%rsp)
	movq	89768(%rsp), %rax
	movq	%rax, 182888(%rsp)
	movq	89776(%rsp), %rax
	movq	%rax, 182896(%rsp)
	movq	89784(%rsp), %rax
	movq	%rax, 182904(%rsp)
	movq	89792(%rsp), %rax
	movq	%rax, 182912(%rsp)
	movq	89800(%rsp), %rax
	movq	%rax, 182920(%rsp)
	movq	89808(%rsp), %rax
	movq	%rax, 182928(%rsp)
	movq	89816(%rsp), %rax
	movq	%rax, 182936(%rsp)
	movq	89824(%rsp), %rax
	movq	%rax, 182944(%rsp)
	movq	89832(%rsp), %rax
	movq	%rax, 182952(%rsp)
	movq	89840(%rsp), %rax
	movq	%rax, 182960(%rsp)
	movq	89848(%rsp), %rax
	movq	%rax, 182968(%rsp)
	movq	89856(%rsp), %rax
	movq	%rax, 182976(%rsp)
	movq	89864(%rsp), %rax
	movq	%rax, 182984(%rsp)
	movq	89872(%rsp), %rax
	movq	%rax, 182992(%rsp)
	movq	89880(%rsp), %rax
	movq	%rax, 183000(%rsp)
	movq	89888(%rsp), %rax
	movq	%rax, 183008(%rsp)
	movq	89896(%rsp), %rax
	movq	%rax, 183016(%rsp)
	movq	89904(%rsp), %rax
	movq	%rax, 183024(%rsp)
	movq	89912(%rsp), %rax
	movq	%rax, 183032(%rsp)
	movq	89920(%rsp), %rax
	movq	%rax, 183040(%rsp)
	movq	89928(%rsp), %rax
	movq	%rax, 183048(%rsp)
	movq	89936(%rsp), %rax
	movq	%rax, 183056(%rsp)
	movq	89944(%rsp), %rax
	movq	%rax, 183064(%rsp)
	movq	89952(%rsp), %rax
	movq	%rax, 183072(%rsp)
	movq	89960(%rsp), %rax
	movq	%rax, 183080(%rsp)
	movq	89968(%rsp), %rax
	movq	%rax, 183088(%rsp)
	movq	89976(%rsp), %rax
	movq	%rax, 183096(%rsp)
	movq	89984(%rsp), %rax
	movq	%rax, 183104(%rsp)
	movq	89992(%rsp), %rax
	movq	%rax, 183112(%rsp)
	movq	90000(%rsp), %rax
	movq	%rax, 183120(%rsp)
	movq	90008(%rsp), %rax
	movq	%rax, 183128(%rsp)
	movq	90016(%rsp), %rax
	movq	%rax, 183136(%rsp)
	movq	90024(%rsp), %rax
	movq	%rax, 183144(%rsp)
	movq	90032(%rsp), %rax
	movq	%rax, 183152(%rsp)
	movq	90040(%rsp), %rax
	movq	%rax, 183160(%rsp)
	movq	90048(%rsp), %rax
	movq	%rax, 183168(%rsp)
	movq	90056(%rsp), %rax
	movq	%rax, 183176(%rsp)
	movq	90064(%rsp), %rax
	movq	%rax, 183184(%rsp)
	movq	90072(%rsp), %rax
	movq	%rax, 183192(%rsp)
	movq	90080(%rsp), %rax
	movq	%rax, 183200(%rsp)
	movq	90088(%rsp), %rax
	movq	%rax, 183208(%rsp)
	movq	90096(%rsp), %rax
	movq	%rax, 183216(%rsp)
	movq	90104(%rsp), %rax
	movq	%rax, 183224(%rsp)
	movq	90112(%rsp), %rax
	movq	%rax, 183232(%rsp)
	movq	90120(%rsp), %rax
	movq	%rax, 183240(%rsp)
	movq	90128(%rsp), %rax
	movq	%rax, 183248(%rsp)
	movq	90136(%rsp), %rax
	movq	%rax, 183256(%rsp)
	movq	90144(%rsp), %rax
	movq	%rax, 183264(%rsp)
	movq	90152(%rsp), %rax
	movq	%rax, 183272(%rsp)
	movq	90160(%rsp), %rax
	movq	%rax, 183280(%rsp)
	movq	90168(%rsp), %rax
	movq	%rax, 183288(%rsp)
	movq	90176(%rsp), %rax
	movq	%rax, 183296(%rsp)
	movq	90184(%rsp), %rax
	movq	%rax, 183304(%rsp)
	movq	90192(%rsp), %rax
	movq	%rax, 183312(%rsp)
	movq	90200(%rsp), %rax
	movq	%rax, 183320(%rsp)
	movq	90208(%rsp), %rax
	movq	%rax, 183328(%rsp)
	movq	90216(%rsp), %rax
	movq	%rax, 183336(%rsp)
	movq	90224(%rsp), %rax
	movq	%rax, 183344(%rsp)
	movq	90232(%rsp), %rax
	movq	%rax, 183352(%rsp)
	movq	90240(%rsp), %rax
	movq	%rax, 183360(%rsp)
	movq	90248(%rsp), %rax
	movq	%rax, 183368(%rsp)
	movq	90256(%rsp), %rax
	movq	%rax, 183376(%rsp)
	movq	90264(%rsp), %rax
	movq	%rax, 183384(%rsp)
	movq	90272(%rsp), %rax
	movq	%rax, 183392(%rsp)
	movq	90280(%rsp), %rax
	movq	%rax, 183400(%rsp)
	movq	90288(%rsp), %rax
	movq	%rax, 183408(%rsp)
	movq	90296(%rsp), %rax
	movq	%rax, 183416(%rsp)
	movq	90304(%rsp), %rax
	movq	%rax, 183424(%rsp)
	movq	90312(%rsp), %rax
	movq	%rax, 183432(%rsp)
	movq	90320(%rsp), %rax
	movq	%rax, 183440(%rsp)
	movq	90328(%rsp), %rax
	movq	%rax, 183448(%rsp)
	movq	90336(%rsp), %rax
	movq	%rax, 183456(%rsp)
	movq	90344(%rsp), %rax
	movq	%rax, 183464(%rsp)
	movq	90352(%rsp), %rax
	movq	%rax, 183472(%rsp)
	movq	90360(%rsp), %rax
	movq	%rax, 183480(%rsp)
	movq	90368(%rsp), %rax
	movq	%rax, 183488(%rsp)
	movq	90376(%rsp), %rax
	movq	%rax, 183496(%rsp)
	movq	90384(%rsp), %rax
	movq	%rax, 183504(%rsp)
	movq	90392(%rsp), %rax
	movq	%rax, 183512(%rsp)
	movq	90400(%rsp), %rax
	movq	%rax, 183520(%rsp)
	movq	90408(%rsp), %rax
	movq	%rax, 183528(%rsp)
	movq	90416(%rsp), %rax
	movq	%rax, 183536(%rsp)
	movq	90424(%rsp), %rax
	movq	%rax, 183544(%rsp)
	movq	90432(%rsp), %rax
	movq	%rax, 183552(%rsp)
	movq	90440(%rsp), %rax
	movq	%rax, 183560(%rsp)
	movq	90448(%rsp), %rax
	movq	%rax, 183568(%rsp)
	movq	90456(%rsp), %rax
	movq	%rax, 183576(%rsp)
	movq	90464(%rsp), %rax
	movq	%rax, 183584(%rsp)
	movq	90472(%rsp), %rax
	movq	%rax, 183592(%rsp)
	movq	90480(%rsp), %rax
	movq	%rax, 183600(%rsp)
	movq	90488(%rsp), %rax
	movq	%rax, 183608(%rsp)
	movq	90496(%rsp), %rax
	movq	%rax, 183616(%rsp)
	movq	90504(%rsp), %rax
	movq	%rax, 183624(%rsp)
	movq	90512(%rsp), %rax
	movq	%rax, 183632(%rsp)
	movq	90520(%rsp), %rax
	movq	%rax, 183640(%rsp)
	movq	90528(%rsp), %rax
	movq	%rax, 183648(%rsp)
	movq	90536(%rsp), %rax
	movq	%rax, 183656(%rsp)
	movq	90544(%rsp), %rax
	movq	%rax, 183664(%rsp)
	movq	90552(%rsp), %rax
	movq	%rax, 183672(%rsp)
	movq	90560(%rsp), %rax
	movq	%rax, 183680(%rsp)
	movq	90568(%rsp), %rax
	movq	%rax, 183688(%rsp)
	movq	90576(%rsp), %rax
	movq	%rax, 183696(%rsp)
	movq	90584(%rsp), %rax
	movq	%rax, 183704(%rsp)
	movq	90592(%rsp), %rax
	movq	%rax, 183712(%rsp)
	movq	90600(%rsp), %rax
	movq	%rax, 183720(%rsp)
	movq	90608(%rsp), %rax
	movq	%rax, 183728(%rsp)
	movq	90616(%rsp), %rax
	movq	%rax, 183736(%rsp)
	movq	90624(%rsp), %rax
	movq	%rax, 183744(%rsp)
	movq	90632(%rsp), %rax
	movq	%rax, 183752(%rsp)
	movq	90640(%rsp), %rax
	movq	%rax, 183760(%rsp)
	movq	90648(%rsp), %rax
	movq	%rax, 183768(%rsp)
	movq	90656(%rsp), %rax
	movq	%rax, 183776(%rsp)
	movq	90664(%rsp), %rax
	movq	%rax, 183784(%rsp)
	movq	90672(%rsp), %rax
	movq	%rax, 183792(%rsp)
	movq	90680(%rsp), %rax
	movq	%rax, 183800(%rsp)
	movq	90688(%rsp), %rax
	movq	%rax, 183808(%rsp)
	movq	90696(%rsp), %rax
	movq	%rax, 183816(%rsp)
	movq	90704(%rsp), %rax
	movq	%rax, 183824(%rsp)
	movq	90712(%rsp), %rax
	movq	%rax, 183832(%rsp)
	movq	90720(%rsp), %rax
	movq	%rax, 183840(%rsp)
	movq	90728(%rsp), %rax
	movq	%rax, 183848(%rsp)
	movq	90736(%rsp), %rax
	movq	%rax, 183856(%rsp)
	movq	90744(%rsp), %rax
	movq	%rax, 183864(%rsp)
	movq	90752(%rsp), %rax
	movq	%rax, 183872(%rsp)
	movq	90760(%rsp), %rax
	movq	%rax, 183880(%rsp)
	movq	90768(%rsp), %rax
	movq	%rax, 183888(%rsp)
	movq	90776(%rsp), %rax
	movq	%rax, 183896(%rsp)
	movq	90784(%rsp), %rax
	movq	%rax, 183904(%rsp)
	movq	90792(%rsp), %rax
	movq	%rax, 183912(%rsp)
	movq	90800(%rsp), %rax
	movq	%rax, 183920(%rsp)
	movq	90808(%rsp), %rax
	movq	%rax, 183928(%rsp)
	movq	90816(%rsp), %rax
	movq	%rax, 183936(%rsp)
	movq	90824(%rsp), %rax
	movq	%rax, 183944(%rsp)
	movq	90832(%rsp), %rax
	movq	%rax, 183952(%rsp)
	movq	90840(%rsp), %rax
	movq	%rax, 183960(%rsp)
	movq	90848(%rsp), %rax
	movq	%rax, 183968(%rsp)
	movq	90856(%rsp), %rax
	movq	%rax, 183976(%rsp)
	movq	90864(%rsp), %rax
	movq	%rax, 183984(%rsp)
	movq	90872(%rsp), %rax
	movq	%rax, 183992(%rsp)
	movq	90880(%rsp), %rax
	movq	%rax, 184000(%rsp)
	movq	90888(%rsp), %rax
	movq	%rax, 184008(%rsp)
	movq	90896(%rsp), %rax
	movq	%rax, 184016(%rsp)
	movq	90904(%rsp), %rax
	movq	%rax, 184024(%rsp)
	movq	90912(%rsp), %rax
	movq	%rax, 184032(%rsp)
	movq	90920(%rsp), %rax
	movq	%rax, 184040(%rsp)
	movq	90928(%rsp), %rax
	movq	%rax, 184048(%rsp)
	movq	90936(%rsp), %rax
	movq	%rax, 184056(%rsp)
	movq	90944(%rsp), %rax
	movq	%rax, 184064(%rsp)
	movq	90952(%rsp), %rax
	movq	%rax, 184072(%rsp)
	movq	90960(%rsp), %rax
	movq	%rax, 184080(%rsp)
	movq	90968(%rsp), %rax
	movq	%rax, 184088(%rsp)
	movq	90976(%rsp), %rax
	movq	%rax, 184096(%rsp)
	movq	90984(%rsp), %rax
	movq	%rax, 184104(%rsp)
	movq	90992(%rsp), %rax
	movq	%rax, 184112(%rsp)
	movq	91000(%rsp), %rax
	movq	%rax, 184120(%rsp)
	movq	91008(%rsp), %rax
	movq	%rax, 184128(%rsp)
	movq	91016(%rsp), %rax
	movq	%rax, 184136(%rsp)
	movq	91024(%rsp), %rax
	movq	%rax, 184144(%rsp)
	movq	91032(%rsp), %rax
	movq	%rax, 184152(%rsp)
	movq	91040(%rsp), %rax
	movq	%rax, 184160(%rsp)
	movq	91048(%rsp), %rax
	movq	%rax, 184168(%rsp)
	movq	91056(%rsp), %rax
	movq	%rax, 184176(%rsp)
	movq	91064(%rsp), %rax
	movq	%rax, 184184(%rsp)
	movq	91072(%rsp), %rax
	movq	%rax, 184192(%rsp)
	movq	91080(%rsp), %rax
	movq	%rax, 184200(%rsp)
	movq	91088(%rsp), %rax
	movq	%rax, 184208(%rsp)
	movq	91096(%rsp), %rax
	movq	%rax, 184216(%rsp)
	movq	91104(%rsp), %rax
	movq	%rax, 184224(%rsp)
	movq	91112(%rsp), %rax
	movq	%rax, 184232(%rsp)
	movq	91120(%rsp), %rax
	movq	%rax, 184240(%rsp)
	movq	91128(%rsp), %rax
	movq	%rax, 184248(%rsp)
	movq	91136(%rsp), %rax
	movq	%rax, 184256(%rsp)
	movq	91144(%rsp), %rax
	movq	%rax, 184264(%rsp)
	movq	91152(%rsp), %rax
	movq	%rax, 184272(%rsp)
	movq	91160(%rsp), %rax
	movq	%rax, 184280(%rsp)
	movq	91168(%rsp), %rax
	movq	%rax, 184288(%rsp)
	movq	91176(%rsp), %rax
	movq	%rax, 184296(%rsp)
	movq	91184(%rsp), %rax
	movq	%rax, 184304(%rsp)
	movq	91192(%rsp), %rax
	movq	%rax, 184312(%rsp)
	movq	91200(%rsp), %rax
	movq	%rax, 184320(%rsp)
	movq	91208(%rsp), %rax
	movq	%rax, 184328(%rsp)
	movq	91216(%rsp), %rax
	movq	%rax, 184336(%rsp)
	movq	91224(%rsp), %rax
	movq	%rax, 184344(%rsp)
	movq	91232(%rsp), %rax
	movq	%rax, 184352(%rsp)
	movq	91240(%rsp), %rax
	movq	%rax, 184360(%rsp)
	movq	91248(%rsp), %rax
	movq	%rax, 184368(%rsp)
	movq	91256(%rsp), %rax
	movq	%rax, 184376(%rsp)
	movq	91264(%rsp), %rax
	movq	%rax, 184384(%rsp)
	movq	91272(%rsp), %rax
	movq	%rax, 184392(%rsp)
	movq	91280(%rsp), %rax
	movq	%rax, 184400(%rsp)
	movq	91288(%rsp), %rax
	movq	%rax, 184408(%rsp)
	movq	91296(%rsp), %rax
	movq	%rax, 184416(%rsp)
	movq	91304(%rsp), %rax
	movq	%rax, 184424(%rsp)
	movq	91312(%rsp), %rax
	movq	%rax, 184432(%rsp)
	movq	91320(%rsp), %rax
	movq	%rax, 184440(%rsp)
	movq	91328(%rsp), %rax
	movq	%rax, 184448(%rsp)
	movq	91336(%rsp), %rax
	movq	%rax, 184456(%rsp)
	movq	91344(%rsp), %rax
	movq	%rax, 184464(%rsp)
	movq	91352(%rsp), %rax
	movq	%rax, 184472(%rsp)
	movq	91360(%rsp), %rax
	movq	%rax, 184480(%rsp)
	movq	91368(%rsp), %rax
	movq	%rax, 184488(%rsp)
	movq	91376(%rsp), %rax
	movq	%rax, 184496(%rsp)
	movq	91384(%rsp), %rax
	movq	%rax, 184504(%rsp)
	movq	91392(%rsp), %rax
	movq	%rax, 184512(%rsp)
	movq	91400(%rsp), %rax
	movq	%rax, 184520(%rsp)
	movq	91408(%rsp), %rax
	movq	%rax, 184528(%rsp)
	movq	91416(%rsp), %rax
	movq	%rax, 184536(%rsp)
	movq	91424(%rsp), %rax
	movq	%rax, 184544(%rsp)
	movq	91432(%rsp), %rax
	movq	%rax, 184552(%rsp)
	movq	91440(%rsp), %rax
	movq	%rax, 184560(%rsp)
	movq	91448(%rsp), %rax
	movq	%rax, 184568(%rsp)
	movq	91456(%rsp), %rax
	movq	%rax, 184576(%rsp)
	movq	91464(%rsp), %rax
	movq	%rax, 184584(%rsp)
	movq	91472(%rsp), %rax
	movq	%rax, 184592(%rsp)
	movq	91480(%rsp), %rax
	movq	%rax, 184600(%rsp)
	movq	91488(%rsp), %rax
	movq	%rax, 184608(%rsp)
	movq	91496(%rsp), %rax
	movq	%rax, 184616(%rsp)
	movq	91504(%rsp), %rax
	movq	%rax, 184624(%rsp)
	movq	91512(%rsp), %rax
	movq	%rax, 184632(%rsp)
	movq	91520(%rsp), %rax
	movq	%rax, 184640(%rsp)
	movq	91528(%rsp), %rax
	movq	%rax, 184648(%rsp)
	movq	91536(%rsp), %rax
	movq	%rax, 184656(%rsp)
	movq	91544(%rsp), %rax
	movq	%rax, 184664(%rsp)
	movq	91552(%rsp), %rax
	movq	%rax, 184672(%rsp)
	movq	91560(%rsp), %rax
	movq	%rax, 184680(%rsp)
	movq	91568(%rsp), %rax
	movq	%rax, 184688(%rsp)
	movq	91576(%rsp), %rax
	movq	%rax, 184696(%rsp)
	movq	91584(%rsp), %rax
	movq	%rax, 184704(%rsp)
	movq	91592(%rsp), %rax
	movq	%rax, 184712(%rsp)
	movq	91600(%rsp), %rax
	movq	%rax, 184720(%rsp)
	movq	91608(%rsp), %rax
	movq	%rax, 184728(%rsp)
	movq	91616(%rsp), %rax
	movq	%rax, 184736(%rsp)
	movq	91624(%rsp), %rax
	movq	%rax, 184744(%rsp)
	movq	91632(%rsp), %rax
	movq	%rax, 184752(%rsp)
	movq	91640(%rsp), %rax
	movq	%rax, 184760(%rsp)
	movq	91648(%rsp), %rax
	movq	%rax, 184768(%rsp)
	movq	91656(%rsp), %rax
	movq	%rax, 184776(%rsp)
	movq	91664(%rsp), %rax
	movq	%rax, 184784(%rsp)
	movq	91672(%rsp), %rax
	movq	%rax, 184792(%rsp)
	movq	91680(%rsp), %rax
	movq	%rax, 184800(%rsp)
	movq	91688(%rsp), %rax
	movq	%rax, 184808(%rsp)
	movq	91696(%rsp), %rax
	movq	%rax, 184816(%rsp)
	movq	91704(%rsp), %rax
	movq	%rax, 184824(%rsp)
	movq	91712(%rsp), %rax
	movq	%rax, 184832(%rsp)
	movq	91720(%rsp), %rax
	movq	%rax, 184840(%rsp)
	movq	91728(%rsp), %rax
	movq	%rax, 184848(%rsp)
	movq	91736(%rsp), %rax
	movq	%rax, 184856(%rsp)
	movq	91744(%rsp), %rax
	movq	%rax, 184864(%rsp)
	movq	91752(%rsp), %rax
	movq	%rax, 184872(%rsp)
	movq	91760(%rsp), %rax
	movq	%rax, 184880(%rsp)
	movq	91768(%rsp), %rax
	movq	%rax, 184888(%rsp)
	movq	91776(%rsp), %rax
	movq	%rax, 184896(%rsp)
	movq	91784(%rsp), %rax
	movq	%rax, 184904(%rsp)
	movq	91792(%rsp), %rax
	movq	%rax, 184912(%rsp)
	movq	91800(%rsp), %rax
	movq	%rax, 184920(%rsp)
	movq	91808(%rsp), %rax
	movq	%rax, 184928(%rsp)
	movq	91816(%rsp), %rax
	movq	%rax, 184936(%rsp)
	movq	91824(%rsp), %rax
	movq	%rax, 184944(%rsp)
	movq	91832(%rsp), %rax
	movq	%rax, 184952(%rsp)
	movq	91840(%rsp), %rax
	movq	%rax, 184960(%rsp)
	movq	91848(%rsp), %rax
	movq	%rax, 184968(%rsp)
	movq	91856(%rsp), %rax
	movq	%rax, 184976(%rsp)
	movq	91864(%rsp), %rax
	movq	%rax, 184984(%rsp)
	movq	91872(%rsp), %rax
	movq	%rax, 184992(%rsp)
	movq	91880(%rsp), %rax
	movq	%rax, 185000(%rsp)
	movq	91888(%rsp), %rax
	movq	%rax, 185008(%rsp)
	movq	91896(%rsp), %rax
	movq	%rax, 185016(%rsp)
	movq	91904(%rsp), %rax
	movq	%rax, 185024(%rsp)
	movq	91912(%rsp), %rax
	movq	%rax, 185032(%rsp)
	movq	91920(%rsp), %rax
	movq	%rax, 185040(%rsp)
	movq	91928(%rsp), %rax
	movq	%rax, 185048(%rsp)
	movq	91936(%rsp), %rax
	movq	%rax, 185056(%rsp)
	movq	91944(%rsp), %rax
	movq	%rax, 185064(%rsp)
	movq	91952(%rsp), %rax
	movq	%rax, 185072(%rsp)
	movq	91960(%rsp), %rax
	movq	%rax, 185080(%rsp)
	movq	91968(%rsp), %rax
	movq	%rax, 185088(%rsp)
	movq	91976(%rsp), %rax
	movq	%rax, 185096(%rsp)
	movq	91984(%rsp), %rax
	movq	%rax, 185104(%rsp)
	movq	91992(%rsp), %rax
	movq	%rax, 185112(%rsp)
	movq	92000(%rsp), %rax
	movq	%rax, 185120(%rsp)
	movq	92008(%rsp), %rax
	movq	%rax, 185128(%rsp)
	movq	92016(%rsp), %rax
	movq	%rax, 185136(%rsp)
	movq	92024(%rsp), %rax
	movq	%rax, 185144(%rsp)
	movq	92032(%rsp), %rax
	movq	%rax, 185152(%rsp)
	movq	92040(%rsp), %rax
	movq	%rax, 185160(%rsp)
	movq	92048(%rsp), %rax
	movq	%rax, 185168(%rsp)
	movq	92056(%rsp), %rax
	movq	%rax, 185176(%rsp)
	movq	92064(%rsp), %rax
	movq	%rax, 185184(%rsp)
	movq	92072(%rsp), %rax
	movq	%rax, 185192(%rsp)
	movq	92080(%rsp), %rax
	movq	%rax, 185200(%rsp)
	movq	92088(%rsp), %rax
	movq	%rax, 185208(%rsp)
	movq	92096(%rsp), %rax
	movq	%rax, 185216(%rsp)
	movq	92104(%rsp), %rax
	movq	%rax, 185224(%rsp)
	movq	92112(%rsp), %rax
	movq	%rax, 185232(%rsp)
	movq	92120(%rsp), %rax
	movq	%rax, 185240(%rsp)
	movq	92128(%rsp), %rax
	movq	%rax, 185248(%rsp)
	movq	92136(%rsp), %rax
	movq	%rax, 185256(%rsp)
	movq	92144(%rsp), %rax
	movq	%rax, 185264(%rsp)
	movq	92152(%rsp), %rax
	movq	%rax, 185272(%rsp)
	movq	92160(%rsp), %rax
	movq	%rax, 185280(%rsp)
	movq	92168(%rsp), %rax
	movq	%rax, 185288(%rsp)
	movq	92176(%rsp), %rax
	movq	%rax, 185296(%rsp)
	movq	92184(%rsp), %rax
	movq	%rax, 185304(%rsp)
	movq	92192(%rsp), %rax
	movq	%rax, 185312(%rsp)
	movq	92200(%rsp), %rax
	movq	%rax, 185320(%rsp)
	movq	92208(%rsp), %rax
	movq	%rax, 185328(%rsp)
	movq	92216(%rsp), %rax
	movq	%rax, 185336(%rsp)
	movq	92224(%rsp), %rax
	movq	%rax, 185344(%rsp)
	movq	92232(%rsp), %rax
	movq	%rax, 185352(%rsp)
	movq	92240(%rsp), %rax
	movq	%rax, 185360(%rsp)
	movq	92248(%rsp), %rax
	movq	%rax, 185368(%rsp)
	movq	92256(%rsp), %rax
	movq	%rax, 185376(%rsp)
	movq	92264(%rsp), %rax
	movq	%rax, 185384(%rsp)
	movq	92272(%rsp), %rax
	movq	%rax, 185392(%rsp)
	movq	92280(%rsp), %rax
	movq	%rax, 185400(%rsp)
	movq	92288(%rsp), %rax
	movq	%rax, 185408(%rsp)
	movq	92296(%rsp), %rax
	movq	%rax, 185416(%rsp)
	movq	92304(%rsp), %rax
	movq	%rax, 185424(%rsp)
	movq	92312(%rsp), %rax
	movq	%rax, 185432(%rsp)
	movq	92320(%rsp), %rax
	movq	%rax, 185440(%rsp)
	movq	92328(%rsp), %rax
	movq	%rax, 185448(%rsp)
	movq	92336(%rsp), %rax
	movq	%rax, 185456(%rsp)
	movq	92344(%rsp), %rax
	movq	%rax, 185464(%rsp)
	movq	92352(%rsp), %rax
	movq	%rax, 185472(%rsp)
	movq	92360(%rsp), %rax
	movq	%rax, 185480(%rsp)
	movq	92368(%rsp), %rax
	movq	%rax, 185488(%rsp)
	movq	92376(%rsp), %rax
	movq	%rax, 185496(%rsp)
	movq	92384(%rsp), %rax
	movq	%rax, 185504(%rsp)
	movq	92392(%rsp), %rax
	movq	%rax, 185512(%rsp)
	movq	92400(%rsp), %rax
	movq	%rax, 185520(%rsp)
	movq	92408(%rsp), %rax
	movq	%rax, 185528(%rsp)
	movq	92416(%rsp), %rax
	movq	%rax, 185536(%rsp)
	movq	92424(%rsp), %rax
	movq	%rax, 185544(%rsp)
	movq	92432(%rsp), %rax
	movq	%rax, 185552(%rsp)
	movq	92440(%rsp), %rax
	movq	%rax, 185560(%rsp)
	movq	92448(%rsp), %rax
	movq	%rax, 185568(%rsp)
	movq	92456(%rsp), %rax
	movq	%rax, 185576(%rsp)
	movq	92464(%rsp), %rax
	movq	%rax, 185584(%rsp)
	movq	92472(%rsp), %rax
	movq	%rax, 185592(%rsp)
	movq	92480(%rsp), %rax
	movq	%rax, 185600(%rsp)
	movq	92488(%rsp), %rax
	movq	%rax, 185608(%rsp)
	movq	92496(%rsp), %rax
	movq	%rax, 185616(%rsp)
	movq	92504(%rsp), %rax
	movq	%rax, 185624(%rsp)
	movq	92512(%rsp), %rax
	movq	%rax, 185632(%rsp)
	movq	92520(%rsp), %rax
	movq	%rax, 185640(%rsp)
	movq	92528(%rsp), %rax
	movq	%rax, 185648(%rsp)
	movq	92536(%rsp), %rax
	movq	%rax, 185656(%rsp)
	movq	92544(%rsp), %rax
	movq	%rax, 185664(%rsp)
	movq	92552(%rsp), %rax
	movq	%rax, 185672(%rsp)
	movq	92560(%rsp), %rax
	movq	%rax, 185680(%rsp)
	movq	92568(%rsp), %rax
	movq	%rax, 185688(%rsp)
	movq	92576(%rsp), %rax
	movq	%rax, 185696(%rsp)
	movq	92584(%rsp), %rax
	movq	%rax, 185704(%rsp)
	movq	92592(%rsp), %rax
	movq	%rax, 185712(%rsp)
	movq	92600(%rsp), %rax
	movq	%rax, 185720(%rsp)
	movq	92608(%rsp), %rax
	movq	%rax, 185728(%rsp)
	movq	92616(%rsp), %rax
	movq	%rax, 185736(%rsp)
	movq	92624(%rsp), %rax
	movq	%rax, 185744(%rsp)
	movq	92632(%rsp), %rax
	movq	%rax, 185752(%rsp)
	movq	92640(%rsp), %rax
	movq	%rax, 185760(%rsp)
	movq	92648(%rsp), %rax
	movq	%rax, 185768(%rsp)
	movq	92656(%rsp), %rax
	movq	%rax, 185776(%rsp)
	movq	92664(%rsp), %rax
	movq	%rax, 185784(%rsp)
	movq	92672(%rsp), %rax
	movq	%rax, 185792(%rsp)
	movq	92680(%rsp), %rax
	movq	%rax, 185800(%rsp)
	movq	92688(%rsp), %rax
	movq	%rax, 185808(%rsp)
	movq	92696(%rsp), %rax
	movq	%rax, 185816(%rsp)
	movq	92704(%rsp), %rax
	movq	%rax, 185824(%rsp)
	movq	92712(%rsp), %rax
	movq	%rax, 185832(%rsp)
	movq	92720(%rsp), %rax
	movq	%rax, 185840(%rsp)
	movq	92728(%rsp), %rax
	movq	%rax, 185848(%rsp)
	movq	92736(%rsp), %rax
	movq	%rax, 185856(%rsp)
	movq	92744(%rsp), %rax
	movq	%rax, 185864(%rsp)
	movq	92752(%rsp), %rax
	movq	%rax, 185872(%rsp)
	movq	92760(%rsp), %rax
	movq	%rax, 185880(%rsp)
	movq	92768(%rsp), %rax
	movq	%rax, 185888(%rsp)
	movq	92776(%rsp), %rax
	movq	%rax, 185896(%rsp)
	movq	92784(%rsp), %rax
	movq	%rax, 185904(%rsp)
	movq	92792(%rsp), %rax
	movq	%rax, 185912(%rsp)
	movq	92800(%rsp), %rax
	movq	%rax, 185920(%rsp)
	movq	92808(%rsp), %rax
	movq	%rax, 185928(%rsp)
	movq	92816(%rsp), %rax
	movq	%rax, 185936(%rsp)
	movq	92824(%rsp), %rax
	movq	%rax, 185944(%rsp)
	movq	92832(%rsp), %rax
	movq	%rax, 185952(%rsp)
	movq	92840(%rsp), %rax
	movq	%rax, 185960(%rsp)
	movq	92848(%rsp), %rax
	movq	%rax, 185968(%rsp)
	movq	92856(%rsp), %rax
	movq	%rax, 185976(%rsp)
	movq	92864(%rsp), %rax
	movq	%rax, 185984(%rsp)
	movq	92872(%rsp), %rax
	movq	%rax, 185992(%rsp)
	movq	92880(%rsp), %rax
	movq	%rax, 186000(%rsp)
	movq	92888(%rsp), %rax
	movq	%rax, 186008(%rsp)
	movq	92896(%rsp), %rax
	movq	%rax, 186016(%rsp)
	movq	92904(%rsp), %rax
	movq	%rax, 186024(%rsp)
	movq	92912(%rsp), %rax
	movq	%rax, 186032(%rsp)
	movq	92920(%rsp), %rax
	movq	%rax, 186040(%rsp)
	movq	92928(%rsp), %rax
	movq	%rax, 186048(%rsp)
	movq	92936(%rsp), %rax
	movq	%rax, 186056(%rsp)
	movq	92944(%rsp), %rax
	movq	%rax, 186064(%rsp)
	movq	92952(%rsp), %rax
	movq	%rax, 186072(%rsp)
	movq	92960(%rsp), %rax
	movq	%rax, 186080(%rsp)
	movq	92968(%rsp), %rax
	movq	%rax, 186088(%rsp)
	movq	92976(%rsp), %rax
	movq	%rax, 186096(%rsp)
	movq	92984(%rsp), %rax
	movq	%rax, 186104(%rsp)
	movq	92992(%rsp), %rax
	movq	%rax, 186112(%rsp)
	movq	93000(%rsp), %rax
	movq	%rax, 186120(%rsp)
	movq	93008(%rsp), %rax
	movq	%rax, 186128(%rsp)
	movq	93016(%rsp), %rax
	movq	%rax, 186136(%rsp)
	movq	93024(%rsp), %rax
	movq	%rax, 186144(%rsp)
	movq	93032(%rsp), %rax
	movq	%rax, 186152(%rsp)
	movq	93040(%rsp), %rax
	movq	%rax, 186160(%rsp)
	movq	93048(%rsp), %rax
	movq	%rax, 186168(%rsp)
	movq	93056(%rsp), %rax
	movq	%rax, 186176(%rsp)
	movq	93064(%rsp), %rax
	movq	%rax, 186184(%rsp)
	movq	93072(%rsp), %rax
	movq	%rax, 186192(%rsp)
	movq	93080(%rsp), %rax
	movq	%rax, 186200(%rsp)
	movq	93088(%rsp), %rax
	movq	%rax, 186208(%rsp)
	movq	93096(%rsp), %rax
	movq	%rax, 186216(%rsp)
	movq	93104(%rsp), %rax
	movq	%rax, 186224(%rsp)
	movq	93112(%rsp), %rax
	movq	%rax, 186232(%rsp)
	movq	93120(%rsp), %rax
	movq	%rax, 186240(%rsp)
	movq	93128(%rsp), %rax
	movq	%rax, 186248(%rsp)
	movq	93136(%rsp), %rax
	movq	%rax, 186256(%rsp)
	movq	93144(%rsp), %rax
	movq	%rax, 186264(%rsp)
	movq	93152(%rsp), %rax
	movq	%rax, 186272(%rsp)
	movq	93160(%rsp), %rax
	movq	%rax, 186280(%rsp)
	movq	93168(%rsp), %rax
	movq	%rax, 186288(%rsp)
	movq	93176(%rsp), %rax
	movq	%rax, 186296(%rsp)
	movq	93184(%rsp), %rax
	movq	%rax, 186304(%rsp)
	movq	93192(%rsp), %rax
	movq	%rax, 186312(%rsp)
	movq	93200(%rsp), %rax
	movq	%rax, 186320(%rsp)
	movq	93208(%rsp), %rax
	movq	%rax, 186328(%rsp)
	movq	93216(%rsp), %rax
	movq	%rax, 186336(%rsp)
	movq	93224(%rsp), %rax
	movq	%rax, 186344(%rsp)
	movq	93232(%rsp), %rax
	movq	%rax, 186352(%rsp)
	movq	93240(%rsp), %rax
	movq	%rax, 186360(%rsp)
	movq	93248(%rsp), %rax
	movq	%rax, 186368(%rsp)
	movq	93256(%rsp), %rax
	movq	%rax, 186376(%rsp)
	movq	93264(%rsp), %rax
	movq	%rax, 186384(%rsp)
	movq	93272(%rsp), %rax
	movq	%rax, 186392(%rsp)
	movq	93280(%rsp), %rax
	movq	%rax, 186400(%rsp)
	movq	93288(%rsp), %rax
	movq	%rax, 186408(%rsp)
	movq	93296(%rsp), %rax
	movq	%rax, 186416(%rsp)
	movq	93304(%rsp), %rax
	movq	%rax, 186424(%rsp)
	movq	93312(%rsp), %rax
	movq	%rax, 186432(%rsp)
	movq	93320(%rsp), %rax
	movq	%rax, 186440(%rsp)
	movq	93328(%rsp), %rax
	movq	%rax, 186448(%rsp)
	movq	93336(%rsp), %rax
	movq	%rax, 186456(%rsp)
	movq	93344(%rsp), %rax
	movq	%rax, 186464(%rsp)
	movq	93352(%rsp), %rax
	movq	%rax, 186472(%rsp)
	movq	93360(%rsp), %rax
	movq	%rax, 186480(%rsp)
	movq	93368(%rsp), %rax
	movq	%rax, 186488(%rsp)
	movq	93376(%rsp), %rax
	movq	%rax, 186496(%rsp)
	movq	93384(%rsp), %rax
	movq	%rax, 186504(%rsp)
	movq	93392(%rsp), %rax
	movq	%rax, 186512(%rsp)
	movq	93400(%rsp), %rax
	movq	%rax, 186520(%rsp)
	movq	93408(%rsp), %rax
	movq	%rax, 186528(%rsp)
	movq	93416(%rsp), %rax
	movq	%rax, 186536(%rsp)
	movq	93424(%rsp), %rax
	movq	%rax, 186544(%rsp)
	movq	93432(%rsp), %rax
	movq	%rax, 186552(%rsp)
	movq	93440(%rsp), %rax
	movq	%rax, 186560(%rsp)
	movq	93448(%rsp), %rax
	movq	%rax, 186568(%rsp)
	movq	93456(%rsp), %rax
	movq	%rax, 186576(%rsp)
	movq	93464(%rsp), %rax
	movq	%rax, 186584(%rsp)
	movq	93472(%rsp), %rax
	movq	%rax, 186592(%rsp)
	movq	93480(%rsp), %rax
	movq	%rax, 186600(%rsp)
	movq	93488(%rsp), %rax
	movq	%rax, 186608(%rsp)
	movq	93496(%rsp), %rax
	movq	%rax, 186616(%rsp)
	movq	93504(%rsp), %rax
	movq	%rax, 186624(%rsp)
	movq	93512(%rsp), %rax
	movq	%rax, 186632(%rsp)
	movq	93520(%rsp), %rax
	movq	%rax, 186640(%rsp)
	movq	93528(%rsp), %rax
	movq	%rax, 186648(%rsp)
	movq	93536(%rsp), %rax
	movq	%rax, 186656(%rsp)
	movq	93544(%rsp), %rax
	movq	%rax, 186664(%rsp)
	movq	93552(%rsp), %rax
	movq	%rax, 186672(%rsp)
	movq	93560(%rsp), %rax
	movq	%rax, 186680(%rsp)
	movq	93568(%rsp), %rax
	movq	%rax, 186688(%rsp)
	movq	93576(%rsp), %rax
	movq	%rax, 186696(%rsp)
	movq	93584(%rsp), %rax
	movq	%rax, 186704(%rsp)
	movq	93592(%rsp), %rax
	movq	%rax, 186712(%rsp)
	movq	93600(%rsp), %rax
	movq	%rax, 186720(%rsp)
	movq	93608(%rsp), %rax
	movq	%rax, 186728(%rsp)
	movq	93616(%rsp), %rax
	movq	%rax, 186736(%rsp)
	movq	93624(%rsp), %rax
	movq	%rax, 186744(%rsp)
	movq	93632(%rsp), %rax
	movq	%rax, 186752(%rsp)
	movq	93640(%rsp), %rax
	movq	%rax, 186760(%rsp)
	movq	93648(%rsp), %rax
	movq	%rax, 186768(%rsp)
	movq	93656(%rsp), %rax
	movq	%rax, 186776(%rsp)
	movq	93664(%rsp), %rax
	movq	%rax, 186784(%rsp)
	movq	93672(%rsp), %rax
	movq	%rax, 186792(%rsp)
	movq	93680(%rsp), %rax
	movq	%rax, 186800(%rsp)
	movq	93688(%rsp), %rax
	movq	%rax, 186808(%rsp)
	movq	93696(%rsp), %rax
	movq	%rax, 186816(%rsp)
	movq	93704(%rsp), %rax
	movq	%rax, 186824(%rsp)
	movq	93712(%rsp), %rax
	movq	%rax, 186832(%rsp)
	movq	93720(%rsp), %rax
	movq	%rax, 186840(%rsp)
	movq	93728(%rsp), %rax
	movq	%rax, 186848(%rsp)
	movq	93736(%rsp), %rax
	movq	%rax, 186856(%rsp)
	movq	93744(%rsp), %rax
	movq	%rax, 186864(%rsp)
	movq	93752(%rsp), %rax
	movq	%rax, 186872(%rsp)
	movq	93760(%rsp), %rax
	movq	%rax, 186880(%rsp)
	movq	93768(%rsp), %rax
	movq	%rax, 186888(%rsp)
	movq	93776(%rsp), %rax
	movq	%rax, 186896(%rsp)
	movq	93784(%rsp), %rax
	movq	%rax, 186904(%rsp)
	movq	93792(%rsp), %rax
	movq	%rax, 186912(%rsp)
	movq	93800(%rsp), %rax
	movq	%rax, 186920(%rsp)
	movq	93808(%rsp), %rax
	movq	%rax, 186928(%rsp)
	movq	93816(%rsp), %rax
	movq	%rax, 186936(%rsp)
	movq	93824(%rsp), %rax
	movq	%rax, 186944(%rsp)
	movq	93832(%rsp), %rax
	movq	%rax, 186952(%rsp)
	movq	93840(%rsp), %rax
	movq	%rax, 186960(%rsp)
	movq	93848(%rsp), %rax
	movq	%rax, 186968(%rsp)
	movq	93856(%rsp), %rax
	movq	%rax, 186976(%rsp)
	movq	93864(%rsp), %rax
	movq	%rax, 186984(%rsp)
	movq	93872(%rsp), %rax
	movq	%rax, 186992(%rsp)
	movq	93880(%rsp), %rax
	movq	%rax, 187000(%rsp)
	movq	93888(%rsp), %rax
	movq	%rax, 187008(%rsp)
	movq	93896(%rsp), %rax
	movq	%rax, 187016(%rsp)
	movq	93904(%rsp), %rax
	movq	%rax, 187024(%rsp)
	movq	93912(%rsp), %rax
	movq	%rax, 187032(%rsp)
	movq	93920(%rsp), %rax
	movq	%rax, 187040(%rsp)
	movq	93928(%rsp), %rax
	movq	%rax, 187048(%rsp)
	movq	93936(%rsp), %rax
	movq	%rax, 187056(%rsp)
	movq	93944(%rsp), %rax
	movq	%rax, 187064(%rsp)
	movq	93952(%rsp), %rax
	movq	%rax, 187072(%rsp)
	movq	93960(%rsp), %rax
	movq	%rax, 187080(%rsp)
	movq	93968(%rsp), %rax
	movq	%rax, 187088(%rsp)
	movq	93976(%rsp), %rax
	movq	%rax, 187096(%rsp)
	movq	93984(%rsp), %rax
	movq	%rax, 187104(%rsp)
	movq	93992(%rsp), %rax
	movq	%rax, 187112(%rsp)
	movq	94000(%rsp), %rax
	movq	%rax, 187120(%rsp)
	movq	94008(%rsp), %rax
	movq	%rax, 187128(%rsp)
	movq	94016(%rsp), %rax
	movq	%rax, 187136(%rsp)
	movq	94024(%rsp), %rax
	movq	%rax, 187144(%rsp)
	movq	94032(%rsp), %rax
	movq	%rax, 187152(%rsp)
	movq	94040(%rsp), %rax
	movq	%rax, 187160(%rsp)
	movq	94048(%rsp), %rax
	movq	%rax, 187168(%rsp)
	movq	94056(%rsp), %rax
	movq	%rax, 187176(%rsp)
	movq	94064(%rsp), %rax
	movq	%rax, 187184(%rsp)
	movq	94072(%rsp), %rax
	movq	%rax, 187192(%rsp)
	movq	94080(%rsp), %rax
	movq	%rax, 187200(%rsp)
	movq	94088(%rsp), %rax
	movq	%rax, 187208(%rsp)
	movq	94096(%rsp), %rax
	movq	%rax, 187216(%rsp)
	movq	94104(%rsp), %rax
	movq	%rax, 187224(%rsp)
	movq	94112(%rsp), %rax
	movq	%rax, 187232(%rsp)
	movq	94120(%rsp), %rax
	movq	%rax, 187240(%rsp)
	movq	94128(%rsp), %rax
	movq	%rax, 187248(%rsp)
	movq	94136(%rsp), %rax
	movq	%rax, 187256(%rsp)
	movq	94144(%rsp), %rax
	movq	%rax, 187264(%rsp)
	movq	94152(%rsp), %rax
	movq	%rax, 187272(%rsp)
	movq	94160(%rsp), %rax
	movq	%rax, 187280(%rsp)
	movq	94168(%rsp), %rax
	movq	%rax, 187288(%rsp)
	movq	94176(%rsp), %rax
	movq	%rax, 187296(%rsp)
	movq	94184(%rsp), %rax
	movq	%rax, 187304(%rsp)
	movq	94192(%rsp), %rax
	movq	%rax, 187312(%rsp)
	movq	94200(%rsp), %rax
	movq	%rax, 187320(%rsp)
	movq	94208(%rsp), %rax
	movq	%rax, 187328(%rsp)
	movq	94216(%rsp), %rax
	movq	%rax, 187336(%rsp)
	movq	94224(%rsp), %rax
	movq	%rax, 187344(%rsp)
	movq	94232(%rsp), %rax
	movq	%rax, 187352(%rsp)
	movq	94240(%rsp), %rax
	movq	%rax, 187360(%rsp)
	movq	94248(%rsp), %rax
	movq	%rax, 187368(%rsp)
	movq	94256(%rsp), %rax
	movq	%rax, 187376(%rsp)
	movq	94264(%rsp), %rax
	movq	%rax, 187384(%rsp)
	movq	94272(%rsp), %rax
	movq	%rax, 187392(%rsp)
	movq	94280(%rsp), %rax
	movq	%rax, 187400(%rsp)
	movq	94288(%rsp), %rax
	movq	%rax, 187408(%rsp)
	movq	94296(%rsp), %rax
	movq	%rax, 187416(%rsp)
	movq	94304(%rsp), %rax
	movq	%rax, 187424(%rsp)
	movq	94312(%rsp), %rax
	movq	%rax, 187432(%rsp)
	movq	94320(%rsp), %rax
	movq	%rax, 187440(%rsp)
	movq	94328(%rsp), %rax
	movq	%rax, 187448(%rsp)
	movq	94336(%rsp), %rax
	movq	%rax, 187456(%rsp)
	movq	94344(%rsp), %rax
	movq	%rax, 187464(%rsp)
	movq	94352(%rsp), %rax
	movq	%rax, 187472(%rsp)
	movq	94360(%rsp), %rax
	movq	%rax, 187480(%rsp)
	movq	94368(%rsp), %rax
	movq	%rax, 187488(%rsp)
	movq	94376(%rsp), %rax
	movq	%rax, 187496(%rsp)
	movq	94384(%rsp), %rax
	movq	%rax, 187504(%rsp)
	movq	94392(%rsp), %rax
	movq	%rax, 187512(%rsp)
	movq	94400(%rsp), %rax
	movq	%rax, 187520(%rsp)
	movq	94408(%rsp), %rax
	movq	%rax, 187528(%rsp)
	movq	94416(%rsp), %rax
	movq	%rax, 187536(%rsp)
	movq	94424(%rsp), %rax
	movq	%rax, 187544(%rsp)
	movq	94432(%rsp), %rax
	movq	%rax, 187552(%rsp)
	movq	94440(%rsp), %rax
	movq	%rax, 187560(%rsp)
	movq	94448(%rsp), %rax
	movq	%rax, 187568(%rsp)
	movq	94456(%rsp), %rax
	movq	%rax, 187576(%rsp)
	movq	94464(%rsp), %rax
	movq	%rax, 187584(%rsp)
	movq	94472(%rsp), %rax
	movq	%rax, 187592(%rsp)
	movq	94480(%rsp), %rax
	movq	%rax, 187600(%rsp)
	movq	94488(%rsp), %rax
	movq	%rax, 187608(%rsp)
	movq	94496(%rsp), %rax
	movq	%rax, 187616(%rsp)
	movq	94504(%rsp), %rax
	movq	%rax, 187624(%rsp)
	movq	94512(%rsp), %rax
	movq	%rax, 187632(%rsp)
	movq	94520(%rsp), %rax
	movq	%rax, 187640(%rsp)
	movq	94528(%rsp), %rax
	movq	%rax, 187648(%rsp)
	movq	94536(%rsp), %rax
	movq	%rax, 187656(%rsp)
	movq	94544(%rsp), %rax
	movq	%rax, 187664(%rsp)
	movq	94552(%rsp), %rax
	movq	%rax, 187672(%rsp)
	movq	94560(%rsp), %rax
	movq	%rax, 187680(%rsp)
	movq	94568(%rsp), %rax
	movq	%rax, 187688(%rsp)
	movq	94576(%rsp), %rax
	movq	%rax, 187696(%rsp)
	movq	94584(%rsp), %rax
	movq	%rax, 187704(%rsp)
	movq	94592(%rsp), %rax
	movq	%rax, 187712(%rsp)
	movq	94600(%rsp), %rax
	movq	%rax, 187720(%rsp)
	movq	94608(%rsp), %rax
	movq	%rax, 187728(%rsp)
	movq	94616(%rsp), %rax
	movq	%rax, 187736(%rsp)
	movq	94624(%rsp), %rax
	movq	%rax, 187744(%rsp)
	movq	94632(%rsp), %rax
	movq	%rax, 187752(%rsp)
	movq	94640(%rsp), %rax
	movq	%rax, 187760(%rsp)
	movq	94648(%rsp), %rax
	movq	%rax, 187768(%rsp)
	movq	94656(%rsp), %rax
	movq	%rax, 187776(%rsp)
	movq	94664(%rsp), %rax
	movq	%rax, 187784(%rsp)
	movq	94672(%rsp), %rax
	movq	%rax, 187792(%rsp)
	movq	94680(%rsp), %rax
	movq	%rax, 187800(%rsp)
	movq	94688(%rsp), %rax
	movq	%rax, 187808(%rsp)
	movq	94696(%rsp), %rax
	movq	%rax, 187816(%rsp)
	movq	94704(%rsp), %rax
	movq	%rax, 187824(%rsp)
	movq	94712(%rsp), %rax
	movq	%rax, 187832(%rsp)
	movq	94720(%rsp), %rax
	movq	%rax, 187840(%rsp)
	movq	94728(%rsp), %rax
	movq	%rax, 187848(%rsp)
	movq	94736(%rsp), %rax
	movq	%rax, 187856(%rsp)
	movq	94744(%rsp), %rax
	movq	%rax, 187864(%rsp)
	movq	94752(%rsp), %rax
	movq	%rax, 187872(%rsp)
	movq	94760(%rsp), %rax
	movq	%rax, 187880(%rsp)
	movq	94768(%rsp), %rax
	movq	%rax, 187888(%rsp)
	movq	94776(%rsp), %rax
	movq	%rax, 187896(%rsp)
	movq	94784(%rsp), %rax
	movq	%rax, 187904(%rsp)
	movq	94792(%rsp), %rax
	movq	%rax, 187912(%rsp)
	movq	94800(%rsp), %rax
	movq	%rax, 187920(%rsp)
	movq	94808(%rsp), %rax
	movq	%rax, 187928(%rsp)
	movq	94816(%rsp), %rax
	movq	%rax, 187936(%rsp)
	movq	94824(%rsp), %rax
	movq	%rax, 187944(%rsp)
	movq	94832(%rsp), %rax
	movq	%rax, 187952(%rsp)
	movq	94840(%rsp), %rax
	movq	%rax, 187960(%rsp)
	movq	94848(%rsp), %rax
	movq	%rax, 187968(%rsp)
	movq	94856(%rsp), %rax
	movq	%rax, 187976(%rsp)
	movq	94864(%rsp), %rax
	movq	%rax, 187984(%rsp)
	movq	94872(%rsp), %rax
	movq	%rax, 187992(%rsp)
	movq	94880(%rsp), %rax
	movq	%rax, 188000(%rsp)
	movq	94888(%rsp), %rax
	movq	%rax, 188008(%rsp)
	movq	94896(%rsp), %rax
	movq	%rax, 188016(%rsp)
	movq	94904(%rsp), %rax
	movq	%rax, 188024(%rsp)
	movq	94912(%rsp), %rax
	movq	%rax, 188032(%rsp)
	movq	94920(%rsp), %rax
	movq	%rax, 188040(%rsp)
	movq	94928(%rsp), %rax
	movq	%rax, 188048(%rsp)
	movq	94936(%rsp), %rax
	movq	%rax, 188056(%rsp)
	movq	94944(%rsp), %rax
	movq	%rax, 188064(%rsp)
	movq	94952(%rsp), %rax
	movq	%rax, 188072(%rsp)
	movq	94960(%rsp), %rax
	movq	%rax, 188080(%rsp)
	movq	94968(%rsp), %rax
	movq	%rax, 188088(%rsp)
	movq	94976(%rsp), %rax
	movq	%rax, 188096(%rsp)
	movq	94984(%rsp), %rax
	movq	%rax, 188104(%rsp)
	movq	94992(%rsp), %rax
	movq	%rax, 188112(%rsp)
	movq	95000(%rsp), %rax
	movq	%rax, 188120(%rsp)
	movq	95008(%rsp), %rax
	movq	%rax, 188128(%rsp)
	movq	95016(%rsp), %rax
	movq	%rax, 188136(%rsp)
	movq	95024(%rsp), %rax
	movq	%rax, 188144(%rsp)
	movq	95032(%rsp), %rax
	movq	%rax, 188152(%rsp)
	movq	95040(%rsp), %rax
	movq	%rax, 188160(%rsp)
	movq	95048(%rsp), %rax
	movq	%rax, 188168(%rsp)
	movq	95056(%rsp), %rax
	movq	%rax, 188176(%rsp)
	movq	95064(%rsp), %rax
	movq	%rax, 188184(%rsp)
	movq	95072(%rsp), %rax
	movq	%rax, 188192(%rsp)
	movq	95080(%rsp), %rax
	movq	%rax, 188200(%rsp)
	movq	95088(%rsp), %rax
	movq	%rax, 188208(%rsp)
	movq	95096(%rsp), %rax
	movq	%rax, 188216(%rsp)
	movq	95104(%rsp), %rax
	movq	%rax, 188224(%rsp)
	movq	95112(%rsp), %rax
	movq	%rax, 188232(%rsp)
	movq	95120(%rsp), %rax
	movq	%rax, 188240(%rsp)
	movq	95128(%rsp), %rax
	movq	%rax, 188248(%rsp)
	movq	95136(%rsp), %rax
	movq	%rax, 188256(%rsp)
	movq	95144(%rsp), %rax
	movq	%rax, 188264(%rsp)
	movq	95152(%rsp), %rax
	movq	%rax, 188272(%rsp)
	movq	95160(%rsp), %rax
	movq	%rax, 188280(%rsp)
	movq	95168(%rsp), %rax
	movq	%rax, 188288(%rsp)
	movq	95176(%rsp), %rax
	movq	%rax, 188296(%rsp)
	movq	95184(%rsp), %rax
	movq	%rax, 188304(%rsp)
	movq	95192(%rsp), %rax
	movq	%rax, 188312(%rsp)
	movq	95200(%rsp), %rax
	movq	%rax, 188320(%rsp)
	movq	95208(%rsp), %rax
	movq	%rax, 188328(%rsp)
	movq	95216(%rsp), %rax
	movq	%rax, 188336(%rsp)
	movq	95224(%rsp), %rax
	movq	%rax, 188344(%rsp)
	movq	95232(%rsp), %rax
	movq	%rax, 188352(%rsp)
	movq	95240(%rsp), %rax
	movq	%rax, 188360(%rsp)
	movq	95248(%rsp), %rax
	movq	%rax, 188368(%rsp)
	movq	95256(%rsp), %rax
	movq	%rax, 188376(%rsp)
	movq	95264(%rsp), %rax
	movq	%rax, 188384(%rsp)
	movq	95272(%rsp), %rax
	movq	%rax, 188392(%rsp)
	movq	95280(%rsp), %rax
	movq	%rax, 188400(%rsp)
	movq	95288(%rsp), %rax
	movq	%rax, 188408(%rsp)
	movq	95296(%rsp), %rax
	movq	%rax, 188416(%rsp)
	movq	95304(%rsp), %rax
	movq	%rax, 188424(%rsp)
	movq	95312(%rsp), %rax
	movq	%rax, 188432(%rsp)
	movq	95320(%rsp), %rax
	movq	%rax, 188440(%rsp)
	movq	95328(%rsp), %rax
	movq	%rax, 188448(%rsp)
	movq	95336(%rsp), %rax
	movq	%rax, 188456(%rsp)
	movq	95344(%rsp), %rax
	movq	%rax, 188464(%rsp)
	movq	95352(%rsp), %rax
	movq	%rax, 188472(%rsp)
	movq	95360(%rsp), %rax
	movq	%rax, 188480(%rsp)
	movq	95368(%rsp), %rax
	movq	%rax, 188488(%rsp)
	movq	95376(%rsp), %rax
	movq	%rax, 188496(%rsp)
	movq	95384(%rsp), %rax
	movq	%rax, 188504(%rsp)
	movq	95392(%rsp), %rax
	movq	%rax, 188512(%rsp)
	movq	95400(%rsp), %rax
	movq	%rax, 188520(%rsp)
	movq	95408(%rsp), %rax
	movq	%rax, 188528(%rsp)
	movq	95416(%rsp), %rax
	movq	%rax, 188536(%rsp)
	movq	95424(%rsp), %rax
	movq	%rax, 188544(%rsp)
	movq	95432(%rsp), %rax
	movq	%rax, 188552(%rsp)
	movq	95440(%rsp), %rax
	movq	%rax, 188560(%rsp)
	movq	95448(%rsp), %rax
	movq	%rax, 188568(%rsp)
	movq	95456(%rsp), %rax
	movq	%rax, 188576(%rsp)
	movq	95464(%rsp), %rax
	movq	%rax, 188584(%rsp)
	movq	95472(%rsp), %rax
	movq	%rax, 188592(%rsp)
	movq	95480(%rsp), %rax
	movq	%rax, 188600(%rsp)
	movq	95488(%rsp), %rax
	movq	%rax, 188608(%rsp)
	movq	95496(%rsp), %rax
	movq	%rax, 188616(%rsp)
	movq	95504(%rsp), %rax
	movq	%rax, 188624(%rsp)
	movq	95512(%rsp), %rax
	movq	%rax, 188632(%rsp)
	movq	95520(%rsp), %rax
	movq	%rax, 188640(%rsp)
	movq	95528(%rsp), %rax
	movq	%rax, 188648(%rsp)
	movq	95536(%rsp), %rax
	movq	%rax, 188656(%rsp)
	movq	95544(%rsp), %rax
	movq	%rax, 188664(%rsp)
	movq	95552(%rsp), %rax
	movq	%rax, 188672(%rsp)
	movq	95560(%rsp), %rax
	movq	%rax, 188680(%rsp)
	movq	95568(%rsp), %rax
	movq	%rax, 188688(%rsp)
	movq	95576(%rsp), %rax
	movq	%rax, 188696(%rsp)
	movq	95584(%rsp), %rax
	movq	%rax, 188704(%rsp)
	movq	95592(%rsp), %rax
	movq	%rax, 188712(%rsp)
	movq	95600(%rsp), %rax
	movq	%rax, 188720(%rsp)
	movq	95608(%rsp), %rax
	movq	%rax, 188728(%rsp)
	movq	95616(%rsp), %rax
	movq	%rax, 188736(%rsp)
	movq	95624(%rsp), %rax
	movq	%rax, 188744(%rsp)
	movq	95632(%rsp), %rax
	movq	%rax, 188752(%rsp)
	movq	95640(%rsp), %rax
	movq	%rax, 188760(%rsp)
	movq	95648(%rsp), %rax
	movq	%rax, 188768(%rsp)
	movq	95656(%rsp), %rax
	movq	%rax, 188776(%rsp)
	movq	95664(%rsp), %rax
	movq	%rax, 188784(%rsp)
	movq	95672(%rsp), %rax
	movq	%rax, 188792(%rsp)
	movq	95680(%rsp), %rax
	movq	%rax, 188800(%rsp)
	movq	95688(%rsp), %rax
	movq	%rax, 188808(%rsp)
	movq	95696(%rsp), %rax
	movq	%rax, 188816(%rsp)
	movq	95704(%rsp), %rax
	movq	%rax, 188824(%rsp)
	movq	95712(%rsp), %rax
	movq	%rax, 188832(%rsp)
	movq	95720(%rsp), %rax
	movq	%rax, 188840(%rsp)
	movq	95728(%rsp), %rax
	movq	%rax, 188848(%rsp)
	movq	95736(%rsp), %rax
	movq	%rax, 188856(%rsp)
	movq	95744(%rsp), %rax
	movq	%rax, 188864(%rsp)
	movq	95752(%rsp), %rax
	movq	%rax, 188872(%rsp)
	movq	95760(%rsp), %rax
	movq	%rax, 188880(%rsp)
	movq	95768(%rsp), %rax
	movq	%rax, 188888(%rsp)
	movq	95776(%rsp), %rax
	movq	%rax, 188896(%rsp)
	movq	95784(%rsp), %rax
	movq	%rax, 188904(%rsp)
	movq	95792(%rsp), %rax
	movq	%rax, 188912(%rsp)
	movq	95800(%rsp), %rax
	movq	%rax, 188920(%rsp)
	movq	95808(%rsp), %rax
	movq	%rax, 188928(%rsp)
	movq	95816(%rsp), %rax
	movq	%rax, 188936(%rsp)
	movq	95824(%rsp), %rax
	movq	%rax, 188944(%rsp)
	movq	95832(%rsp), %rax
	movq	%rax, 188952(%rsp)
	movq	95840(%rsp), %rax
	movq	%rax, 188960(%rsp)
	movq	95848(%rsp), %rax
	movq	%rax, 188968(%rsp)
	movq	95856(%rsp), %rax
	movq	%rax, 188976(%rsp)
	movq	95864(%rsp), %rax
	movq	%rax, 188984(%rsp)
	movq	95872(%rsp), %rax
	movq	%rax, 188992(%rsp)
	movq	95880(%rsp), %rax
	movq	%rax, 189000(%rsp)
	movq	95888(%rsp), %rax
	movq	%rax, 189008(%rsp)
	movq	95896(%rsp), %rax
	movq	%rax, 189016(%rsp)
	movq	95904(%rsp), %rax
	movq	%rax, 189024(%rsp)
	movq	95912(%rsp), %rax
	movq	%rax, 189032(%rsp)
	movq	95920(%rsp), %rax
	movq	%rax, 189040(%rsp)
	movq	95928(%rsp), %rax
	movq	%rax, 189048(%rsp)
	movq	95936(%rsp), %rax
	movq	%rax, 189056(%rsp)
	movq	95944(%rsp), %rax
	movq	%rax, 189064(%rsp)
	movq	95952(%rsp), %rax
	movq	%rax, 189072(%rsp)
	movq	95960(%rsp), %rax
	movq	%rax, 189080(%rsp)
	movq	95968(%rsp), %rax
	movq	%rax, 189088(%rsp)
	movq	95976(%rsp), %rax
	movq	%rax, 189096(%rsp)
	movq	95984(%rsp), %rax
	movq	%rax, 189104(%rsp)
	movq	95992(%rsp), %rax
	movq	%rax, 189112(%rsp)
	movq	96000(%rsp), %rax
	movq	%rax, 189120(%rsp)
	movq	96008(%rsp), %rax
	movq	%rax, 189128(%rsp)
	movq	96016(%rsp), %rax
	movq	%rax, 189136(%rsp)
	movq	96024(%rsp), %rax
	movq	%rax, 189144(%rsp)
	movq	96032(%rsp), %rax
	movq	%rax, 189152(%rsp)
	movq	96040(%rsp), %rax
	movq	%rax, 189160(%rsp)
	movq	96048(%rsp), %rax
	movq	%rax, 189168(%rsp)
	movq	96056(%rsp), %rax
	movq	%rax, 189176(%rsp)
	movq	96064(%rsp), %rax
	movq	%rax, 189184(%rsp)
	movq	96072(%rsp), %rax
	movq	%rax, 189192(%rsp)
	movq	96080(%rsp), %rax
	movq	%rax, 189200(%rsp)
	movq	96088(%rsp), %rax
	movq	%rax, 189208(%rsp)
	movq	96096(%rsp), %rax
	movq	%rax, 189216(%rsp)
	movq	96104(%rsp), %rax
	movq	%rax, 189224(%rsp)
	movq	96112(%rsp), %rax
	movq	%rax, 189232(%rsp)
	movq	96120(%rsp), %rax
	movq	%rax, 189240(%rsp)
	movq	96128(%rsp), %rax
	movq	%rax, 189248(%rsp)
	movq	96136(%rsp), %rax
	movq	%rax, 189256(%rsp)
	movq	96144(%rsp), %rax
	movq	%rax, 189264(%rsp)
	movq	96152(%rsp), %rax
	movq	%rax, 189272(%rsp)
	movq	96160(%rsp), %rax
	movq	%rax, 189280(%rsp)
	movq	96168(%rsp), %rax
	movq	%rax, 189288(%rsp)
	movq	96176(%rsp), %rax
	movq	%rax, 189296(%rsp)
	movq	96184(%rsp), %rax
	movq	%rax, 189304(%rsp)
	movq	96192(%rsp), %rax
	movq	%rax, 189312(%rsp)
	movq	96200(%rsp), %rax
	movq	%rax, 189320(%rsp)
	movq	96208(%rsp), %rax
	movq	%rax, 189328(%rsp)
	movq	96216(%rsp), %rax
	movq	%rax, 189336(%rsp)
	movq	96224(%rsp), %rax
	movq	%rax, 189344(%rsp)
	movq	96232(%rsp), %rax
	movq	%rax, 189352(%rsp)
	movq	96240(%rsp), %rax
	movq	%rax, 189360(%rsp)
	movq	96248(%rsp), %rax
	movq	%rax, 189368(%rsp)
	movq	96256(%rsp), %rax
	movq	%rax, 189376(%rsp)
	movq	96264(%rsp), %rax
	movq	%rax, 189384(%rsp)
	movq	96272(%rsp), %rax
	movq	%rax, 189392(%rsp)
	movq	96280(%rsp), %rax
	movq	%rax, 189400(%rsp)
	movq	96288(%rsp), %rax
	movq	%rax, 189408(%rsp)
	movq	96296(%rsp), %rax
	movq	%rax, 189416(%rsp)
	movq	96304(%rsp), %rax
	movq	%rax, 189424(%rsp)
	movq	96312(%rsp), %rax
	movq	%rax, 189432(%rsp)
	movq	96320(%rsp), %rax
	movq	%rax, 189440(%rsp)
	movq	96328(%rsp), %rax
	movq	%rax, 189448(%rsp)
	movq	96336(%rsp), %rax
	movq	%rax, 189456(%rsp)
	movq	96344(%rsp), %rax
	movq	%rax, 189464(%rsp)
	movq	96352(%rsp), %rax
	movq	%rax, 189472(%rsp)
	movq	96360(%rsp), %rax
	movq	%rax, 189480(%rsp)
	movq	96368(%rsp), %rax
	movq	%rax, 189488(%rsp)
	movq	96376(%rsp), %rax
	movq	%rax, 189496(%rsp)
	movq	96384(%rsp), %rax
	movq	%rax, 189504(%rsp)
	movq	96392(%rsp), %rax
	movq	%rax, 189512(%rsp)
	movq	96400(%rsp), %rax
	movq	%rax, 189520(%rsp)
	movq	96408(%rsp), %rax
	movq	%rax, 189528(%rsp)
	movq	96416(%rsp), %rax
	movq	%rax, 189536(%rsp)
	movq	96424(%rsp), %rax
	movq	%rax, 189544(%rsp)
	movq	96432(%rsp), %rax
	movq	%rax, 189552(%rsp)
	movq	96440(%rsp), %rax
	movq	%rax, 189560(%rsp)
	movq	96448(%rsp), %rax
	movq	%rax, 189568(%rsp)
	movq	96456(%rsp), %rax
	movq	%rax, 189576(%rsp)
	movq	96464(%rsp), %rax
	movq	%rax, 189584(%rsp)
	movq	96472(%rsp), %rax
	movq	%rax, 189592(%rsp)
	movq	96480(%rsp), %rax
	movq	%rax, 189600(%rsp)
	movq	96488(%rsp), %rax
	movq	%rax, 189608(%rsp)
	movq	96496(%rsp), %rax
	movq	%rax, 189616(%rsp)
	movq	96504(%rsp), %rax
	movq	%rax, 189624(%rsp)
	movq	96512(%rsp), %rax
	movq	%rax, 189632(%rsp)
	movq	96520(%rsp), %rax
	movq	%rax, 189640(%rsp)
	movq	96528(%rsp), %rax
	movq	%rax, 189648(%rsp)
	movq	96536(%rsp), %rax
	movq	%rax, 189656(%rsp)
	movq	96544(%rsp), %rax
	movq	%rax, 189664(%rsp)
	movq	96552(%rsp), %rax
	movq	%rax, 189672(%rsp)
	movq	96560(%rsp), %rax
	movq	%rax, 189680(%rsp)
	movq	96568(%rsp), %rax
	movq	%rax, 189688(%rsp)
	movq	96576(%rsp), %rax
	movq	%rax, 189696(%rsp)
	movq	96584(%rsp), %rax
	movq	%rax, 189704(%rsp)
	movq	96592(%rsp), %rax
	movq	%rax, 189712(%rsp)
	movq	96600(%rsp), %rax
	movq	%rax, 189720(%rsp)
	movq	96608(%rsp), %rax
	movq	%rax, 189728(%rsp)
	movq	96616(%rsp), %rax
	movq	%rax, 189736(%rsp)
	movq	96624(%rsp), %rax
	movq	%rax, 189744(%rsp)
	movq	96632(%rsp), %rax
	movq	%rax, 189752(%rsp)
	movq	96640(%rsp), %rax
	movq	%rax, 189760(%rsp)
	movq	96648(%rsp), %rax
	movq	%rax, 189768(%rsp)
	movq	96656(%rsp), %rax
	movq	%rax, 189776(%rsp)
	movq	96664(%rsp), %rax
	movq	%rax, 189784(%rsp)
	movq	96672(%rsp), %rax
	movq	%rax, 189792(%rsp)
	movq	96680(%rsp), %rax
	movq	%rax, 189800(%rsp)
	movq	96688(%rsp), %rax
	movq	%rax, 189808(%rsp)
	movq	96696(%rsp), %rax
	movq	%rax, 189816(%rsp)
	movq	96704(%rsp), %rax
	movq	%rax, 189824(%rsp)
	movq	96712(%rsp), %rax
	movq	%rax, 189832(%rsp)
	movq	96720(%rsp), %rax
	movq	%rax, 189840(%rsp)
	movq	96728(%rsp), %rax
	movq	%rax, 189848(%rsp)
	movq	96736(%rsp), %rax
	movq	%rax, 189856(%rsp)
	movq	96744(%rsp), %rax
	movq	%rax, 189864(%rsp)
	movq	96752(%rsp), %rax
	movq	%rax, 189872(%rsp)
	movq	96760(%rsp), %rax
	movq	%rax, 189880(%rsp)
	movq	96768(%rsp), %rax
	movq	%rax, 189888(%rsp)
	movq	96776(%rsp), %rax
	movq	%rax, 189896(%rsp)
	movq	96784(%rsp), %rax
	movq	%rax, 189904(%rsp)
	movq	96792(%rsp), %rax
	movq	%rax, 189912(%rsp)
	movq	96800(%rsp), %rax
	movq	%rax, 189920(%rsp)
	movq	96808(%rsp), %rax
	movq	%rax, 189928(%rsp)
	movq	96816(%rsp), %rax
	movq	%rax, 189936(%rsp)
	movq	96824(%rsp), %rax
	movq	%rax, 189944(%rsp)
	movq	96832(%rsp), %rax
	movq	%rax, 189952(%rsp)
	movq	96840(%rsp), %rax
	movq	%rax, 189960(%rsp)
	movq	96848(%rsp), %rax
	movq	%rax, 189968(%rsp)
	movq	96856(%rsp), %rax
	movq	%rax, 189976(%rsp)
	movq	96864(%rsp), %rax
	movq	%rax, 189984(%rsp)
	movq	96872(%rsp), %rax
	movq	%rax, 189992(%rsp)
	movq	96880(%rsp), %rax
	movq	%rax, 190000(%rsp)
	movq	96888(%rsp), %rax
	movq	%rax, 190008(%rsp)
	movq	96896(%rsp), %rax
	movq	%rax, 190016(%rsp)
	movq	96904(%rsp), %rax
	movq	%rax, 190024(%rsp)
	movq	96912(%rsp), %rax
	movq	%rax, 190032(%rsp)
	movq	96920(%rsp), %rax
	movq	%rax, 190040(%rsp)
	movq	96928(%rsp), %rax
	movq	%rax, 190048(%rsp)
	movq	96936(%rsp), %rax
	movq	%rax, 190056(%rsp)
	movq	96944(%rsp), %rax
	movq	%rax, 190064(%rsp)
	movq	96952(%rsp), %rax
	movq	%rax, 190072(%rsp)
	movq	96960(%rsp), %rax
	movq	%rax, 190080(%rsp)
	movq	96968(%rsp), %rax
	movq	%rax, 190088(%rsp)
	movq	96976(%rsp), %rax
	movq	%rax, 190096(%rsp)
	movq	96984(%rsp), %rax
	movq	%rax, 190104(%rsp)
	movq	96992(%rsp), %rax
	movq	%rax, 190112(%rsp)
	movq	97000(%rsp), %rax
	movq	%rax, 190120(%rsp)
	movq	97008(%rsp), %rax
	movq	%rax, 190128(%rsp)
	movq	97016(%rsp), %rax
	movq	%rax, 190136(%rsp)
	movq	97024(%rsp), %rax
	movq	%rax, 190144(%rsp)
	movq	97032(%rsp), %rax
	movq	%rax, 190152(%rsp)
	movq	97040(%rsp), %rax
	movq	%rax, 190160(%rsp)
	movq	97048(%rsp), %rax
	movq	%rax, 190168(%rsp)
	movq	97056(%rsp), %rax
	movq	%rax, 190176(%rsp)
	movq	97064(%rsp), %rax
	movq	%rax, 190184(%rsp)
	movq	97072(%rsp), %rax
	movq	%rax, 190192(%rsp)
	movq	97080(%rsp), %rax
	movq	%rax, 190200(%rsp)
	movq	97088(%rsp), %rax
	movq	%rax, 190208(%rsp)
	movq	97096(%rsp), %rax
	movq	%rax, 190216(%rsp)
	movq	97104(%rsp), %rax
	movq	%rax, 190224(%rsp)
	movq	97112(%rsp), %rax
	movq	%rax, 190232(%rsp)
	movq	97120(%rsp), %rax
	movq	%rax, 190240(%rsp)
	movq	97128(%rsp), %rax
	movq	%rax, 190248(%rsp)
	movq	97136(%rsp), %rax
	movq	%rax, 190256(%rsp)
	movq	97144(%rsp), %rax
	movq	%rax, 190264(%rsp)
	movq	97152(%rsp), %rax
	movq	%rax, 190272(%rsp)
	movq	97160(%rsp), %rax
	movq	%rax, 190280(%rsp)
	movq	97168(%rsp), %rax
	movq	%rax, 190288(%rsp)
	movq	97176(%rsp), %rax
	movq	%rax, 190296(%rsp)
	movq	97184(%rsp), %rax
	movq	%rax, 190304(%rsp)
	movq	97192(%rsp), %rax
	movq	%rax, 190312(%rsp)
	movq	97200(%rsp), %rax
	movq	%rax, 190320(%rsp)
	movq	97208(%rsp), %rax
	movq	%rax, 190328(%rsp)
	movq	97216(%rsp), %rax
	movq	%rax, 190336(%rsp)
	movq	97224(%rsp), %rax
	movq	%rax, 190344(%rsp)
	movq	97232(%rsp), %rax
	movq	%rax, 190352(%rsp)
	movq	97240(%rsp), %rax
	movq	%rax, 190360(%rsp)
	movq	97248(%rsp), %rax
	movq	%rax, 190368(%rsp)
	movq	97256(%rsp), %rax
	movq	%rax, 190376(%rsp)
	movq	97264(%rsp), %rax
	movq	%rax, 190384(%rsp)
	movq	97272(%rsp), %rax
	movq	%rax, 190392(%rsp)
	movq	97280(%rsp), %rax
	movq	%rax, 190400(%rsp)
	movq	97288(%rsp), %rax
	movq	%rax, 190408(%rsp)
	movq	97296(%rsp), %rax
	movq	%rax, 190416(%rsp)
	movq	97304(%rsp), %rax
	movq	%rax, 190424(%rsp)
	movq	97312(%rsp), %rax
	movq	%rax, 190432(%rsp)
	movq	97320(%rsp), %rax
	movq	%rax, 190440(%rsp)
	movq	97328(%rsp), %rax
	movq	%rax, 190448(%rsp)
	movq	97336(%rsp), %rax
	movq	%rax, 190456(%rsp)
	movq	97344(%rsp), %rax
	movq	%rax, 190464(%rsp)
	movq	97352(%rsp), %rax
	movq	%rax, 190472(%rsp)
	movq	97360(%rsp), %rax
	movq	%rax, 190480(%rsp)
	movq	97368(%rsp), %rax
	movq	%rax, 190488(%rsp)
	movq	97376(%rsp), %rax
	movq	%rax, 190496(%rsp)
	movq	97384(%rsp), %rax
	movq	%rax, 190504(%rsp)
	movq	97392(%rsp), %rax
	movq	%rax, 190512(%rsp)
	movq	97400(%rsp), %rax
	movq	%rax, 190520(%rsp)
	movq	97408(%rsp), %rax
	movq	%rax, 190528(%rsp)
	movq	97416(%rsp), %rax
	movq	%rax, 190536(%rsp)
	movq	97424(%rsp), %rax
	movq	%rax, 190544(%rsp)
	movq	97432(%rsp), %rax
	movq	%rax, 190552(%rsp)
	movq	97440(%rsp), %rax
	movq	%rax, 190560(%rsp)
	movq	97448(%rsp), %rax
	movq	%rax, 190568(%rsp)
	movq	97456(%rsp), %rax
	movq	%rax, 190576(%rsp)
	movq	97464(%rsp), %rax
	movq	%rax, 190584(%rsp)
	movq	97472(%rsp), %rax
	movq	%rax, 190592(%rsp)
	movq	97480(%rsp), %rax
	movq	%rax, 190600(%rsp)
	movq	97488(%rsp), %rax
	movq	%rax, 190608(%rsp)
	movq	97496(%rsp), %rax
	movq	%rax, 190616(%rsp)
	movq	97504(%rsp), %rax
	movq	%rax, 190624(%rsp)
	movq	97512(%rsp), %rax
	movq	%rax, 190632(%rsp)
	movq	97520(%rsp), %rax
	movq	%rax, 190640(%rsp)
	movq	97528(%rsp), %rax
	movq	%rax, 190648(%rsp)
	movq	97536(%rsp), %rax
	movq	%rax, 190656(%rsp)
	movq	97544(%rsp), %rax
	movq	%rax, 190664(%rsp)
	movq	97552(%rsp), %rax
	movq	%rax, 190672(%rsp)
	movq	97560(%rsp), %rax
	movq	%rax, 190680(%rsp)
	movq	97568(%rsp), %rax
	movq	%rax, 190688(%rsp)
	movq	97576(%rsp), %rax
	movq	%rax, 190696(%rsp)
	movq	97584(%rsp), %rax
	movq	%rax, 190704(%rsp)
	movq	97592(%rsp), %rax
	movq	%rax, 190712(%rsp)
	movq	97600(%rsp), %rax
	movq	%rax, 190720(%rsp)
	movq	97608(%rsp), %rax
	movq	%rax, 190728(%rsp)
	movq	97616(%rsp), %rax
	movq	%rax, 190736(%rsp)
	movq	97624(%rsp), %rax
	movq	%rax, 190744(%rsp)
	movq	97632(%rsp), %rax
	movq	%rax, 190752(%rsp)
	movq	97640(%rsp), %rax
	movq	%rax, 190760(%rsp)
	movq	97648(%rsp), %rax
	movq	%rax, 190768(%rsp)
	movq	97656(%rsp), %rax
	movq	%rax, 190776(%rsp)
	movq	97664(%rsp), %rax
	movq	%rax, 190784(%rsp)
	movq	97672(%rsp), %rax
	movq	%rax, 190792(%rsp)
	movq	97680(%rsp), %rax
	movq	%rax, 190800(%rsp)
	movq	97688(%rsp), %rax
	movq	%rax, 190808(%rsp)
	movq	97696(%rsp), %rax
	movq	%rax, 190816(%rsp)
	movq	97704(%rsp), %rax
	movq	%rax, 190824(%rsp)
	movq	97712(%rsp), %rax
	movq	%rax, 190832(%rsp)
	movq	97720(%rsp), %rax
	movq	%rax, 190840(%rsp)
	movq	97728(%rsp), %rax
	movq	%rax, 190848(%rsp)
	movq	97736(%rsp), %rax
	movq	%rax, 190856(%rsp)
	movq	97744(%rsp), %rax
	movq	%rax, 190864(%rsp)
	movq	97752(%rsp), %rax
	movq	%rax, 190872(%rsp)
	movq	97760(%rsp), %rax
	movq	%rax, 190880(%rsp)
	movq	97768(%rsp), %rax
	movq	%rax, 190888(%rsp)
	movq	97776(%rsp), %rax
	movq	%rax, 190896(%rsp)
	movq	97784(%rsp), %rax
	movq	%rax, 190904(%rsp)
	movq	97792(%rsp), %rax
	movq	%rax, 190912(%rsp)
	movq	97800(%rsp), %rax
	movq	%rax, 190920(%rsp)
	movq	97808(%rsp), %rax
	movq	%rax, 190928(%rsp)
	movq	97816(%rsp), %rax
	movq	%rax, 190936(%rsp)
	movq	97824(%rsp), %rax
	movq	%rax, 190944(%rsp)
	movq	97832(%rsp), %rax
	movq	%rax, 190952(%rsp)
	movq	97840(%rsp), %rax
	movq	%rax, 190960(%rsp)
	movq	97848(%rsp), %rax
	movq	%rax, 190968(%rsp)
	movq	97856(%rsp), %rax
	movq	%rax, 190976(%rsp)
	movq	97864(%rsp), %rax
	movq	%rax, 190984(%rsp)
	movq	97872(%rsp), %rax
	movq	%rax, 190992(%rsp)
	movq	97880(%rsp), %rax
	movq	%rax, 191000(%rsp)
	movq	97888(%rsp), %rax
	movq	%rax, 191008(%rsp)
	movq	97896(%rsp), %rax
	movq	%rax, 191016(%rsp)
	movq	97904(%rsp), %rax
	movq	%rax, 191024(%rsp)
	movq	97912(%rsp), %rax
	movq	%rax, 191032(%rsp)
	movq	97920(%rsp), %rax
	movq	%rax, 191040(%rsp)
	movq	97928(%rsp), %rax
	movq	%rax, 191048(%rsp)
	movq	97936(%rsp), %rax
	movq	%rax, 191056(%rsp)
	movq	97944(%rsp), %rax
	movq	%rax, 191064(%rsp)
	movq	97952(%rsp), %rax
	movq	%rax, 191072(%rsp)
	movq	97960(%rsp), %rax
	movq	%rax, 191080(%rsp)
	movq	97968(%rsp), %rax
	movq	%rax, 191088(%rsp)
	movq	97976(%rsp), %rax
	movq	%rax, 191096(%rsp)
	movq	97984(%rsp), %rax
	movq	%rax, 191104(%rsp)
	movq	97992(%rsp), %rax
	movq	%rax, 191112(%rsp)
	movq	98000(%rsp), %rax
	movq	%rax, 191120(%rsp)
	movq	98008(%rsp), %rax
	movq	%rax, 191128(%rsp)
	movq	98016(%rsp), %rax
	movq	%rax, 191136(%rsp)
	movq	98024(%rsp), %rax
	movq	%rax, 191144(%rsp)
	movq	98032(%rsp), %rax
	movq	%rax, 191152(%rsp)
	movq	98040(%rsp), %rax
	movq	%rax, 191160(%rsp)
	movq	98048(%rsp), %rax
	movq	%rax, 191168(%rsp)
	movq	98056(%rsp), %rax
	movq	%rax, 191176(%rsp)
	movq	98064(%rsp), %rax
	movq	%rax, 191184(%rsp)
	movq	98072(%rsp), %rax
	movq	%rax, 191192(%rsp)
	movq	98080(%rsp), %rax
	movq	%rax, 191200(%rsp)
	movq	98088(%rsp), %rax
	movq	%rax, 191208(%rsp)
	movq	98096(%rsp), %rax
	movq	%rax, 191216(%rsp)
	movq	98104(%rsp), %rax
	movq	%rax, 191224(%rsp)
	movq	98112(%rsp), %rax
	movq	%rax, 191232(%rsp)
	movq	98120(%rsp), %rax
	movq	%rax, 191240(%rsp)
	movq	98128(%rsp), %rax
	movq	%rax, 191248(%rsp)
	movq	98136(%rsp), %rax
	movq	%rax, 191256(%rsp)
	movq	98144(%rsp), %rax
	movq	%rax, 191264(%rsp)
	movq	98152(%rsp), %rax
	movq	%rax, 191272(%rsp)
	movq	98160(%rsp), %rax
	movq	%rax, 191280(%rsp)
	movq	98168(%rsp), %rax
	movq	%rax, 191288(%rsp)
	movq	98176(%rsp), %rax
	movq	%rax, 191296(%rsp)
	movq	98184(%rsp), %rax
	movq	%rax, 191304(%rsp)
	movq	98192(%rsp), %rax
	movq	%rax, 191312(%rsp)
	movq	98200(%rsp), %rax
	movq	%rax, 191320(%rsp)
	movq	98208(%rsp), %rax
	movq	%rax, 191328(%rsp)
	movq	98216(%rsp), %rax
	movq	%rax, 191336(%rsp)
	movq	98224(%rsp), %rax
	movq	%rax, 191344(%rsp)
	movq	98232(%rsp), %rax
	movq	%rax, 191352(%rsp)
	movq	98240(%rsp), %rax
	movq	%rax, 191360(%rsp)
	movq	98248(%rsp), %rax
	movq	%rax, 191368(%rsp)
	movq	98256(%rsp), %rax
	movq	%rax, 191376(%rsp)
	movq	98264(%rsp), %rax
	movq	%rax, 191384(%rsp)
	movq	98272(%rsp), %rax
	movq	%rax, 191392(%rsp)
	movq	98280(%rsp), %rax
	movq	%rax, 191400(%rsp)
	movq	98288(%rsp), %rax
	movq	%rax, 191408(%rsp)
	movq	98296(%rsp), %rax
	movq	%rax, 191416(%rsp)
	movq	98304(%rsp), %rax
	movq	%rax, 191424(%rsp)
	movq	98312(%rsp), %rax
	movq	%rax, 191432(%rsp)
	movq	98320(%rsp), %rax
	movq	%rax, 191440(%rsp)
	movq	98328(%rsp), %rax
	movq	%rax, 191448(%rsp)
	movq	98336(%rsp), %rax
	movq	%rax, 191456(%rsp)
	movq	98344(%rsp), %rax
	movq	%rax, 191464(%rsp)
	movq	98352(%rsp), %rax
	movq	%rax, 191472(%rsp)
	movq	98360(%rsp), %rax
	movq	%rax, 191480(%rsp)
	movq	98368(%rsp), %rax
	movq	%rax, 191488(%rsp)
	movq	98376(%rsp), %rax
	movq	%rax, 191496(%rsp)
	movq	98384(%rsp), %rax
	movq	%rax, 191504(%rsp)
	movq	98392(%rsp), %rax
	movq	%rax, 191512(%rsp)
	movq	98400(%rsp), %rax
	movq	%rax, 191520(%rsp)
	movq	98408(%rsp), %rax
	movq	%rax, 191528(%rsp)
	movq	98416(%rsp), %rax
	movq	%rax, 191536(%rsp)
	movq	98424(%rsp), %rax
	movq	%rax, 191544(%rsp)
	movq	98432(%rsp), %rax
	movq	%rax, 191552(%rsp)
	movq	98440(%rsp), %rax
	movq	%rax, 191560(%rsp)
	movq	98448(%rsp), %rax
	movq	%rax, 191568(%rsp)
	movq	98456(%rsp), %rax
	movq	%rax, 191576(%rsp)
	movq	98464(%rsp), %rax
	movq	%rax, 191584(%rsp)
	movq	98472(%rsp), %rax
	movq	%rax, 191592(%rsp)
	movq	98480(%rsp), %rax
	movq	%rax, 191600(%rsp)
	movq	98488(%rsp), %rax
	movq	%rax, 191608(%rsp)
	movq	98496(%rsp), %rax
	movq	%rax, 191616(%rsp)
	movq	98504(%rsp), %rax
	movq	%rax, 191624(%rsp)
	movq	98512(%rsp), %rax
	movq	%rax, 191632(%rsp)
	movq	98520(%rsp), %rax
	movq	%rax, 191640(%rsp)
	movq	98528(%rsp), %rax
	movq	%rax, 191648(%rsp)
	movq	98536(%rsp), %rax
	movq	%rax, 191656(%rsp)
	movq	98544(%rsp), %rax
	movq	%rax, 191664(%rsp)
	movq	98552(%rsp), %rax
	movq	%rax, 191672(%rsp)
	movq	98560(%rsp), %rax
	movq	%rax, 191680(%rsp)
	movq	98568(%rsp), %rax
	movq	%rax, 191688(%rsp)
	movq	98576(%rsp), %rax
	movq	%rax, 191696(%rsp)
	movq	98584(%rsp), %rax
	movq	%rax, 191704(%rsp)
	movq	98592(%rsp), %rax
	movq	%rax, 191712(%rsp)
	movq	98600(%rsp), %rax
	movq	%rax, 191720(%rsp)
	movq	98608(%rsp), %rax
	movq	%rax, 191728(%rsp)
	movq	98616(%rsp), %rax
	movq	%rax, 191736(%rsp)
	movq	98624(%rsp), %rax
	movq	%rax, 191744(%rsp)
	movq	98632(%rsp), %rax
	movq	%rax, 191752(%rsp)
	movq	98640(%rsp), %rax
	movq	%rax, 191760(%rsp)
	movq	98648(%rsp), %rax
	movq	%rax, 191768(%rsp)
	movq	98656(%rsp), %rax
	movq	%rax, 191776(%rsp)
	movq	98664(%rsp), %rax
	movq	%rax, 191784(%rsp)
	movq	98672(%rsp), %rax
	movq	%rax, 191792(%rsp)
	movq	98680(%rsp), %rax
	movq	%rax, 191800(%rsp)
	movq	98688(%rsp), %rax
	movq	%rax, 191808(%rsp)
	movq	98696(%rsp), %rax
	movq	%rax, 191816(%rsp)
	movq	98704(%rsp), %rax
	movq	%rax, 191824(%rsp)
	movq	98712(%rsp), %rax
	movq	%rax, 191832(%rsp)
	movq	98720(%rsp), %rax
	movq	%rax, 191840(%rsp)
	movq	98728(%rsp), %rax
	movq	%rax, 191848(%rsp)
	movq	98736(%rsp), %rax
	movq	%rax, 191856(%rsp)
	movq	98744(%rsp), %rax
	movq	%rax, 191864(%rsp)
	movq	98752(%rsp), %rax
	movq	%rax, 191872(%rsp)
	movq	98760(%rsp), %rax
	movq	%rax, 191880(%rsp)
	movq	98768(%rsp), %rax
	movq	%rax, 191888(%rsp)
	movq	98776(%rsp), %rax
	movq	%rax, 191896(%rsp)
	movq	98784(%rsp), %rax
	movq	%rax, 191904(%rsp)
	movq	98792(%rsp), %rax
	movq	%rax, 191912(%rsp)
	movq	98800(%rsp), %rax
	movq	%rax, 191920(%rsp)
	movq	98808(%rsp), %rax
	movq	%rax, 191928(%rsp)
	movq	98816(%rsp), %rax
	movq	%rax, 191936(%rsp)
	movq	98824(%rsp), %rax
	movq	%rax, 191944(%rsp)
	movq	98832(%rsp), %rax
	movq	%rax, 191952(%rsp)
	movq	98840(%rsp), %rax
	movq	%rax, 191960(%rsp)
	movq	98848(%rsp), %rax
	movq	%rax, 191968(%rsp)
	movq	98856(%rsp), %rax
	movq	%rax, 191976(%rsp)
	movq	98864(%rsp), %rax
	movq	%rax, 191984(%rsp)
	movq	98872(%rsp), %rax
	movq	%rax, 191992(%rsp)
	movq	98880(%rsp), %rax
	movq	%rax, 192000(%rsp)
	movq	98888(%rsp), %rax
	movq	%rax, 192008(%rsp)
	movq	98896(%rsp), %rax
	movq	%rax, 192016(%rsp)
	movq	98904(%rsp), %rax
	movq	%rax, 192024(%rsp)
	movq	98912(%rsp), %rax
	movq	%rax, 192032(%rsp)
	movq	98920(%rsp), %rax
	movq	%rax, 192040(%rsp)
	movq	98928(%rsp), %rax
	movq	%rax, 192048(%rsp)
	movq	98936(%rsp), %rax
	movq	%rax, 192056(%rsp)
	movq	98944(%rsp), %rax
	movq	%rax, 192064(%rsp)
	movq	98952(%rsp), %rax
	movq	%rax, 192072(%rsp)
	movq	98960(%rsp), %rax
	movq	%rax, 192080(%rsp)
	movq	98968(%rsp), %rax
	movq	%rax, 192088(%rsp)
	movq	98976(%rsp), %rax
	movq	%rax, 192096(%rsp)
	movq	98984(%rsp), %rax
	movq	%rax, 192104(%rsp)
	movq	98992(%rsp), %rax
	movq	%rax, 192112(%rsp)
	movq	99000(%rsp), %rax
	movq	%rax, 192120(%rsp)
	movq	99008(%rsp), %rax
	movq	%rax, 192128(%rsp)
	movq	99016(%rsp), %rax
	movq	%rax, 192136(%rsp)
	movq	99024(%rsp), %rax
	movq	%rax, 192144(%rsp)
	movq	99032(%rsp), %rax
	movq	%rax, 192152(%rsp)
	movq	99040(%rsp), %rax
	movq	%rax, 192160(%rsp)
	movq	99048(%rsp), %rax
	movq	%rax, 192168(%rsp)
	movq	99056(%rsp), %rax
	movq	%rax, 192176(%rsp)
	movq	99064(%rsp), %rax
	movq	%rax, 192184(%rsp)
	movq	99072(%rsp), %rax
	movq	%rax, 192192(%rsp)
	movq	99080(%rsp), %rax
	movq	%rax, 192200(%rsp)
	movq	99088(%rsp), %rax
	movq	%rax, 192208(%rsp)
	movq	99096(%rsp), %rax
	movq	%rax, 192216(%rsp)
	movq	99104(%rsp), %rax
	movq	%rax, 192224(%rsp)
	movq	99112(%rsp), %rax
	movq	%rax, 192232(%rsp)
	movq	99120(%rsp), %rax
	movq	%rax, 192240(%rsp)
	movq	99128(%rsp), %rax
	movq	%rax, 192248(%rsp)
	movq	99136(%rsp), %rax
	movq	%rax, 192256(%rsp)
	movq	99144(%rsp), %rax
	movq	%rax, 192264(%rsp)
	movq	99152(%rsp), %rax
	movq	%rax, 192272(%rsp)
	movq	99160(%rsp), %rax
	movq	%rax, 192280(%rsp)
	movq	99168(%rsp), %rax
	movq	%rax, 192288(%rsp)
	movq	99176(%rsp), %rax
	movq	%rax, 192296(%rsp)
	movq	99184(%rsp), %rax
	movq	%rax, 192304(%rsp)
	movq	99192(%rsp), %rax
	movq	%rax, 192312(%rsp)
	movq	99200(%rsp), %rax
	movq	%rax, 192320(%rsp)
	movq	99208(%rsp), %rax
	movq	%rax, 192328(%rsp)
	movq	99216(%rsp), %rax
	movq	%rax, 192336(%rsp)
	movq	99224(%rsp), %rax
	movq	%rax, 192344(%rsp)
	movq	99232(%rsp), %rax
	movq	%rax, 192352(%rsp)
	movq	99240(%rsp), %rax
	movq	%rax, 192360(%rsp)
	movq	99248(%rsp), %rax
	movq	%rax, 192368(%rsp)
	movq	99256(%rsp), %rax
	movq	%rax, 192376(%rsp)
	movq	99264(%rsp), %rax
	movq	%rax, 192384(%rsp)
	movq	99272(%rsp), %rax
	movq	%rax, 192392(%rsp)
	movq	99280(%rsp), %rax
	movq	%rax, 192400(%rsp)
	movq	99288(%rsp), %rax
	movq	%rax, 192408(%rsp)
	movq	99296(%rsp), %rax
	movq	%rax, 192416(%rsp)
	movq	99304(%rsp), %rax
	movq	%rax, 192424(%rsp)
	movq	99312(%rsp), %rax
	movq	%rax, 192432(%rsp)
	movq	99320(%rsp), %rax
	movq	%rax, 192440(%rsp)
	movq	99328(%rsp), %rax
	movq	%rax, 192448(%rsp)
	movq	99336(%rsp), %rax
	movq	%rax, 192456(%rsp)
	movq	99344(%rsp), %rax
	movq	%rax, 192464(%rsp)
	movq	99352(%rsp), %rax
	movq	%rax, 192472(%rsp)
	movq	99360(%rsp), %rax
	movq	%rax, 192480(%rsp)
	movq	99368(%rsp), %rax
	movq	%rax, 192488(%rsp)
	movq	99376(%rsp), %rax
	movq	%rax, 192496(%rsp)
	movq	99384(%rsp), %rax
	movq	%rax, 192504(%rsp)
	movq	99392(%rsp), %rax
	movq	%rax, 192512(%rsp)
	movq	99400(%rsp), %rax
	movq	%rax, 192520(%rsp)
	movq	99408(%rsp), %rax
	movq	%rax, 192528(%rsp)
	movq	99416(%rsp), %rax
	movq	%rax, 192536(%rsp)
	movq	99424(%rsp), %rax
	movq	%rax, 192544(%rsp)
	movq	99432(%rsp), %rax
	movq	%rax, 192552(%rsp)
	movq	99440(%rsp), %rax
	movq	%rax, 192560(%rsp)
	movq	99448(%rsp), %rax
	movq	%rax, 192568(%rsp)
	movq	99456(%rsp), %rax
	movq	%rax, 192576(%rsp)
	movq	99464(%rsp), %rax
	movq	%rax, 192584(%rsp)
	movq	99472(%rsp), %rax
	movq	%rax, 192592(%rsp)
	movq	99480(%rsp), %rax
	movq	%rax, 192600(%rsp)
	movq	99488(%rsp), %rax
	movq	%rax, 192608(%rsp)
	movq	99496(%rsp), %rax
	movq	%rax, 192616(%rsp)
	movq	99504(%rsp), %rax
	movq	%rax, 192624(%rsp)
	movq	99512(%rsp), %rax
	movq	%rax, 192632(%rsp)
	movq	99520(%rsp), %rax
	movq	%rax, 192640(%rsp)
	movq	99528(%rsp), %rax
	movq	%rax, 192648(%rsp)
	movq	99536(%rsp), %rax
	movq	%rax, 192656(%rsp)
	movq	99544(%rsp), %rax
	movq	%rax, 192664(%rsp)
	leaq	960(%rsp), %rax
	movl	(%rax), %ecx
	movl	%ecx, 192672(%rsp)
	movl	4(%rax), %ecx
	movl	%ecx, 192676(%rsp)
	movl	8(%rax), %ecx
	movl	%ecx, 192680(%rsp)
	movl	12(%rax), %ecx
	movl	%ecx, 192684(%rsp)
	movl	16(%rax), %ecx
	movl	%ecx, 192688(%rsp)
	movl	20(%rax), %ecx
	movl	%ecx, 192692(%rsp)
	movl	24(%rax), %ecx
	movl	%ecx, 192696(%rsp)
	movl	28(%rax), %ecx
	movl	%ecx, 192700(%rsp)
	movl	32(%rax), %ecx
	movl	%ecx, 192704(%rsp)
	movl	36(%rax), %ecx
	movl	%ecx, 192708(%rsp)
	movl	40(%rax), %ecx
	movl	%ecx, 192712(%rsp)
	movl	44(%rax), %ecx
	movl	%ecx, 192716(%rsp)
	movl	48(%rax), %ecx
	movl	%ecx, 192720(%rsp)
	movl	52(%rax), %ecx
	movl	%ecx, 192724(%rsp)
	movl	56(%rax), %ecx
	movl	%ecx, 192728(%rsp)
	movl	60(%rax), %ecx
	movl	%ecx, 192732(%rsp)
	movl	64(%rax), %ecx
	movl	%ecx, 192736(%rsp)
	movl	68(%rax), %ecx
	movl	%ecx, 192740(%rsp)
	movl	72(%rax), %ecx
	movl	%ecx, 192744(%rsp)
	movl	76(%rax), %ecx
	movl	%ecx, 192748(%rsp)
	movl	80(%rax), %ecx
	movl	%ecx, 192752(%rsp)
	movl	84(%rax), %ecx
	movl	%ecx, 192756(%rsp)
	movl	88(%rax), %ecx
	movl	%ecx, 192760(%rsp)
	movl	92(%rax), %ecx
	movl	%ecx, 192764(%rsp)
	movl	96(%rax), %ecx
	movl	%ecx, 192768(%rsp)
	movl	100(%rax), %ecx
	movl	%ecx, 192772(%rsp)
	movl	104(%rax), %ecx
	movl	%ecx, 192776(%rsp)
	movl	108(%rax), %ecx
	movl	%ecx, 192780(%rsp)
	movl	112(%rax), %ecx
	movl	%ecx, 192784(%rsp)
	movl	116(%rax), %ecx
	movl	%ecx, 192788(%rsp)
	movl	120(%rax), %ecx
	movl	%ecx, 192792(%rsp)
	movl	124(%rax), %ecx
	movl	%ecx, 192796(%rsp)
	movl	128(%rax), %ecx
	movl	%ecx, 192800(%rsp)
	movl	132(%rax), %ecx
	movl	%ecx, 192804(%rsp)
	movl	136(%rax), %ecx
	movl	%ecx, 192808(%rsp)
	movl	140(%rax), %ecx
	movl	%ecx, 192812(%rsp)
	movl	144(%rax), %ecx
	movl	%ecx, 192816(%rsp)
	movl	148(%rax), %ecx
	movl	%ecx, 192820(%rsp)
	movl	152(%rax), %ecx
	movl	%ecx, 192824(%rsp)
	movl	156(%rax), %ecx
	movl	%ecx, 192828(%rsp)
	movl	160(%rax), %ecx
	movl	%ecx, 192832(%rsp)
	movl	164(%rax), %ecx
	movl	%ecx, 192836(%rsp)
	movl	168(%rax), %ecx
	movl	%ecx, 192840(%rsp)
	movl	172(%rax), %ecx
	movl	%ecx, 192844(%rsp)
	movl	176(%rax), %ecx
	movl	%ecx, 192848(%rsp)
	movl	180(%rax), %ecx
	movl	%ecx, 192852(%rsp)
	movl	184(%rax), %ecx
	movl	%ecx, 192856(%rsp)
	movl	188(%rax), %ecx
	movl	%ecx, 192860(%rsp)
	movl	192(%rax), %ecx
	movl	%ecx, 192864(%rsp)
	movl	196(%rax), %ecx
	movl	%ecx, 192868(%rsp)
	movl	200(%rax), %ecx
	movl	%ecx, 192872(%rsp)
	movl	204(%rax), %ecx
	movl	%ecx, 192876(%rsp)
	movl	208(%rax), %ecx
	movl	%ecx, 192880(%rsp)
	movl	212(%rax), %ecx
	movl	%ecx, 192884(%rsp)
	movl	216(%rax), %ecx
	movl	%ecx, 192888(%rsp)
	movl	220(%rax), %ecx
	movl	%ecx, 192892(%rsp)
	movl	224(%rax), %ecx
	movl	%ecx, 192896(%rsp)
	movl	228(%rax), %ecx
	movl	%ecx, 192900(%rsp)
	movl	232(%rax), %ecx
	movl	%ecx, 192904(%rsp)
	movl	236(%rax), %ecx
	movl	%ecx, 192908(%rsp)
	movl	240(%rax), %ecx
	movl	%ecx, 192912(%rsp)
	movl	244(%rax), %ecx
	movl	%ecx, 192916(%rsp)
	movl	248(%rax), %ecx
	movl	%ecx, 192920(%rsp)
	movl	252(%rax), %ecx
	movl	%ecx, 192924(%rsp)
	movl	256(%rax), %ecx
	movl	%ecx, 192928(%rsp)
	movl	260(%rax), %ecx
	movl	%ecx, 192932(%rsp)
	movl	264(%rax), %ecx
	movl	%ecx, 192936(%rsp)
	movl	268(%rax), %ecx
	movl	%ecx, 192940(%rsp)
	movl	272(%rax), %ecx
	movl	%ecx, 192944(%rsp)
	movl	276(%rax), %ecx
	movl	%ecx, 192948(%rsp)
	movl	280(%rax), %ecx
	movl	%ecx, 192952(%rsp)
	movl	284(%rax), %ecx
	movl	%ecx, 192956(%rsp)
	movl	288(%rax), %ecx
	movl	%ecx, 192960(%rsp)
	movl	292(%rax), %ecx
	movl	%ecx, 192964(%rsp)
	movl	296(%rax), %ecx
	movl	%ecx, 192968(%rsp)
	movl	300(%rax), %ecx
	movl	%ecx, 192972(%rsp)
	movl	304(%rax), %ecx
	movl	%ecx, 192976(%rsp)
	movl	308(%rax), %ecx
	movl	%ecx, 192980(%rsp)
	movl	312(%rax), %ecx
	movl	%ecx, 192984(%rsp)
	movl	316(%rax), %ecx
	movl	%ecx, 192988(%rsp)
	movl	320(%rax), %ecx
	movl	%ecx, 192992(%rsp)
	movl	324(%rax), %ecx
	movl	%ecx, 192996(%rsp)
	movl	328(%rax), %ecx
	movl	%ecx, 193000(%rsp)
	movl	332(%rax), %ecx
	movl	%ecx, 193004(%rsp)
	movl	336(%rax), %ecx
	movl	%ecx, 193008(%rsp)
	movl	340(%rax), %ecx
	movl	%ecx, 193012(%rsp)
	movl	344(%rax), %ecx
	movl	%ecx, 193016(%rsp)
	movl	348(%rax), %ecx
	movl	%ecx, 193020(%rsp)
	movl	352(%rax), %ecx
	movl	%ecx, 193024(%rsp)
	movl	356(%rax), %ecx
	movl	%ecx, 193028(%rsp)
	movl	360(%rax), %ecx
	movl	%ecx, 193032(%rsp)
	movl	364(%rax), %ecx
	movl	%ecx, 193036(%rsp)
	movl	368(%rax), %ecx
	movl	%ecx, 193040(%rsp)
	movl	372(%rax), %ecx
	movl	%ecx, 193044(%rsp)
	movl	376(%rax), %ecx
	movl	%ecx, 193048(%rsp)
	movl	380(%rax), %ecx
	movl	%ecx, 193052(%rsp)
	movl	384(%rax), %ecx
	movl	%ecx, 193056(%rsp)
	movl	388(%rax), %ecx
	movl	%ecx, 193060(%rsp)
	movl	392(%rax), %ecx
	movl	%ecx, 193064(%rsp)
	movl	396(%rax), %ecx
	movl	%ecx, 193068(%rsp)
	movl	400(%rax), %ecx
	movl	%ecx, 193072(%rsp)
	movl	404(%rax), %ecx
	movl	%ecx, 193076(%rsp)
	movl	408(%rax), %ecx
	movl	%ecx, 193080(%rsp)
	movl	412(%rax), %ecx
	movl	%ecx, 193084(%rsp)
	movl	416(%rax), %ecx
	movl	%ecx, 193088(%rsp)
	movl	420(%rax), %ecx
	movl	%ecx, 193092(%rsp)
	movl	424(%rax), %ecx
	movl	%ecx, 193096(%rsp)
	movl	428(%rax), %ecx
	movl	%ecx, 193100(%rsp)
	movl	432(%rax), %ecx
	movl	%ecx, 193104(%rsp)
	movl	436(%rax), %ecx
	movl	%ecx, 193108(%rsp)
	movl	440(%rax), %ecx
	movl	%ecx, 193112(%rsp)
	movl	444(%rax), %ecx
	movl	%ecx, 193116(%rsp)
	movl	448(%rax), %ecx
	movl	%ecx, 193120(%rsp)
	movl	452(%rax), %ecx
	movl	%ecx, 193124(%rsp)
	movl	456(%rax), %ecx
	movl	%ecx, 193128(%rsp)
	movl	460(%rax), %ecx
	movl	%ecx, 193132(%rsp)
	movl	464(%rax), %ecx
	movl	%ecx, 193136(%rsp)
	movl	468(%rax), %ecx
	movl	%ecx, 193140(%rsp)
	movl	472(%rax), %ecx
	movl	%ecx, 193144(%rsp)
	movl	476(%rax), %ecx
	movl	%ecx, 193148(%rsp)
	movl	480(%rax), %ecx
	movl	%ecx, 193152(%rsp)
	movl	484(%rax), %ecx
	movl	%ecx, 193156(%rsp)
	movl	488(%rax), %ecx
	movl	%ecx, 193160(%rsp)
	movl	492(%rax), %ecx
	movl	%ecx, 193164(%rsp)
	movl	496(%rax), %ecx
	movl	%ecx, 193168(%rsp)
	movl	500(%rax), %ecx
	movl	%ecx, 193172(%rsp)
	movl	504(%rax), %ecx
	movl	%ecx, 193176(%rsp)
	movl	508(%rax), %ecx
	movl	%ecx, 193180(%rsp)
	movl	512(%rax), %ecx
	movl	%ecx, 193184(%rsp)
	movl	516(%rax), %ecx
	movl	%ecx, 193188(%rsp)
	movl	520(%rax), %ecx
	movl	%ecx, 193192(%rsp)
	movl	524(%rax), %ecx
	movl	%ecx, 193196(%rsp)
	movl	528(%rax), %ecx
	movl	%ecx, 193200(%rsp)
	movl	532(%rax), %ecx
	movl	%ecx, 193204(%rsp)
	movl	536(%rax), %ecx
	movl	%ecx, 193208(%rsp)
	movl	540(%rax), %ecx
	movl	%ecx, 193212(%rsp)
	movl	544(%rax), %ecx
	movl	%ecx, 193216(%rsp)
	movl	548(%rax), %ecx
	movl	%ecx, 193220(%rsp)
	movl	552(%rax), %ecx
	movl	%ecx, 193224(%rsp)
	movl	556(%rax), %ecx
	movl	%ecx, 193228(%rsp)
	movl	560(%rax), %ecx
	movl	%ecx, 193232(%rsp)
	movl	564(%rax), %ecx
	movl	%ecx, 193236(%rsp)
	movl	568(%rax), %ecx
	movl	%ecx, 193240(%rsp)
	movl	572(%rax), %ecx
	movl	%ecx, 193244(%rsp)
	movl	576(%rax), %ecx
	movl	%ecx, 193248(%rsp)
	movl	580(%rax), %ecx
	movl	%ecx, 193252(%rsp)
	movl	584(%rax), %ecx
	movl	%ecx, 193256(%rsp)
	movl	588(%rax), %ecx
	movl	%ecx, 193260(%rsp)
	movl	592(%rax), %ecx
	movl	%ecx, 193264(%rsp)
	movl	596(%rax), %ecx
	movl	%ecx, 193268(%rsp)
	movl	600(%rax), %ecx
	movl	%ecx, 193272(%rsp)
	movl	604(%rax), %ecx
	movl	%ecx, 193276(%rsp)
	movl	608(%rax), %ecx
	movl	%ecx, 193280(%rsp)
	movl	612(%rax), %ecx
	movl	%ecx, 193284(%rsp)
	movl	616(%rax), %ecx
	movl	%ecx, 193288(%rsp)
	movl	620(%rax), %ecx
	movl	%ecx, 193292(%rsp)
	movl	624(%rax), %ecx
	movl	%ecx, 193296(%rsp)
	movl	628(%rax), %ecx
	movl	%ecx, 193300(%rsp)
	movl	632(%rax), %ecx
	movl	%ecx, 193304(%rsp)
	movl	636(%rax), %ecx
	movl	%ecx, 193308(%rsp)
	movl	640(%rax), %ecx
	movl	%ecx, 193312(%rsp)
	movl	644(%rax), %ecx
	movl	%ecx, 193316(%rsp)
	movl	648(%rax), %ecx
	movl	%ecx, 193320(%rsp)
	movl	652(%rax), %ecx
	movl	%ecx, 193324(%rsp)
	movl	656(%rax), %ecx
	movl	%ecx, 193328(%rsp)
	movl	660(%rax), %ecx
	movl	%ecx, 193332(%rsp)
	movl	664(%rax), %ecx
	movl	%ecx, 193336(%rsp)
	movl	668(%rax), %ecx
	movl	%ecx, 193340(%rsp)
	movl	672(%rax), %ecx
	movl	%ecx, 193344(%rsp)
	movl	676(%rax), %ecx
	movl	%ecx, 193348(%rsp)
	movl	680(%rax), %ecx
	movl	%ecx, 193352(%rsp)
	movl	684(%rax), %ecx
	movl	%ecx, 193356(%rsp)
	movl	688(%rax), %ecx
	movl	%ecx, 193360(%rsp)
	movl	692(%rax), %ecx
	movl	%ecx, 193364(%rsp)
	movl	696(%rax), %ecx
	movl	%ecx, 193368(%rsp)
	movl	700(%rax), %ecx
	movl	%ecx, 193372(%rsp)
	movl	704(%rax), %ecx
	movl	%ecx, 193376(%rsp)
	movl	708(%rax), %ecx
	movl	%ecx, 193380(%rsp)
	movl	712(%rax), %ecx
	movl	%ecx, 193384(%rsp)
	movl	716(%rax), %ecx
	movl	%ecx, 193388(%rsp)
	movl	720(%rax), %ecx
	movl	%ecx, 193392(%rsp)
	movl	724(%rax), %ecx
	movl	%ecx, 193396(%rsp)
	movl	728(%rax), %ecx
	movl	%ecx, 193400(%rsp)
	movl	732(%rax), %ecx
	movl	%ecx, 193404(%rsp)
	movl	736(%rax), %ecx
	movl	%ecx, 193408(%rsp)
	movl	740(%rax), %ecx
	movl	%ecx, 193412(%rsp)
	movl	744(%rax), %ecx
	movl	%ecx, 193416(%rsp)
	movl	748(%rax), %ecx
	movl	%ecx, 193420(%rsp)
	movl	752(%rax), %ecx
	movl	%ecx, 193424(%rsp)
	movl	756(%rax), %ecx
	movl	%ecx, 193428(%rsp)
	movl	760(%rax), %ecx
	movl	%ecx, 193432(%rsp)
	movl	764(%rax), %ecx
	movl	%ecx, 193436(%rsp)
	movl	768(%rax), %ecx
	movl	%ecx, 193440(%rsp)
	movl	772(%rax), %ecx
	movl	%ecx, 193444(%rsp)
	movl	776(%rax), %ecx
	movl	%ecx, 193448(%rsp)
	movl	780(%rax), %ecx
	movl	%ecx, 193452(%rsp)
	movl	784(%rax), %ecx
	movl	%ecx, 193456(%rsp)
	movl	788(%rax), %ecx
	movl	%ecx, 193460(%rsp)
	movl	792(%rax), %ecx
	movl	%ecx, 193464(%rsp)
	movl	796(%rax), %ecx
	movl	%ecx, 193468(%rsp)
	movl	800(%rax), %ecx
	movl	%ecx, 193472(%rsp)
	movl	804(%rax), %ecx
	movl	%ecx, 193476(%rsp)
	movl	808(%rax), %ecx
	movl	%ecx, 193480(%rsp)
	movl	812(%rax), %ecx
	movl	%ecx, 193484(%rsp)
	movl	816(%rax), %ecx
	movl	%ecx, 193488(%rsp)
	movl	820(%rax), %ecx
	movl	%ecx, 193492(%rsp)
	movl	824(%rax), %ecx
	movl	%ecx, 193496(%rsp)
	movl	828(%rax), %ecx
	movl	%ecx, 193500(%rsp)
	movl	832(%rax), %ecx
	movl	%ecx, 193504(%rsp)
	movl	836(%rax), %ecx
	movl	%ecx, 193508(%rsp)
	movl	840(%rax), %ecx
	movl	%ecx, 193512(%rsp)
	movl	844(%rax), %ecx
	movl	%ecx, 193516(%rsp)
	movl	848(%rax), %ecx
	movl	%ecx, 193520(%rsp)
	movl	852(%rax), %ecx
	movl	%ecx, 193524(%rsp)
	movl	856(%rax), %ecx
	movl	%ecx, 193528(%rsp)
	movl	860(%rax), %ecx
	movl	%ecx, 193532(%rsp)
	movl	864(%rax), %ecx
	movl	%ecx, 193536(%rsp)
	movl	868(%rax), %ecx
	movl	%ecx, 193540(%rsp)
	movl	872(%rax), %ecx
	movl	%ecx, 193544(%rsp)
	movl	876(%rax), %ecx
	movl	%ecx, 193548(%rsp)
	movl	880(%rax), %ecx
	movl	%ecx, 193552(%rsp)
	movl	884(%rax), %ecx
	movl	%ecx, 193556(%rsp)
	movl	888(%rax), %ecx
	movl	%ecx, 193560(%rsp)
	movl	892(%rax), %ecx
	movl	%ecx, 193564(%rsp)
	movl	896(%rax), %ecx
	movl	%ecx, 193568(%rsp)
	movl	900(%rax), %ecx
	movl	%ecx, 193572(%rsp)
	movl	904(%rax), %ecx
	movl	%ecx, 193576(%rsp)
	movl	908(%rax), %ecx
	movl	%ecx, 193580(%rsp)
	movl	912(%rax), %ecx
	movl	%ecx, 193584(%rsp)
	movl	916(%rax), %ecx
	movl	%ecx, 193588(%rsp)
	movl	920(%rax), %ecx
	movl	%ecx, 193592(%rsp)
	movl	924(%rax), %ecx
	movl	%ecx, 193596(%rsp)
	movl	928(%rax), %ecx
	movl	%ecx, 193600(%rsp)
	movl	932(%rax), %ecx
	movl	%ecx, 193604(%rsp)
	movl	936(%rax), %ecx
	movl	%ecx, 193608(%rsp)
	movl	940(%rax), %ecx
	movl	%ecx, 193612(%rsp)
	movl	944(%rax), %ecx
	movl	%ecx, 193616(%rsp)
	movl	948(%rax), %ecx
	movl	%ecx, 193620(%rsp)
	movl	952(%rax), %ecx
	movl	%ecx, 193624(%rsp)
	movl	956(%rax), %ecx
	movl	%ecx, 193628(%rsp)
	movl	960(%rax), %ecx
	movl	%ecx, 193632(%rsp)
	movl	964(%rax), %ecx
	movl	%ecx, 193636(%rsp)
	movl	968(%rax), %ecx
	movl	%ecx, 193640(%rsp)
	movl	972(%rax), %ecx
	movl	%ecx, 193644(%rsp)
	movl	976(%rax), %ecx
	movl	%ecx, 193648(%rsp)
	movl	980(%rax), %ecx
	movl	%ecx, 193652(%rsp)
	movl	984(%rax), %ecx
	movl	%ecx, 193656(%rsp)
	movl	988(%rax), %ecx
	movl	%ecx, 193660(%rsp)
	movl	992(%rax), %ecx
	movl	%ecx, 193664(%rsp)
	movl	996(%rax), %ecx
	movl	%ecx, 193668(%rsp)
	movl	1000(%rax), %ecx
	movl	%ecx, 193672(%rsp)
	movl	1004(%rax), %ecx
	movl	%ecx, 193676(%rsp)
	movl	1008(%rax), %ecx
	movl	%ecx, 193680(%rsp)
	movl	1012(%rax), %ecx
	movl	%ecx, 193684(%rsp)
	movl	1016(%rax), %ecx
	movl	%ecx, 193688(%rsp)
	movl	1020(%rax), %ecx
	movl	%ecx, 193692(%rsp)
	movl	1024(%rax), %ecx
	movl	%ecx, 193696(%rsp)
	movl	1028(%rax), %ecx
	movl	%ecx, 193700(%rsp)
	movl	1032(%rax), %ecx
	movl	%ecx, 193704(%rsp)
	movl	1036(%rax), %ecx
	movl	%ecx, 193708(%rsp)
	movl	1040(%rax), %ecx
	movl	%ecx, 193712(%rsp)
	movl	1044(%rax), %ecx
	movl	%ecx, 193716(%rsp)
	movl	1048(%rax), %ecx
	movl	%ecx, 193720(%rsp)
	movl	1052(%rax), %ecx
	movl	%ecx, 193724(%rsp)
	movl	1056(%rax), %ecx
	movl	%ecx, 193728(%rsp)
	movl	1060(%rax), %ecx
	movl	%ecx, 193732(%rsp)
	movl	1064(%rax), %ecx
	movl	%ecx, 193736(%rsp)
	movl	1068(%rax), %ecx
	movl	%ecx, 193740(%rsp)
	movl	1072(%rax), %ecx
	movl	%ecx, 193744(%rsp)
	movl	1076(%rax), %ecx
	movl	%ecx, 193748(%rsp)
	movl	1080(%rax), %ecx
	movl	%ecx, 193752(%rsp)
	movl	1084(%rax), %ecx
	movl	%ecx, 193756(%rsp)
	movl	1088(%rax), %ecx
	movl	%ecx, 193760(%rsp)
	movl	1092(%rax), %ecx
	movl	%ecx, 193764(%rsp)
	movl	1096(%rax), %ecx
	movl	%ecx, 193768(%rsp)
	movl	1100(%rax), %ecx
	movl	%ecx, 193772(%rsp)
	movl	1104(%rax), %ecx
	movl	%ecx, 193776(%rsp)
	movl	1108(%rax), %ecx
	movl	%ecx, 193780(%rsp)
	movl	1112(%rax), %ecx
	movl	%ecx, 193784(%rsp)
	movl	1116(%rax), %ecx
	movl	%ecx, 193788(%rsp)
	movl	1120(%rax), %ecx
	movl	%ecx, 193792(%rsp)
	movl	1124(%rax), %ecx
	movl	%ecx, 193796(%rsp)
	movl	1128(%rax), %ecx
	movl	%ecx, 193800(%rsp)
	movl	1132(%rax), %ecx
	movl	%ecx, 193804(%rsp)
	movl	1136(%rax), %ecx
	movl	%ecx, 193808(%rsp)
	movl	1140(%rax), %ecx
	movl	%ecx, 193812(%rsp)
	movl	1144(%rax), %ecx
	movl	%ecx, 193816(%rsp)
	movl	1148(%rax), %ecx
	movl	%ecx, 193820(%rsp)
	movl	1152(%rax), %ecx
	movl	%ecx, 193824(%rsp)
	movl	1156(%rax), %ecx
	movl	%ecx, 193828(%rsp)
	movl	1160(%rax), %ecx
	movl	%ecx, 193832(%rsp)
	movl	1164(%rax), %ecx
	movl	%ecx, 193836(%rsp)
	movl	1168(%rax), %ecx
	movl	%ecx, 193840(%rsp)
	movl	1172(%rax), %ecx
	movl	%ecx, 193844(%rsp)
	movl	1176(%rax), %ecx
	movl	%ecx, 193848(%rsp)
	movl	1180(%rax), %ecx
	movl	%ecx, 193852(%rsp)
	movl	1184(%rax), %ecx
	movl	%ecx, 193856(%rsp)
	movl	1188(%rax), %ecx
	movl	%ecx, 193860(%rsp)
	movl	1192(%rax), %ecx
	movl	%ecx, 193864(%rsp)
	movl	1196(%rax), %ecx
	movl	%ecx, 193868(%rsp)
	movl	1200(%rax), %ecx
	movl	%ecx, 193872(%rsp)
	movl	1204(%rax), %ecx
	movl	%ecx, 193876(%rsp)
	movl	1208(%rax), %ecx
	movl	%ecx, 193880(%rsp)
	movl	1212(%rax), %ecx
	movl	%ecx, 193884(%rsp)
	movl	1216(%rax), %ecx
	movl	%ecx, 193888(%rsp)
	movl	1220(%rax), %ecx
	movl	%ecx, 193892(%rsp)
	movl	1224(%rax), %ecx
	movl	%ecx, 193896(%rsp)
	movl	1228(%rax), %ecx
	movl	%ecx, 193900(%rsp)
	movl	1232(%rax), %ecx
	movl	%ecx, 193904(%rsp)
	movl	1236(%rax), %ecx
	movl	%ecx, 193908(%rsp)
	movl	1240(%rax), %ecx
	movl	%ecx, 193912(%rsp)
	movl	1244(%rax), %ecx
	movl	%ecx, 193916(%rsp)
	movl	1248(%rax), %ecx
	movl	%ecx, 193920(%rsp)
	movl	1252(%rax), %ecx
	movl	%ecx, 193924(%rsp)
	movl	1256(%rax), %ecx
	movl	%ecx, 193928(%rsp)
	movl	1260(%rax), %ecx
	movl	%ecx, 193932(%rsp)
	movl	1264(%rax), %ecx
	movl	%ecx, 193936(%rsp)
	movl	1268(%rax), %ecx
	movl	%ecx, 193940(%rsp)
	movl	1272(%rax), %ecx
	movl	%ecx, 193944(%rsp)
	movl	1276(%rax), %ecx
	movl	%ecx, 193948(%rsp)
	movl	1280(%rax), %ecx
	movl	%ecx, 193952(%rsp)
	movl	1284(%rax), %ecx
	movl	%ecx, 193956(%rsp)
	movl	1288(%rax), %ecx
	movl	%ecx, 193960(%rsp)
	movl	1292(%rax), %ecx
	movl	%ecx, 193964(%rsp)
	movl	1296(%rax), %ecx
	movl	%ecx, 193968(%rsp)
	movl	1300(%rax), %ecx
	movl	%ecx, 193972(%rsp)
	movl	1304(%rax), %ecx
	movl	%ecx, 193976(%rsp)
	movl	1308(%rax), %ecx
	movl	%ecx, 193980(%rsp)
	movl	1312(%rax), %ecx
	movl	%ecx, 193984(%rsp)
	movl	1316(%rax), %ecx
	movl	%ecx, 193988(%rsp)
	movl	1320(%rax), %ecx
	movl	%ecx, 193992(%rsp)
	movl	1324(%rax), %ecx
	movl	%ecx, 193996(%rsp)
	movl	1328(%rax), %ecx
	movl	%ecx, 194000(%rsp)
	movl	1332(%rax), %ecx
	movl	%ecx, 194004(%rsp)
	movl	1336(%rax), %ecx
	movl	%ecx, 194008(%rsp)
	movl	1340(%rax), %ecx
	movl	%ecx, 194012(%rsp)
	movl	1344(%rax), %ecx
	movl	%ecx, 194016(%rsp)
	movl	1348(%rax), %ecx
	movl	%ecx, 194020(%rsp)
	movl	1352(%rax), %ecx
	movl	%ecx, 194024(%rsp)
	movl	1356(%rax), %ecx
	movl	%ecx, 194028(%rsp)
	movl	1360(%rax), %ecx
	movl	%ecx, 194032(%rsp)
	movl	1364(%rax), %ecx
	movl	%ecx, 194036(%rsp)
	movl	1368(%rax), %ecx
	movl	%ecx, 194040(%rsp)
	movl	1372(%rax), %ecx
	movl	%ecx, 194044(%rsp)
	movl	1376(%rax), %ecx
	movl	%ecx, 194048(%rsp)
	movl	1380(%rax), %ecx
	movl	%ecx, 194052(%rsp)
	movl	1384(%rax), %ecx
	movl	%ecx, 194056(%rsp)
	movl	1388(%rax), %ecx
	movl	%ecx, 194060(%rsp)
	movl	1392(%rax), %ecx
	movl	%ecx, 194064(%rsp)
	movl	1396(%rax), %ecx
	movl	%ecx, 194068(%rsp)
	movl	1400(%rax), %ecx
	movl	%ecx, 194072(%rsp)
	movl	1404(%rax), %ecx
	movl	%ecx, 194076(%rsp)
	movl	1408(%rax), %ecx
	movl	%ecx, 194080(%rsp)
	movl	1412(%rax), %ecx
	movl	%ecx, 194084(%rsp)
	movl	1416(%rax), %ecx
	movl	%ecx, 194088(%rsp)
	movl	1420(%rax), %ecx
	movl	%ecx, 194092(%rsp)
	movl	1424(%rax), %ecx
	movl	%ecx, 194096(%rsp)
	movl	1428(%rax), %ecx
	movl	%ecx, 194100(%rsp)
	movl	1432(%rax), %ecx
	movl	%ecx, 194104(%rsp)
	movl	1436(%rax), %ecx
	movl	%ecx, 194108(%rsp)
	movl	1440(%rax), %ecx
	movl	%ecx, 194112(%rsp)
	movl	1444(%rax), %ecx
	movl	%ecx, 194116(%rsp)
	movl	1448(%rax), %ecx
	movl	%ecx, 194120(%rsp)
	movl	1452(%rax), %ecx
	movl	%ecx, 194124(%rsp)
	movl	1456(%rax), %ecx
	movl	%ecx, 194128(%rsp)
	movl	1460(%rax), %ecx
	movl	%ecx, 194132(%rsp)
	movl	1464(%rax), %ecx
	movl	%ecx, 194136(%rsp)
	movl	1468(%rax), %ecx
	movl	%ecx, 194140(%rsp)
	movl	1472(%rax), %ecx
	movl	%ecx, 194144(%rsp)
	movl	1476(%rax), %ecx
	movl	%ecx, 194148(%rsp)
	movl	1480(%rax), %ecx
	movl	%ecx, 194152(%rsp)
	movl	1484(%rax), %ecx
	movl	%ecx, 194156(%rsp)
	movl	1488(%rax), %ecx
	movl	%ecx, 194160(%rsp)
	movl	1492(%rax), %ecx
	movl	%ecx, 194164(%rsp)
	movl	1496(%rax), %ecx
	movl	%ecx, 194168(%rsp)
	movl	1500(%rax), %ecx
	movl	%ecx, 194172(%rsp)
	movl	1504(%rax), %ecx
	movl	%ecx, 194176(%rsp)
	movl	1508(%rax), %ecx
	movl	%ecx, 194180(%rsp)
	movl	1512(%rax), %ecx
	movl	%ecx, 194184(%rsp)
	movl	1516(%rax), %ecx
	movl	%ecx, 194188(%rsp)
	movl	1520(%rax), %ecx
	movl	%ecx, 194192(%rsp)
	movl	1524(%rax), %ecx
	movl	%ecx, 194196(%rsp)
	movl	1528(%rax), %ecx
	movl	%ecx, 194200(%rsp)
	movl	1532(%rax), %ecx
	movl	%ecx, 194204(%rsp)
	movl	1536(%rax), %ecx
	movl	%ecx, 194208(%rsp)
	movl	1540(%rax), %ecx
	movl	%ecx, 194212(%rsp)
	movl	1544(%rax), %ecx
	movl	%ecx, 194216(%rsp)
	movl	1548(%rax), %ecx
	movl	%ecx, 194220(%rsp)
	movl	1552(%rax), %ecx
	movl	%ecx, 194224(%rsp)
	movl	1556(%rax), %ecx
	movl	%ecx, 194228(%rsp)
	movl	1560(%rax), %ecx
	movl	%ecx, 194232(%rsp)
	movl	1564(%rax), %ecx
	movl	%ecx, 194236(%rsp)
	movl	1568(%rax), %ecx
	movl	%ecx, 194240(%rsp)
	movl	1572(%rax), %ecx
	movl	%ecx, 194244(%rsp)
	movl	1576(%rax), %ecx
	movl	%ecx, 194248(%rsp)
	movl	1580(%rax), %ecx
	movl	%ecx, 194252(%rsp)
	movl	1584(%rax), %ecx
	movl	%ecx, 194256(%rsp)
	movl	1588(%rax), %ecx
	movl	%ecx, 194260(%rsp)
	movl	1592(%rax), %ecx
	movl	%ecx, 194264(%rsp)
	movl	1596(%rax), %ecx
	movl	%ecx, 194268(%rsp)
	movl	1600(%rax), %ecx
	movl	%ecx, 194272(%rsp)
	movl	1604(%rax), %ecx
	movl	%ecx, 194276(%rsp)
	movl	1608(%rax), %ecx
	movl	%ecx, 194280(%rsp)
	movl	1612(%rax), %ecx
	movl	%ecx, 194284(%rsp)
	movl	1616(%rax), %ecx
	movl	%ecx, 194288(%rsp)
	movl	1620(%rax), %ecx
	movl	%ecx, 194292(%rsp)
	movl	1624(%rax), %ecx
	movl	%ecx, 194296(%rsp)
	movl	1628(%rax), %ecx
	movl	%ecx, 194300(%rsp)
	movl	1632(%rax), %ecx
	movl	%ecx, 194304(%rsp)
	movl	1636(%rax), %ecx
	movl	%ecx, 194308(%rsp)
	movl	1640(%rax), %ecx
	movl	%ecx, 194312(%rsp)
	movl	1644(%rax), %ecx
	movl	%ecx, 194316(%rsp)
	movl	1648(%rax), %ecx
	movl	%ecx, 194320(%rsp)
	movl	1652(%rax), %ecx
	movl	%ecx, 194324(%rsp)
	movl	1656(%rax), %ecx
	movl	%ecx, 194328(%rsp)
	movl	1660(%rax), %ecx
	movl	%ecx, 194332(%rsp)
	movl	1664(%rax), %ecx
	movl	%ecx, 194336(%rsp)
	movl	1668(%rax), %ecx
	movl	%ecx, 194340(%rsp)
	movl	1672(%rax), %ecx
	movl	%ecx, 194344(%rsp)
	movl	1676(%rax), %ecx
	movl	%ecx, 194348(%rsp)
	movl	1680(%rax), %ecx
	movl	%ecx, 194352(%rsp)
	movl	1684(%rax), %ecx
	movl	%ecx, 194356(%rsp)
	movl	1688(%rax), %ecx
	movl	%ecx, 194360(%rsp)
	movl	1692(%rax), %ecx
	movl	%ecx, 194364(%rsp)
	movl	1696(%rax), %ecx
	movl	%ecx, 194368(%rsp)
	movl	1700(%rax), %ecx
	movl	%ecx, 194372(%rsp)
	movl	1704(%rax), %ecx
	movl	%ecx, 194376(%rsp)
	movl	1708(%rax), %ecx
	movl	%ecx, 194380(%rsp)
	movl	1712(%rax), %ecx
	movl	%ecx, 194384(%rsp)
	movl	1716(%rax), %ecx
	movl	%ecx, 194388(%rsp)
	movl	1720(%rax), %ecx
	movl	%ecx, 194392(%rsp)
	movl	1724(%rax), %ecx
	movl	%ecx, 194396(%rsp)
	movl	1728(%rax), %ecx
	movl	%ecx, 194400(%rsp)
	movl	1732(%rax), %ecx
	movl	%ecx, 194404(%rsp)
	movl	1736(%rax), %ecx
	movl	%ecx, 194408(%rsp)
	movl	1740(%rax), %ecx
	movl	%ecx, 194412(%rsp)
	movl	1744(%rax), %ecx
	movl	%ecx, 194416(%rsp)
	movl	1748(%rax), %ecx
	movl	%ecx, 194420(%rsp)
	movl	1752(%rax), %ecx
	movl	%ecx, 194424(%rsp)
	movl	1756(%rax), %ecx
	movl	%ecx, 194428(%rsp)
	movl	1760(%rax), %ecx
	movl	%ecx, 194432(%rsp)
	movl	1764(%rax), %ecx
	movl	%ecx, 194436(%rsp)
	movl	1768(%rax), %ecx
	movl	%ecx, 194440(%rsp)
	movl	1772(%rax), %ecx
	movl	%ecx, 194444(%rsp)
	movl	1776(%rax), %ecx
	movl	%ecx, 194448(%rsp)
	movl	1780(%rax), %ecx
	movl	%ecx, 194452(%rsp)
	movl	1784(%rax), %ecx
	movl	%ecx, 194456(%rsp)
	movl	1788(%rax), %ecx
	movl	%ecx, 194460(%rsp)
	movl	1792(%rax), %ecx
	movl	%ecx, 194464(%rsp)
	movl	1796(%rax), %ecx
	movl	%ecx, 194468(%rsp)
	movl	1800(%rax), %ecx
	movl	%ecx, 194472(%rsp)
	movl	1804(%rax), %ecx
	movl	%ecx, 194476(%rsp)
	movl	1808(%rax), %ecx
	movl	%ecx, 194480(%rsp)
	movl	1812(%rax), %ecx
	movl	%ecx, 194484(%rsp)
	movl	1816(%rax), %ecx
	movl	%ecx, 194488(%rsp)
	movl	1820(%rax), %ecx
	movl	%ecx, 194492(%rsp)
	movl	1824(%rax), %ecx
	movl	%ecx, 194496(%rsp)
	movl	1828(%rax), %ecx
	movl	%ecx, 194500(%rsp)
	movl	1832(%rax), %ecx
	movl	%ecx, 194504(%rsp)
	movl	1836(%rax), %ecx
	movl	%ecx, 194508(%rsp)
	movl	1840(%rax), %ecx
	movl	%ecx, 194512(%rsp)
	movl	1844(%rax), %ecx
	movl	%ecx, 194516(%rsp)
	movl	1848(%rax), %ecx
	movl	%ecx, 194520(%rsp)
	movl	1852(%rax), %ecx
	movl	%ecx, 194524(%rsp)
	movl	1856(%rax), %ecx
	movl	%ecx, 194528(%rsp)
	movl	1860(%rax), %ecx
	movl	%ecx, 194532(%rsp)
	movl	1864(%rax), %ecx
	movl	%ecx, 194536(%rsp)
	movl	1868(%rax), %ecx
	movl	%ecx, 194540(%rsp)
	movl	1872(%rax), %ecx
	movl	%ecx, 194544(%rsp)
	movl	1876(%rax), %ecx
	movl	%ecx, 194548(%rsp)
	movl	1880(%rax), %ecx
	movl	%ecx, 194552(%rsp)
	movl	1884(%rax), %ecx
	movl	%ecx, 194556(%rsp)
	movl	1888(%rax), %ecx
	movl	%ecx, 194560(%rsp)
	movl	1892(%rax), %ecx
	movl	%ecx, 194564(%rsp)
	movl	1896(%rax), %ecx
	movl	%ecx, 194568(%rsp)
	movl	1900(%rax), %ecx
	movl	%ecx, 194572(%rsp)
	movl	1904(%rax), %ecx
	movl	%ecx, 194576(%rsp)
	movl	1908(%rax), %ecx
	movl	%ecx, 194580(%rsp)
	movl	1912(%rax), %ecx
	movl	%ecx, 194584(%rsp)
	movl	1916(%rax), %ecx
	movl	%ecx, 194588(%rsp)
	movl	1920(%rax), %ecx
	movl	%ecx, 194592(%rsp)
	movl	1924(%rax), %ecx
	movl	%ecx, 194596(%rsp)
	movl	1928(%rax), %ecx
	movl	%ecx, 194600(%rsp)
	movl	1932(%rax), %ecx
	movl	%ecx, 194604(%rsp)
	movl	1936(%rax), %ecx
	movl	%ecx, 194608(%rsp)
	movl	1940(%rax), %ecx
	movl	%ecx, 194612(%rsp)
	movl	1944(%rax), %ecx
	movl	%ecx, 194616(%rsp)
	movl	1948(%rax), %ecx
	movl	%ecx, 194620(%rsp)
	movl	1952(%rax), %ecx
	movl	%ecx, 194624(%rsp)
	movl	1956(%rax), %ecx
	movl	%ecx, 194628(%rsp)
	movl	1960(%rax), %ecx
	movl	%ecx, 194632(%rsp)
	movl	1964(%rax), %ecx
	movl	%ecx, 194636(%rsp)
	movl	1968(%rax), %ecx
	movl	%ecx, 194640(%rsp)
	movl	1972(%rax), %ecx
	movl	%ecx, 194644(%rsp)
	movl	1976(%rax), %ecx
	movl	%ecx, 194648(%rsp)
	movl	1980(%rax), %ecx
	movl	%ecx, 194652(%rsp)
	movl	1984(%rax), %ecx
	movl	%ecx, 194656(%rsp)
	movl	1988(%rax), %ecx
	movl	%ecx, 194660(%rsp)
	movl	1992(%rax), %ecx
	movl	%ecx, 194664(%rsp)
	movl	1996(%rax), %ecx
	movl	%ecx, 194668(%rsp)
	movl	2000(%rax), %ecx
	movl	%ecx, 194672(%rsp)
	movl	2004(%rax), %ecx
	movl	%ecx, 194676(%rsp)
	movl	2008(%rax), %ecx
	movl	%ecx, 194680(%rsp)
	movl	2012(%rax), %ecx
	movl	%ecx, 194684(%rsp)
	movl	2016(%rax), %ecx
	movl	%ecx, 194688(%rsp)
	movl	2020(%rax), %ecx
	movl	%ecx, 194692(%rsp)
	movl	2024(%rax), %ecx
	movl	%ecx, 194696(%rsp)
	movl	2028(%rax), %ecx
	movl	%ecx, 194700(%rsp)
	movl	2032(%rax), %ecx
	movl	%ecx, 194704(%rsp)
	movl	2036(%rax), %ecx
	movl	%ecx, 194708(%rsp)
	movl	2040(%rax), %ecx
	movl	%ecx, 194712(%rsp)
	movl	2044(%rax), %ecx
	movl	%ecx, 194716(%rsp)
	movl	2048(%rax), %ecx
	movl	%ecx, 194720(%rsp)
	movl	2052(%rax), %ecx
	movl	%ecx, 194724(%rsp)
	movl	2056(%rax), %ecx
	movl	%ecx, 194728(%rsp)
	movl	2060(%rax), %ecx
	movl	%ecx, 194732(%rsp)
	movl	2064(%rax), %ecx
	movl	%ecx, 194736(%rsp)
	movl	2068(%rax), %ecx
	movl	%ecx, 194740(%rsp)
	movl	2072(%rax), %ecx
	movl	%ecx, 194744(%rsp)
	movl	2076(%rax), %ecx
	movl	%ecx, 194748(%rsp)
	movl	2080(%rax), %ecx
	movl	%ecx, 194752(%rsp)
	movl	2084(%rax), %ecx
	movl	%ecx, 194756(%rsp)
	movl	2088(%rax), %ecx
	movl	%ecx, 194760(%rsp)
	movl	2092(%rax), %ecx
	movl	%ecx, 194764(%rsp)
	movl	2096(%rax), %ecx
	movl	%ecx, 194768(%rsp)
	movl	2100(%rax), %ecx
	movl	%ecx, 194772(%rsp)
	movl	2104(%rax), %ecx
	movl	%ecx, 194776(%rsp)
	movl	2108(%rax), %ecx
	movl	%ecx, 194780(%rsp)
	movl	2112(%rax), %ecx
	movl	%ecx, 194784(%rsp)
	movl	2116(%rax), %ecx
	movl	%ecx, 194788(%rsp)
	movl	2120(%rax), %ecx
	movl	%ecx, 194792(%rsp)
	movl	2124(%rax), %ecx
	movl	%ecx, 194796(%rsp)
	movl	2128(%rax), %ecx
	movl	%ecx, 194800(%rsp)
	movl	2132(%rax), %ecx
	movl	%ecx, 194804(%rsp)
	movl	2136(%rax), %ecx
	movl	%ecx, 194808(%rsp)
	movl	2140(%rax), %ecx
	movl	%ecx, 194812(%rsp)
	movl	2144(%rax), %ecx
	movl	%ecx, 194816(%rsp)
	movl	2148(%rax), %ecx
	movl	%ecx, 194820(%rsp)
	movl	2152(%rax), %ecx
	movl	%ecx, 194824(%rsp)
	movl	2156(%rax), %ecx
	movl	%ecx, 194828(%rsp)
	movl	2160(%rax), %ecx
	movl	%ecx, 194832(%rsp)
	movl	2164(%rax), %ecx
	movl	%ecx, 194836(%rsp)
	movl	2168(%rax), %ecx
	movl	%ecx, 194840(%rsp)
	movl	2172(%rax), %ecx
	movl	%ecx, 194844(%rsp)
	movl	2176(%rax), %ecx
	movl	%ecx, 194848(%rsp)
	movl	2180(%rax), %ecx
	movl	%ecx, 194852(%rsp)
	movl	2184(%rax), %ecx
	movl	%ecx, 194856(%rsp)
	movl	2188(%rax), %ecx
	movl	%ecx, 194860(%rsp)
	movl	2192(%rax), %ecx
	movl	%ecx, 194864(%rsp)
	movl	2196(%rax), %ecx
	movl	%ecx, 194868(%rsp)
	movl	2200(%rax), %ecx
	movl	%ecx, 194872(%rsp)
	movl	2204(%rax), %ecx
	movl	%ecx, 194876(%rsp)
	movl	2208(%rax), %ecx
	movl	%ecx, 194880(%rsp)
	movl	2212(%rax), %ecx
	movl	%ecx, 194884(%rsp)
	movl	2216(%rax), %ecx
	movl	%ecx, 194888(%rsp)
	movl	2220(%rax), %ecx
	movl	%ecx, 194892(%rsp)
	movl	2224(%rax), %ecx
	movl	%ecx, 194896(%rsp)
	movl	2228(%rax), %ecx
	movl	%ecx, 194900(%rsp)
	movl	2232(%rax), %ecx
	movl	%ecx, 194904(%rsp)
	movl	2236(%rax), %ecx
	movl	%ecx, 194908(%rsp)
	movl	2240(%rax), %ecx
	movl	%ecx, 194912(%rsp)
	movl	2244(%rax), %ecx
	movl	%ecx, 194916(%rsp)
	movl	2248(%rax), %ecx
	movl	%ecx, 194920(%rsp)
	movl	2252(%rax), %ecx
	movl	%ecx, 194924(%rsp)
	movl	2256(%rax), %ecx
	movl	%ecx, 194928(%rsp)
	movl	2260(%rax), %ecx
	movl	%ecx, 194932(%rsp)
	movl	2264(%rax), %ecx
	movl	%ecx, 194936(%rsp)
	movl	2268(%rax), %ecx
	movl	%ecx, 194940(%rsp)
	movl	2272(%rax), %ecx
	movl	%ecx, 194944(%rsp)
	movl	2276(%rax), %ecx
	movl	%ecx, 194948(%rsp)
	movl	2280(%rax), %ecx
	movl	%ecx, 194952(%rsp)
	movl	2284(%rax), %ecx
	movl	%ecx, 194956(%rsp)
	movl	2288(%rax), %ecx
	movl	%ecx, 194960(%rsp)
	movl	2292(%rax), %ecx
	movl	%ecx, 194964(%rsp)
	movl	2296(%rax), %ecx
	movl	%ecx, 194968(%rsp)
	movl	2300(%rax), %ecx
	movl	%ecx, 194972(%rsp)
	movl	2304(%rax), %ecx
	movl	%ecx, 194976(%rsp)
	movl	2308(%rax), %ecx
	movl	%ecx, 194980(%rsp)
	movl	2312(%rax), %ecx
	movl	%ecx, 194984(%rsp)
	movl	2316(%rax), %ecx
	movl	%ecx, 194988(%rsp)
	movl	2320(%rax), %ecx
	movl	%ecx, 194992(%rsp)
	movl	2324(%rax), %ecx
	movl	%ecx, 194996(%rsp)
	movl	2328(%rax), %ecx
	movl	%ecx, 195000(%rsp)
	movl	2332(%rax), %ecx
	movl	%ecx, 195004(%rsp)
	movl	2336(%rax), %ecx
	movl	%ecx, 195008(%rsp)
	movl	2340(%rax), %ecx
	movl	%ecx, 195012(%rsp)
	movl	2344(%rax), %ecx
	movl	%ecx, 195016(%rsp)
	movl	2348(%rax), %ecx
	movl	%ecx, 195020(%rsp)
	movl	2352(%rax), %ecx
	movl	%ecx, 195024(%rsp)
	movl	2356(%rax), %ecx
	movl	%ecx, 195028(%rsp)
	movl	2360(%rax), %ecx
	movl	%ecx, 195032(%rsp)
	movl	2364(%rax), %ecx
	movl	%ecx, 195036(%rsp)
	movl	2368(%rax), %ecx
	movl	%ecx, 195040(%rsp)
	movl	2372(%rax), %ecx
	movl	%ecx, 195044(%rsp)
	movl	2376(%rax), %ecx
	movl	%ecx, 195048(%rsp)
	movl	2380(%rax), %ecx
	movl	%ecx, 195052(%rsp)
	movl	2384(%rax), %ecx
	movl	%ecx, 195056(%rsp)
	movl	2388(%rax), %ecx
	movl	%ecx, 195060(%rsp)
	movl	2392(%rax), %ecx
	movl	%ecx, 195064(%rsp)
	movl	2396(%rax), %ecx
	movl	%ecx, 195068(%rsp)
	movl	2400(%rax), %ecx
	movl	%ecx, 195072(%rsp)
	movl	2404(%rax), %ecx
	movl	%ecx, 195076(%rsp)
	movl	2408(%rax), %ecx
	movl	%ecx, 195080(%rsp)
	movl	2412(%rax), %ecx
	movl	%ecx, 195084(%rsp)
	movl	2416(%rax), %ecx
	movl	%ecx, 195088(%rsp)
	movl	2420(%rax), %ecx
	movl	%ecx, 195092(%rsp)
	movl	2424(%rax), %ecx
	movl	%ecx, 195096(%rsp)
	movl	2428(%rax), %ecx
	movl	%ecx, 195100(%rsp)
	movl	2432(%rax), %ecx
	movl	%ecx, 195104(%rsp)
	movl	2436(%rax), %ecx
	movl	%ecx, 195108(%rsp)
	movl	2440(%rax), %ecx
	movl	%ecx, 195112(%rsp)
	movl	2444(%rax), %ecx
	movl	%ecx, 195116(%rsp)
	movl	2448(%rax), %ecx
	movl	%ecx, 195120(%rsp)
	movl	2452(%rax), %ecx
	movl	%ecx, 195124(%rsp)
	movl	2456(%rax), %ecx
	movl	%ecx, 195128(%rsp)
	movl	2460(%rax), %ecx
	movl	%ecx, 195132(%rsp)
	movl	2464(%rax), %ecx
	movl	%ecx, 195136(%rsp)
	movl	2468(%rax), %ecx
	movl	%ecx, 195140(%rsp)
	movl	2472(%rax), %ecx
	movl	%ecx, 195144(%rsp)
	movl	2476(%rax), %ecx
	movl	%ecx, 195148(%rsp)
	movl	2480(%rax), %ecx
	movl	%ecx, 195152(%rsp)
	movl	2484(%rax), %ecx
	movl	%ecx, 195156(%rsp)
	movl	2488(%rax), %ecx
	movl	%ecx, 195160(%rsp)
	movl	2492(%rax), %ecx
	movl	%ecx, 195164(%rsp)
	movl	2496(%rax), %ecx
	movl	%ecx, 195168(%rsp)
	movl	2500(%rax), %ecx
	movl	%ecx, 195172(%rsp)
	movl	2504(%rax), %ecx
	movl	%ecx, 195176(%rsp)
	movl	2508(%rax), %ecx
	movl	%ecx, 195180(%rsp)
	movl	2512(%rax), %ecx
	movl	%ecx, 195184(%rsp)
	movl	2516(%rax), %ecx
	movl	%ecx, 195188(%rsp)
	movl	2520(%rax), %ecx
	movl	%ecx, 195192(%rsp)
	movl	2524(%rax), %ecx
	movl	%ecx, 195196(%rsp)
	movl	2528(%rax), %ecx
	movl	%ecx, 195200(%rsp)
	movl	2532(%rax), %ecx
	movl	%ecx, 195204(%rsp)
	movl	2536(%rax), %ecx
	movl	%ecx, 195208(%rsp)
	movl	2540(%rax), %ecx
	movl	%ecx, 195212(%rsp)
	movl	2544(%rax), %ecx
	movl	%ecx, 195216(%rsp)
	movl	2548(%rax), %ecx
	movl	%ecx, 195220(%rsp)
	movl	2552(%rax), %ecx
	movl	%ecx, 195224(%rsp)
	movl	2556(%rax), %ecx
	movl	%ecx, 195228(%rsp)
	movl	2560(%rax), %ecx
	movl	%ecx, 195232(%rsp)
	movl	2564(%rax), %ecx
	movl	%ecx, 195236(%rsp)
	movl	2568(%rax), %ecx
	movl	%ecx, 195240(%rsp)
	movl	2572(%rax), %ecx
	movl	%ecx, 195244(%rsp)
	movl	2576(%rax), %ecx
	movl	%ecx, 195248(%rsp)
	movl	2580(%rax), %ecx
	movl	%ecx, 195252(%rsp)
	movl	2584(%rax), %ecx
	movl	%ecx, 195256(%rsp)
	movl	2588(%rax), %ecx
	movl	%ecx, 195260(%rsp)
	movl	2592(%rax), %ecx
	movl	%ecx, 195264(%rsp)
	movl	2596(%rax), %ecx
	movl	%ecx, 195268(%rsp)
	movl	2600(%rax), %ecx
	movl	%ecx, 195272(%rsp)
	movl	2604(%rax), %ecx
	movl	%ecx, 195276(%rsp)
	movl	2608(%rax), %ecx
	movl	%ecx, 195280(%rsp)
	movl	2612(%rax), %ecx
	movl	%ecx, 195284(%rsp)
	movl	2616(%rax), %ecx
	movl	%ecx, 195288(%rsp)
	movl	2620(%rax), %ecx
	movl	%ecx, 195292(%rsp)
	movl	2624(%rax), %ecx
	movl	%ecx, 195296(%rsp)
	movl	2628(%rax), %ecx
	movl	%ecx, 195300(%rsp)
	movl	2632(%rax), %ecx
	movl	%ecx, 195304(%rsp)
	movl	2636(%rax), %ecx
	movl	%ecx, 195308(%rsp)
	movl	2640(%rax), %ecx
	movl	%ecx, 195312(%rsp)
	movl	2644(%rax), %ecx
	movl	%ecx, 195316(%rsp)
	movl	2648(%rax), %ecx
	movl	%ecx, 195320(%rsp)
	movl	2652(%rax), %ecx
	movl	%ecx, 195324(%rsp)
	movl	2656(%rax), %ecx
	movl	%ecx, 195328(%rsp)
	movl	2660(%rax), %ecx
	movl	%ecx, 195332(%rsp)
	movl	2664(%rax), %ecx
	movl	%ecx, 195336(%rsp)
	movl	2668(%rax), %ecx
	movl	%ecx, 195340(%rsp)
	movl	2672(%rax), %ecx
	movl	%ecx, 195344(%rsp)
	movl	2676(%rax), %ecx
	movl	%ecx, 195348(%rsp)
	movl	2680(%rax), %ecx
	movl	%ecx, 195352(%rsp)
	movl	2684(%rax), %ecx
	movl	%ecx, 195356(%rsp)
	movl	2688(%rax), %ecx
	movl	%ecx, 195360(%rsp)
	movl	2692(%rax), %ecx
	movl	%ecx, 195364(%rsp)
	movl	2696(%rax), %ecx
	movl	%ecx, 195368(%rsp)
	movl	2700(%rax), %ecx
	movl	%ecx, 195372(%rsp)
	movl	2704(%rax), %ecx
	movl	%ecx, 195376(%rsp)
	movl	2708(%rax), %ecx
	movl	%ecx, 195380(%rsp)
	movl	2712(%rax), %ecx
	movl	%ecx, 195384(%rsp)
	movl	2716(%rax), %ecx
	movl	%ecx, 195388(%rsp)
	movl	2720(%rax), %ecx
	movl	%ecx, 195392(%rsp)
	movl	2724(%rax), %ecx
	movl	%ecx, 195396(%rsp)
	movl	2728(%rax), %ecx
	movl	%ecx, 195400(%rsp)
	movl	2732(%rax), %ecx
	movl	%ecx, 195404(%rsp)
	movl	2736(%rax), %ecx
	movl	%ecx, 195408(%rsp)
	movl	2740(%rax), %ecx
	movl	%ecx, 195412(%rsp)
	movl	2744(%rax), %ecx
	movl	%ecx, 195416(%rsp)
	movl	2748(%rax), %ecx
	movl	%ecx, 195420(%rsp)
	movl	2752(%rax), %ecx
	movl	%ecx, 195424(%rsp)
	movl	2756(%rax), %ecx
	movl	%ecx, 195428(%rsp)
	movl	2760(%rax), %ecx
	movl	%ecx, 195432(%rsp)
	movl	2764(%rax), %ecx
	movl	%ecx, 195436(%rsp)
	movl	2768(%rax), %ecx
	movl	%ecx, 195440(%rsp)
	movl	2772(%rax), %ecx
	movl	%ecx, 195444(%rsp)
	movl	2776(%rax), %ecx
	movl	%ecx, 195448(%rsp)
	movl	2780(%rax), %ecx
	movl	%ecx, 195452(%rsp)
	movl	2784(%rax), %ecx
	movl	%ecx, 195456(%rsp)
	movl	2788(%rax), %ecx
	movl	%ecx, 195460(%rsp)
	movl	2792(%rax), %ecx
	movl	%ecx, 195464(%rsp)
	movl	2796(%rax), %ecx
	movl	%ecx, 195468(%rsp)
	movl	2800(%rax), %ecx
	movl	%ecx, 195472(%rsp)
	movl	2804(%rax), %ecx
	movl	%ecx, 195476(%rsp)
	movl	2808(%rax), %ecx
	movl	%ecx, 195480(%rsp)
	movl	2812(%rax), %ecx
	movl	%ecx, 195484(%rsp)
	movl	2816(%rax), %ecx
	movl	%ecx, 195488(%rsp)
	movl	2820(%rax), %ecx
	movl	%ecx, 195492(%rsp)
	movl	2824(%rax), %ecx
	movl	%ecx, 195496(%rsp)
	movl	2828(%rax), %ecx
	movl	%ecx, 195500(%rsp)
	movl	2832(%rax), %ecx
	movl	%ecx, 195504(%rsp)
	movl	2836(%rax), %ecx
	movl	%ecx, 195508(%rsp)
	movl	2840(%rax), %ecx
	movl	%ecx, 195512(%rsp)
	movl	2844(%rax), %ecx
	movl	%ecx, 195516(%rsp)
	movl	2848(%rax), %ecx
	movl	%ecx, 195520(%rsp)
	movl	2852(%rax), %ecx
	movl	%ecx, 195524(%rsp)
	movl	2856(%rax), %ecx
	movl	%ecx, 195528(%rsp)
	movl	2860(%rax), %ecx
	movl	%ecx, 195532(%rsp)
	movl	2864(%rax), %ecx
	movl	%ecx, 195536(%rsp)
	movl	2868(%rax), %ecx
	movl	%ecx, 195540(%rsp)
	movl	2872(%rax), %ecx
	movl	%ecx, 195544(%rsp)
	movl	2876(%rax), %ecx
	movl	%ecx, 195548(%rsp)
	movl	2880(%rax), %ecx
	movl	%ecx, 195552(%rsp)
	movl	2884(%rax), %ecx
	movl	%ecx, 195556(%rsp)
	movl	2888(%rax), %ecx
	movl	%ecx, 195560(%rsp)
	movl	2892(%rax), %ecx
	movl	%ecx, 195564(%rsp)
	movl	2896(%rax), %ecx
	movl	%ecx, 195568(%rsp)
	movl	2900(%rax), %ecx
	movl	%ecx, 195572(%rsp)
	movl	2904(%rax), %ecx
	movl	%ecx, 195576(%rsp)
	movl	2908(%rax), %ecx
	movl	%ecx, 195580(%rsp)
	movl	2912(%rax), %ecx
	movl	%ecx, 195584(%rsp)
	movl	2916(%rax), %ecx
	movl	%ecx, 195588(%rsp)
	movl	2920(%rax), %ecx
	movl	%ecx, 195592(%rsp)
	movl	2924(%rax), %ecx
	movl	%ecx, 195596(%rsp)
	movl	2928(%rax), %ecx
	movl	%ecx, 195600(%rsp)
	movl	2932(%rax), %ecx
	movl	%ecx, 195604(%rsp)
	movl	2936(%rax), %ecx
	movl	%ecx, 195608(%rsp)
	movl	2940(%rax), %ecx
	movl	%ecx, 195612(%rsp)
	movl	2944(%rax), %ecx
	movl	%ecx, 195616(%rsp)
	movl	2948(%rax), %ecx
	movl	%ecx, 195620(%rsp)
	movl	2952(%rax), %ecx
	movl	%ecx, 195624(%rsp)
	movl	2956(%rax), %ecx
	movl	%ecx, 195628(%rsp)
	movl	2960(%rax), %ecx
	movl	%ecx, 195632(%rsp)
	movl	2964(%rax), %ecx
	movl	%ecx, 195636(%rsp)
	movl	2968(%rax), %ecx
	movl	%ecx, 195640(%rsp)
	movl	2972(%rax), %ecx
	movl	%ecx, 195644(%rsp)
	movl	2976(%rax), %ecx
	movl	%ecx, 195648(%rsp)
	movl	2980(%rax), %ecx
	movl	%ecx, 195652(%rsp)
	movl	2984(%rax), %ecx
	movl	%ecx, 195656(%rsp)
	movl	2988(%rax), %ecx
	movl	%ecx, 195660(%rsp)
	movl	2992(%rax), %ecx
	movl	%ecx, 195664(%rsp)
	movl	2996(%rax), %ecx
	movl	%ecx, 195668(%rsp)
	movl	3000(%rax), %ecx
	movl	%ecx, 195672(%rsp)
	movl	3004(%rax), %ecx
	movl	%ecx, 195676(%rsp)
	movl	3008(%rax), %ecx
	movl	%ecx, 195680(%rsp)
	movl	3012(%rax), %ecx
	movl	%ecx, 195684(%rsp)
	movl	3016(%rax), %ecx
	movl	%ecx, 195688(%rsp)
	movl	3020(%rax), %ecx
	movl	%ecx, 195692(%rsp)
	movl	3024(%rax), %ecx
	movl	%ecx, 195696(%rsp)
	movl	3028(%rax), %ecx
	movl	%ecx, 195700(%rsp)
	movl	3032(%rax), %ecx
	movl	%ecx, 195704(%rsp)
	movl	3036(%rax), %ecx
	movl	%ecx, 195708(%rsp)
	movl	3040(%rax), %ecx
	movl	%ecx, 195712(%rsp)
	movl	3044(%rax), %ecx
	movl	%ecx, 195716(%rsp)
	movl	3048(%rax), %ecx
	movl	%ecx, 195720(%rsp)
	movl	3052(%rax), %ecx
	movl	%ecx, 195724(%rsp)
	movl	3056(%rax), %ecx
	movl	%ecx, 195728(%rsp)
	movl	3060(%rax), %ecx
	movl	%ecx, 195732(%rsp)
	movl	3064(%rax), %ecx
	movl	%ecx, 195736(%rsp)
	movl	3068(%rax), %ecx
	movl	%ecx, 195740(%rsp)
	movl	3072(%rax), %ecx
	movl	%ecx, 195744(%rsp)
	movl	3076(%rax), %ecx
	movl	%ecx, 195748(%rsp)
	movl	3080(%rax), %ecx
	movl	%ecx, 195752(%rsp)
	movl	3084(%rax), %ecx
	movl	%ecx, 195756(%rsp)
	movl	3088(%rax), %ecx
	movl	%ecx, 195760(%rsp)
	movl	3092(%rax), %ecx
	movl	%ecx, 195764(%rsp)
	movl	3096(%rax), %ecx
	movl	%ecx, 195768(%rsp)
	movl	3100(%rax), %ecx
	movl	%ecx, 195772(%rsp)
	movl	3104(%rax), %ecx
	movl	%ecx, 195776(%rsp)
	movl	3108(%rax), %ecx
	movl	%ecx, 195780(%rsp)
	movl	3112(%rax), %ecx
	movl	%ecx, 195784(%rsp)
	movl	3116(%rax), %ecx
	movl	%ecx, 195788(%rsp)
	movl	3120(%rax), %ecx
	movl	%ecx, 195792(%rsp)
	movl	3124(%rax), %ecx
	movl	%ecx, 195796(%rsp)
	movl	3128(%rax), %ecx
	movl	%ecx, 195800(%rsp)
	movl	3132(%rax), %ecx
	movl	%ecx, 195804(%rsp)
	movl	3136(%rax), %ecx
	movl	%ecx, 195808(%rsp)
	movl	3140(%rax), %ecx
	movl	%ecx, 195812(%rsp)
	movl	3144(%rax), %ecx
	movl	%ecx, 195816(%rsp)
	movl	3148(%rax), %ecx
	movl	%ecx, 195820(%rsp)
	movl	3152(%rax), %ecx
	movl	%ecx, 195824(%rsp)
	movl	3156(%rax), %ecx
	movl	%ecx, 195828(%rsp)
	movl	3160(%rax), %ecx
	movl	%ecx, 195832(%rsp)
	movl	3164(%rax), %ecx
	movl	%ecx, 195836(%rsp)
	movl	3168(%rax), %ecx
	movl	%ecx, 195840(%rsp)
	movl	3172(%rax), %ecx
	movl	%ecx, 195844(%rsp)
	movl	3176(%rax), %ecx
	movl	%ecx, 195848(%rsp)
	movl	3180(%rax), %ecx
	movl	%ecx, 195852(%rsp)
	movl	3184(%rax), %ecx
	movl	%ecx, 195856(%rsp)
	movl	3188(%rax), %ecx
	movl	%ecx, 195860(%rsp)
	movl	3192(%rax), %ecx
	movl	%ecx, 195864(%rsp)
	movl	3196(%rax), %ecx
	movl	%ecx, 195868(%rsp)
	movl	3200(%rax), %ecx
	movl	%ecx, 195872(%rsp)
	movl	3204(%rax), %ecx
	movl	%ecx, 195876(%rsp)
	movl	3208(%rax), %ecx
	movl	%ecx, 195880(%rsp)
	movl	3212(%rax), %ecx
	movl	%ecx, 195884(%rsp)
	movl	3216(%rax), %ecx
	movl	%ecx, 195888(%rsp)
	movl	3220(%rax), %ecx
	movl	%ecx, 195892(%rsp)
	movl	3224(%rax), %ecx
	movl	%ecx, 195896(%rsp)
	movl	3228(%rax), %ecx
	movl	%ecx, 195900(%rsp)
	movl	3232(%rax), %ecx
	movl	%ecx, 195904(%rsp)
	movl	3236(%rax), %ecx
	movl	%ecx, 195908(%rsp)
	movl	3240(%rax), %ecx
	movl	%ecx, 195912(%rsp)
	movl	3244(%rax), %ecx
	movl	%ecx, 195916(%rsp)
	movl	3248(%rax), %ecx
	movl	%ecx, 195920(%rsp)
	movl	3252(%rax), %ecx
	movl	%ecx, 195924(%rsp)
	movl	3256(%rax), %ecx
	movl	%ecx, 195928(%rsp)
	movl	3260(%rax), %ecx
	movl	%ecx, 195932(%rsp)
	movl	3264(%rax), %ecx
	movl	%ecx, 195936(%rsp)
	movl	3268(%rax), %ecx
	movl	%ecx, 195940(%rsp)
	movl	3272(%rax), %ecx
	movl	%ecx, 195944(%rsp)
	movl	3276(%rax), %ecx
	movl	%ecx, 195948(%rsp)
	movl	3280(%rax), %ecx
	movl	%ecx, 195952(%rsp)
	movl	3284(%rax), %ecx
	movl	%ecx, 195956(%rsp)
	movl	3288(%rax), %ecx
	movl	%ecx, 195960(%rsp)
	movl	3292(%rax), %ecx
	movl	%ecx, 195964(%rsp)
	movl	3296(%rax), %ecx
	movl	%ecx, 195968(%rsp)
	movl	3300(%rax), %ecx
	movl	%ecx, 195972(%rsp)
	movl	3304(%rax), %ecx
	movl	%ecx, 195976(%rsp)
	movl	3308(%rax), %ecx
	movl	%ecx, 195980(%rsp)
	movl	3312(%rax), %ecx
	movl	%ecx, 195984(%rsp)
	movl	3316(%rax), %ecx
	movl	%ecx, 195988(%rsp)
	movl	3320(%rax), %ecx
	movl	%ecx, 195992(%rsp)
	movl	3324(%rax), %ecx
	movl	%ecx, 195996(%rsp)
	movl	3328(%rax), %ecx
	movl	%ecx, 196000(%rsp)
	movl	3332(%rax), %ecx
	movl	%ecx, 196004(%rsp)
	movl	3336(%rax), %ecx
	movl	%ecx, 196008(%rsp)
	movl	3340(%rax), %ecx
	movl	%ecx, 196012(%rsp)
	movl	3344(%rax), %ecx
	movl	%ecx, 196016(%rsp)
	movl	3348(%rax), %ecx
	movl	%ecx, 196020(%rsp)
	movl	3352(%rax), %ecx
	movl	%ecx, 196024(%rsp)
	movl	3356(%rax), %ecx
	movl	%ecx, 196028(%rsp)
	movl	3360(%rax), %ecx
	movl	%ecx, 196032(%rsp)
	movl	3364(%rax), %ecx
	movl	%ecx, 196036(%rsp)
	movl	3368(%rax), %ecx
	movl	%ecx, 196040(%rsp)
	movl	3372(%rax), %ecx
	movl	%ecx, 196044(%rsp)
	movl	3376(%rax), %ecx
	movl	%ecx, 196048(%rsp)
	movl	3380(%rax), %ecx
	movl	%ecx, 196052(%rsp)
	movl	3384(%rax), %ecx
	movl	%ecx, 196056(%rsp)
	movl	3388(%rax), %ecx
	movl	%ecx, 196060(%rsp)
	movl	3392(%rax), %ecx
	movl	%ecx, 196064(%rsp)
	movl	3396(%rax), %ecx
	movl	%ecx, 196068(%rsp)
	movl	3400(%rax), %ecx
	movl	%ecx, 196072(%rsp)
	movl	3404(%rax), %ecx
	movl	%ecx, 196076(%rsp)
	movl	3408(%rax), %ecx
	movl	%ecx, 196080(%rsp)
	movl	3412(%rax), %ecx
	movl	%ecx, 196084(%rsp)
	movl	3416(%rax), %ecx
	movl	%ecx, 196088(%rsp)
	movl	3420(%rax), %ecx
	movl	%ecx, 196092(%rsp)
	movl	3424(%rax), %ecx
	movl	%ecx, 196096(%rsp)
	movl	3428(%rax), %ecx
	movl	%ecx, 196100(%rsp)
	movl	3432(%rax), %ecx
	movl	%ecx, 196104(%rsp)
	movl	3436(%rax), %ecx
	movl	%ecx, 196108(%rsp)
	movl	3440(%rax), %ecx
	movl	%ecx, 196112(%rsp)
	movl	3444(%rax), %ecx
	movl	%ecx, 196116(%rsp)
	movl	3448(%rax), %ecx
	movl	%ecx, 196120(%rsp)
	movl	3452(%rax), %ecx
	movl	%ecx, 196124(%rsp)
	movl	3456(%rax), %ecx
	movl	%ecx, 196128(%rsp)
	movl	3460(%rax), %ecx
	movl	%ecx, 196132(%rsp)
	movl	3464(%rax), %ecx
	movl	%ecx, 196136(%rsp)
	movl	3468(%rax), %ecx
	movl	%ecx, 196140(%rsp)
	movl	3472(%rax), %ecx
	movl	%ecx, 196144(%rsp)
	movl	3476(%rax), %ecx
	movl	%ecx, 196148(%rsp)
	movl	3480(%rax), %ecx
	movl	%ecx, 196152(%rsp)
	movl	3484(%rax), %ecx
	movl	%ecx, 196156(%rsp)
	movl	3488(%rax), %ecx
	movl	%ecx, 196160(%rsp)
	movl	3492(%rax), %ecx
	movl	%ecx, 196164(%rsp)
	movl	3496(%rax), %ecx
	movl	%ecx, 196168(%rsp)
	movl	3500(%rax), %ecx
	movl	%ecx, 196172(%rsp)
	movl	3504(%rax), %ecx
	movl	%ecx, 196176(%rsp)
	movl	3508(%rax), %ecx
	movl	%ecx, 196180(%rsp)
	movl	3512(%rax), %ecx
	movl	%ecx, 196184(%rsp)
	movl	3516(%rax), %ecx
	movl	%ecx, 196188(%rsp)
	movl	3520(%rax), %ecx
	movl	%ecx, 196192(%rsp)
	movl	3524(%rax), %ecx
	movl	%ecx, 196196(%rsp)
	movl	3528(%rax), %ecx
	movl	%ecx, 196200(%rsp)
	movl	3532(%rax), %ecx
	movl	%ecx, 196204(%rsp)
	movl	3536(%rax), %ecx
	movl	%ecx, 196208(%rsp)
	movl	3540(%rax), %ecx
	movl	%ecx, 196212(%rsp)
	movl	3544(%rax), %ecx
	movl	%ecx, 196216(%rsp)
	movl	3548(%rax), %ecx
	movl	%ecx, 196220(%rsp)
	movl	3552(%rax), %ecx
	movl	%ecx, 196224(%rsp)
	movl	3556(%rax), %ecx
	movl	%ecx, 196228(%rsp)
	movl	3560(%rax), %ecx
	movl	%ecx, 196232(%rsp)
	movl	3564(%rax), %ecx
	movl	%ecx, 196236(%rsp)
	movl	3568(%rax), %ecx
	movl	%ecx, 196240(%rsp)
	movl	3572(%rax), %ecx
	movl	%ecx, 196244(%rsp)
	movl	3576(%rax), %ecx
	movl	%ecx, 196248(%rsp)
	movl	3580(%rax), %ecx
	movl	%ecx, 196252(%rsp)
	movl	3584(%rax), %ecx
	movl	%ecx, 196256(%rsp)
	movl	3588(%rax), %ecx
	movl	%ecx, 196260(%rsp)
	movl	3592(%rax), %ecx
	movl	%ecx, 196264(%rsp)
	movl	3596(%rax), %ecx
	movl	%ecx, 196268(%rsp)
	movl	3600(%rax), %ecx
	movl	%ecx, 196272(%rsp)
	movl	3604(%rax), %ecx
	movl	%ecx, 196276(%rsp)
	movl	3608(%rax), %ecx
	movl	%ecx, 196280(%rsp)
	movl	3612(%rax), %ecx
	movl	%ecx, 196284(%rsp)
	movl	3616(%rax), %ecx
	movl	%ecx, 196288(%rsp)
	movl	3620(%rax), %ecx
	movl	%ecx, 196292(%rsp)
	movl	3624(%rax), %ecx
	movl	%ecx, 196296(%rsp)
	movl	3628(%rax), %ecx
	movl	%ecx, 196300(%rsp)
	movl	3632(%rax), %ecx
	movl	%ecx, 196304(%rsp)
	movl	3636(%rax), %ecx
	movl	%ecx, 196308(%rsp)
	movl	3640(%rax), %ecx
	movl	%ecx, 196312(%rsp)
	movl	3644(%rax), %ecx
	movl	%ecx, 196316(%rsp)
	movl	3648(%rax), %ecx
	movl	%ecx, 196320(%rsp)
	movl	3652(%rax), %ecx
	movl	%ecx, 196324(%rsp)
	movl	3656(%rax), %ecx
	movl	%ecx, 196328(%rsp)
	movl	3660(%rax), %ecx
	movl	%ecx, 196332(%rsp)
	movl	3664(%rax), %ecx
	movl	%ecx, 196336(%rsp)
	movl	3668(%rax), %ecx
	movl	%ecx, 196340(%rsp)
	movl	3672(%rax), %ecx
	movl	%ecx, 196344(%rsp)
	movl	3676(%rax), %ecx
	movl	%ecx, 196348(%rsp)
	movl	3680(%rax), %ecx
	movl	%ecx, 196352(%rsp)
	movl	3684(%rax), %ecx
	movl	%ecx, 196356(%rsp)
	movl	3688(%rax), %ecx
	movl	%ecx, 196360(%rsp)
	movl	3692(%rax), %ecx
	movl	%ecx, 196364(%rsp)
	movl	3696(%rax), %ecx
	movl	%ecx, 196368(%rsp)
	movl	3700(%rax), %ecx
	movl	%ecx, 196372(%rsp)
	movl	3704(%rax), %ecx
	movl	%ecx, 196376(%rsp)
	movl	3708(%rax), %ecx
	movl	%ecx, 196380(%rsp)
	movl	3712(%rax), %ecx
	movl	%ecx, 196384(%rsp)
	movl	3716(%rax), %ecx
	movl	%ecx, 196388(%rsp)
	movl	3720(%rax), %ecx
	movl	%ecx, 196392(%rsp)
	movl	3724(%rax), %ecx
	movl	%ecx, 196396(%rsp)
	movl	3728(%rax), %ecx
	movl	%ecx, 196400(%rsp)
	movl	3732(%rax), %ecx
	movl	%ecx, 196404(%rsp)
	movl	3736(%rax), %ecx
	movl	%ecx, 196408(%rsp)
	movl	3740(%rax), %ecx
	movl	%ecx, 196412(%rsp)
	movl	3744(%rax), %ecx
	movl	%ecx, 196416(%rsp)
	movl	3748(%rax), %ecx
	movl	%ecx, 196420(%rsp)
	movl	3752(%rax), %ecx
	movl	%ecx, 196424(%rsp)
	movl	3756(%rax), %ecx
	movl	%ecx, 196428(%rsp)
	movl	3760(%rax), %ecx
	movl	%ecx, 196432(%rsp)
	movl	3764(%rax), %ecx
	movl	%ecx, 196436(%rsp)
	movl	3768(%rax), %ecx
	movl	%ecx, 196440(%rsp)
	movl	3772(%rax), %ecx
	movl	%ecx, 196444(%rsp)
	movl	3776(%rax), %ecx
	movl	%ecx, 196448(%rsp)
	movl	3780(%rax), %ecx
	movl	%ecx, 196452(%rsp)
	movl	3784(%rax), %ecx
	movl	%ecx, 196456(%rsp)
	movl	3788(%rax), %ecx
	movl	%ecx, 196460(%rsp)
	movl	3792(%rax), %ecx
	movl	%ecx, 196464(%rsp)
	movl	3796(%rax), %ecx
	movl	%ecx, 196468(%rsp)
	movl	3800(%rax), %ecx
	movl	%ecx, 196472(%rsp)
	movl	3804(%rax), %ecx
	movl	%ecx, 196476(%rsp)
	movl	3808(%rax), %ecx
	movl	%ecx, 196480(%rsp)
	movl	3812(%rax), %ecx
	movl	%ecx, 196484(%rsp)
	movl	3816(%rax), %ecx
	movl	%ecx, 196488(%rsp)
	movl	3820(%rax), %ecx
	movl	%ecx, 196492(%rsp)
	movl	3824(%rax), %ecx
	movl	%ecx, 196496(%rsp)
	movl	3828(%rax), %ecx
	movl	%ecx, 196500(%rsp)
	movl	3832(%rax), %ecx
	movl	%ecx, 196504(%rsp)
	movl	3836(%rax), %ecx
	movl	%ecx, 196508(%rsp)
	movl	3840(%rax), %ecx
	movl	%ecx, 196512(%rsp)
	movl	3844(%rax), %ecx
	movl	%ecx, 196516(%rsp)
	movl	3848(%rax), %ecx
	movl	%ecx, 196520(%rsp)
	movl	3852(%rax), %ecx
	movl	%ecx, 196524(%rsp)
	movl	3856(%rax), %ecx
	movl	%ecx, 196528(%rsp)
	movl	3860(%rax), %ecx
	movl	%ecx, 196532(%rsp)
	movl	3864(%rax), %ecx
	movl	%ecx, 196536(%rsp)
	movl	3868(%rax), %ecx
	movl	%ecx, 196540(%rsp)
	movl	3872(%rax), %ecx
	movl	%ecx, 196544(%rsp)
	movl	3876(%rax), %ecx
	movl	%ecx, 196548(%rsp)
	movl	3880(%rax), %ecx
	movl	%ecx, 196552(%rsp)
	movl	3884(%rax), %ecx
	movl	%ecx, 196556(%rsp)
	movl	3888(%rax), %ecx
	movl	%ecx, 196560(%rsp)
	movl	3892(%rax), %ecx
	movl	%ecx, 196564(%rsp)
	movl	3896(%rax), %ecx
	movl	%ecx, 196568(%rsp)
	movl	3900(%rax), %ecx
	movl	%ecx, 196572(%rsp)
	movl	3904(%rax), %ecx
	movl	%ecx, 196576(%rsp)
	movl	3908(%rax), %ecx
	movl	%ecx, 196580(%rsp)
	movl	3912(%rax), %ecx
	movl	%ecx, 196584(%rsp)
	movl	3916(%rax), %ecx
	movl	%ecx, 196588(%rsp)
	movl	3920(%rax), %ecx
	movl	%ecx, 196592(%rsp)
	movl	3924(%rax), %ecx
	movl	%ecx, 196596(%rsp)
	movl	3928(%rax), %ecx
	movl	%ecx, 196600(%rsp)
	movl	3932(%rax), %ecx
	movl	%ecx, 196604(%rsp)
	movl	3936(%rax), %ecx
	movl	%ecx, 196608(%rsp)
	movl	3940(%rax), %ecx
	movl	%ecx, 196612(%rsp)
	movl	3944(%rax), %ecx
	movl	%ecx, 196616(%rsp)
	movl	3948(%rax), %ecx
	movl	%ecx, 196620(%rsp)
	movl	3952(%rax), %ecx
	movl	%ecx, 196624(%rsp)
	movl	3956(%rax), %ecx
	movl	%ecx, 196628(%rsp)
	movl	3960(%rax), %ecx
	movl	%ecx, 196632(%rsp)
	movl	3964(%rax), %ecx
	movl	%ecx, 196636(%rsp)
	movl	3968(%rax), %ecx
	movl	%ecx, 196640(%rsp)
	movl	3972(%rax), %ecx
	movl	%ecx, 196644(%rsp)
	movl	3976(%rax), %ecx
	movl	%ecx, 196648(%rsp)
	movl	3980(%rax), %ecx
	movl	%ecx, 196652(%rsp)
	movl	3984(%rax), %ecx
	movl	%ecx, 196656(%rsp)
	movl	3988(%rax), %ecx
	movl	%ecx, 196660(%rsp)
	movl	3992(%rax), %ecx
	movl	%ecx, 196664(%rsp)
	movl	3996(%rax), %ecx
	movl	%ecx, 196668(%rsp)
	movl	4000(%rax), %ecx
	movl	%ecx, 196672(%rsp)
	movl	4004(%rax), %ecx
	movl	%ecx, 196676(%rsp)
	movl	4008(%rax), %ecx
	movl	%ecx, 196680(%rsp)
	movl	4012(%rax), %ecx
	movl	%ecx, 196684(%rsp)
	movl	4016(%rax), %ecx
	movl	%ecx, 196688(%rsp)
	movl	4020(%rax), %ecx
	movl	%ecx, 196692(%rsp)
	movl	4024(%rax), %ecx
	movl	%ecx, 196696(%rsp)
	movl	4028(%rax), %ecx
	movl	%ecx, 196700(%rsp)
	movl	4032(%rax), %ecx
	movl	%ecx, 196704(%rsp)
	movl	4036(%rax), %ecx
	movl	%ecx, 196708(%rsp)
	movl	4040(%rax), %ecx
	movl	%ecx, 196712(%rsp)
	movl	4044(%rax), %ecx
	movl	%ecx, 196716(%rsp)
	movl	4048(%rax), %ecx
	movl	%ecx, 196720(%rsp)
	movl	4052(%rax), %ecx
	movl	%ecx, 196724(%rsp)
	movl	4056(%rax), %ecx
	movl	%ecx, 196728(%rsp)
	movl	4060(%rax), %ecx
	movl	%ecx, 196732(%rsp)
	movl	4064(%rax), %ecx
	movl	%ecx, 196736(%rsp)
	movl	4068(%rax), %ecx
	movl	%ecx, 196740(%rsp)
	movl	4072(%rax), %ecx
	movl	%ecx, 196744(%rsp)
	movl	4076(%rax), %ecx
	movl	%ecx, 196748(%rsp)
	movl	4080(%rax), %ecx
	movl	%ecx, 196752(%rsp)
	movl	4084(%rax), %ecx
	movl	%ecx, 196756(%rsp)
	movl	4088(%rax), %ecx
	movl	%ecx, 196760(%rsp)
	movl	4092(%rax), %ecx
	movl	%ecx, 196764(%rsp)
	movl	4096(%rax), %ecx
	movl	%ecx, 196768(%rsp)
	movl	4100(%rax), %ecx
	movl	%ecx, 196772(%rsp)
	movl	4104(%rax), %ecx
	movl	%ecx, 196776(%rsp)
	movl	4108(%rax), %ecx
	movl	%ecx, 196780(%rsp)
	movl	4112(%rax), %ecx
	movl	%ecx, 196784(%rsp)
	movl	4116(%rax), %ecx
	movl	%ecx, 196788(%rsp)
	movl	4120(%rax), %ecx
	movl	%ecx, 196792(%rsp)
	movl	4124(%rax), %ecx
	movl	%ecx, 196796(%rsp)
	movl	4128(%rax), %ecx
	movl	%ecx, 196800(%rsp)
	movl	4132(%rax), %ecx
	movl	%ecx, 196804(%rsp)
	movl	4136(%rax), %ecx
	movl	%ecx, 196808(%rsp)
	movl	4140(%rax), %ecx
	movl	%ecx, 196812(%rsp)
	movl	4144(%rax), %ecx
	movl	%ecx, 196816(%rsp)
	movl	4148(%rax), %ecx
	movl	%ecx, 196820(%rsp)
	movl	4152(%rax), %ecx
	movl	%ecx, 196824(%rsp)
	movl	4156(%rax), %ecx
	movl	%ecx, 196828(%rsp)
	movl	4160(%rax), %ecx
	movl	%ecx, 196832(%rsp)
	movl	4164(%rax), %ecx
	movl	%ecx, 196836(%rsp)
	movl	4168(%rax), %ecx
	movl	%ecx, 196840(%rsp)
	movl	4172(%rax), %ecx
	movl	%ecx, 196844(%rsp)
	movl	4176(%rax), %ecx
	movl	%ecx, 196848(%rsp)
	movl	4180(%rax), %ecx
	movl	%ecx, 196852(%rsp)
	movl	4184(%rax), %ecx
	movl	%ecx, 196856(%rsp)
	movl	4188(%rax), %ecx
	movl	%ecx, 196860(%rsp)
	movl	4192(%rax), %ecx
	movl	%ecx, 196864(%rsp)
	movl	4196(%rax), %ecx
	movl	%ecx, 196868(%rsp)
	movl	4200(%rax), %ecx
	movl	%ecx, 196872(%rsp)
	movl	4204(%rax), %ecx
	movl	%ecx, 196876(%rsp)
	movl	4208(%rax), %ecx
	movl	%ecx, 196880(%rsp)
	movl	4212(%rax), %ecx
	movl	%ecx, 196884(%rsp)
	movl	4216(%rax), %ecx
	movl	%ecx, 196888(%rsp)
	movl	4220(%rax), %ecx
	movl	%ecx, 196892(%rsp)
	movl	4224(%rax), %ecx
	movl	%ecx, 196896(%rsp)
	movl	4228(%rax), %ecx
	movl	%ecx, 196900(%rsp)
	movl	4232(%rax), %ecx
	movl	%ecx, 196904(%rsp)
	movl	4236(%rax), %ecx
	movl	%ecx, 196908(%rsp)
	movl	4240(%rax), %ecx
	movl	%ecx, 196912(%rsp)
	movl	4244(%rax), %ecx
	movl	%ecx, 196916(%rsp)
	movl	4248(%rax), %ecx
	movl	%ecx, 196920(%rsp)
	movl	4252(%rax), %ecx
	movl	%ecx, 196924(%rsp)
	movl	4256(%rax), %ecx
	movl	%ecx, 196928(%rsp)
	movl	4260(%rax), %ecx
	movl	%ecx, 196932(%rsp)
	movl	4264(%rax), %ecx
	movl	%ecx, 196936(%rsp)
	movl	4268(%rax), %ecx
	movl	%ecx, 196940(%rsp)
	movl	4272(%rax), %ecx
	movl	%ecx, 196944(%rsp)
	movl	4276(%rax), %ecx
	movl	%ecx, 196948(%rsp)
	movl	4280(%rax), %ecx
	movl	%ecx, 196952(%rsp)
	movl	4284(%rax), %ecx
	movl	%ecx, 196956(%rsp)
	movl	4288(%rax), %ecx
	movl	%ecx, 196960(%rsp)
	movl	4292(%rax), %ecx
	movl	%ecx, 196964(%rsp)
	movl	4296(%rax), %ecx
	movl	%ecx, 196968(%rsp)
	movl	4300(%rax), %ecx
	movl	%ecx, 196972(%rsp)
	movl	4304(%rax), %ecx
	movl	%ecx, 196976(%rsp)
	movl	4308(%rax), %ecx
	movl	%ecx, 196980(%rsp)
	movl	4312(%rax), %ecx
	movl	%ecx, 196984(%rsp)
	movl	4316(%rax), %ecx
	movl	%ecx, 196988(%rsp)
	movl	4320(%rax), %ecx
	movl	%ecx, 196992(%rsp)
	movl	4324(%rax), %ecx
	movl	%ecx, 196996(%rsp)
	movl	4328(%rax), %ecx
	movl	%ecx, 197000(%rsp)
	movl	4332(%rax), %ecx
	movl	%ecx, 197004(%rsp)
	movl	4336(%rax), %ecx
	movl	%ecx, 197008(%rsp)
	movl	4340(%rax), %ecx
	movl	%ecx, 197012(%rsp)
	movl	4344(%rax), %ecx
	movl	%ecx, 197016(%rsp)
	movl	4348(%rax), %ecx
	movl	%ecx, 197020(%rsp)
	movl	4352(%rax), %ecx
	movl	%ecx, 197024(%rsp)
	movl	4356(%rax), %ecx
	movl	%ecx, 197028(%rsp)
	movl	4360(%rax), %ecx
	movl	%ecx, 197032(%rsp)
	movl	4364(%rax), %ecx
	movl	%ecx, 197036(%rsp)
	movl	4368(%rax), %ecx
	movl	%ecx, 197040(%rsp)
	movl	4372(%rax), %ecx
	movl	%ecx, 197044(%rsp)
	movl	4376(%rax), %ecx
	movl	%ecx, 197048(%rsp)
	movl	4380(%rax), %ecx
	movl	%ecx, 197052(%rsp)
	movl	4384(%rax), %ecx
	movl	%ecx, 197056(%rsp)
	movl	4388(%rax), %ecx
	movl	%ecx, 197060(%rsp)
	movl	4392(%rax), %ecx
	movl	%ecx, 197064(%rsp)
	movl	4396(%rax), %ecx
	movl	%ecx, 197068(%rsp)
	movl	4400(%rax), %ecx
	movl	%ecx, 197072(%rsp)
	movl	4404(%rax), %ecx
	movl	%ecx, 197076(%rsp)
	movl	4408(%rax), %ecx
	movl	%ecx, 197080(%rsp)
	movl	4412(%rax), %ecx
	movl	%ecx, 197084(%rsp)
	movl	4416(%rax), %ecx
	movl	%ecx, 197088(%rsp)
	movl	4420(%rax), %ecx
	movl	%ecx, 197092(%rsp)
	movl	4424(%rax), %ecx
	movl	%ecx, 197096(%rsp)
	movl	4428(%rax), %ecx
	movl	%ecx, 197100(%rsp)
	movl	4432(%rax), %ecx
	movl	%ecx, 197104(%rsp)
	movl	4436(%rax), %ecx
	movl	%ecx, 197108(%rsp)
	movl	4440(%rax), %ecx
	movl	%ecx, 197112(%rsp)
	movl	4444(%rax), %ecx
	movl	%ecx, 197116(%rsp)
	movl	4448(%rax), %ecx
	movl	%ecx, 197120(%rsp)
	movl	4452(%rax), %ecx
	movl	%ecx, 197124(%rsp)
	movl	4456(%rax), %ecx
	movl	%ecx, 197128(%rsp)
	movl	4460(%rax), %ecx
	movl	%ecx, 197132(%rsp)
	movl	4464(%rax), %ecx
	movl	%ecx, 197136(%rsp)
	movl	4468(%rax), %ecx
	movl	%ecx, 197140(%rsp)
	movl	4472(%rax), %ecx
	movl	%ecx, 197144(%rsp)
	movl	4476(%rax), %ecx
	movl	%ecx, 197148(%rsp)
	movl	4480(%rax), %ecx
	movl	%ecx, 197152(%rsp)
	movl	4484(%rax), %ecx
	movl	%ecx, 197156(%rsp)
	movl	4488(%rax), %ecx
	movl	%ecx, 197160(%rsp)
	movl	4492(%rax), %ecx
	movl	%ecx, 197164(%rsp)
	movl	4496(%rax), %ecx
	movl	%ecx, 197168(%rsp)
	movl	4500(%rax), %ecx
	movl	%ecx, 197172(%rsp)
	movl	4504(%rax), %ecx
	movl	%ecx, 197176(%rsp)
	movl	4508(%rax), %ecx
	movl	%ecx, 197180(%rsp)
	movl	4512(%rax), %ecx
	movl	%ecx, 197184(%rsp)
	movl	4516(%rax), %ecx
	movl	%ecx, 197188(%rsp)
	movl	4520(%rax), %ecx
	movl	%ecx, 197192(%rsp)
	movl	4524(%rax), %ecx
	movl	%ecx, 197196(%rsp)
	movl	4528(%rax), %ecx
	movl	%ecx, 197200(%rsp)
	movl	4532(%rax), %ecx
	movl	%ecx, 197204(%rsp)
	movl	4536(%rax), %ecx
	movl	%ecx, 197208(%rsp)
	movl	4540(%rax), %ecx
	movl	%ecx, 197212(%rsp)
	movl	4544(%rax), %ecx
	movl	%ecx, 197216(%rsp)
	movl	4548(%rax), %ecx
	movl	%ecx, 197220(%rsp)
	movl	4552(%rax), %ecx
	movl	%ecx, 197224(%rsp)
	movl	4556(%rax), %ecx
	movl	%ecx, 197228(%rsp)
	movl	4560(%rax), %ecx
	movl	%ecx, 197232(%rsp)
	movl	4564(%rax), %ecx
	movl	%ecx, 197236(%rsp)
	movl	4568(%rax), %ecx
	movl	%ecx, 197240(%rsp)
	movl	4572(%rax), %ecx
	movl	%ecx, 197244(%rsp)
	movl	4576(%rax), %ecx
	movl	%ecx, 197248(%rsp)
	movl	4580(%rax), %ecx
	movl	%ecx, 197252(%rsp)
	movl	4584(%rax), %ecx
	movl	%ecx, 197256(%rsp)
	movl	4588(%rax), %ecx
	movl	%ecx, 197260(%rsp)
	movl	4592(%rax), %ecx
	movl	%ecx, 197264(%rsp)
	movl	4596(%rax), %ecx
	movl	%ecx, 197268(%rsp)
	movl	4600(%rax), %ecx
	movl	%ecx, 197272(%rsp)
	movl	4604(%rax), %ecx
	movl	%ecx, 197276(%rsp)
	movl	4608(%rax), %ecx
	movl	%ecx, 197280(%rsp)
	movl	4612(%rax), %ecx
	movl	%ecx, 197284(%rsp)
	movl	4616(%rax), %ecx
	movl	%ecx, 197288(%rsp)
	movl	4620(%rax), %ecx
	movl	%ecx, 197292(%rsp)
	movl	4624(%rax), %ecx
	movl	%ecx, 197296(%rsp)
	movl	4628(%rax), %ecx
	movl	%ecx, 197300(%rsp)
	movl	4632(%rax), %ecx
	movl	%ecx, 197304(%rsp)
	movl	4636(%rax), %ecx
	movl	%ecx, 197308(%rsp)
	movl	4640(%rax), %ecx
	movl	%ecx, 197312(%rsp)
	movl	4644(%rax), %ecx
	movl	%ecx, 197316(%rsp)
	movl	4648(%rax), %ecx
	movl	%ecx, 197320(%rsp)
	movl	4652(%rax), %ecx
	movl	%ecx, 197324(%rsp)
	movl	4656(%rax), %ecx
	movl	%ecx, 197328(%rsp)
	movl	4660(%rax), %ecx
	movl	%ecx, 197332(%rsp)
	movl	4664(%rax), %ecx
	movl	%ecx, 197336(%rsp)
	movl	4668(%rax), %ecx
	movl	%ecx, 197340(%rsp)
	movl	4672(%rax), %ecx
	movl	%ecx, 197344(%rsp)
	movl	4676(%rax), %ecx
	movl	%ecx, 197348(%rsp)
	movl	4680(%rax), %ecx
	movl	%ecx, 197352(%rsp)
	movl	4684(%rax), %ecx
	movl	%ecx, 197356(%rsp)
	movl	4688(%rax), %ecx
	movl	%ecx, 197360(%rsp)
	movl	4692(%rax), %ecx
	movl	%ecx, 197364(%rsp)
	movl	4696(%rax), %ecx
	movl	%ecx, 197368(%rsp)
	movl	4700(%rax), %ecx
	movl	%ecx, 197372(%rsp)
	movl	4704(%rax), %ecx
	movl	%ecx, 197376(%rsp)
	movl	4708(%rax), %ecx
	movl	%ecx, 197380(%rsp)
	movl	4712(%rax), %ecx
	movl	%ecx, 197384(%rsp)
	movl	4716(%rax), %ecx
	movl	%ecx, 197388(%rsp)
	movl	4720(%rax), %ecx
	movl	%ecx, 197392(%rsp)
	movl	4724(%rax), %ecx
	movl	%ecx, 197396(%rsp)
	movl	4728(%rax), %ecx
	movl	%ecx, 197400(%rsp)
	movl	4732(%rax), %ecx
	movl	%ecx, 197404(%rsp)
	movl	4736(%rax), %ecx
	movl	%ecx, 197408(%rsp)
	movl	4740(%rax), %ecx
	movl	%ecx, 197412(%rsp)
	movl	4744(%rax), %ecx
	movl	%ecx, 197416(%rsp)
	movl	4748(%rax), %ecx
	movl	%ecx, 197420(%rsp)
	movl	4752(%rax), %ecx
	movl	%ecx, 197424(%rsp)
	movl	4756(%rax), %ecx
	movl	%ecx, 197428(%rsp)
	movl	4760(%rax), %ecx
	movl	%ecx, 197432(%rsp)
	movl	4764(%rax), %ecx
	movl	%ecx, 197436(%rsp)
	movl	4768(%rax), %ecx
	movl	%ecx, 197440(%rsp)
	movl	4772(%rax), %ecx
	movl	%ecx, 197444(%rsp)
	movl	4776(%rax), %ecx
	movl	%ecx, 197448(%rsp)
	movl	4780(%rax), %ecx
	movl	%ecx, 197452(%rsp)
	movl	4784(%rax), %ecx
	movl	%ecx, 197456(%rsp)
	movl	4788(%rax), %ecx
	movl	%ecx, 197460(%rsp)
	movl	4792(%rax), %ecx
	movl	%ecx, 197464(%rsp)
	movl	4796(%rax), %ecx
	movl	%ecx, 197468(%rsp)
	movl	4800(%rax), %ecx
	movl	%ecx, 197472(%rsp)
	movl	4804(%rax), %ecx
	movl	%ecx, 197476(%rsp)
	movl	4808(%rax), %ecx
	movl	%ecx, 197480(%rsp)
	movl	4812(%rax), %ecx
	movl	%ecx, 197484(%rsp)
	movl	4816(%rax), %ecx
	movl	%ecx, 197488(%rsp)
	movl	4820(%rax), %ecx
	movl	%ecx, 197492(%rsp)
	movl	4824(%rax), %ecx
	movl	%ecx, 197496(%rsp)
	movl	4828(%rax), %ecx
	movl	%ecx, 197500(%rsp)
	movl	4832(%rax), %ecx
	movl	%ecx, 197504(%rsp)
	movl	4836(%rax), %ecx
	movl	%ecx, 197508(%rsp)
	movl	4840(%rax), %ecx
	movl	%ecx, 197512(%rsp)
	movl	4844(%rax), %ecx
	movl	%ecx, 197516(%rsp)
	movl	4848(%rax), %ecx
	movl	%ecx, 197520(%rsp)
	movl	4852(%rax), %ecx
	movl	%ecx, 197524(%rsp)
	movl	4856(%rax), %ecx
	movl	%ecx, 197528(%rsp)
	movl	4860(%rax), %ecx
	movl	%ecx, 197532(%rsp)
	movl	4864(%rax), %ecx
	movl	%ecx, 197536(%rsp)
	movl	4868(%rax), %ecx
	movl	%ecx, 197540(%rsp)
	movl	4872(%rax), %ecx
	movl	%ecx, 197544(%rsp)
	movl	4876(%rax), %ecx
	movl	%ecx, 197548(%rsp)
	movl	4880(%rax), %ecx
	movl	%ecx, 197552(%rsp)
	movl	4884(%rax), %ecx
	movl	%ecx, 197556(%rsp)
	movl	4888(%rax), %ecx
	movl	%ecx, 197560(%rsp)
	movl	4892(%rax), %ecx
	movl	%ecx, 197564(%rsp)
	movl	4896(%rax), %ecx
	movl	%ecx, 197568(%rsp)
	movl	4900(%rax), %ecx
	movl	%ecx, 197572(%rsp)
	movl	4904(%rax), %ecx
	movl	%ecx, 197576(%rsp)
	movl	4908(%rax), %ecx
	movl	%ecx, 197580(%rsp)
	movl	4912(%rax), %ecx
	movl	%ecx, 197584(%rsp)
	movl	4916(%rax), %ecx
	movl	%ecx, 197588(%rsp)
	movl	4920(%rax), %ecx
	movl	%ecx, 197592(%rsp)
	movl	4924(%rax), %ecx
	movl	%ecx, 197596(%rsp)
	movl	4928(%rax), %ecx
	movl	%ecx, 197600(%rsp)
	movl	4932(%rax), %ecx
	movl	%ecx, 197604(%rsp)
	movl	4936(%rax), %ecx
	movl	%ecx, 197608(%rsp)
	movl	4940(%rax), %ecx
	movl	%ecx, 197612(%rsp)
	movl	4944(%rax), %ecx
	movl	%ecx, 197616(%rsp)
	movl	4948(%rax), %ecx
	movl	%ecx, 197620(%rsp)
	movl	4952(%rax), %ecx
	movl	%ecx, 197624(%rsp)
	movl	4956(%rax), %ecx
	movl	%ecx, 197628(%rsp)
	movl	4960(%rax), %ecx
	movl	%ecx, 197632(%rsp)
	movl	4964(%rax), %ecx
	movl	%ecx, 197636(%rsp)
	movl	4968(%rax), %ecx
	movl	%ecx, 197640(%rsp)
	movl	4972(%rax), %ecx
	movl	%ecx, 197644(%rsp)
	movl	4976(%rax), %ecx
	movl	%ecx, 197648(%rsp)
	movl	4980(%rax), %ecx
	movl	%ecx, 197652(%rsp)
	movl	4984(%rax), %ecx
	movl	%ecx, 197656(%rsp)
	movl	4988(%rax), %ecx
	movl	%ecx, 197660(%rsp)
	movl	4992(%rax), %ecx
	movl	%ecx, 197664(%rsp)
	movl	4996(%rax), %ecx
	movl	%ecx, 197668(%rsp)
	movl	5000(%rax), %ecx
	movl	%ecx, 197672(%rsp)
	movl	5004(%rax), %ecx
	movl	%ecx, 197676(%rsp)
	movl	5008(%rax), %ecx
	movl	%ecx, 197680(%rsp)
	movl	5012(%rax), %ecx
	movl	%ecx, 197684(%rsp)
	movl	5016(%rax), %ecx
	movl	%ecx, 197688(%rsp)
	movl	5020(%rax), %ecx
	movl	%ecx, 197692(%rsp)
	movl	5024(%rax), %ecx
	movl	%ecx, 197696(%rsp)
	movl	5028(%rax), %ecx
	movl	%ecx, 197700(%rsp)
	movl	5032(%rax), %ecx
	movl	%ecx, 197704(%rsp)
	movl	5036(%rax), %ecx
	movl	%ecx, 197708(%rsp)
	movl	5040(%rax), %ecx
	movl	%ecx, 197712(%rsp)
	movl	5044(%rax), %ecx
	movl	%ecx, 197716(%rsp)
	movl	5048(%rax), %ecx
	movl	%ecx, 197720(%rsp)
	movl	5052(%rax), %ecx
	movl	%ecx, 197724(%rsp)
	movl	5056(%rax), %ecx
	movl	%ecx, 197728(%rsp)
	movl	5060(%rax), %ecx
	movl	%ecx, 197732(%rsp)
	movl	5064(%rax), %ecx
	movl	%ecx, 197736(%rsp)
	movl	5068(%rax), %ecx
	movl	%ecx, 197740(%rsp)
	movl	5072(%rax), %ecx
	movl	%ecx, 197744(%rsp)
	movl	5076(%rax), %ecx
	movl	%ecx, 197748(%rsp)
	movl	5080(%rax), %ecx
	movl	%ecx, 197752(%rsp)
	movl	5084(%rax), %ecx
	movl	%ecx, 197756(%rsp)
	movl	5088(%rax), %ecx
	movl	%ecx, 197760(%rsp)
	movl	5092(%rax), %ecx
	movl	%ecx, 197764(%rsp)
	movl	5096(%rax), %ecx
	movl	%ecx, 197768(%rsp)
	movl	5100(%rax), %ecx
	movl	%ecx, 197772(%rsp)
	movl	5104(%rax), %ecx
	movl	%ecx, 197776(%rsp)
	movl	5108(%rax), %ecx
	movl	%ecx, 197780(%rsp)
	movl	5112(%rax), %ecx
	movl	%ecx, 197784(%rsp)
	movl	5116(%rax), %ecx
	movl	%ecx, 197788(%rsp)
	movl	5120(%rax), %ecx
	movl	%ecx, 197792(%rsp)
	movl	5124(%rax), %ecx
	movl	%ecx, 197796(%rsp)
	movl	5128(%rax), %ecx
	movl	%ecx, 197800(%rsp)
	movl	5132(%rax), %ecx
	movl	%ecx, 197804(%rsp)
	movl	5136(%rax), %ecx
	movl	%ecx, 197808(%rsp)
	movl	5140(%rax), %ecx
	movl	%ecx, 197812(%rsp)
	movl	5144(%rax), %ecx
	movl	%ecx, 197816(%rsp)
	movl	5148(%rax), %ecx
	movl	%ecx, 197820(%rsp)
	movl	5152(%rax), %ecx
	movl	%ecx, 197824(%rsp)
	movl	5156(%rax), %ecx
	movl	%ecx, 197828(%rsp)
	movl	5160(%rax), %ecx
	movl	%ecx, 197832(%rsp)
	movl	5164(%rax), %ecx
	movl	%ecx, 197836(%rsp)
	movl	5168(%rax), %ecx
	movl	%ecx, 197840(%rsp)
	movl	5172(%rax), %ecx
	movl	%ecx, 197844(%rsp)
	movl	5176(%rax), %ecx
	movl	%ecx, 197848(%rsp)
	movl	5180(%rax), %ecx
	movl	%ecx, 197852(%rsp)
	movl	5184(%rax), %ecx
	movl	%ecx, 197856(%rsp)
	movl	5188(%rax), %ecx
	movl	%ecx, 197860(%rsp)
	movl	5192(%rax), %ecx
	movl	%ecx, 197864(%rsp)
	movl	5196(%rax), %ecx
	movl	%ecx, 197868(%rsp)
	movl	5200(%rax), %ecx
	movl	%ecx, 197872(%rsp)
	movl	5204(%rax), %ecx
	movl	%ecx, 197876(%rsp)
	movl	5208(%rax), %ecx
	movl	%ecx, 197880(%rsp)
	movl	5212(%rax), %ecx
	movl	%ecx, 197884(%rsp)
	movl	5216(%rax), %ecx
	movl	%ecx, 197888(%rsp)
	movl	5220(%rax), %ecx
	movl	%ecx, 197892(%rsp)
	movl	5224(%rax), %ecx
	movl	%ecx, 197896(%rsp)
	movl	5228(%rax), %ecx
	movl	%ecx, 197900(%rsp)
	movl	5232(%rax), %ecx
	movl	%ecx, 197904(%rsp)
	movl	5236(%rax), %ecx
	movl	%ecx, 197908(%rsp)
	movl	5240(%rax), %ecx
	movl	%ecx, 197912(%rsp)
	movl	5244(%rax), %ecx
	movl	%ecx, 197916(%rsp)
	movl	5248(%rax), %ecx
	movl	%ecx, 197920(%rsp)
	movl	5252(%rax), %ecx
	movl	%ecx, 197924(%rsp)
	movl	5256(%rax), %ecx
	movl	%ecx, 197928(%rsp)
	movl	5260(%rax), %ecx
	movl	%ecx, 197932(%rsp)
	movl	5264(%rax), %ecx
	movl	%ecx, 197936(%rsp)
	movl	5268(%rax), %ecx
	movl	%ecx, 197940(%rsp)
	movl	5272(%rax), %ecx
	movl	%ecx, 197944(%rsp)
	movl	5276(%rax), %ecx
	movl	%ecx, 197948(%rsp)
	movl	5280(%rax), %ecx
	movl	%ecx, 197952(%rsp)
	movl	5284(%rax), %ecx
	movl	%ecx, 197956(%rsp)
	movl	5288(%rax), %ecx
	movl	%ecx, 197960(%rsp)
	movl	5292(%rax), %ecx
	movl	%ecx, 197964(%rsp)
	movl	5296(%rax), %ecx
	movl	%ecx, 197968(%rsp)
	movl	5300(%rax), %ecx
	movl	%ecx, 197972(%rsp)
	movl	5304(%rax), %ecx
	movl	%ecx, 197976(%rsp)
	movl	5308(%rax), %ecx
	movl	%ecx, 197980(%rsp)
	movl	5312(%rax), %ecx
	movl	%ecx, 197984(%rsp)
	movl	5316(%rax), %ecx
	movl	%ecx, 197988(%rsp)
	movl	5320(%rax), %ecx
	movl	%ecx, 197992(%rsp)
	movl	5324(%rax), %ecx
	movl	%ecx, 197996(%rsp)
	movl	5328(%rax), %ecx
	movl	%ecx, 198000(%rsp)
	movl	5332(%rax), %ecx
	movl	%ecx, 198004(%rsp)
	movl	5336(%rax), %ecx
	movl	%ecx, 198008(%rsp)
	movl	5340(%rax), %ecx
	movl	%ecx, 198012(%rsp)
	movl	5344(%rax), %ecx
	movl	%ecx, 198016(%rsp)
	movl	5348(%rax), %ecx
	movl	%ecx, 198020(%rsp)
	movl	5352(%rax), %ecx
	movl	%ecx, 198024(%rsp)
	movl	5356(%rax), %ecx
	movl	%ecx, 198028(%rsp)
	movl	5360(%rax), %ecx
	movl	%ecx, 198032(%rsp)
	movl	5364(%rax), %ecx
	movl	%ecx, 198036(%rsp)
	movl	5368(%rax), %ecx
	movl	%ecx, 198040(%rsp)
	movl	5372(%rax), %ecx
	movl	%ecx, 198044(%rsp)
	movl	5376(%rax), %ecx
	movl	%ecx, 198048(%rsp)
	movl	5380(%rax), %ecx
	movl	%ecx, 198052(%rsp)
	movl	5384(%rax), %ecx
	movl	%ecx, 198056(%rsp)
	movl	5388(%rax), %ecx
	movl	%ecx, 198060(%rsp)
	movl	5392(%rax), %ecx
	movl	%ecx, 198064(%rsp)
	movl	5396(%rax), %ecx
	movl	%ecx, 198068(%rsp)
	movl	5400(%rax), %ecx
	movl	%ecx, 198072(%rsp)
	movl	5404(%rax), %ecx
	movl	%ecx, 198076(%rsp)
	movl	5408(%rax), %ecx
	movl	%ecx, 198080(%rsp)
	movl	5412(%rax), %ecx
	movl	%ecx, 198084(%rsp)
	movl	5416(%rax), %ecx
	movl	%ecx, 198088(%rsp)
	movl	5420(%rax), %ecx
	movl	%ecx, 198092(%rsp)
	movl	5424(%rax), %ecx
	movl	%ecx, 198096(%rsp)
	movl	5428(%rax), %ecx
	movl	%ecx, 198100(%rsp)
	movl	5432(%rax), %ecx
	movl	%ecx, 198104(%rsp)
	movl	5436(%rax), %ecx
	movl	%ecx, 198108(%rsp)
	movl	5440(%rax), %ecx
	movl	%ecx, 198112(%rsp)
	movl	5444(%rax), %ecx
	movl	%ecx, 198116(%rsp)
	movl	5448(%rax), %ecx
	movl	%ecx, 198120(%rsp)
	movl	5452(%rax), %ecx
	movl	%ecx, 198124(%rsp)
	movl	5456(%rax), %ecx
	movl	%ecx, 198128(%rsp)
	movl	5460(%rax), %ecx
	movl	%ecx, 198132(%rsp)
	movl	5464(%rax), %ecx
	movl	%ecx, 198136(%rsp)
	movl	5468(%rax), %eax
	movl	%eax, 198140(%rsp)
	movb	24(%rsp), %al
	movb	%al, 56(%rsp)
	movb	25(%rsp), %al
	movb	%al, 57(%rsp)
	movb	26(%rsp), %al
	movb	%al, 58(%rsp)
	movb	27(%rsp), %al
	movb	%al, 59(%rsp)
	movb	28(%rsp), %al
	movb	%al, 60(%rsp)
	movb	29(%rsp), %al
	movb	%al, 61(%rsp)
	movb	30(%rsp), %al
	movb	%al, 62(%rsp)
	movb	31(%rsp), %al
	movb	%al, 63(%rsp)
	movb	32(%rsp), %al
	movb	%al, 64(%rsp)
	movb	33(%rsp), %al
	movb	%al, 65(%rsp)
	movb	34(%rsp), %al
	movb	%al, 66(%rsp)
	movb	35(%rsp), %al
	movb	%al, 67(%rsp)
	movb	36(%rsp), %al
	movb	%al, 68(%rsp)
	movb	37(%rsp), %al
	movb	%al, 69(%rsp)
	movb	38(%rsp), %al
	movb	%al, 70(%rsp)
	movb	39(%rsp), %al
	movb	%al, 71(%rsp)
	movb	40(%rsp), %al
	movb	%al, 72(%rsp)
	movb	41(%rsp), %al
	movb	%al, 73(%rsp)
	movb	42(%rsp), %al
	movb	%al, 74(%rsp)
	movb	43(%rsp), %al
	movb	%al, 75(%rsp)
	movb	44(%rsp), %al
	movb	%al, 76(%rsp)
	movb	45(%rsp), %al
	movb	%al, 77(%rsp)
	movb	46(%rsp), %al
	movb	%al, 78(%rsp)
	movb	47(%rsp), %al
	movb	%al, 79(%rsp)
	movb	48(%rsp), %al
	movb	%al, 80(%rsp)
	movb	49(%rsp), %al
	movb	%al, 81(%rsp)
	movb	50(%rsp), %al
	movb	%al, 82(%rsp)
	movb	51(%rsp), %al
	movb	%al, 83(%rsp)
	movb	52(%rsp), %al
	movb	%al, 84(%rsp)
	movb	53(%rsp), %al
	movb	%al, 85(%rsp)
	movb	54(%rsp), %al
	movb	%al, 86(%rsp)
	movb	55(%rsp), %al
	movb	%al, 87(%rsp)
	movb	215836(%rsp), %al
	movb	%al, 88(%rsp)
	movb	215837(%rsp), %al
	movb	%al, 89(%rsp)
	movb	215838(%rsp), %al
	movb	%al, 90(%rsp)
	movb	215839(%rsp), %al
	movb	%al, 91(%rsp)
	movb	215840(%rsp), %al
	movb	%al, 92(%rsp)
	movb	215841(%rsp), %al
	movb	%al, 93(%rsp)
	movb	215842(%rsp), %al
	movb	%al, 94(%rsp)
	movb	215843(%rsp), %al
	movb	%al, 95(%rsp)
	movb	215844(%rsp), %al
	movb	%al, 96(%rsp)
	movb	215845(%rsp), %al
	movb	%al, 97(%rsp)
	movb	215846(%rsp), %al
	movb	%al, 98(%rsp)
	movb	215847(%rsp), %al
	movb	%al, 99(%rsp)
	movb	215848(%rsp), %al
	movb	%al, 100(%rsp)
	movb	215849(%rsp), %al
	movb	%al, 101(%rsp)
	movb	215850(%rsp), %al
	movb	%al, 102(%rsp)
	movb	215851(%rsp), %al
	movb	%al, 103(%rsp)
	movb	215852(%rsp), %al
	movb	%al, 104(%rsp)
	movb	215853(%rsp), %al
	movb	%al, 105(%rsp)
	movb	215854(%rsp), %al
	movb	%al, 106(%rsp)
	movb	215855(%rsp), %al
	movb	%al, 107(%rsp)
	movb	215856(%rsp), %al
	movb	%al, 108(%rsp)
	movb	215857(%rsp), %al
	movb	%al, 109(%rsp)
	movb	215858(%rsp), %al
	movb	%al, 110(%rsp)
	movb	215859(%rsp), %al
	movb	%al, 111(%rsp)
	leaq	24(%rsp), %rax
	leaq	56(%rsp), %rdx
	movb	$31, %cl
	movq	$136, %rsi
	movb	%cl, %dil
	movq	%rsi, %rcx
	leaq	-248(%rsp), %rsp
	call	L_keccak1600_32_56$1
Lmayo2_crypto_sign_open$90:
	leaq	248(%rsp), %rsp
	leaq	24(%rsp), %rax
	leaq	215424(%rsp), %rcx
	call	Ldecode_o_tenc$1
Lmayo2_crypto_sign_open$89:
	leaq	215680(%rsp), %rax
	leaq	215860(%rsp), %rcx
	call	Ldecode_sig$1
Lmayo2_crypto_sign_open$88:
	movq	$0, %rax
	jmp 	Lmayo2_crypto_sign_open$86
Lmayo2_crypto_sign_open$87:
	movl	$0, 205440(%rsp,%rax,4)
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$86:
	cmpq	$2496, %rax
	jb  	Lmayo2_crypto_sign_open$87
	movq	$0, %rax
	jmp 	Lmayo2_crypto_sign_open$84
Lmayo2_crypto_sign_open$85:
	movl	192672(%rsp,%rax,4), %ecx
	movl	%ecx, 198144(%rsp,%rax,4)
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$84:
	cmpq	$1368, %rax
	jb  	Lmayo2_crypto_sign_open$85
	jmp 	Lmayo2_crypto_sign_open$82
Lmayo2_crypto_sign_open$83:
	movl	$0, 198144(%rsp,%rax,4)
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$82:
	cmpq	$1824, %rax
	jb  	Lmayo2_crypto_sign_open$83
	leaq	99552(%rsp), %r9
	leaq	158112(%rsp), %r10
	leaq	198144(%rsp), %rbx
	leaq	215860(%rsp), %r11
	leaq	205440(%rsp), %rbp
	leaq	-159744(%rsp), %rsp
	call	Lbitsliced_m_calculate_PS$1
Lmayo2_crypto_sign_open$81:
	leaq	159744(%rsp), %rsp
	movq	$0, %rax
	jmp 	Lmayo2_crypto_sign_open$79
Lmayo2_crypto_sign_open$80:
	movl	$0, 432(%rsp,%rax,4)
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$79:
	cmpq	$128, %rax
	jb  	Lmayo2_crypto_sign_open$80
	leaq	215860(%rsp), %r12
	leaq	205440(%rsp), %r14
	leaq	432(%rsp), %r13
	call	Lmul_add_mat_x_bitsliced_m_mat_ver$1
Lmayo2_crypto_sign_open$78:
	movq	$0, %rax
	jmp 	Lmayo2_crypto_sign_open$76
Lmayo2_crypto_sign_open$77:
	movl	$0, 112(%rsp,%rax,4)
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$76:
	cmpq	$80, %rax
	jb  	Lmayo2_crypto_sign_open$77
	leaq	432(%rsp), %rax
	leaq	112(%rsp), %rcx
	call	Lbitsliced_m_upper$1
Lmayo2_crypto_sign_open$75:
	movb	$0, 215552(%rsp)
	movb	$0, 215553(%rsp)
	movb	$0, 215554(%rsp)
	movb	$0, 215555(%rsp)
	movb	$0, 215556(%rsp)
	movb	$0, 215557(%rsp)
	movb	$0, 215558(%rsp)
	movb	$0, 215559(%rsp)
	movb	$0, 215560(%rsp)
	movb	$0, 215561(%rsp)
	movb	$0, 215562(%rsp)
	movb	$0, 215563(%rsp)
	movb	$0, 215564(%rsp)
	movb	$0, 215565(%rsp)
	movb	$0, 215566(%rsp)
	movb	$0, 215567(%rsp)
	movb	$0, 215568(%rsp)
	movb	$0, 215569(%rsp)
	movb	$0, 215570(%rsp)
	movb	$0, 215571(%rsp)
	movb	$0, 215572(%rsp)
	movb	$0, 215573(%rsp)
	movb	$0, 215574(%rsp)
	movb	$0, 215575(%rsp)
	movb	$0, 215576(%rsp)
	movb	$0, 215577(%rsp)
	movb	$0, 215578(%rsp)
	movb	$0, 215579(%rsp)
	movb	$0, 215580(%rsp)
	movb	$0, 215581(%rsp)
	movb	$0, 215582(%rsp)
	movb	$0, 215583(%rsp)
	movb	$0, 215584(%rsp)
	movb	$0, 215585(%rsp)
	movb	$0, 215586(%rsp)
	movb	$0, 215587(%rsp)
	movb	$0, 215588(%rsp)
	movb	$0, 215589(%rsp)
	movb	$0, 215590(%rsp)
	movb	$0, 215591(%rsp)
	movb	$0, 215592(%rsp)
	movb	$0, 215593(%rsp)
	movb	$0, 215594(%rsp)
	movb	$0, 215595(%rsp)
	movb	$0, 215596(%rsp)
	movb	$0, 215597(%rsp)
	movb	$0, 215598(%rsp)
	movb	$0, 215599(%rsp)
	movb	$0, 215600(%rsp)
	movb	$0, 215601(%rsp)
	movb	$0, 215602(%rsp)
	movb	$0, 215603(%rsp)
	movb	$0, 215604(%rsp)
	movb	$0, 215605(%rsp)
	movb	$0, 215606(%rsp)
	movb	$0, 215607(%rsp)
	movb	$0, 215608(%rsp)
	movb	$0, 215609(%rsp)
	movb	$0, 215610(%rsp)
	movb	$0, 215611(%rsp)
	movb	$0, 215612(%rsp)
	movb	$0, 215613(%rsp)
	movb	$0, 215614(%rsp)
	movb	$0, 215615(%rsp)
	movb	$0, 215616(%rsp)
	movb	$0, 215617(%rsp)
	movb	$0, 215618(%rsp)
	movb	$0, 215619(%rsp)
	movb	$0, 215620(%rsp)
	movb	$0, 215621(%rsp)
	movb	$0, 215622(%rsp)
	movb	$0, 215623(%rsp)
	movb	$0, 215624(%rsp)
	movb	$0, 215625(%rsp)
	movb	$0, 215626(%rsp)
	movb	$0, 215627(%rsp)
	movb	$0, 215628(%rsp)
	movb	$0, 215629(%rsp)
	movb	$0, 215630(%rsp)
	movb	$0, 215631(%rsp)
	movb	$0, 215632(%rsp)
	movb	$0, 215633(%rsp)
	movb	$0, 215634(%rsp)
	movb	$0, 215635(%rsp)
	movb	$0, 215636(%rsp)
	movb	$0, 215637(%rsp)
	movb	$0, 215638(%rsp)
	movb	$0, 215639(%rsp)
	movb	$0, 215640(%rsp)
	movb	$0, 215641(%rsp)
	movb	$0, 215642(%rsp)
	movb	$0, 215643(%rsp)
	movb	$0, 215644(%rsp)
	movb	$0, 215645(%rsp)
	movb	$0, 215646(%rsp)
	movb	$0, 215647(%rsp)
	movb	$0, 215648(%rsp)
	movb	$0, 215649(%rsp)
	movb	$0, 215650(%rsp)
	movb	$0, 215651(%rsp)
	movb	$0, 215652(%rsp)
	movb	$0, 215653(%rsp)
	movb	$0, 215654(%rsp)
	movb	$0, 215655(%rsp)
	movb	$0, 215656(%rsp)
	movb	$0, 215657(%rsp)
	movb	$0, 215658(%rsp)
	movb	$0, 215659(%rsp)
	movb	$0, 215660(%rsp)
	movb	$0, 215661(%rsp)
	movb	$0, 215662(%rsp)
	movb	$0, 215663(%rsp)
	movb	$0, 215664(%rsp)
	movb	$0, 215665(%rsp)
	movb	$0, 215666(%rsp)
	movb	$0, 215667(%rsp)
	movb	$0, 215668(%rsp)
	movb	$0, 215669(%rsp)
	movb	$0, 215670(%rsp)
	movb	$0, 215671(%rsp)
	movb	$0, 215672(%rsp)
	movb	$0, 215673(%rsp)
	movb	$0, 215674(%rsp)
	movb	$0, 215675(%rsp)
	movb	$0, 215676(%rsp)
	movb	$0, 215677(%rsp)
	movb	$0, 215678(%rsp)
	movb	$0, 215679(%rsp)
	leaq	208(%rsp), %rdi
	leaq	215488(%rsp), %rax
	call	Lunbitslice_m_vec$1
Lmayo2_crypto_sign_open$74:
	movb	215488(%rsp), %al
	movq	$0, %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215489(%rsp), %al
	movq	$0, %rcx
	leaq	1(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215490(%rsp), %al
	movq	$0, %rcx
	leaq	2(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215491(%rsp), %al
	movq	$0, %rcx
	leaq	3(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215492(%rsp), %al
	movq	$0, %rcx
	leaq	4(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215493(%rsp), %al
	movq	$0, %rcx
	leaq	5(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215494(%rsp), %al
	movq	$0, %rcx
	leaq	6(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215495(%rsp), %al
	movq	$0, %rcx
	leaq	7(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215496(%rsp), %al
	movq	$0, %rcx
	leaq	8(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215497(%rsp), %al
	movq	$0, %rcx
	leaq	9(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215498(%rsp), %al
	movq	$0, %rcx
	leaq	10(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215499(%rsp), %al
	movq	$0, %rcx
	leaq	11(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215500(%rsp), %al
	movq	$0, %rcx
	leaq	12(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215501(%rsp), %al
	movq	$0, %rcx
	leaq	13(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215502(%rsp), %al
	movq	$0, %rcx
	leaq	14(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215503(%rsp), %al
	movq	$0, %rcx
	leaq	15(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215504(%rsp), %al
	movq	$0, %rcx
	leaq	16(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215505(%rsp), %al
	movq	$0, %rcx
	leaq	17(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215506(%rsp), %al
	movq	$0, %rcx
	leaq	18(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215507(%rsp), %al
	movq	$0, %rcx
	leaq	19(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215508(%rsp), %al
	movq	$0, %rcx
	leaq	20(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215509(%rsp), %al
	movq	$0, %rcx
	leaq	21(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215510(%rsp), %al
	movq	$0, %rcx
	leaq	22(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215511(%rsp), %al
	movq	$0, %rcx
	leaq	23(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215512(%rsp), %al
	movq	$0, %rcx
	leaq	24(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215513(%rsp), %al
	movq	$0, %rcx
	leaq	25(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215514(%rsp), %al
	movq	$0, %rcx
	leaq	26(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215515(%rsp), %al
	movq	$0, %rcx
	leaq	27(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215516(%rsp), %al
	movq	$0, %rcx
	leaq	28(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215517(%rsp), %al
	movq	$0, %rcx
	leaq	29(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215518(%rsp), %al
	movq	$0, %rcx
	leaq	30(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215519(%rsp), %al
	movq	$0, %rcx
	leaq	31(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215520(%rsp), %al
	movq	$0, %rcx
	leaq	32(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215521(%rsp), %al
	movq	$0, %rcx
	leaq	33(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215522(%rsp), %al
	movq	$0, %rcx
	leaq	34(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215523(%rsp), %al
	movq	$0, %rcx
	leaq	35(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215524(%rsp), %al
	movq	$0, %rcx
	leaq	36(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215525(%rsp), %al
	movq	$0, %rcx
	leaq	37(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215526(%rsp), %al
	movq	$0, %rcx
	leaq	38(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215527(%rsp), %al
	movq	$0, %rcx
	leaq	39(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215528(%rsp), %al
	movq	$0, %rcx
	leaq	40(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215529(%rsp), %al
	movq	$0, %rcx
	leaq	41(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215530(%rsp), %al
	movq	$0, %rcx
	leaq	42(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215531(%rsp), %al
	movq	$0, %rcx
	leaq	43(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215532(%rsp), %al
	movq	$0, %rcx
	leaq	44(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215533(%rsp), %al
	movq	$0, %rcx
	leaq	45(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215534(%rsp), %al
	movq	$0, %rcx
	leaq	46(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215535(%rsp), %al
	movq	$0, %rcx
	leaq	47(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215536(%rsp), %al
	movq	$0, %rcx
	leaq	48(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215537(%rsp), %al
	movq	$0, %rcx
	leaq	49(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215538(%rsp), %al
	movq	$0, %rcx
	leaq	50(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215539(%rsp), %al
	movq	$0, %rcx
	leaq	51(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215540(%rsp), %al
	movq	$0, %rcx
	leaq	52(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215541(%rsp), %al
	movq	$0, %rcx
	leaq	53(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215542(%rsp), %al
	movq	$0, %rcx
	leaq	54(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215543(%rsp), %al
	movq	$0, %rcx
	leaq	55(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215544(%rsp), %al
	movq	$0, %rcx
	leaq	56(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215545(%rsp), %al
	movq	$0, %rcx
	leaq	57(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215546(%rsp), %al
	movq	$0, %rcx
	leaq	58(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215547(%rsp), %al
	movq	$0, %rcx
	leaq	59(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215548(%rsp), %al
	movq	$0, %rcx
	leaq	60(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215549(%rsp), %al
	movq	$0, %rcx
	leaq	61(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215550(%rsp), %al
	movq	$0, %rcx
	leaq	62(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215551(%rsp), %al
	movq	$0, %rcx
	leaq	63(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	leaq	176(%rsp), %rdi
	leaq	215488(%rsp), %rax
	call	Lunbitslice_m_vec$1
Lmayo2_crypto_sign_open$73:
	movb	215488(%rsp), %al
	movq	$1, %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215489(%rsp), %al
	movq	$1, %rcx
	leaq	1(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215490(%rsp), %al
	movq	$1, %rcx
	leaq	2(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215491(%rsp), %al
	movq	$1, %rcx
	leaq	3(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215492(%rsp), %al
	movq	$1, %rcx
	leaq	4(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215493(%rsp), %al
	movq	$1, %rcx
	leaq	5(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215494(%rsp), %al
	movq	$1, %rcx
	leaq	6(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215495(%rsp), %al
	movq	$1, %rcx
	leaq	7(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215496(%rsp), %al
	movq	$1, %rcx
	leaq	8(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215497(%rsp), %al
	movq	$1, %rcx
	leaq	9(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215498(%rsp), %al
	movq	$1, %rcx
	leaq	10(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215499(%rsp), %al
	movq	$1, %rcx
	leaq	11(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215500(%rsp), %al
	movq	$1, %rcx
	leaq	12(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215501(%rsp), %al
	movq	$1, %rcx
	leaq	13(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215502(%rsp), %al
	movq	$1, %rcx
	leaq	14(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215503(%rsp), %al
	movq	$1, %rcx
	leaq	15(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215504(%rsp), %al
	movq	$1, %rcx
	leaq	16(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215505(%rsp), %al
	movq	$1, %rcx
	leaq	17(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215506(%rsp), %al
	movq	$1, %rcx
	leaq	18(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215507(%rsp), %al
	movq	$1, %rcx
	leaq	19(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215508(%rsp), %al
	movq	$1, %rcx
	leaq	20(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215509(%rsp), %al
	movq	$1, %rcx
	leaq	21(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215510(%rsp), %al
	movq	$1, %rcx
	leaq	22(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215511(%rsp), %al
	movq	$1, %rcx
	leaq	23(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215512(%rsp), %al
	movq	$1, %rcx
	leaq	24(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215513(%rsp), %al
	movq	$1, %rcx
	leaq	25(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215514(%rsp), %al
	movq	$1, %rcx
	leaq	26(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215515(%rsp), %al
	movq	$1, %rcx
	leaq	27(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215516(%rsp), %al
	movq	$1, %rcx
	leaq	28(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215517(%rsp), %al
	movq	$1, %rcx
	leaq	29(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215518(%rsp), %al
	movq	$1, %rcx
	leaq	30(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215519(%rsp), %al
	movq	$1, %rcx
	leaq	31(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215520(%rsp), %al
	movq	$1, %rcx
	leaq	32(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215521(%rsp), %al
	movq	$1, %rcx
	leaq	33(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215522(%rsp), %al
	movq	$1, %rcx
	leaq	34(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215523(%rsp), %al
	movq	$1, %rcx
	leaq	35(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215524(%rsp), %al
	movq	$1, %rcx
	leaq	36(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215525(%rsp), %al
	movq	$1, %rcx
	leaq	37(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215526(%rsp), %al
	movq	$1, %rcx
	leaq	38(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215527(%rsp), %al
	movq	$1, %rcx
	leaq	39(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215528(%rsp), %al
	movq	$1, %rcx
	leaq	40(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215529(%rsp), %al
	movq	$1, %rcx
	leaq	41(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215530(%rsp), %al
	movq	$1, %rcx
	leaq	42(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215531(%rsp), %al
	movq	$1, %rcx
	leaq	43(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215532(%rsp), %al
	movq	$1, %rcx
	leaq	44(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215533(%rsp), %al
	movq	$1, %rcx
	leaq	45(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215534(%rsp), %al
	movq	$1, %rcx
	leaq	46(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215535(%rsp), %al
	movq	$1, %rcx
	leaq	47(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215536(%rsp), %al
	movq	$1, %rcx
	leaq	48(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215537(%rsp), %al
	movq	$1, %rcx
	leaq	49(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215538(%rsp), %al
	movq	$1, %rcx
	leaq	50(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215539(%rsp), %al
	movq	$1, %rcx
	leaq	51(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215540(%rsp), %al
	movq	$1, %rcx
	leaq	52(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215541(%rsp), %al
	movq	$1, %rcx
	leaq	53(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215542(%rsp), %al
	movq	$1, %rcx
	leaq	54(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215543(%rsp), %al
	movq	$1, %rcx
	leaq	55(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215544(%rsp), %al
	movq	$1, %rcx
	leaq	56(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215545(%rsp), %al
	movq	$1, %rcx
	leaq	57(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215546(%rsp), %al
	movq	$1, %rcx
	leaq	58(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215547(%rsp), %al
	movq	$1, %rcx
	leaq	59(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215548(%rsp), %al
	movq	$1, %rcx
	leaq	60(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215549(%rsp), %al
	movq	$1, %rcx
	leaq	61(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215550(%rsp), %al
	movq	$1, %rcx
	leaq	62(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215551(%rsp), %al
	movq	$1, %rcx
	leaq	63(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	leaq	144(%rsp), %rdi
	leaq	215488(%rsp), %rax
	call	Lunbitslice_m_vec$1
Lmayo2_crypto_sign_open$72:
	movb	215488(%rsp), %al
	movq	$2, %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215489(%rsp), %al
	movq	$2, %rcx
	leaq	1(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215490(%rsp), %al
	movq	$2, %rcx
	leaq	2(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215491(%rsp), %al
	movq	$2, %rcx
	leaq	3(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215492(%rsp), %al
	movq	$2, %rcx
	leaq	4(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215493(%rsp), %al
	movq	$2, %rcx
	leaq	5(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215494(%rsp), %al
	movq	$2, %rcx
	leaq	6(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215495(%rsp), %al
	movq	$2, %rcx
	leaq	7(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215496(%rsp), %al
	movq	$2, %rcx
	leaq	8(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215497(%rsp), %al
	movq	$2, %rcx
	leaq	9(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215498(%rsp), %al
	movq	$2, %rcx
	leaq	10(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215499(%rsp), %al
	movq	$2, %rcx
	leaq	11(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215500(%rsp), %al
	movq	$2, %rcx
	leaq	12(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215501(%rsp), %al
	movq	$2, %rcx
	leaq	13(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215502(%rsp), %al
	movq	$2, %rcx
	leaq	14(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215503(%rsp), %al
	movq	$2, %rcx
	leaq	15(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215504(%rsp), %al
	movq	$2, %rcx
	leaq	16(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215505(%rsp), %al
	movq	$2, %rcx
	leaq	17(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215506(%rsp), %al
	movq	$2, %rcx
	leaq	18(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215507(%rsp), %al
	movq	$2, %rcx
	leaq	19(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215508(%rsp), %al
	movq	$2, %rcx
	leaq	20(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215509(%rsp), %al
	movq	$2, %rcx
	leaq	21(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215510(%rsp), %al
	movq	$2, %rcx
	leaq	22(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215511(%rsp), %al
	movq	$2, %rcx
	leaq	23(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215512(%rsp), %al
	movq	$2, %rcx
	leaq	24(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215513(%rsp), %al
	movq	$2, %rcx
	leaq	25(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215514(%rsp), %al
	movq	$2, %rcx
	leaq	26(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215515(%rsp), %al
	movq	$2, %rcx
	leaq	27(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215516(%rsp), %al
	movq	$2, %rcx
	leaq	28(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215517(%rsp), %al
	movq	$2, %rcx
	leaq	29(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215518(%rsp), %al
	movq	$2, %rcx
	leaq	30(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215519(%rsp), %al
	movq	$2, %rcx
	leaq	31(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215520(%rsp), %al
	movq	$2, %rcx
	leaq	32(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215521(%rsp), %al
	movq	$2, %rcx
	leaq	33(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215522(%rsp), %al
	movq	$2, %rcx
	leaq	34(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215523(%rsp), %al
	movq	$2, %rcx
	leaq	35(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215524(%rsp), %al
	movq	$2, %rcx
	leaq	36(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215525(%rsp), %al
	movq	$2, %rcx
	leaq	37(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215526(%rsp), %al
	movq	$2, %rcx
	leaq	38(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215527(%rsp), %al
	movq	$2, %rcx
	leaq	39(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215528(%rsp), %al
	movq	$2, %rcx
	leaq	40(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215529(%rsp), %al
	movq	$2, %rcx
	leaq	41(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215530(%rsp), %al
	movq	$2, %rcx
	leaq	42(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215531(%rsp), %al
	movq	$2, %rcx
	leaq	43(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215532(%rsp), %al
	movq	$2, %rcx
	leaq	44(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215533(%rsp), %al
	movq	$2, %rcx
	leaq	45(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215534(%rsp), %al
	movq	$2, %rcx
	leaq	46(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215535(%rsp), %al
	movq	$2, %rcx
	leaq	47(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215536(%rsp), %al
	movq	$2, %rcx
	leaq	48(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215537(%rsp), %al
	movq	$2, %rcx
	leaq	49(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215538(%rsp), %al
	movq	$2, %rcx
	leaq	50(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215539(%rsp), %al
	movq	$2, %rcx
	leaq	51(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215540(%rsp), %al
	movq	$2, %rcx
	leaq	52(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215541(%rsp), %al
	movq	$2, %rcx
	leaq	53(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215542(%rsp), %al
	movq	$2, %rcx
	leaq	54(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215543(%rsp), %al
	movq	$2, %rcx
	leaq	55(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215544(%rsp), %al
	movq	$2, %rcx
	leaq	56(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215545(%rsp), %al
	movq	$2, %rcx
	leaq	57(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215546(%rsp), %al
	movq	$2, %rcx
	leaq	58(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215547(%rsp), %al
	movq	$2, %rcx
	leaq	59(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215548(%rsp), %al
	movq	$2, %rcx
	leaq	60(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215549(%rsp), %al
	movq	$2, %rcx
	leaq	61(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215550(%rsp), %al
	movq	$2, %rcx
	leaq	62(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215551(%rsp), %al
	movq	$2, %rcx
	leaq	63(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	leaq	112(%rsp), %rdi
	leaq	215488(%rsp), %rax
	call	Lunbitslice_m_vec$1
Lmayo2_crypto_sign_open$71:
	movb	215488(%rsp), %al
	movq	$3, %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215489(%rsp), %al
	movq	$3, %rcx
	leaq	1(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215490(%rsp), %al
	movq	$3, %rcx
	leaq	2(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215491(%rsp), %al
	movq	$3, %rcx
	leaq	3(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215492(%rsp), %al
	movq	$3, %rcx
	leaq	4(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215493(%rsp), %al
	movq	$3, %rcx
	leaq	5(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215494(%rsp), %al
	movq	$3, %rcx
	leaq	6(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215495(%rsp), %al
	movq	$3, %rcx
	leaq	7(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215496(%rsp), %al
	movq	$3, %rcx
	leaq	8(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215497(%rsp), %al
	movq	$3, %rcx
	leaq	9(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215498(%rsp), %al
	movq	$3, %rcx
	leaq	10(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215499(%rsp), %al
	movq	$3, %rcx
	leaq	11(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215500(%rsp), %al
	movq	$3, %rcx
	leaq	12(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215501(%rsp), %al
	movq	$3, %rcx
	leaq	13(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215502(%rsp), %al
	movq	$3, %rcx
	leaq	14(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215503(%rsp), %al
	movq	$3, %rcx
	leaq	15(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215504(%rsp), %al
	movq	$3, %rcx
	leaq	16(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215505(%rsp), %al
	movq	$3, %rcx
	leaq	17(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215506(%rsp), %al
	movq	$3, %rcx
	leaq	18(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215507(%rsp), %al
	movq	$3, %rcx
	leaq	19(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215508(%rsp), %al
	movq	$3, %rcx
	leaq	20(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215509(%rsp), %al
	movq	$3, %rcx
	leaq	21(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215510(%rsp), %al
	movq	$3, %rcx
	leaq	22(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215511(%rsp), %al
	movq	$3, %rcx
	leaq	23(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215512(%rsp), %al
	movq	$3, %rcx
	leaq	24(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215513(%rsp), %al
	movq	$3, %rcx
	leaq	25(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215514(%rsp), %al
	movq	$3, %rcx
	leaq	26(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215515(%rsp), %al
	movq	$3, %rcx
	leaq	27(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215516(%rsp), %al
	movq	$3, %rcx
	leaq	28(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215517(%rsp), %al
	movq	$3, %rcx
	leaq	29(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215518(%rsp), %al
	movq	$3, %rcx
	leaq	30(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215519(%rsp), %al
	movq	$3, %rcx
	leaq	31(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215520(%rsp), %al
	movq	$3, %rcx
	leaq	32(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215521(%rsp), %al
	movq	$3, %rcx
	leaq	33(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215522(%rsp), %al
	movq	$3, %rcx
	leaq	34(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215523(%rsp), %al
	movq	$3, %rcx
	leaq	35(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215524(%rsp), %al
	movq	$3, %rcx
	leaq	36(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215525(%rsp), %al
	movq	$3, %rcx
	leaq	37(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215526(%rsp), %al
	movq	$3, %rcx
	leaq	38(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215527(%rsp), %al
	movq	$3, %rcx
	leaq	39(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215528(%rsp), %al
	movq	$3, %rcx
	leaq	40(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215529(%rsp), %al
	movq	$3, %rcx
	leaq	41(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215530(%rsp), %al
	movq	$3, %rcx
	leaq	42(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215531(%rsp), %al
	movq	$3, %rcx
	leaq	43(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215532(%rsp), %al
	movq	$3, %rcx
	leaq	44(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215533(%rsp), %al
	movq	$3, %rcx
	leaq	45(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215534(%rsp), %al
	movq	$3, %rcx
	leaq	46(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215535(%rsp), %al
	movq	$3, %rcx
	leaq	47(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215536(%rsp), %al
	movq	$3, %rcx
	leaq	48(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215537(%rsp), %al
	movq	$3, %rcx
	leaq	49(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215538(%rsp), %al
	movq	$3, %rcx
	leaq	50(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215539(%rsp), %al
	movq	$3, %rcx
	leaq	51(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215540(%rsp), %al
	movq	$3, %rcx
	leaq	52(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215541(%rsp), %al
	movq	$3, %rcx
	leaq	53(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215542(%rsp), %al
	movq	$3, %rcx
	leaq	54(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215543(%rsp), %al
	movq	$3, %rcx
	leaq	55(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215544(%rsp), %al
	movq	$3, %rcx
	leaq	56(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215545(%rsp), %al
	movq	$3, %rcx
	leaq	57(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215546(%rsp), %al
	movq	$3, %rcx
	leaq	58(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215547(%rsp), %al
	movq	$3, %rcx
	leaq	59(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215548(%rsp), %al
	movq	$3, %rcx
	leaq	60(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215549(%rsp), %al
	movq	$3, %rcx
	leaq	61(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215550(%rsp), %al
	movq	$3, %rcx
	leaq	62(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215551(%rsp), %al
	movq	$3, %rcx
	leaq	63(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	leaq	304(%rsp), %rdi
	leaq	215488(%rsp), %rax
	call	Lunbitslice_m_vec$1
Lmayo2_crypto_sign_open$70:
	movb	215488(%rsp), %al
	movq	$4, %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215489(%rsp), %al
	movq	$4, %rcx
	leaq	1(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215490(%rsp), %al
	movq	$4, %rcx
	leaq	2(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215491(%rsp), %al
	movq	$4, %rcx
	leaq	3(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215492(%rsp), %al
	movq	$4, %rcx
	leaq	4(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215493(%rsp), %al
	movq	$4, %rcx
	leaq	5(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215494(%rsp), %al
	movq	$4, %rcx
	leaq	6(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215495(%rsp), %al
	movq	$4, %rcx
	leaq	7(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215496(%rsp), %al
	movq	$4, %rcx
	leaq	8(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215497(%rsp), %al
	movq	$4, %rcx
	leaq	9(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215498(%rsp), %al
	movq	$4, %rcx
	leaq	10(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215499(%rsp), %al
	movq	$4, %rcx
	leaq	11(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215500(%rsp), %al
	movq	$4, %rcx
	leaq	12(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215501(%rsp), %al
	movq	$4, %rcx
	leaq	13(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215502(%rsp), %al
	movq	$4, %rcx
	leaq	14(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215503(%rsp), %al
	movq	$4, %rcx
	leaq	15(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215504(%rsp), %al
	movq	$4, %rcx
	leaq	16(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215505(%rsp), %al
	movq	$4, %rcx
	leaq	17(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215506(%rsp), %al
	movq	$4, %rcx
	leaq	18(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215507(%rsp), %al
	movq	$4, %rcx
	leaq	19(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215508(%rsp), %al
	movq	$4, %rcx
	leaq	20(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215509(%rsp), %al
	movq	$4, %rcx
	leaq	21(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215510(%rsp), %al
	movq	$4, %rcx
	leaq	22(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215511(%rsp), %al
	movq	$4, %rcx
	leaq	23(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215512(%rsp), %al
	movq	$4, %rcx
	leaq	24(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215513(%rsp), %al
	movq	$4, %rcx
	leaq	25(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215514(%rsp), %al
	movq	$4, %rcx
	leaq	26(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215515(%rsp), %al
	movq	$4, %rcx
	leaq	27(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215516(%rsp), %al
	movq	$4, %rcx
	leaq	28(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215517(%rsp), %al
	movq	$4, %rcx
	leaq	29(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215518(%rsp), %al
	movq	$4, %rcx
	leaq	30(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215519(%rsp), %al
	movq	$4, %rcx
	leaq	31(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215520(%rsp), %al
	movq	$4, %rcx
	leaq	32(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215521(%rsp), %al
	movq	$4, %rcx
	leaq	33(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215522(%rsp), %al
	movq	$4, %rcx
	leaq	34(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215523(%rsp), %al
	movq	$4, %rcx
	leaq	35(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215524(%rsp), %al
	movq	$4, %rcx
	leaq	36(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215525(%rsp), %al
	movq	$4, %rcx
	leaq	37(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215526(%rsp), %al
	movq	$4, %rcx
	leaq	38(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215527(%rsp), %al
	movq	$4, %rcx
	leaq	39(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215528(%rsp), %al
	movq	$4, %rcx
	leaq	40(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215529(%rsp), %al
	movq	$4, %rcx
	leaq	41(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215530(%rsp), %al
	movq	$4, %rcx
	leaq	42(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215531(%rsp), %al
	movq	$4, %rcx
	leaq	43(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215532(%rsp), %al
	movq	$4, %rcx
	leaq	44(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215533(%rsp), %al
	movq	$4, %rcx
	leaq	45(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215534(%rsp), %al
	movq	$4, %rcx
	leaq	46(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215535(%rsp), %al
	movq	$4, %rcx
	leaq	47(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215536(%rsp), %al
	movq	$4, %rcx
	leaq	48(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215537(%rsp), %al
	movq	$4, %rcx
	leaq	49(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215538(%rsp), %al
	movq	$4, %rcx
	leaq	50(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215539(%rsp), %al
	movq	$4, %rcx
	leaq	51(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215540(%rsp), %al
	movq	$4, %rcx
	leaq	52(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215541(%rsp), %al
	movq	$4, %rcx
	leaq	53(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215542(%rsp), %al
	movq	$4, %rcx
	leaq	54(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215543(%rsp), %al
	movq	$4, %rcx
	leaq	55(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215544(%rsp), %al
	movq	$4, %rcx
	leaq	56(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215545(%rsp), %al
	movq	$4, %rcx
	leaq	57(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215546(%rsp), %al
	movq	$4, %rcx
	leaq	58(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215547(%rsp), %al
	movq	$4, %rcx
	leaq	59(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215548(%rsp), %al
	movq	$4, %rcx
	leaq	60(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215549(%rsp), %al
	movq	$4, %rcx
	leaq	61(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215550(%rsp), %al
	movq	$4, %rcx
	leaq	62(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215551(%rsp), %al
	movq	$4, %rcx
	leaq	63(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	leaq	272(%rsp), %rdi
	leaq	215488(%rsp), %rax
	call	Lunbitslice_m_vec$1
Lmayo2_crypto_sign_open$69:
	movb	215488(%rsp), %al
	movq	$5, %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215489(%rsp), %al
	movq	$5, %rcx
	leaq	1(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215490(%rsp), %al
	movq	$5, %rcx
	leaq	2(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215491(%rsp), %al
	movq	$5, %rcx
	leaq	3(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215492(%rsp), %al
	movq	$5, %rcx
	leaq	4(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215493(%rsp), %al
	movq	$5, %rcx
	leaq	5(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215494(%rsp), %al
	movq	$5, %rcx
	leaq	6(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215495(%rsp), %al
	movq	$5, %rcx
	leaq	7(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215496(%rsp), %al
	movq	$5, %rcx
	leaq	8(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215497(%rsp), %al
	movq	$5, %rcx
	leaq	9(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215498(%rsp), %al
	movq	$5, %rcx
	leaq	10(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215499(%rsp), %al
	movq	$5, %rcx
	leaq	11(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215500(%rsp), %al
	movq	$5, %rcx
	leaq	12(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215501(%rsp), %al
	movq	$5, %rcx
	leaq	13(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215502(%rsp), %al
	movq	$5, %rcx
	leaq	14(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215503(%rsp), %al
	movq	$5, %rcx
	leaq	15(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215504(%rsp), %al
	movq	$5, %rcx
	leaq	16(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215505(%rsp), %al
	movq	$5, %rcx
	leaq	17(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215506(%rsp), %al
	movq	$5, %rcx
	leaq	18(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215507(%rsp), %al
	movq	$5, %rcx
	leaq	19(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215508(%rsp), %al
	movq	$5, %rcx
	leaq	20(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215509(%rsp), %al
	movq	$5, %rcx
	leaq	21(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215510(%rsp), %al
	movq	$5, %rcx
	leaq	22(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215511(%rsp), %al
	movq	$5, %rcx
	leaq	23(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215512(%rsp), %al
	movq	$5, %rcx
	leaq	24(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215513(%rsp), %al
	movq	$5, %rcx
	leaq	25(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215514(%rsp), %al
	movq	$5, %rcx
	leaq	26(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215515(%rsp), %al
	movq	$5, %rcx
	leaq	27(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215516(%rsp), %al
	movq	$5, %rcx
	leaq	28(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215517(%rsp), %al
	movq	$5, %rcx
	leaq	29(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215518(%rsp), %al
	movq	$5, %rcx
	leaq	30(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215519(%rsp), %al
	movq	$5, %rcx
	leaq	31(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215520(%rsp), %al
	movq	$5, %rcx
	leaq	32(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215521(%rsp), %al
	movq	$5, %rcx
	leaq	33(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215522(%rsp), %al
	movq	$5, %rcx
	leaq	34(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215523(%rsp), %al
	movq	$5, %rcx
	leaq	35(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215524(%rsp), %al
	movq	$5, %rcx
	leaq	36(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215525(%rsp), %al
	movq	$5, %rcx
	leaq	37(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215526(%rsp), %al
	movq	$5, %rcx
	leaq	38(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215527(%rsp), %al
	movq	$5, %rcx
	leaq	39(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215528(%rsp), %al
	movq	$5, %rcx
	leaq	40(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215529(%rsp), %al
	movq	$5, %rcx
	leaq	41(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215530(%rsp), %al
	movq	$5, %rcx
	leaq	42(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215531(%rsp), %al
	movq	$5, %rcx
	leaq	43(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215532(%rsp), %al
	movq	$5, %rcx
	leaq	44(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215533(%rsp), %al
	movq	$5, %rcx
	leaq	45(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215534(%rsp), %al
	movq	$5, %rcx
	leaq	46(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215535(%rsp), %al
	movq	$5, %rcx
	leaq	47(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215536(%rsp), %al
	movq	$5, %rcx
	leaq	48(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215537(%rsp), %al
	movq	$5, %rcx
	leaq	49(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215538(%rsp), %al
	movq	$5, %rcx
	leaq	50(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215539(%rsp), %al
	movq	$5, %rcx
	leaq	51(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215540(%rsp), %al
	movq	$5, %rcx
	leaq	52(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215541(%rsp), %al
	movq	$5, %rcx
	leaq	53(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215542(%rsp), %al
	movq	$5, %rcx
	leaq	54(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215543(%rsp), %al
	movq	$5, %rcx
	leaq	55(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215544(%rsp), %al
	movq	$5, %rcx
	leaq	56(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215545(%rsp), %al
	movq	$5, %rcx
	leaq	57(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215546(%rsp), %al
	movq	$5, %rcx
	leaq	58(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215547(%rsp), %al
	movq	$5, %rcx
	leaq	59(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215548(%rsp), %al
	movq	$5, %rcx
	leaq	60(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215549(%rsp), %al
	movq	$5, %rcx
	leaq	61(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215550(%rsp), %al
	movq	$5, %rcx
	leaq	62(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215551(%rsp), %al
	movq	$5, %rcx
	leaq	63(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	leaq	240(%rsp), %rdi
	leaq	215488(%rsp), %rax
	call	Lunbitslice_m_vec$1
Lmayo2_crypto_sign_open$68:
	movb	215488(%rsp), %al
	movq	$6, %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215489(%rsp), %al
	movq	$6, %rcx
	leaq	1(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215490(%rsp), %al
	movq	$6, %rcx
	leaq	2(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215491(%rsp), %al
	movq	$6, %rcx
	leaq	3(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215492(%rsp), %al
	movq	$6, %rcx
	leaq	4(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215493(%rsp), %al
	movq	$6, %rcx
	leaq	5(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215494(%rsp), %al
	movq	$6, %rcx
	leaq	6(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215495(%rsp), %al
	movq	$6, %rcx
	leaq	7(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215496(%rsp), %al
	movq	$6, %rcx
	leaq	8(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215497(%rsp), %al
	movq	$6, %rcx
	leaq	9(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215498(%rsp), %al
	movq	$6, %rcx
	leaq	10(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215499(%rsp), %al
	movq	$6, %rcx
	leaq	11(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215500(%rsp), %al
	movq	$6, %rcx
	leaq	12(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215501(%rsp), %al
	movq	$6, %rcx
	leaq	13(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215502(%rsp), %al
	movq	$6, %rcx
	leaq	14(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215503(%rsp), %al
	movq	$6, %rcx
	leaq	15(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215504(%rsp), %al
	movq	$6, %rcx
	leaq	16(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215505(%rsp), %al
	movq	$6, %rcx
	leaq	17(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215506(%rsp), %al
	movq	$6, %rcx
	leaq	18(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215507(%rsp), %al
	movq	$6, %rcx
	leaq	19(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215508(%rsp), %al
	movq	$6, %rcx
	leaq	20(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215509(%rsp), %al
	movq	$6, %rcx
	leaq	21(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215510(%rsp), %al
	movq	$6, %rcx
	leaq	22(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215511(%rsp), %al
	movq	$6, %rcx
	leaq	23(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215512(%rsp), %al
	movq	$6, %rcx
	leaq	24(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215513(%rsp), %al
	movq	$6, %rcx
	leaq	25(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215514(%rsp), %al
	movq	$6, %rcx
	leaq	26(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215515(%rsp), %al
	movq	$6, %rcx
	leaq	27(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215516(%rsp), %al
	movq	$6, %rcx
	leaq	28(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215517(%rsp), %al
	movq	$6, %rcx
	leaq	29(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215518(%rsp), %al
	movq	$6, %rcx
	leaq	30(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215519(%rsp), %al
	movq	$6, %rcx
	leaq	31(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215520(%rsp), %al
	movq	$6, %rcx
	leaq	32(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215521(%rsp), %al
	movq	$6, %rcx
	leaq	33(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215522(%rsp), %al
	movq	$6, %rcx
	leaq	34(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215523(%rsp), %al
	movq	$6, %rcx
	leaq	35(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215524(%rsp), %al
	movq	$6, %rcx
	leaq	36(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215525(%rsp), %al
	movq	$6, %rcx
	leaq	37(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215526(%rsp), %al
	movq	$6, %rcx
	leaq	38(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215527(%rsp), %al
	movq	$6, %rcx
	leaq	39(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215528(%rsp), %al
	movq	$6, %rcx
	leaq	40(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215529(%rsp), %al
	movq	$6, %rcx
	leaq	41(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215530(%rsp), %al
	movq	$6, %rcx
	leaq	42(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215531(%rsp), %al
	movq	$6, %rcx
	leaq	43(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215532(%rsp), %al
	movq	$6, %rcx
	leaq	44(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215533(%rsp), %al
	movq	$6, %rcx
	leaq	45(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215534(%rsp), %al
	movq	$6, %rcx
	leaq	46(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215535(%rsp), %al
	movq	$6, %rcx
	leaq	47(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215536(%rsp), %al
	movq	$6, %rcx
	leaq	48(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215537(%rsp), %al
	movq	$6, %rcx
	leaq	49(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215538(%rsp), %al
	movq	$6, %rcx
	leaq	50(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215539(%rsp), %al
	movq	$6, %rcx
	leaq	51(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215540(%rsp), %al
	movq	$6, %rcx
	leaq	52(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215541(%rsp), %al
	movq	$6, %rcx
	leaq	53(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215542(%rsp), %al
	movq	$6, %rcx
	leaq	54(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215543(%rsp), %al
	movq	$6, %rcx
	leaq	55(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215544(%rsp), %al
	movq	$6, %rcx
	leaq	56(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215545(%rsp), %al
	movq	$6, %rcx
	leaq	57(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215546(%rsp), %al
	movq	$6, %rcx
	leaq	58(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215547(%rsp), %al
	movq	$6, %rcx
	leaq	59(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215548(%rsp), %al
	movq	$6, %rcx
	leaq	60(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215549(%rsp), %al
	movq	$6, %rcx
	leaq	61(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215550(%rsp), %al
	movq	$6, %rcx
	leaq	62(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215551(%rsp), %al
	movq	$6, %rcx
	leaq	63(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	leaq	368(%rsp), %rdi
	leaq	215488(%rsp), %rax
	call	Lunbitslice_m_vec$1
Lmayo2_crypto_sign_open$67:
	movb	215488(%rsp), %al
	movq	$7, %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215489(%rsp), %al
	movq	$7, %rcx
	leaq	1(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215490(%rsp), %al
	movq	$7, %rcx
	leaq	2(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215491(%rsp), %al
	movq	$7, %rcx
	leaq	3(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215492(%rsp), %al
	movq	$7, %rcx
	leaq	4(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215493(%rsp), %al
	movq	$7, %rcx
	leaq	5(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215494(%rsp), %al
	movq	$7, %rcx
	leaq	6(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215495(%rsp), %al
	movq	$7, %rcx
	leaq	7(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215496(%rsp), %al
	movq	$7, %rcx
	leaq	8(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215497(%rsp), %al
	movq	$7, %rcx
	leaq	9(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215498(%rsp), %al
	movq	$7, %rcx
	leaq	10(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215499(%rsp), %al
	movq	$7, %rcx
	leaq	11(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215500(%rsp), %al
	movq	$7, %rcx
	leaq	12(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215501(%rsp), %al
	movq	$7, %rcx
	leaq	13(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215502(%rsp), %al
	movq	$7, %rcx
	leaq	14(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215503(%rsp), %al
	movq	$7, %rcx
	leaq	15(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215504(%rsp), %al
	movq	$7, %rcx
	leaq	16(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215505(%rsp), %al
	movq	$7, %rcx
	leaq	17(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215506(%rsp), %al
	movq	$7, %rcx
	leaq	18(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215507(%rsp), %al
	movq	$7, %rcx
	leaq	19(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215508(%rsp), %al
	movq	$7, %rcx
	leaq	20(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215509(%rsp), %al
	movq	$7, %rcx
	leaq	21(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215510(%rsp), %al
	movq	$7, %rcx
	leaq	22(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215511(%rsp), %al
	movq	$7, %rcx
	leaq	23(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215512(%rsp), %al
	movq	$7, %rcx
	leaq	24(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215513(%rsp), %al
	movq	$7, %rcx
	leaq	25(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215514(%rsp), %al
	movq	$7, %rcx
	leaq	26(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215515(%rsp), %al
	movq	$7, %rcx
	leaq	27(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215516(%rsp), %al
	movq	$7, %rcx
	leaq	28(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215517(%rsp), %al
	movq	$7, %rcx
	leaq	29(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215518(%rsp), %al
	movq	$7, %rcx
	leaq	30(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215519(%rsp), %al
	movq	$7, %rcx
	leaq	31(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215520(%rsp), %al
	movq	$7, %rcx
	leaq	32(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215521(%rsp), %al
	movq	$7, %rcx
	leaq	33(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215522(%rsp), %al
	movq	$7, %rcx
	leaq	34(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215523(%rsp), %al
	movq	$7, %rcx
	leaq	35(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215524(%rsp), %al
	movq	$7, %rcx
	leaq	36(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215525(%rsp), %al
	movq	$7, %rcx
	leaq	37(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215526(%rsp), %al
	movq	$7, %rcx
	leaq	38(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215527(%rsp), %al
	movq	$7, %rcx
	leaq	39(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215528(%rsp), %al
	movq	$7, %rcx
	leaq	40(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215529(%rsp), %al
	movq	$7, %rcx
	leaq	41(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215530(%rsp), %al
	movq	$7, %rcx
	leaq	42(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215531(%rsp), %al
	movq	$7, %rcx
	leaq	43(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215532(%rsp), %al
	movq	$7, %rcx
	leaq	44(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215533(%rsp), %al
	movq	$7, %rcx
	leaq	45(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215534(%rsp), %al
	movq	$7, %rcx
	leaq	46(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215535(%rsp), %al
	movq	$7, %rcx
	leaq	47(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215536(%rsp), %al
	movq	$7, %rcx
	leaq	48(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215537(%rsp), %al
	movq	$7, %rcx
	leaq	49(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215538(%rsp), %al
	movq	$7, %rcx
	leaq	50(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215539(%rsp), %al
	movq	$7, %rcx
	leaq	51(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215540(%rsp), %al
	movq	$7, %rcx
	leaq	52(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215541(%rsp), %al
	movq	$7, %rcx
	leaq	53(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215542(%rsp), %al
	movq	$7, %rcx
	leaq	54(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215543(%rsp), %al
	movq	$7, %rcx
	leaq	55(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215544(%rsp), %al
	movq	$7, %rcx
	leaq	56(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215545(%rsp), %al
	movq	$7, %rcx
	leaq	57(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215546(%rsp), %al
	movq	$7, %rcx
	leaq	58(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215547(%rsp), %al
	movq	$7, %rcx
	leaq	59(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215548(%rsp), %al
	movq	$7, %rcx
	leaq	60(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215549(%rsp), %al
	movq	$7, %rcx
	leaq	61(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215550(%rsp), %al
	movq	$7, %rcx
	leaq	62(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215551(%rsp), %al
	movq	$7, %rcx
	leaq	63(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	leaq	336(%rsp), %rdi
	leaq	215488(%rsp), %rax
	call	Lunbitslice_m_vec$1
Lmayo2_crypto_sign_open$66:
	movb	215488(%rsp), %al
	movq	$8, %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215489(%rsp), %al
	movq	$8, %rcx
	leaq	1(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215490(%rsp), %al
	movq	$8, %rcx
	leaq	2(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215491(%rsp), %al
	movq	$8, %rcx
	leaq	3(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215492(%rsp), %al
	movq	$8, %rcx
	leaq	4(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215493(%rsp), %al
	movq	$8, %rcx
	leaq	5(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215494(%rsp), %al
	movq	$8, %rcx
	leaq	6(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215495(%rsp), %al
	movq	$8, %rcx
	leaq	7(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215496(%rsp), %al
	movq	$8, %rcx
	leaq	8(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215497(%rsp), %al
	movq	$8, %rcx
	leaq	9(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215498(%rsp), %al
	movq	$8, %rcx
	leaq	10(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215499(%rsp), %al
	movq	$8, %rcx
	leaq	11(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215500(%rsp), %al
	movq	$8, %rcx
	leaq	12(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215501(%rsp), %al
	movq	$8, %rcx
	leaq	13(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215502(%rsp), %al
	movq	$8, %rcx
	leaq	14(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215503(%rsp), %al
	movq	$8, %rcx
	leaq	15(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215504(%rsp), %al
	movq	$8, %rcx
	leaq	16(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215505(%rsp), %al
	movq	$8, %rcx
	leaq	17(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215506(%rsp), %al
	movq	$8, %rcx
	leaq	18(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215507(%rsp), %al
	movq	$8, %rcx
	leaq	19(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215508(%rsp), %al
	movq	$8, %rcx
	leaq	20(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215509(%rsp), %al
	movq	$8, %rcx
	leaq	21(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215510(%rsp), %al
	movq	$8, %rcx
	leaq	22(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215511(%rsp), %al
	movq	$8, %rcx
	leaq	23(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215512(%rsp), %al
	movq	$8, %rcx
	leaq	24(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215513(%rsp), %al
	movq	$8, %rcx
	leaq	25(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215514(%rsp), %al
	movq	$8, %rcx
	leaq	26(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215515(%rsp), %al
	movq	$8, %rcx
	leaq	27(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215516(%rsp), %al
	movq	$8, %rcx
	leaq	28(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215517(%rsp), %al
	movq	$8, %rcx
	leaq	29(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215518(%rsp), %al
	movq	$8, %rcx
	leaq	30(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215519(%rsp), %al
	movq	$8, %rcx
	leaq	31(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215520(%rsp), %al
	movq	$8, %rcx
	leaq	32(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215521(%rsp), %al
	movq	$8, %rcx
	leaq	33(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215522(%rsp), %al
	movq	$8, %rcx
	leaq	34(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215523(%rsp), %al
	movq	$8, %rcx
	leaq	35(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215524(%rsp), %al
	movq	$8, %rcx
	leaq	36(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215525(%rsp), %al
	movq	$8, %rcx
	leaq	37(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215526(%rsp), %al
	movq	$8, %rcx
	leaq	38(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215527(%rsp), %al
	movq	$8, %rcx
	leaq	39(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215528(%rsp), %al
	movq	$8, %rcx
	leaq	40(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215529(%rsp), %al
	movq	$8, %rcx
	leaq	41(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215530(%rsp), %al
	movq	$8, %rcx
	leaq	42(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215531(%rsp), %al
	movq	$8, %rcx
	leaq	43(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215532(%rsp), %al
	movq	$8, %rcx
	leaq	44(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215533(%rsp), %al
	movq	$8, %rcx
	leaq	45(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215534(%rsp), %al
	movq	$8, %rcx
	leaq	46(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215535(%rsp), %al
	movq	$8, %rcx
	leaq	47(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215536(%rsp), %al
	movq	$8, %rcx
	leaq	48(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215537(%rsp), %al
	movq	$8, %rcx
	leaq	49(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215538(%rsp), %al
	movq	$8, %rcx
	leaq	50(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215539(%rsp), %al
	movq	$8, %rcx
	leaq	51(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215540(%rsp), %al
	movq	$8, %rcx
	leaq	52(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215541(%rsp), %al
	movq	$8, %rcx
	leaq	53(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215542(%rsp), %al
	movq	$8, %rcx
	leaq	54(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215543(%rsp), %al
	movq	$8, %rcx
	leaq	55(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215544(%rsp), %al
	movq	$8, %rcx
	leaq	56(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215545(%rsp), %al
	movq	$8, %rcx
	leaq	57(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215546(%rsp), %al
	movq	$8, %rcx
	leaq	58(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215547(%rsp), %al
	movq	$8, %rcx
	leaq	59(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215548(%rsp), %al
	movq	$8, %rcx
	leaq	60(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215549(%rsp), %al
	movq	$8, %rcx
	leaq	61(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215550(%rsp), %al
	movq	$8, %rcx
	leaq	62(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215551(%rsp), %al
	movq	$8, %rcx
	leaq	63(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	leaq	400(%rsp), %rdi
	leaq	215488(%rsp), %rax
	call	Lunbitslice_m_vec$1
Lmayo2_crypto_sign_open$65:
	movb	215488(%rsp), %al
	movq	$9, %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215489(%rsp), %al
	movq	$9, %rcx
	leaq	1(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215490(%rsp), %al
	movq	$9, %rcx
	leaq	2(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215491(%rsp), %al
	movq	$9, %rcx
	leaq	3(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215492(%rsp), %al
	movq	$9, %rcx
	leaq	4(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215493(%rsp), %al
	movq	$9, %rcx
	leaq	5(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215494(%rsp), %al
	movq	$9, %rcx
	leaq	6(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215495(%rsp), %al
	movq	$9, %rcx
	leaq	7(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215496(%rsp), %al
	movq	$9, %rcx
	leaq	8(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215497(%rsp), %al
	movq	$9, %rcx
	leaq	9(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215498(%rsp), %al
	movq	$9, %rcx
	leaq	10(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215499(%rsp), %al
	movq	$9, %rcx
	leaq	11(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215500(%rsp), %al
	movq	$9, %rcx
	leaq	12(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215501(%rsp), %al
	movq	$9, %rcx
	leaq	13(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215502(%rsp), %al
	movq	$9, %rcx
	leaq	14(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215503(%rsp), %al
	movq	$9, %rcx
	leaq	15(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215504(%rsp), %al
	movq	$9, %rcx
	leaq	16(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215505(%rsp), %al
	movq	$9, %rcx
	leaq	17(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215506(%rsp), %al
	movq	$9, %rcx
	leaq	18(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215507(%rsp), %al
	movq	$9, %rcx
	leaq	19(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215508(%rsp), %al
	movq	$9, %rcx
	leaq	20(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215509(%rsp), %al
	movq	$9, %rcx
	leaq	21(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215510(%rsp), %al
	movq	$9, %rcx
	leaq	22(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215511(%rsp), %al
	movq	$9, %rcx
	leaq	23(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215512(%rsp), %al
	movq	$9, %rcx
	leaq	24(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215513(%rsp), %al
	movq	$9, %rcx
	leaq	25(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215514(%rsp), %al
	movq	$9, %rcx
	leaq	26(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215515(%rsp), %al
	movq	$9, %rcx
	leaq	27(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215516(%rsp), %al
	movq	$9, %rcx
	leaq	28(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215517(%rsp), %al
	movq	$9, %rcx
	leaq	29(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215518(%rsp), %al
	movq	$9, %rcx
	leaq	30(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215519(%rsp), %al
	movq	$9, %rcx
	leaq	31(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215520(%rsp), %al
	movq	$9, %rcx
	leaq	32(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215521(%rsp), %al
	movq	$9, %rcx
	leaq	33(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215522(%rsp), %al
	movq	$9, %rcx
	leaq	34(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215523(%rsp), %al
	movq	$9, %rcx
	leaq	35(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215524(%rsp), %al
	movq	$9, %rcx
	leaq	36(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215525(%rsp), %al
	movq	$9, %rcx
	leaq	37(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215526(%rsp), %al
	movq	$9, %rcx
	leaq	38(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215527(%rsp), %al
	movq	$9, %rcx
	leaq	39(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215528(%rsp), %al
	movq	$9, %rcx
	leaq	40(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215529(%rsp), %al
	movq	$9, %rcx
	leaq	41(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215530(%rsp), %al
	movq	$9, %rcx
	leaq	42(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215531(%rsp), %al
	movq	$9, %rcx
	leaq	43(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215532(%rsp), %al
	movq	$9, %rcx
	leaq	44(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215533(%rsp), %al
	movq	$9, %rcx
	leaq	45(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215534(%rsp), %al
	movq	$9, %rcx
	leaq	46(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215535(%rsp), %al
	movq	$9, %rcx
	leaq	47(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215536(%rsp), %al
	movq	$9, %rcx
	leaq	48(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215537(%rsp), %al
	movq	$9, %rcx
	leaq	49(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215538(%rsp), %al
	movq	$9, %rcx
	leaq	50(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215539(%rsp), %al
	movq	$9, %rcx
	leaq	51(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215540(%rsp), %al
	movq	$9, %rcx
	leaq	52(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215541(%rsp), %al
	movq	$9, %rcx
	leaq	53(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215542(%rsp), %al
	movq	$9, %rcx
	leaq	54(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215543(%rsp), %al
	movq	$9, %rcx
	leaq	55(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215544(%rsp), %al
	movq	$9, %rcx
	leaq	56(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215545(%rsp), %al
	movq	$9, %rcx
	leaq	57(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215546(%rsp), %al
	movq	$9, %rcx
	leaq	58(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215547(%rsp), %al
	movq	$9, %rcx
	leaq	59(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215548(%rsp), %al
	movq	$9, %rcx
	leaq	60(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215549(%rsp), %al
	movq	$9, %rcx
	leaq	61(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215550(%rsp), %al
	movq	$9, %rcx
	leaq	62(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movb	215551(%rsp), %al
	movq	$9, %rcx
	leaq	63(%rcx), %rcx
	xorb	%al, 215552(%rsp,%rcx)
	movzbq	215624(%rsp), %rax
	movzbq	glob_data + 224(%rip), %rcx
	movq	%rax, %rdx
	andq	$1, %rdx
	imulq	%rcx, %rdx
	movq	%rax, %rsi
	andq	$2, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	movq	%rax, %rsi
	andq	$4, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	andq	$8, %rax
	imulq	%rcx, %rax
	xorq	%rax, %rdx
	movq	%rdx, (%rsp)
	movq	(%rsp), %rax
	movq	%rax, 8(%rsp)
	andq	$240, 8(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 16(%rsp)
	shrq	$3, 16(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 8(%rsp)
	shrq	$4, 8(%rsp)
	movq	(%rsp), %rax
	xorq	8(%rsp), %rax
	xorq	16(%rsp), %rax
	andq	$15, %rax
	movzbq	215560(%rsp), %rcx
	xorq	%rax, %rcx
	movq	$72, %rax
	leaq	-64(%rax), %rax
	movb	%cl, 215552(%rsp,%rax)
	movzbq	215624(%rsp), %rax
	movzbq	glob_data + 225(%rip), %rcx
	movq	%rax, %rdx
	andq	$1, %rdx
	imulq	%rcx, %rdx
	movq	%rax, %rsi
	andq	$2, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	movq	%rax, %rsi
	andq	$4, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	andq	$8, %rax
	imulq	%rcx, %rax
	xorq	%rax, %rdx
	movq	%rdx, 16(%rsp)
	movq	16(%rsp), %rax
	movq	%rax, 8(%rsp)
	andq	$240, 8(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, (%rsp)
	shrq	$3, (%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 8(%rsp)
	shrq	$4, 8(%rsp)
	movq	16(%rsp), %rax
	xorq	8(%rsp), %rax
	xorq	(%rsp), %rax
	andq	$15, %rax
	movzbq	215561(%rsp), %rcx
	xorq	%rax, %rcx
	movq	$72, %rax
	leaq	-64(%rax), %rax
	leaq	1(%rax), %rax
	movb	%cl, 215552(%rsp,%rax)
	movzbq	215624(%rsp), %rax
	movzbq	glob_data + 226(%rip), %rcx
	movq	%rax, %rdx
	andq	$1, %rdx
	imulq	%rcx, %rdx
	movq	%rax, %rsi
	andq	$2, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	movq	%rax, %rsi
	andq	$4, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	andq	$8, %rax
	imulq	%rcx, %rax
	xorq	%rax, %rdx
	movq	%rdx, (%rsp)
	movq	(%rsp), %rax
	movq	%rax, 8(%rsp)
	andq	$240, 8(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 16(%rsp)
	shrq	$3, 16(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 8(%rsp)
	shrq	$4, 8(%rsp)
	movq	(%rsp), %rax
	xorq	8(%rsp), %rax
	xorq	16(%rsp), %rax
	andq	$15, %rax
	movzbq	215562(%rsp), %rcx
	xorq	%rax, %rcx
	movq	$72, %rax
	leaq	-64(%rax), %rax
	leaq	2(%rax), %rax
	movb	%cl, 215552(%rsp,%rax)
	movzbq	215624(%rsp), %rax
	movzbq	glob_data + 227(%rip), %rcx
	movq	%rax, %rdx
	andq	$1, %rdx
	imulq	%rcx, %rdx
	movq	%rax, %rsi
	andq	$2, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	movq	%rax, %rsi
	andq	$4, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	andq	$8, %rax
	imulq	%rcx, %rax
	xorq	%rax, %rdx
	movq	%rdx, 16(%rsp)
	movq	16(%rsp), %rax
	movq	%rax, 8(%rsp)
	andq	$240, 8(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, (%rsp)
	shrq	$3, (%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 8(%rsp)
	shrq	$4, 8(%rsp)
	movq	16(%rsp), %rax
	xorq	8(%rsp), %rax
	xorq	(%rsp), %rax
	andq	$15, %rax
	movzbq	215563(%rsp), %rcx
	xorq	%rax, %rcx
	movq	$72, %rax
	leaq	-64(%rax), %rax
	leaq	3(%rax), %rax
	movb	%cl, 215552(%rsp,%rax)
	movzbq	215624(%rsp), %rax
	movzbq	glob_data + 228(%rip), %rcx
	movq	%rax, %rdx
	andq	$1, %rdx
	imulq	%rcx, %rdx
	movq	%rax, %rsi
	andq	$2, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	movq	%rax, %rsi
	andq	$4, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	andq	$8, %rax
	imulq	%rcx, %rax
	xorq	%rax, %rdx
	movq	%rdx, (%rsp)
	movq	(%rsp), %rax
	movq	%rax, 8(%rsp)
	andq	$240, 8(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 16(%rsp)
	shrq	$3, 16(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 8(%rsp)
	shrq	$4, 8(%rsp)
	movq	(%rsp), %rax
	xorq	8(%rsp), %rax
	xorq	16(%rsp), %rax
	andq	$15, %rax
	movzbq	215564(%rsp), %rcx
	xorq	%rax, %rcx
	movq	$72, %rax
	leaq	-64(%rax), %rax
	leaq	4(%rax), %rax
	movb	%cl, 215552(%rsp,%rax)
	movb	$0, 215624(%rsp)
	movzbq	215623(%rsp), %rax
	movzbq	glob_data + 224(%rip), %rcx
	movq	%rax, %rdx
	andq	$1, %rdx
	imulq	%rcx, %rdx
	movq	%rax, %rsi
	andq	$2, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	movq	%rax, %rsi
	andq	$4, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	andq	$8, %rax
	imulq	%rcx, %rax
	xorq	%rax, %rdx
	movq	%rdx, 16(%rsp)
	movq	16(%rsp), %rax
	movq	%rax, 8(%rsp)
	andq	$240, 8(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, (%rsp)
	shrq	$3, (%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 8(%rsp)
	shrq	$4, 8(%rsp)
	movq	16(%rsp), %rax
	xorq	8(%rsp), %rax
	xorq	(%rsp), %rax
	andq	$15, %rax
	movzbq	215559(%rsp), %rcx
	xorq	%rax, %rcx
	movq	$71, %rax
	leaq	-64(%rax), %rax
	movb	%cl, 215552(%rsp,%rax)
	movzbq	215623(%rsp), %rax
	movzbq	glob_data + 225(%rip), %rcx
	movq	%rax, %rdx
	andq	$1, %rdx
	imulq	%rcx, %rdx
	movq	%rax, %rsi
	andq	$2, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	movq	%rax, %rsi
	andq	$4, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	andq	$8, %rax
	imulq	%rcx, %rax
	xorq	%rax, %rdx
	movq	%rdx, (%rsp)
	movq	(%rsp), %rax
	movq	%rax, 8(%rsp)
	andq	$240, 8(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 16(%rsp)
	shrq	$3, 16(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 8(%rsp)
	shrq	$4, 8(%rsp)
	movq	(%rsp), %rax
	xorq	8(%rsp), %rax
	xorq	16(%rsp), %rax
	andq	$15, %rax
	movzbq	215560(%rsp), %rcx
	xorq	%rax, %rcx
	movq	$71, %rax
	leaq	-64(%rax), %rax
	leaq	1(%rax), %rax
	movb	%cl, 215552(%rsp,%rax)
	movzbq	215623(%rsp), %rax
	movzbq	glob_data + 226(%rip), %rcx
	movq	%rax, %rdx
	andq	$1, %rdx
	imulq	%rcx, %rdx
	movq	%rax, %rsi
	andq	$2, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	movq	%rax, %rsi
	andq	$4, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	andq	$8, %rax
	imulq	%rcx, %rax
	xorq	%rax, %rdx
	movq	%rdx, 16(%rsp)
	movq	16(%rsp), %rax
	movq	%rax, 8(%rsp)
	andq	$240, 8(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, (%rsp)
	shrq	$3, (%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 8(%rsp)
	shrq	$4, 8(%rsp)
	movq	16(%rsp), %rax
	xorq	8(%rsp), %rax
	xorq	(%rsp), %rax
	andq	$15, %rax
	movzbq	215561(%rsp), %rcx
	xorq	%rax, %rcx
	movq	$71, %rax
	leaq	-64(%rax), %rax
	leaq	2(%rax), %rax
	movb	%cl, 215552(%rsp,%rax)
	movzbq	215623(%rsp), %rax
	movzbq	glob_data + 227(%rip), %rcx
	movq	%rax, %rdx
	andq	$1, %rdx
	imulq	%rcx, %rdx
	movq	%rax, %rsi
	andq	$2, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	movq	%rax, %rsi
	andq	$4, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	andq	$8, %rax
	imulq	%rcx, %rax
	xorq	%rax, %rdx
	movq	%rdx, (%rsp)
	movq	(%rsp), %rax
	movq	%rax, 8(%rsp)
	andq	$240, 8(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 16(%rsp)
	shrq	$3, 16(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 8(%rsp)
	shrq	$4, 8(%rsp)
	movq	(%rsp), %rax
	xorq	8(%rsp), %rax
	xorq	16(%rsp), %rax
	andq	$15, %rax
	movzbq	215562(%rsp), %rcx
	xorq	%rax, %rcx
	movq	$71, %rax
	leaq	-64(%rax), %rax
	leaq	3(%rax), %rax
	movb	%cl, 215552(%rsp,%rax)
	movzbq	215623(%rsp), %rax
	movzbq	glob_data + 228(%rip), %rcx
	movq	%rax, %rdx
	andq	$1, %rdx
	imulq	%rcx, %rdx
	movq	%rax, %rsi
	andq	$2, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	movq	%rax, %rsi
	andq	$4, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	andq	$8, %rax
	imulq	%rcx, %rax
	xorq	%rax, %rdx
	movq	%rdx, 16(%rsp)
	movq	16(%rsp), %rax
	movq	%rax, 8(%rsp)
	andq	$240, 8(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, (%rsp)
	shrq	$3, (%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 8(%rsp)
	shrq	$4, 8(%rsp)
	movq	16(%rsp), %rax
	xorq	8(%rsp), %rax
	xorq	(%rsp), %rax
	andq	$15, %rax
	movzbq	215563(%rsp), %rcx
	xorq	%rax, %rcx
	movq	$71, %rax
	leaq	-64(%rax), %rax
	leaq	4(%rax), %rax
	movb	%cl, 215552(%rsp,%rax)
	movb	$0, 215623(%rsp)
	movzbq	215622(%rsp), %rax
	movzbq	glob_data + 224(%rip), %rcx
	movq	%rax, %rdx
	andq	$1, %rdx
	imulq	%rcx, %rdx
	movq	%rax, %rsi
	andq	$2, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	movq	%rax, %rsi
	andq	$4, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	andq	$8, %rax
	imulq	%rcx, %rax
	xorq	%rax, %rdx
	movq	%rdx, (%rsp)
	movq	(%rsp), %rax
	movq	%rax, 8(%rsp)
	andq	$240, 8(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 16(%rsp)
	shrq	$3, 16(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 8(%rsp)
	shrq	$4, 8(%rsp)
	movq	(%rsp), %rax
	xorq	8(%rsp), %rax
	xorq	16(%rsp), %rax
	andq	$15, %rax
	movzbq	215558(%rsp), %rcx
	xorq	%rax, %rcx
	movq	$70, %rax
	leaq	-64(%rax), %rax
	movb	%cl, 215552(%rsp,%rax)
	movzbq	215622(%rsp), %rax
	movzbq	glob_data + 225(%rip), %rcx
	movq	%rax, %rdx
	andq	$1, %rdx
	imulq	%rcx, %rdx
	movq	%rax, %rsi
	andq	$2, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	movq	%rax, %rsi
	andq	$4, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	andq	$8, %rax
	imulq	%rcx, %rax
	xorq	%rax, %rdx
	movq	%rdx, 16(%rsp)
	movq	16(%rsp), %rax
	movq	%rax, 8(%rsp)
	andq	$240, 8(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, (%rsp)
	shrq	$3, (%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 8(%rsp)
	shrq	$4, 8(%rsp)
	movq	16(%rsp), %rax
	xorq	8(%rsp), %rax
	xorq	(%rsp), %rax
	andq	$15, %rax
	movzbq	215559(%rsp), %rcx
	xorq	%rax, %rcx
	movq	$70, %rax
	leaq	-64(%rax), %rax
	leaq	1(%rax), %rax
	movb	%cl, 215552(%rsp,%rax)
	movzbq	215622(%rsp), %rax
	movzbq	glob_data + 226(%rip), %rcx
	movq	%rax, %rdx
	andq	$1, %rdx
	imulq	%rcx, %rdx
	movq	%rax, %rsi
	andq	$2, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	movq	%rax, %rsi
	andq	$4, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	andq	$8, %rax
	imulq	%rcx, %rax
	xorq	%rax, %rdx
	movq	%rdx, (%rsp)
	movq	(%rsp), %rax
	movq	%rax, 8(%rsp)
	andq	$240, 8(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 16(%rsp)
	shrq	$3, 16(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 8(%rsp)
	shrq	$4, 8(%rsp)
	movq	(%rsp), %rax
	xorq	8(%rsp), %rax
	xorq	16(%rsp), %rax
	andq	$15, %rax
	movzbq	215560(%rsp), %rcx
	xorq	%rax, %rcx
	movq	$70, %rax
	leaq	-64(%rax), %rax
	leaq	2(%rax), %rax
	movb	%cl, 215552(%rsp,%rax)
	movzbq	215622(%rsp), %rax
	movzbq	glob_data + 227(%rip), %rcx
	movq	%rax, %rdx
	andq	$1, %rdx
	imulq	%rcx, %rdx
	movq	%rax, %rsi
	andq	$2, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	movq	%rax, %rsi
	andq	$4, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	andq	$8, %rax
	imulq	%rcx, %rax
	xorq	%rax, %rdx
	movq	%rdx, 16(%rsp)
	movq	16(%rsp), %rax
	movq	%rax, 8(%rsp)
	andq	$240, 8(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, (%rsp)
	shrq	$3, (%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 8(%rsp)
	shrq	$4, 8(%rsp)
	movq	16(%rsp), %rax
	xorq	8(%rsp), %rax
	xorq	(%rsp), %rax
	andq	$15, %rax
	movzbq	215561(%rsp), %rcx
	xorq	%rax, %rcx
	movq	$70, %rax
	leaq	-64(%rax), %rax
	leaq	3(%rax), %rax
	movb	%cl, 215552(%rsp,%rax)
	movzbq	215622(%rsp), %rax
	movzbq	glob_data + 228(%rip), %rcx
	movq	%rax, %rdx
	andq	$1, %rdx
	imulq	%rcx, %rdx
	movq	%rax, %rsi
	andq	$2, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	movq	%rax, %rsi
	andq	$4, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	andq	$8, %rax
	imulq	%rcx, %rax
	xorq	%rax, %rdx
	movq	%rdx, (%rsp)
	movq	(%rsp), %rax
	movq	%rax, 8(%rsp)
	andq	$240, 8(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 16(%rsp)
	shrq	$3, 16(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 8(%rsp)
	shrq	$4, 8(%rsp)
	movq	(%rsp), %rax
	xorq	8(%rsp), %rax
	xorq	16(%rsp), %rax
	andq	$15, %rax
	movzbq	215562(%rsp), %rcx
	xorq	%rax, %rcx
	movq	$70, %rax
	leaq	-64(%rax), %rax
	leaq	4(%rax), %rax
	movb	%cl, 215552(%rsp,%rax)
	movb	$0, 215622(%rsp)
	movzbq	215621(%rsp), %rax
	movzbq	glob_data + 224(%rip), %rcx
	movq	%rax, %rdx
	andq	$1, %rdx
	imulq	%rcx, %rdx
	movq	%rax, %rsi
	andq	$2, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	movq	%rax, %rsi
	andq	$4, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	andq	$8, %rax
	imulq	%rcx, %rax
	xorq	%rax, %rdx
	movq	%rdx, 16(%rsp)
	movq	16(%rsp), %rax
	movq	%rax, 8(%rsp)
	andq	$240, 8(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, (%rsp)
	shrq	$3, (%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 8(%rsp)
	shrq	$4, 8(%rsp)
	movq	16(%rsp), %rax
	xorq	8(%rsp), %rax
	xorq	(%rsp), %rax
	andq	$15, %rax
	movzbq	215557(%rsp), %rcx
	xorq	%rax, %rcx
	movq	$69, %rax
	leaq	-64(%rax), %rax
	movb	%cl, 215552(%rsp,%rax)
	movzbq	215621(%rsp), %rax
	movzbq	glob_data + 225(%rip), %rcx
	movq	%rax, %rdx
	andq	$1, %rdx
	imulq	%rcx, %rdx
	movq	%rax, %rsi
	andq	$2, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	movq	%rax, %rsi
	andq	$4, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	andq	$8, %rax
	imulq	%rcx, %rax
	xorq	%rax, %rdx
	movq	%rdx, (%rsp)
	movq	(%rsp), %rax
	movq	%rax, 8(%rsp)
	andq	$240, 8(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 16(%rsp)
	shrq	$3, 16(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 8(%rsp)
	shrq	$4, 8(%rsp)
	movq	(%rsp), %rax
	xorq	8(%rsp), %rax
	xorq	16(%rsp), %rax
	andq	$15, %rax
	movzbq	215558(%rsp), %rcx
	xorq	%rax, %rcx
	movq	$69, %rax
	leaq	-64(%rax), %rax
	leaq	1(%rax), %rax
	movb	%cl, 215552(%rsp,%rax)
	movzbq	215621(%rsp), %rax
	movzbq	glob_data + 226(%rip), %rcx
	movq	%rax, %rdx
	andq	$1, %rdx
	imulq	%rcx, %rdx
	movq	%rax, %rsi
	andq	$2, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	movq	%rax, %rsi
	andq	$4, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	andq	$8, %rax
	imulq	%rcx, %rax
	xorq	%rax, %rdx
	movq	%rdx, 16(%rsp)
	movq	16(%rsp), %rax
	movq	%rax, 8(%rsp)
	andq	$240, 8(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, (%rsp)
	shrq	$3, (%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 8(%rsp)
	shrq	$4, 8(%rsp)
	movq	16(%rsp), %rax
	xorq	8(%rsp), %rax
	xorq	(%rsp), %rax
	andq	$15, %rax
	movzbq	215559(%rsp), %rcx
	xorq	%rax, %rcx
	movq	$69, %rax
	leaq	-64(%rax), %rax
	leaq	2(%rax), %rax
	movb	%cl, 215552(%rsp,%rax)
	movzbq	215621(%rsp), %rax
	movzbq	glob_data + 227(%rip), %rcx
	movq	%rax, %rdx
	andq	$1, %rdx
	imulq	%rcx, %rdx
	movq	%rax, %rsi
	andq	$2, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	movq	%rax, %rsi
	andq	$4, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	andq	$8, %rax
	imulq	%rcx, %rax
	xorq	%rax, %rdx
	movq	%rdx, (%rsp)
	movq	(%rsp), %rax
	movq	%rax, 8(%rsp)
	andq	$240, 8(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 16(%rsp)
	shrq	$3, 16(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 8(%rsp)
	shrq	$4, 8(%rsp)
	movq	(%rsp), %rax
	xorq	8(%rsp), %rax
	xorq	16(%rsp), %rax
	andq	$15, %rax
	movzbq	215560(%rsp), %rcx
	xorq	%rax, %rcx
	movq	$69, %rax
	leaq	-64(%rax), %rax
	leaq	3(%rax), %rax
	movb	%cl, 215552(%rsp,%rax)
	movzbq	215621(%rsp), %rax
	movzbq	glob_data + 228(%rip), %rcx
	movq	%rax, %rdx
	andq	$1, %rdx
	imulq	%rcx, %rdx
	movq	%rax, %rsi
	andq	$2, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	movq	%rax, %rsi
	andq	$4, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	andq	$8, %rax
	imulq	%rcx, %rax
	xorq	%rax, %rdx
	movq	%rdx, 16(%rsp)
	movq	16(%rsp), %rax
	movq	%rax, 8(%rsp)
	andq	$240, 8(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, (%rsp)
	shrq	$3, (%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 8(%rsp)
	shrq	$4, 8(%rsp)
	movq	16(%rsp), %rax
	xorq	8(%rsp), %rax
	xorq	(%rsp), %rax
	andq	$15, %rax
	movzbq	215561(%rsp), %rcx
	xorq	%rax, %rcx
	movq	$69, %rax
	leaq	-64(%rax), %rax
	leaq	4(%rax), %rax
	movb	%cl, 215552(%rsp,%rax)
	movb	$0, 215621(%rsp)
	movzbq	215620(%rsp), %rax
	movzbq	glob_data + 224(%rip), %rcx
	movq	%rax, %rdx
	andq	$1, %rdx
	imulq	%rcx, %rdx
	movq	%rax, %rsi
	andq	$2, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	movq	%rax, %rsi
	andq	$4, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	andq	$8, %rax
	imulq	%rcx, %rax
	xorq	%rax, %rdx
	movq	%rdx, (%rsp)
	movq	(%rsp), %rax
	movq	%rax, 8(%rsp)
	andq	$240, 8(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 16(%rsp)
	shrq	$3, 16(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 8(%rsp)
	shrq	$4, 8(%rsp)
	movq	(%rsp), %rax
	xorq	8(%rsp), %rax
	xorq	16(%rsp), %rax
	andq	$15, %rax
	movzbq	215556(%rsp), %rcx
	xorq	%rax, %rcx
	movq	$68, %rax
	leaq	-64(%rax), %rax
	movb	%cl, 215552(%rsp,%rax)
	movzbq	215620(%rsp), %rax
	movzbq	glob_data + 225(%rip), %rcx
	movq	%rax, %rdx
	andq	$1, %rdx
	imulq	%rcx, %rdx
	movq	%rax, %rsi
	andq	$2, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	movq	%rax, %rsi
	andq	$4, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	andq	$8, %rax
	imulq	%rcx, %rax
	xorq	%rax, %rdx
	movq	%rdx, 16(%rsp)
	movq	16(%rsp), %rax
	movq	%rax, 8(%rsp)
	andq	$240, 8(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, (%rsp)
	shrq	$3, (%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 8(%rsp)
	shrq	$4, 8(%rsp)
	movq	16(%rsp), %rax
	xorq	8(%rsp), %rax
	xorq	(%rsp), %rax
	andq	$15, %rax
	movzbq	215557(%rsp), %rcx
	xorq	%rax, %rcx
	movq	$68, %rax
	leaq	-64(%rax), %rax
	leaq	1(%rax), %rax
	movb	%cl, 215552(%rsp,%rax)
	movzbq	215620(%rsp), %rax
	movzbq	glob_data + 226(%rip), %rcx
	movq	%rax, %rdx
	andq	$1, %rdx
	imulq	%rcx, %rdx
	movq	%rax, %rsi
	andq	$2, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	movq	%rax, %rsi
	andq	$4, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	andq	$8, %rax
	imulq	%rcx, %rax
	xorq	%rax, %rdx
	movq	%rdx, (%rsp)
	movq	(%rsp), %rax
	movq	%rax, 8(%rsp)
	andq	$240, 8(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 16(%rsp)
	shrq	$3, 16(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 8(%rsp)
	shrq	$4, 8(%rsp)
	movq	(%rsp), %rax
	xorq	8(%rsp), %rax
	xorq	16(%rsp), %rax
	andq	$15, %rax
	movzbq	215558(%rsp), %rcx
	xorq	%rax, %rcx
	movq	$68, %rax
	leaq	-64(%rax), %rax
	leaq	2(%rax), %rax
	movb	%cl, 215552(%rsp,%rax)
	movzbq	215620(%rsp), %rax
	movzbq	glob_data + 227(%rip), %rcx
	movq	%rax, %rdx
	andq	$1, %rdx
	imulq	%rcx, %rdx
	movq	%rax, %rsi
	andq	$2, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	movq	%rax, %rsi
	andq	$4, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	andq	$8, %rax
	imulq	%rcx, %rax
	xorq	%rax, %rdx
	movq	%rdx, 16(%rsp)
	movq	16(%rsp), %rax
	movq	%rax, 8(%rsp)
	andq	$240, 8(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, (%rsp)
	shrq	$3, (%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 8(%rsp)
	shrq	$4, 8(%rsp)
	movq	16(%rsp), %rax
	xorq	8(%rsp), %rax
	xorq	(%rsp), %rax
	andq	$15, %rax
	movzbq	215559(%rsp), %rcx
	xorq	%rax, %rcx
	movq	$68, %rax
	leaq	-64(%rax), %rax
	leaq	3(%rax), %rax
	movb	%cl, 215552(%rsp,%rax)
	movzbq	215620(%rsp), %rax
	movzbq	glob_data + 228(%rip), %rcx
	movq	%rax, %rdx
	andq	$1, %rdx
	imulq	%rcx, %rdx
	movq	%rax, %rsi
	andq	$2, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	movq	%rax, %rsi
	andq	$4, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	andq	$8, %rax
	imulq	%rcx, %rax
	xorq	%rax, %rdx
	movq	%rdx, (%rsp)
	movq	(%rsp), %rax
	movq	%rax, 8(%rsp)
	andq	$240, 8(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 16(%rsp)
	shrq	$3, 16(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 8(%rsp)
	shrq	$4, 8(%rsp)
	movq	(%rsp), %rax
	xorq	8(%rsp), %rax
	xorq	16(%rsp), %rax
	andq	$15, %rax
	movzbq	215560(%rsp), %rcx
	xorq	%rax, %rcx
	movq	$68, %rax
	leaq	-64(%rax), %rax
	leaq	4(%rax), %rax
	movb	%cl, 215552(%rsp,%rax)
	movb	$0, 215620(%rsp)
	movzbq	215619(%rsp), %rax
	movzbq	glob_data + 224(%rip), %rcx
	movq	%rax, %rdx
	andq	$1, %rdx
	imulq	%rcx, %rdx
	movq	%rax, %rsi
	andq	$2, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	movq	%rax, %rsi
	andq	$4, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	andq	$8, %rax
	imulq	%rcx, %rax
	xorq	%rax, %rdx
	movq	%rdx, 16(%rsp)
	movq	16(%rsp), %rax
	movq	%rax, 8(%rsp)
	andq	$240, 8(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, (%rsp)
	shrq	$3, (%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 8(%rsp)
	shrq	$4, 8(%rsp)
	movq	16(%rsp), %rax
	xorq	8(%rsp), %rax
	xorq	(%rsp), %rax
	andq	$15, %rax
	movzbq	215555(%rsp), %rcx
	xorq	%rax, %rcx
	movq	$67, %rax
	leaq	-64(%rax), %rax
	movb	%cl, 215552(%rsp,%rax)
	movzbq	215619(%rsp), %rax
	movzbq	glob_data + 225(%rip), %rcx
	movq	%rax, %rdx
	andq	$1, %rdx
	imulq	%rcx, %rdx
	movq	%rax, %rsi
	andq	$2, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	movq	%rax, %rsi
	andq	$4, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	andq	$8, %rax
	imulq	%rcx, %rax
	xorq	%rax, %rdx
	movq	%rdx, (%rsp)
	movq	(%rsp), %rax
	movq	%rax, 8(%rsp)
	andq	$240, 8(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 16(%rsp)
	shrq	$3, 16(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 8(%rsp)
	shrq	$4, 8(%rsp)
	movq	(%rsp), %rax
	xorq	8(%rsp), %rax
	xorq	16(%rsp), %rax
	andq	$15, %rax
	movzbq	215556(%rsp), %rcx
	xorq	%rax, %rcx
	movq	$67, %rax
	leaq	-64(%rax), %rax
	leaq	1(%rax), %rax
	movb	%cl, 215552(%rsp,%rax)
	movzbq	215619(%rsp), %rax
	movzbq	glob_data + 226(%rip), %rcx
	movq	%rax, %rdx
	andq	$1, %rdx
	imulq	%rcx, %rdx
	movq	%rax, %rsi
	andq	$2, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	movq	%rax, %rsi
	andq	$4, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	andq	$8, %rax
	imulq	%rcx, %rax
	xorq	%rax, %rdx
	movq	%rdx, 16(%rsp)
	movq	16(%rsp), %rax
	movq	%rax, 8(%rsp)
	andq	$240, 8(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, (%rsp)
	shrq	$3, (%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 8(%rsp)
	shrq	$4, 8(%rsp)
	movq	16(%rsp), %rax
	xorq	8(%rsp), %rax
	xorq	(%rsp), %rax
	andq	$15, %rax
	movzbq	215557(%rsp), %rcx
	xorq	%rax, %rcx
	movq	$67, %rax
	leaq	-64(%rax), %rax
	leaq	2(%rax), %rax
	movb	%cl, 215552(%rsp,%rax)
	movzbq	215619(%rsp), %rax
	movzbq	glob_data + 227(%rip), %rcx
	movq	%rax, %rdx
	andq	$1, %rdx
	imulq	%rcx, %rdx
	movq	%rax, %rsi
	andq	$2, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	movq	%rax, %rsi
	andq	$4, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	andq	$8, %rax
	imulq	%rcx, %rax
	xorq	%rax, %rdx
	movq	%rdx, (%rsp)
	movq	(%rsp), %rax
	movq	%rax, 8(%rsp)
	andq	$240, 8(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 16(%rsp)
	shrq	$3, 16(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 8(%rsp)
	shrq	$4, 8(%rsp)
	movq	(%rsp), %rax
	xorq	8(%rsp), %rax
	xorq	16(%rsp), %rax
	andq	$15, %rax
	movzbq	215558(%rsp), %rcx
	xorq	%rax, %rcx
	movq	$67, %rax
	leaq	-64(%rax), %rax
	leaq	3(%rax), %rax
	movb	%cl, 215552(%rsp,%rax)
	movzbq	215619(%rsp), %rax
	movzbq	glob_data + 228(%rip), %rcx
	movq	%rax, %rdx
	andq	$1, %rdx
	imulq	%rcx, %rdx
	movq	%rax, %rsi
	andq	$2, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	movq	%rax, %rsi
	andq	$4, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	andq	$8, %rax
	imulq	%rcx, %rax
	xorq	%rax, %rdx
	movq	%rdx, 16(%rsp)
	movq	16(%rsp), %rax
	movq	%rax, 8(%rsp)
	andq	$240, 8(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, (%rsp)
	shrq	$3, (%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 8(%rsp)
	shrq	$4, 8(%rsp)
	movq	16(%rsp), %rax
	xorq	8(%rsp), %rax
	xorq	(%rsp), %rax
	andq	$15, %rax
	movzbq	215559(%rsp), %rcx
	xorq	%rax, %rcx
	movq	$67, %rax
	leaq	-64(%rax), %rax
	leaq	4(%rax), %rax
	movb	%cl, 215552(%rsp,%rax)
	movb	$0, 215619(%rsp)
	movzbq	215618(%rsp), %rax
	movzbq	glob_data + 224(%rip), %rcx
	movq	%rax, %rdx
	andq	$1, %rdx
	imulq	%rcx, %rdx
	movq	%rax, %rsi
	andq	$2, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	movq	%rax, %rsi
	andq	$4, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	andq	$8, %rax
	imulq	%rcx, %rax
	xorq	%rax, %rdx
	movq	%rdx, (%rsp)
	movq	(%rsp), %rax
	movq	%rax, 8(%rsp)
	andq	$240, 8(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 16(%rsp)
	shrq	$3, 16(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 8(%rsp)
	shrq	$4, 8(%rsp)
	movq	(%rsp), %rax
	xorq	8(%rsp), %rax
	xorq	16(%rsp), %rax
	andq	$15, %rax
	movzbq	215554(%rsp), %rcx
	xorq	%rax, %rcx
	movq	$66, %rax
	leaq	-64(%rax), %rax
	movb	%cl, 215552(%rsp,%rax)
	movzbq	215618(%rsp), %rax
	movzbq	glob_data + 225(%rip), %rcx
	movq	%rax, %rdx
	andq	$1, %rdx
	imulq	%rcx, %rdx
	movq	%rax, %rsi
	andq	$2, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	movq	%rax, %rsi
	andq	$4, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	andq	$8, %rax
	imulq	%rcx, %rax
	xorq	%rax, %rdx
	movq	%rdx, 16(%rsp)
	movq	16(%rsp), %rax
	movq	%rax, 8(%rsp)
	andq	$240, 8(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, (%rsp)
	shrq	$3, (%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 8(%rsp)
	shrq	$4, 8(%rsp)
	movq	16(%rsp), %rax
	xorq	8(%rsp), %rax
	xorq	(%rsp), %rax
	andq	$15, %rax
	movzbq	215555(%rsp), %rcx
	xorq	%rax, %rcx
	movq	$66, %rax
	leaq	-64(%rax), %rax
	leaq	1(%rax), %rax
	movb	%cl, 215552(%rsp,%rax)
	movzbq	215618(%rsp), %rax
	movzbq	glob_data + 226(%rip), %rcx
	movq	%rax, %rdx
	andq	$1, %rdx
	imulq	%rcx, %rdx
	movq	%rax, %rsi
	andq	$2, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	movq	%rax, %rsi
	andq	$4, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	andq	$8, %rax
	imulq	%rcx, %rax
	xorq	%rax, %rdx
	movq	%rdx, (%rsp)
	movq	(%rsp), %rax
	movq	%rax, 8(%rsp)
	andq	$240, 8(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 16(%rsp)
	shrq	$3, 16(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 8(%rsp)
	shrq	$4, 8(%rsp)
	movq	(%rsp), %rax
	xorq	8(%rsp), %rax
	xorq	16(%rsp), %rax
	andq	$15, %rax
	movzbq	215556(%rsp), %rcx
	xorq	%rax, %rcx
	movq	$66, %rax
	leaq	-64(%rax), %rax
	leaq	2(%rax), %rax
	movb	%cl, 215552(%rsp,%rax)
	movzbq	215618(%rsp), %rax
	movzbq	glob_data + 227(%rip), %rcx
	movq	%rax, %rdx
	andq	$1, %rdx
	imulq	%rcx, %rdx
	movq	%rax, %rsi
	andq	$2, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	movq	%rax, %rsi
	andq	$4, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	andq	$8, %rax
	imulq	%rcx, %rax
	xorq	%rax, %rdx
	movq	%rdx, 16(%rsp)
	movq	16(%rsp), %rax
	movq	%rax, 8(%rsp)
	andq	$240, 8(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, (%rsp)
	shrq	$3, (%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 8(%rsp)
	shrq	$4, 8(%rsp)
	movq	16(%rsp), %rax
	xorq	8(%rsp), %rax
	xorq	(%rsp), %rax
	andq	$15, %rax
	movzbq	215557(%rsp), %rcx
	xorq	%rax, %rcx
	movq	$66, %rax
	leaq	-64(%rax), %rax
	leaq	3(%rax), %rax
	movb	%cl, 215552(%rsp,%rax)
	movzbq	215618(%rsp), %rax
	movzbq	glob_data + 228(%rip), %rcx
	movq	%rax, %rdx
	andq	$1, %rdx
	imulq	%rcx, %rdx
	movq	%rax, %rsi
	andq	$2, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	movq	%rax, %rsi
	andq	$4, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	andq	$8, %rax
	imulq	%rcx, %rax
	xorq	%rax, %rdx
	movq	%rdx, (%rsp)
	movq	(%rsp), %rax
	movq	%rax, 8(%rsp)
	andq	$240, 8(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 16(%rsp)
	shrq	$3, 16(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 8(%rsp)
	shrq	$4, 8(%rsp)
	movq	(%rsp), %rax
	xorq	8(%rsp), %rax
	xorq	16(%rsp), %rax
	andq	$15, %rax
	movzbq	215558(%rsp), %rcx
	xorq	%rax, %rcx
	movq	$66, %rax
	leaq	-64(%rax), %rax
	leaq	4(%rax), %rax
	movb	%cl, 215552(%rsp,%rax)
	movb	$0, 215618(%rsp)
	movzbq	215617(%rsp), %rax
	movzbq	glob_data + 224(%rip), %rcx
	movq	%rax, %rdx
	andq	$1, %rdx
	imulq	%rcx, %rdx
	movq	%rax, %rsi
	andq	$2, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	movq	%rax, %rsi
	andq	$4, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	andq	$8, %rax
	imulq	%rcx, %rax
	xorq	%rax, %rdx
	movq	%rdx, 16(%rsp)
	movq	16(%rsp), %rax
	movq	%rax, 8(%rsp)
	andq	$240, 8(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, (%rsp)
	shrq	$3, (%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 8(%rsp)
	shrq	$4, 8(%rsp)
	movq	16(%rsp), %rax
	xorq	8(%rsp), %rax
	xorq	(%rsp), %rax
	andq	$15, %rax
	movzbq	215553(%rsp), %rcx
	xorq	%rax, %rcx
	movq	$65, %rax
	leaq	-64(%rax), %rax
	movb	%cl, 215552(%rsp,%rax)
	movzbq	215617(%rsp), %rax
	movzbq	glob_data + 225(%rip), %rcx
	movq	%rax, %rdx
	andq	$1, %rdx
	imulq	%rcx, %rdx
	movq	%rax, %rsi
	andq	$2, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	movq	%rax, %rsi
	andq	$4, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	andq	$8, %rax
	imulq	%rcx, %rax
	xorq	%rax, %rdx
	movq	%rdx, (%rsp)
	movq	(%rsp), %rax
	movq	%rax, 8(%rsp)
	andq	$240, 8(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 16(%rsp)
	shrq	$3, 16(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 8(%rsp)
	shrq	$4, 8(%rsp)
	movq	(%rsp), %rax
	xorq	8(%rsp), %rax
	xorq	16(%rsp), %rax
	andq	$15, %rax
	movzbq	215554(%rsp), %rcx
	xorq	%rax, %rcx
	movq	$65, %rax
	leaq	-64(%rax), %rax
	leaq	1(%rax), %rax
	movb	%cl, 215552(%rsp,%rax)
	movzbq	215617(%rsp), %rax
	movzbq	glob_data + 226(%rip), %rcx
	movq	%rax, %rdx
	andq	$1, %rdx
	imulq	%rcx, %rdx
	movq	%rax, %rsi
	andq	$2, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	movq	%rax, %rsi
	andq	$4, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	andq	$8, %rax
	imulq	%rcx, %rax
	xorq	%rax, %rdx
	movq	%rdx, 16(%rsp)
	movq	16(%rsp), %rax
	movq	%rax, 8(%rsp)
	andq	$240, 8(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, (%rsp)
	shrq	$3, (%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 8(%rsp)
	shrq	$4, 8(%rsp)
	movq	16(%rsp), %rax
	xorq	8(%rsp), %rax
	xorq	(%rsp), %rax
	andq	$15, %rax
	movzbq	215555(%rsp), %rcx
	xorq	%rax, %rcx
	movq	$65, %rax
	leaq	-64(%rax), %rax
	leaq	2(%rax), %rax
	movb	%cl, 215552(%rsp,%rax)
	movzbq	215617(%rsp), %rax
	movzbq	glob_data + 227(%rip), %rcx
	movq	%rax, %rdx
	andq	$1, %rdx
	imulq	%rcx, %rdx
	movq	%rax, %rsi
	andq	$2, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	movq	%rax, %rsi
	andq	$4, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	andq	$8, %rax
	imulq	%rcx, %rax
	xorq	%rax, %rdx
	movq	%rdx, (%rsp)
	movq	(%rsp), %rax
	movq	%rax, 8(%rsp)
	andq	$240, 8(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 16(%rsp)
	shrq	$3, 16(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 8(%rsp)
	shrq	$4, 8(%rsp)
	movq	(%rsp), %rax
	xorq	8(%rsp), %rax
	xorq	16(%rsp), %rax
	andq	$15, %rax
	movzbq	215556(%rsp), %rcx
	xorq	%rax, %rcx
	movq	$65, %rax
	leaq	-64(%rax), %rax
	leaq	3(%rax), %rax
	movb	%cl, 215552(%rsp,%rax)
	movzbq	215617(%rsp), %rax
	movzbq	glob_data + 228(%rip), %rcx
	movq	%rax, %rdx
	andq	$1, %rdx
	imulq	%rcx, %rdx
	movq	%rax, %rsi
	andq	$2, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	movq	%rax, %rsi
	andq	$4, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	andq	$8, %rax
	imulq	%rcx, %rax
	xorq	%rax, %rdx
	movq	%rdx, 16(%rsp)
	movq	16(%rsp), %rax
	movq	%rax, 8(%rsp)
	andq	$240, 8(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, (%rsp)
	shrq	$3, (%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 8(%rsp)
	shrq	$4, 8(%rsp)
	movq	16(%rsp), %rax
	xorq	8(%rsp), %rax
	xorq	(%rsp), %rax
	andq	$15, %rax
	movzbq	215557(%rsp), %rcx
	xorq	%rax, %rcx
	movq	$65, %rax
	leaq	-64(%rax), %rax
	leaq	4(%rax), %rax
	movb	%cl, 215552(%rsp,%rax)
	movb	$0, 215617(%rsp)
	movzbq	215616(%rsp), %rax
	movzbq	glob_data + 224(%rip), %rcx
	movq	%rax, %rdx
	andq	$1, %rdx
	imulq	%rcx, %rdx
	movq	%rax, %rsi
	andq	$2, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	movq	%rax, %rsi
	andq	$4, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	andq	$8, %rax
	imulq	%rcx, %rax
	xorq	%rax, %rdx
	movq	%rdx, (%rsp)
	movq	(%rsp), %rax
	movq	%rax, 8(%rsp)
	andq	$240, 8(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 16(%rsp)
	shrq	$3, 16(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 8(%rsp)
	shrq	$4, 8(%rsp)
	movq	(%rsp), %rax
	xorq	8(%rsp), %rax
	xorq	16(%rsp), %rax
	andq	$15, %rax
	movzbq	215552(%rsp), %rcx
	xorq	%rax, %rcx
	movq	$64, %rax
	leaq	-64(%rax), %rax
	movb	%cl, 215552(%rsp,%rax)
	movzbq	215616(%rsp), %rax
	movzbq	glob_data + 225(%rip), %rcx
	movq	%rax, %rdx
	andq	$1, %rdx
	imulq	%rcx, %rdx
	movq	%rax, %rsi
	andq	$2, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	movq	%rax, %rsi
	andq	$4, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	andq	$8, %rax
	imulq	%rcx, %rax
	xorq	%rax, %rdx
	movq	%rdx, 16(%rsp)
	movq	16(%rsp), %rax
	movq	%rax, 8(%rsp)
	andq	$240, 8(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, (%rsp)
	shrq	$3, (%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 8(%rsp)
	shrq	$4, 8(%rsp)
	movq	16(%rsp), %rax
	xorq	8(%rsp), %rax
	xorq	(%rsp), %rax
	andq	$15, %rax
	movzbq	215553(%rsp), %rcx
	xorq	%rax, %rcx
	movq	$64, %rax
	leaq	-64(%rax), %rax
	leaq	1(%rax), %rax
	movb	%cl, 215552(%rsp,%rax)
	movzbq	215616(%rsp), %rax
	movzbq	glob_data + 226(%rip), %rcx
	movq	%rax, %rdx
	andq	$1, %rdx
	imulq	%rcx, %rdx
	movq	%rax, %rsi
	andq	$2, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	movq	%rax, %rsi
	andq	$4, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	andq	$8, %rax
	imulq	%rcx, %rax
	xorq	%rax, %rdx
	movq	%rdx, (%rsp)
	movq	(%rsp), %rax
	movq	%rax, 8(%rsp)
	andq	$240, 8(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 16(%rsp)
	shrq	$3, 16(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 8(%rsp)
	shrq	$4, 8(%rsp)
	movq	(%rsp), %rax
	xorq	8(%rsp), %rax
	xorq	16(%rsp), %rax
	andq	$15, %rax
	movzbq	215554(%rsp), %rcx
	xorq	%rax, %rcx
	movq	$64, %rax
	leaq	-64(%rax), %rax
	leaq	2(%rax), %rax
	movb	%cl, 215552(%rsp,%rax)
	movzbq	215616(%rsp), %rax
	movzbq	glob_data + 227(%rip), %rcx
	movq	%rax, %rdx
	andq	$1, %rdx
	imulq	%rcx, %rdx
	movq	%rax, %rsi
	andq	$2, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	movq	%rax, %rsi
	andq	$4, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	andq	$8, %rax
	imulq	%rcx, %rax
	xorq	%rax, %rdx
	movq	%rdx, 16(%rsp)
	movq	16(%rsp), %rax
	movq	%rax, 8(%rsp)
	andq	$240, 8(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, (%rsp)
	shrq	$3, (%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 8(%rsp)
	shrq	$4, 8(%rsp)
	movq	16(%rsp), %rax
	xorq	8(%rsp), %rax
	xorq	(%rsp), %rax
	andq	$15, %rax
	movzbq	215555(%rsp), %rcx
	xorq	%rax, %rcx
	movq	$64, %rax
	leaq	-64(%rax), %rax
	leaq	3(%rax), %rax
	movb	%cl, 215552(%rsp,%rax)
	movzbq	215616(%rsp), %rax
	movzbq	glob_data + 228(%rip), %rcx
	movq	%rax, %rdx
	andq	$1, %rdx
	imulq	%rcx, %rdx
	movq	%rax, %rsi
	andq	$2, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	movq	%rax, %rsi
	andq	$4, %rsi
	imulq	%rcx, %rsi
	xorq	%rsi, %rdx
	andq	$8, %rax
	imulq	%rcx, %rax
	xorq	%rax, %rdx
	movq	%rdx, (%rsp)
	movq	(%rsp), %rax
	movq	%rax, 8(%rsp)
	andq	$240, 8(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 16(%rsp)
	shrq	$3, 16(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 8(%rsp)
	shrq	$4, 8(%rsp)
	movq	(%rsp), %rax
	xorq	8(%rsp), %rax
	xorq	16(%rsp), %rax
	andq	$15, %rax
	movzbq	215556(%rsp), %rcx
	xorq	%rax, %rcx
	movq	$64, %rax
	leaq	-64(%rax), %rax
	leaq	4(%rax), %rax
	movb	%cl, 215552(%rsp,%rax)
	movb	$0, 215616(%rsp)
	movq	$0, %rax
	movb	215552(%rsp), %cl
	movb	215424(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$64
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$64:
	movb	215553(%rsp), %cl
	movb	215425(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$63
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$63:
	movb	215554(%rsp), %cl
	movb	215426(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$62
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$62:
	movb	215555(%rsp), %cl
	movb	215427(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$61
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$61:
	movb	215556(%rsp), %cl
	movb	215428(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$60
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$60:
	movb	215557(%rsp), %cl
	movb	215429(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$59
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$59:
	movb	215558(%rsp), %cl
	movb	215430(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$58
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$58:
	movb	215559(%rsp), %cl
	movb	215431(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$57
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$57:
	movb	215560(%rsp), %cl
	movb	215432(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$56
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$56:
	movb	215561(%rsp), %cl
	movb	215433(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$55
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$55:
	movb	215562(%rsp), %cl
	movb	215434(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$54
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$54:
	movb	215563(%rsp), %cl
	movb	215435(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$53
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$53:
	movb	215564(%rsp), %cl
	movb	215436(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$52
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$52:
	movb	215565(%rsp), %cl
	movb	215437(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$51
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$51:
	movb	215566(%rsp), %cl
	movb	215438(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$50
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$50:
	movb	215567(%rsp), %cl
	movb	215439(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$49
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$49:
	movb	215568(%rsp), %cl
	movb	215440(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$48
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$48:
	movb	215569(%rsp), %cl
	movb	215441(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$47
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$47:
	movb	215570(%rsp), %cl
	movb	215442(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$46
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$46:
	movb	215571(%rsp), %cl
	movb	215443(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$45
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$45:
	movb	215572(%rsp), %cl
	movb	215444(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$44
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$44:
	movb	215573(%rsp), %cl
	movb	215445(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$43
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$43:
	movb	215574(%rsp), %cl
	movb	215446(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$42
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$42:
	movb	215575(%rsp), %cl
	movb	215447(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$41
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$41:
	movb	215576(%rsp), %cl
	movb	215448(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$40
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$40:
	movb	215577(%rsp), %cl
	movb	215449(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$39
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$39:
	movb	215578(%rsp), %cl
	movb	215450(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$38
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$38:
	movb	215579(%rsp), %cl
	movb	215451(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$37
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$37:
	movb	215580(%rsp), %cl
	movb	215452(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$36
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$36:
	movb	215581(%rsp), %cl
	movb	215453(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$35
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$35:
	movb	215582(%rsp), %cl
	movb	215454(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$34
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$34:
	movb	215583(%rsp), %cl
	movb	215455(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$33
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$33:
	movb	215584(%rsp), %cl
	movb	215456(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$32
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$32:
	movb	215585(%rsp), %cl
	movb	215457(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$31
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$31:
	movb	215586(%rsp), %cl
	movb	215458(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$30
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$30:
	movb	215587(%rsp), %cl
	movb	215459(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$29
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$29:
	movb	215588(%rsp), %cl
	movb	215460(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$28
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$28:
	movb	215589(%rsp), %cl
	movb	215461(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$27
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$27:
	movb	215590(%rsp), %cl
	movb	215462(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$26
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$26:
	movb	215591(%rsp), %cl
	movb	215463(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$25
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$25:
	movb	215592(%rsp), %cl
	movb	215464(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$24
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$24:
	movb	215593(%rsp), %cl
	movb	215465(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$23
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$23:
	movb	215594(%rsp), %cl
	movb	215466(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$22
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$22:
	movb	215595(%rsp), %cl
	movb	215467(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$21
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$21:
	movb	215596(%rsp), %cl
	movb	215468(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$20
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$20:
	movb	215597(%rsp), %cl
	movb	215469(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$19
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$19:
	movb	215598(%rsp), %cl
	movb	215470(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$18
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$18:
	movb	215599(%rsp), %cl
	movb	215471(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$17
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$17:
	movb	215600(%rsp), %cl
	movb	215472(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$16
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$16:
	movb	215601(%rsp), %cl
	movb	215473(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$15
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$15:
	movb	215602(%rsp), %cl
	movb	215474(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$14
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$14:
	movb	215603(%rsp), %cl
	movb	215475(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$13
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$13:
	movb	215604(%rsp), %cl
	movb	215476(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$12
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$12:
	movb	215605(%rsp), %cl
	movb	215477(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$11
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$11:
	movb	215606(%rsp), %cl
	movb	215478(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$10
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$10:
	movb	215607(%rsp), %cl
	movb	215479(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$9
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$9:
	movb	215608(%rsp), %cl
	movb	215480(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$8
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$8:
	movb	215609(%rsp), %cl
	movb	215481(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$7
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$7:
	movb	215610(%rsp), %cl
	movb	215482(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$6
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$6:
	movb	215611(%rsp), %cl
	movb	215483(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$5
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$5:
	movb	215612(%rsp), %cl
	movb	215484(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$4
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$4:
	movb	215613(%rsp), %cl
	movb	215485(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$3
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$3:
	movb	215614(%rsp), %cl
	movb	215486(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$2
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$2:
	movb	215615(%rsp), %cl
	movb	215487(%rsp), %dl
	cmpb	%dl, %cl
	je  	Lmayo2_crypto_sign_open$1
	leaq	1(%rax), %rax
Lmayo2_crypto_sign_open$1:
	movq	216176(%rsp), %rbx
	movq	216184(%rsp), %rbp
	movq	216192(%rsp), %r12
	movq	216200(%rsp), %r13
	movq	216208(%rsp), %r14
	movq	216216(%rsp), %r15
	movq	216224(%rsp), %rsp
	ret
Lmul_add_mat_x_bitsliced_m_mat_ver$1:
	movb	(%r12), %cl
	movq	%r14, %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1249:
	leaq	32(%rsp), %rsp
	leaq	32(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1248:
	leaq	32(%rsp), %rsp
	leaq	64(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1247:
	leaq	32(%rsp), %rsp
	leaq	96(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1246:
	leaq	32(%rsp), %rsp
	movb	1(%r12), %cl
	leaq	128(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1245:
	leaq	32(%rsp), %rsp
	leaq	160(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1244:
	leaq	32(%rsp), %rsp
	leaq	192(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1243:
	leaq	32(%rsp), %rsp
	leaq	224(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1242:
	leaq	32(%rsp), %rsp
	movb	2(%r12), %cl
	leaq	256(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1241:
	leaq	32(%rsp), %rsp
	leaq	288(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1240:
	leaq	32(%rsp), %rsp
	leaq	320(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1239:
	leaq	32(%rsp), %rsp
	leaq	352(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1238:
	leaq	32(%rsp), %rsp
	movb	3(%r12), %cl
	leaq	384(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1237:
	leaq	32(%rsp), %rsp
	leaq	416(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1236:
	leaq	32(%rsp), %rsp
	leaq	448(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1235:
	leaq	32(%rsp), %rsp
	leaq	480(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1234:
	leaq	32(%rsp), %rsp
	movb	4(%r12), %cl
	leaq	512(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1233:
	leaq	32(%rsp), %rsp
	leaq	544(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1232:
	leaq	32(%rsp), %rsp
	leaq	576(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1231:
	leaq	32(%rsp), %rsp
	leaq	608(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1230:
	leaq	32(%rsp), %rsp
	movb	5(%r12), %cl
	leaq	640(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1229:
	leaq	32(%rsp), %rsp
	leaq	672(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1228:
	leaq	32(%rsp), %rsp
	leaq	704(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1227:
	leaq	32(%rsp), %rsp
	leaq	736(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1226:
	leaq	32(%rsp), %rsp
	movb	6(%r12), %cl
	leaq	768(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1225:
	leaq	32(%rsp), %rsp
	leaq	800(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1224:
	leaq	32(%rsp), %rsp
	leaq	832(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1223:
	leaq	32(%rsp), %rsp
	leaq	864(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1222:
	leaq	32(%rsp), %rsp
	movb	7(%r12), %cl
	leaq	896(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1221:
	leaq	32(%rsp), %rsp
	leaq	928(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1220:
	leaq	32(%rsp), %rsp
	leaq	960(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1219:
	leaq	32(%rsp), %rsp
	leaq	992(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1218:
	leaq	32(%rsp), %rsp
	movb	8(%r12), %cl
	leaq	1024(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1217:
	leaq	32(%rsp), %rsp
	leaq	1056(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1216:
	leaq	32(%rsp), %rsp
	leaq	1088(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1215:
	leaq	32(%rsp), %rsp
	leaq	1120(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1214:
	leaq	32(%rsp), %rsp
	movb	9(%r12), %cl
	leaq	1152(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1213:
	leaq	32(%rsp), %rsp
	leaq	1184(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1212:
	leaq	32(%rsp), %rsp
	leaq	1216(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1211:
	leaq	32(%rsp), %rsp
	leaq	1248(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1210:
	leaq	32(%rsp), %rsp
	movb	10(%r12), %cl
	leaq	1280(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1209:
	leaq	32(%rsp), %rsp
	leaq	1312(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1208:
	leaq	32(%rsp), %rsp
	leaq	1344(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1207:
	leaq	32(%rsp), %rsp
	leaq	1376(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1206:
	leaq	32(%rsp), %rsp
	movb	11(%r12), %cl
	leaq	1408(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1205:
	leaq	32(%rsp), %rsp
	leaq	1440(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1204:
	leaq	32(%rsp), %rsp
	leaq	1472(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1203:
	leaq	32(%rsp), %rsp
	leaq	1504(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1202:
	leaq	32(%rsp), %rsp
	movb	12(%r12), %cl
	leaq	1536(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1201:
	leaq	32(%rsp), %rsp
	leaq	1568(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1200:
	leaq	32(%rsp), %rsp
	leaq	1600(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1199:
	leaq	32(%rsp), %rsp
	leaq	1632(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1198:
	leaq	32(%rsp), %rsp
	movb	13(%r12), %cl
	leaq	1664(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1197:
	leaq	32(%rsp), %rsp
	leaq	1696(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1196:
	leaq	32(%rsp), %rsp
	leaq	1728(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1195:
	leaq	32(%rsp), %rsp
	leaq	1760(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1194:
	leaq	32(%rsp), %rsp
	movb	14(%r12), %cl
	leaq	1792(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1193:
	leaq	32(%rsp), %rsp
	leaq	1824(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1192:
	leaq	32(%rsp), %rsp
	leaq	1856(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1191:
	leaq	32(%rsp), %rsp
	leaq	1888(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1190:
	leaq	32(%rsp), %rsp
	movb	15(%r12), %cl
	leaq	1920(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1189:
	leaq	32(%rsp), %rsp
	leaq	1952(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1188:
	leaq	32(%rsp), %rsp
	leaq	1984(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1187:
	leaq	32(%rsp), %rsp
	leaq	2016(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1186:
	leaq	32(%rsp), %rsp
	movb	16(%r12), %cl
	leaq	2048(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1185:
	leaq	32(%rsp), %rsp
	leaq	2080(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1184:
	leaq	32(%rsp), %rsp
	leaq	2112(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1183:
	leaq	32(%rsp), %rsp
	leaq	2144(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1182:
	leaq	32(%rsp), %rsp
	movb	17(%r12), %cl
	leaq	2176(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1181:
	leaq	32(%rsp), %rsp
	leaq	2208(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1180:
	leaq	32(%rsp), %rsp
	leaq	2240(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1179:
	leaq	32(%rsp), %rsp
	leaq	2272(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1178:
	leaq	32(%rsp), %rsp
	movb	18(%r12), %cl
	leaq	2304(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1177:
	leaq	32(%rsp), %rsp
	leaq	2336(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1176:
	leaq	32(%rsp), %rsp
	leaq	2368(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1175:
	leaq	32(%rsp), %rsp
	leaq	2400(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1174:
	leaq	32(%rsp), %rsp
	movb	19(%r12), %cl
	leaq	2432(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1173:
	leaq	32(%rsp), %rsp
	leaq	2464(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1172:
	leaq	32(%rsp), %rsp
	leaq	2496(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1171:
	leaq	32(%rsp), %rsp
	leaq	2528(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1170:
	leaq	32(%rsp), %rsp
	movb	20(%r12), %cl
	leaq	2560(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1169:
	leaq	32(%rsp), %rsp
	leaq	2592(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1168:
	leaq	32(%rsp), %rsp
	leaq	2624(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1167:
	leaq	32(%rsp), %rsp
	leaq	2656(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1166:
	leaq	32(%rsp), %rsp
	movb	21(%r12), %cl
	leaq	2688(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1165:
	leaq	32(%rsp), %rsp
	leaq	2720(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1164:
	leaq	32(%rsp), %rsp
	leaq	2752(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1163:
	leaq	32(%rsp), %rsp
	leaq	2784(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1162:
	leaq	32(%rsp), %rsp
	movb	22(%r12), %cl
	leaq	2816(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1161:
	leaq	32(%rsp), %rsp
	leaq	2848(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1160:
	leaq	32(%rsp), %rsp
	leaq	2880(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1159:
	leaq	32(%rsp), %rsp
	leaq	2912(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1158:
	leaq	32(%rsp), %rsp
	movb	23(%r12), %cl
	leaq	2944(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1157:
	leaq	32(%rsp), %rsp
	leaq	2976(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1156:
	leaq	32(%rsp), %rsp
	leaq	3008(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1155:
	leaq	32(%rsp), %rsp
	leaq	3040(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1154:
	leaq	32(%rsp), %rsp
	movb	24(%r12), %cl
	leaq	3072(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1153:
	leaq	32(%rsp), %rsp
	leaq	3104(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1152:
	leaq	32(%rsp), %rsp
	leaq	3136(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1151:
	leaq	32(%rsp), %rsp
	leaq	3168(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1150:
	leaq	32(%rsp), %rsp
	movb	25(%r12), %cl
	leaq	3200(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1149:
	leaq	32(%rsp), %rsp
	leaq	3232(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1148:
	leaq	32(%rsp), %rsp
	leaq	3264(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1147:
	leaq	32(%rsp), %rsp
	leaq	3296(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1146:
	leaq	32(%rsp), %rsp
	movb	26(%r12), %cl
	leaq	3328(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1145:
	leaq	32(%rsp), %rsp
	leaq	3360(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1144:
	leaq	32(%rsp), %rsp
	leaq	3392(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1143:
	leaq	32(%rsp), %rsp
	leaq	3424(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1142:
	leaq	32(%rsp), %rsp
	movb	27(%r12), %cl
	leaq	3456(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1141:
	leaq	32(%rsp), %rsp
	leaq	3488(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1140:
	leaq	32(%rsp), %rsp
	leaq	3520(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1139:
	leaq	32(%rsp), %rsp
	leaq	3552(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1138:
	leaq	32(%rsp), %rsp
	movb	28(%r12), %cl
	leaq	3584(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1137:
	leaq	32(%rsp), %rsp
	leaq	3616(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1136:
	leaq	32(%rsp), %rsp
	leaq	3648(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1135:
	leaq	32(%rsp), %rsp
	leaq	3680(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1134:
	leaq	32(%rsp), %rsp
	movb	29(%r12), %cl
	leaq	3712(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1133:
	leaq	32(%rsp), %rsp
	leaq	3744(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1132:
	leaq	32(%rsp), %rsp
	leaq	3776(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1131:
	leaq	32(%rsp), %rsp
	leaq	3808(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1130:
	leaq	32(%rsp), %rsp
	movb	30(%r12), %cl
	leaq	3840(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1129:
	leaq	32(%rsp), %rsp
	leaq	3872(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1128:
	leaq	32(%rsp), %rsp
	leaq	3904(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1127:
	leaq	32(%rsp), %rsp
	leaq	3936(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1126:
	leaq	32(%rsp), %rsp
	movb	31(%r12), %cl
	leaq	3968(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1125:
	leaq	32(%rsp), %rsp
	leaq	4000(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1124:
	leaq	32(%rsp), %rsp
	leaq	4032(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1123:
	leaq	32(%rsp), %rsp
	leaq	4064(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1122:
	leaq	32(%rsp), %rsp
	movb	32(%r12), %cl
	leaq	4096(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1121:
	leaq	32(%rsp), %rsp
	leaq	4128(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1120:
	leaq	32(%rsp), %rsp
	leaq	4160(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1119:
	leaq	32(%rsp), %rsp
	leaq	4192(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1118:
	leaq	32(%rsp), %rsp
	movb	33(%r12), %cl
	leaq	4224(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1117:
	leaq	32(%rsp), %rsp
	leaq	4256(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1116:
	leaq	32(%rsp), %rsp
	leaq	4288(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1115:
	leaq	32(%rsp), %rsp
	leaq	4320(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1114:
	leaq	32(%rsp), %rsp
	movb	34(%r12), %cl
	leaq	4352(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1113:
	leaq	32(%rsp), %rsp
	leaq	4384(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1112:
	leaq	32(%rsp), %rsp
	leaq	4416(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1111:
	leaq	32(%rsp), %rsp
	leaq	4448(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1110:
	leaq	32(%rsp), %rsp
	movb	35(%r12), %cl
	leaq	4480(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1109:
	leaq	32(%rsp), %rsp
	leaq	4512(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1108:
	leaq	32(%rsp), %rsp
	leaq	4544(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1107:
	leaq	32(%rsp), %rsp
	leaq	4576(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1106:
	leaq	32(%rsp), %rsp
	movb	36(%r12), %cl
	leaq	4608(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1105:
	leaq	32(%rsp), %rsp
	leaq	4640(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1104:
	leaq	32(%rsp), %rsp
	leaq	4672(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1103:
	leaq	32(%rsp), %rsp
	leaq	4704(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1102:
	leaq	32(%rsp), %rsp
	movb	37(%r12), %cl
	leaq	4736(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1101:
	leaq	32(%rsp), %rsp
	leaq	4768(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1100:
	leaq	32(%rsp), %rsp
	leaq	4800(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1099:
	leaq	32(%rsp), %rsp
	leaq	4832(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1098:
	leaq	32(%rsp), %rsp
	movb	38(%r12), %cl
	leaq	4864(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1097:
	leaq	32(%rsp), %rsp
	leaq	4896(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1096:
	leaq	32(%rsp), %rsp
	leaq	4928(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1095:
	leaq	32(%rsp), %rsp
	leaq	4960(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1094:
	leaq	32(%rsp), %rsp
	movb	39(%r12), %cl
	leaq	4992(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1093:
	leaq	32(%rsp), %rsp
	leaq	5024(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1092:
	leaq	32(%rsp), %rsp
	leaq	5056(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1091:
	leaq	32(%rsp), %rsp
	leaq	5088(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1090:
	leaq	32(%rsp), %rsp
	movb	40(%r12), %cl
	leaq	5120(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1089:
	leaq	32(%rsp), %rsp
	leaq	5152(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1088:
	leaq	32(%rsp), %rsp
	leaq	5184(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1087:
	leaq	32(%rsp), %rsp
	leaq	5216(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1086:
	leaq	32(%rsp), %rsp
	movb	41(%r12), %cl
	leaq	5248(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1085:
	leaq	32(%rsp), %rsp
	leaq	5280(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1084:
	leaq	32(%rsp), %rsp
	leaq	5312(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1083:
	leaq	32(%rsp), %rsp
	leaq	5344(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1082:
	leaq	32(%rsp), %rsp
	movb	42(%r12), %cl
	leaq	5376(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1081:
	leaq	32(%rsp), %rsp
	leaq	5408(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1080:
	leaq	32(%rsp), %rsp
	leaq	5440(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1079:
	leaq	32(%rsp), %rsp
	leaq	5472(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1078:
	leaq	32(%rsp), %rsp
	movb	43(%r12), %cl
	leaq	5504(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1077:
	leaq	32(%rsp), %rsp
	leaq	5536(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1076:
	leaq	32(%rsp), %rsp
	leaq	5568(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1075:
	leaq	32(%rsp), %rsp
	leaq	5600(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1074:
	leaq	32(%rsp), %rsp
	movb	44(%r12), %cl
	leaq	5632(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1073:
	leaq	32(%rsp), %rsp
	leaq	5664(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1072:
	leaq	32(%rsp), %rsp
	leaq	5696(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1071:
	leaq	32(%rsp), %rsp
	leaq	5728(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1070:
	leaq	32(%rsp), %rsp
	movb	45(%r12), %cl
	leaq	5760(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1069:
	leaq	32(%rsp), %rsp
	leaq	5792(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1068:
	leaq	32(%rsp), %rsp
	leaq	5824(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1067:
	leaq	32(%rsp), %rsp
	leaq	5856(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1066:
	leaq	32(%rsp), %rsp
	movb	46(%r12), %cl
	leaq	5888(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1065:
	leaq	32(%rsp), %rsp
	leaq	5920(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1064:
	leaq	32(%rsp), %rsp
	leaq	5952(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1063:
	leaq	32(%rsp), %rsp
	leaq	5984(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1062:
	leaq	32(%rsp), %rsp
	movb	47(%r12), %cl
	leaq	6016(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1061:
	leaq	32(%rsp), %rsp
	leaq	6048(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1060:
	leaq	32(%rsp), %rsp
	leaq	6080(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1059:
	leaq	32(%rsp), %rsp
	leaq	6112(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1058:
	leaq	32(%rsp), %rsp
	movb	48(%r12), %cl
	leaq	6144(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1057:
	leaq	32(%rsp), %rsp
	leaq	6176(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1056:
	leaq	32(%rsp), %rsp
	leaq	6208(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1055:
	leaq	32(%rsp), %rsp
	leaq	6240(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1054:
	leaq	32(%rsp), %rsp
	movb	49(%r12), %cl
	leaq	6272(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1053:
	leaq	32(%rsp), %rsp
	leaq	6304(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1052:
	leaq	32(%rsp), %rsp
	leaq	6336(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1051:
	leaq	32(%rsp), %rsp
	leaq	6368(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1050:
	leaq	32(%rsp), %rsp
	movb	50(%r12), %cl
	leaq	6400(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1049:
	leaq	32(%rsp), %rsp
	leaq	6432(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1048:
	leaq	32(%rsp), %rsp
	leaq	6464(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1047:
	leaq	32(%rsp), %rsp
	leaq	6496(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1046:
	leaq	32(%rsp), %rsp
	movb	51(%r12), %cl
	leaq	6528(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1045:
	leaq	32(%rsp), %rsp
	leaq	6560(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1044:
	leaq	32(%rsp), %rsp
	leaq	6592(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1043:
	leaq	32(%rsp), %rsp
	leaq	6624(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1042:
	leaq	32(%rsp), %rsp
	movb	52(%r12), %cl
	leaq	6656(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1041:
	leaq	32(%rsp), %rsp
	leaq	6688(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1040:
	leaq	32(%rsp), %rsp
	leaq	6720(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1039:
	leaq	32(%rsp), %rsp
	leaq	6752(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1038:
	leaq	32(%rsp), %rsp
	movb	53(%r12), %cl
	leaq	6784(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1037:
	leaq	32(%rsp), %rsp
	leaq	6816(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1036:
	leaq	32(%rsp), %rsp
	leaq	6848(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1035:
	leaq	32(%rsp), %rsp
	leaq	6880(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1034:
	leaq	32(%rsp), %rsp
	movb	54(%r12), %cl
	leaq	6912(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1033:
	leaq	32(%rsp), %rsp
	leaq	6944(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1032:
	leaq	32(%rsp), %rsp
	leaq	6976(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1031:
	leaq	32(%rsp), %rsp
	leaq	7008(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1030:
	leaq	32(%rsp), %rsp
	movb	55(%r12), %cl
	leaq	7040(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1029:
	leaq	32(%rsp), %rsp
	leaq	7072(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1028:
	leaq	32(%rsp), %rsp
	leaq	7104(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1027:
	leaq	32(%rsp), %rsp
	leaq	7136(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1026:
	leaq	32(%rsp), %rsp
	movb	56(%r12), %cl
	leaq	7168(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1025:
	leaq	32(%rsp), %rsp
	leaq	7200(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1024:
	leaq	32(%rsp), %rsp
	leaq	7232(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1023:
	leaq	32(%rsp), %rsp
	leaq	7264(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1022:
	leaq	32(%rsp), %rsp
	movb	57(%r12), %cl
	leaq	7296(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1021:
	leaq	32(%rsp), %rsp
	leaq	7328(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1020:
	leaq	32(%rsp), %rsp
	leaq	7360(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1019:
	leaq	32(%rsp), %rsp
	leaq	7392(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1018:
	leaq	32(%rsp), %rsp
	movb	58(%r12), %cl
	leaq	7424(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1017:
	leaq	32(%rsp), %rsp
	leaq	7456(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1016:
	leaq	32(%rsp), %rsp
	leaq	7488(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1015:
	leaq	32(%rsp), %rsp
	leaq	7520(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1014:
	leaq	32(%rsp), %rsp
	movb	59(%r12), %cl
	leaq	7552(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1013:
	leaq	32(%rsp), %rsp
	leaq	7584(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1012:
	leaq	32(%rsp), %rsp
	leaq	7616(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1011:
	leaq	32(%rsp), %rsp
	leaq	7648(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1010:
	leaq	32(%rsp), %rsp
	movb	60(%r12), %cl
	leaq	7680(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1009:
	leaq	32(%rsp), %rsp
	leaq	7712(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1008:
	leaq	32(%rsp), %rsp
	leaq	7744(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1007:
	leaq	32(%rsp), %rsp
	leaq	7776(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1006:
	leaq	32(%rsp), %rsp
	movb	61(%r12), %cl
	leaq	7808(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1005:
	leaq	32(%rsp), %rsp
	leaq	7840(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1004:
	leaq	32(%rsp), %rsp
	leaq	7872(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1003:
	leaq	32(%rsp), %rsp
	leaq	7904(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1002:
	leaq	32(%rsp), %rsp
	movb	62(%r12), %cl
	leaq	7936(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1001:
	leaq	32(%rsp), %rsp
	leaq	7968(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$1000:
	leaq	32(%rsp), %rsp
	leaq	8000(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$999:
	leaq	32(%rsp), %rsp
	leaq	8032(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$998:
	leaq	32(%rsp), %rsp
	movb	63(%r12), %cl
	leaq	8064(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$997:
	leaq	32(%rsp), %rsp
	leaq	8096(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$996:
	leaq	32(%rsp), %rsp
	leaq	8128(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$995:
	leaq	32(%rsp), %rsp
	leaq	8160(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$994:
	leaq	32(%rsp), %rsp
	movb	64(%r12), %cl
	leaq	8192(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$993:
	leaq	32(%rsp), %rsp
	leaq	8224(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$992:
	leaq	32(%rsp), %rsp
	leaq	8256(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$991:
	leaq	32(%rsp), %rsp
	leaq	8288(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$990:
	leaq	32(%rsp), %rsp
	movb	65(%r12), %cl
	leaq	8320(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$989:
	leaq	32(%rsp), %rsp
	leaq	8352(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$988:
	leaq	32(%rsp), %rsp
	leaq	8384(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$987:
	leaq	32(%rsp), %rsp
	leaq	8416(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$986:
	leaq	32(%rsp), %rsp
	movb	66(%r12), %cl
	leaq	8448(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$985:
	leaq	32(%rsp), %rsp
	leaq	8480(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$984:
	leaq	32(%rsp), %rsp
	leaq	8512(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$983:
	leaq	32(%rsp), %rsp
	leaq	8544(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$982:
	leaq	32(%rsp), %rsp
	movb	67(%r12), %cl
	leaq	8576(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$981:
	leaq	32(%rsp), %rsp
	leaq	8608(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$980:
	leaq	32(%rsp), %rsp
	leaq	8640(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$979:
	leaq	32(%rsp), %rsp
	leaq	8672(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$978:
	leaq	32(%rsp), %rsp
	movb	68(%r12), %cl
	leaq	8704(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$977:
	leaq	32(%rsp), %rsp
	leaq	8736(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$976:
	leaq	32(%rsp), %rsp
	leaq	8768(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$975:
	leaq	32(%rsp), %rsp
	leaq	8800(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$974:
	leaq	32(%rsp), %rsp
	movb	69(%r12), %cl
	leaq	8832(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$973:
	leaq	32(%rsp), %rsp
	leaq	8864(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$972:
	leaq	32(%rsp), %rsp
	leaq	8896(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$971:
	leaq	32(%rsp), %rsp
	leaq	8928(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$970:
	leaq	32(%rsp), %rsp
	movb	70(%r12), %cl
	leaq	8960(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$969:
	leaq	32(%rsp), %rsp
	leaq	8992(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$968:
	leaq	32(%rsp), %rsp
	leaq	9024(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$967:
	leaq	32(%rsp), %rsp
	leaq	9056(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$966:
	leaq	32(%rsp), %rsp
	movb	71(%r12), %cl
	leaq	9088(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$965:
	leaq	32(%rsp), %rsp
	leaq	9120(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$964:
	leaq	32(%rsp), %rsp
	leaq	9152(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$963:
	leaq	32(%rsp), %rsp
	leaq	9184(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$962:
	leaq	32(%rsp), %rsp
	movb	72(%r12), %cl
	leaq	9216(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$961:
	leaq	32(%rsp), %rsp
	leaq	9248(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$960:
	leaq	32(%rsp), %rsp
	leaq	9280(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$959:
	leaq	32(%rsp), %rsp
	leaq	9312(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$958:
	leaq	32(%rsp), %rsp
	movb	73(%r12), %cl
	leaq	9344(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$957:
	leaq	32(%rsp), %rsp
	leaq	9376(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$956:
	leaq	32(%rsp), %rsp
	leaq	9408(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$955:
	leaq	32(%rsp), %rsp
	leaq	9440(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$954:
	leaq	32(%rsp), %rsp
	movb	74(%r12), %cl
	leaq	9472(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$953:
	leaq	32(%rsp), %rsp
	leaq	9504(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$952:
	leaq	32(%rsp), %rsp
	leaq	9536(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$951:
	leaq	32(%rsp), %rsp
	leaq	9568(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$950:
	leaq	32(%rsp), %rsp
	movb	75(%r12), %cl
	leaq	9600(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$949:
	leaq	32(%rsp), %rsp
	leaq	9632(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$948:
	leaq	32(%rsp), %rsp
	leaq	9664(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$947:
	leaq	32(%rsp), %rsp
	leaq	9696(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$946:
	leaq	32(%rsp), %rsp
	movb	76(%r12), %cl
	leaq	9728(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$945:
	leaq	32(%rsp), %rsp
	leaq	9760(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$944:
	leaq	32(%rsp), %rsp
	leaq	9792(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$943:
	leaq	32(%rsp), %rsp
	leaq	9824(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$942:
	leaq	32(%rsp), %rsp
	movb	77(%r12), %cl
	leaq	9856(%r14), %rax
	movq	%r13, %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$941:
	leaq	32(%rsp), %rsp
	leaq	9888(%r14), %rax
	leaq	32(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$940:
	leaq	32(%rsp), %rsp
	leaq	9920(%r14), %rax
	leaq	64(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$939:
	leaq	32(%rsp), %rsp
	leaq	9952(%r14), %rax
	leaq	96(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$938:
	leaq	32(%rsp), %rsp
	movb	78(%r12), %cl
	movq	%r14, %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$937:
	leaq	32(%rsp), %rsp
	leaq	32(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$936:
	leaq	32(%rsp), %rsp
	leaq	64(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$935:
	leaq	32(%rsp), %rsp
	leaq	96(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$934:
	leaq	32(%rsp), %rsp
	movb	79(%r12), %cl
	leaq	128(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$933:
	leaq	32(%rsp), %rsp
	leaq	160(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$932:
	leaq	32(%rsp), %rsp
	leaq	192(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$931:
	leaq	32(%rsp), %rsp
	leaq	224(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$930:
	leaq	32(%rsp), %rsp
	movb	80(%r12), %cl
	leaq	256(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$929:
	leaq	32(%rsp), %rsp
	leaq	288(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$928:
	leaq	32(%rsp), %rsp
	leaq	320(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$927:
	leaq	32(%rsp), %rsp
	leaq	352(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$926:
	leaq	32(%rsp), %rsp
	movb	81(%r12), %cl
	leaq	384(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$925:
	leaq	32(%rsp), %rsp
	leaq	416(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$924:
	leaq	32(%rsp), %rsp
	leaq	448(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$923:
	leaq	32(%rsp), %rsp
	leaq	480(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$922:
	leaq	32(%rsp), %rsp
	movb	82(%r12), %cl
	leaq	512(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$921:
	leaq	32(%rsp), %rsp
	leaq	544(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$920:
	leaq	32(%rsp), %rsp
	leaq	576(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$919:
	leaq	32(%rsp), %rsp
	leaq	608(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$918:
	leaq	32(%rsp), %rsp
	movb	83(%r12), %cl
	leaq	640(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$917:
	leaq	32(%rsp), %rsp
	leaq	672(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$916:
	leaq	32(%rsp), %rsp
	leaq	704(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$915:
	leaq	32(%rsp), %rsp
	leaq	736(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$914:
	leaq	32(%rsp), %rsp
	movb	84(%r12), %cl
	leaq	768(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$913:
	leaq	32(%rsp), %rsp
	leaq	800(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$912:
	leaq	32(%rsp), %rsp
	leaq	832(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$911:
	leaq	32(%rsp), %rsp
	leaq	864(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$910:
	leaq	32(%rsp), %rsp
	movb	85(%r12), %cl
	leaq	896(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$909:
	leaq	32(%rsp), %rsp
	leaq	928(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$908:
	leaq	32(%rsp), %rsp
	leaq	960(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$907:
	leaq	32(%rsp), %rsp
	leaq	992(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$906:
	leaq	32(%rsp), %rsp
	movb	86(%r12), %cl
	leaq	1024(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$905:
	leaq	32(%rsp), %rsp
	leaq	1056(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$904:
	leaq	32(%rsp), %rsp
	leaq	1088(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$903:
	leaq	32(%rsp), %rsp
	leaq	1120(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$902:
	leaq	32(%rsp), %rsp
	movb	87(%r12), %cl
	leaq	1152(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$901:
	leaq	32(%rsp), %rsp
	leaq	1184(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$900:
	leaq	32(%rsp), %rsp
	leaq	1216(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$899:
	leaq	32(%rsp), %rsp
	leaq	1248(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$898:
	leaq	32(%rsp), %rsp
	movb	88(%r12), %cl
	leaq	1280(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$897:
	leaq	32(%rsp), %rsp
	leaq	1312(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$896:
	leaq	32(%rsp), %rsp
	leaq	1344(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$895:
	leaq	32(%rsp), %rsp
	leaq	1376(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$894:
	leaq	32(%rsp), %rsp
	movb	89(%r12), %cl
	leaq	1408(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$893:
	leaq	32(%rsp), %rsp
	leaq	1440(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$892:
	leaq	32(%rsp), %rsp
	leaq	1472(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$891:
	leaq	32(%rsp), %rsp
	leaq	1504(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$890:
	leaq	32(%rsp), %rsp
	movb	90(%r12), %cl
	leaq	1536(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$889:
	leaq	32(%rsp), %rsp
	leaq	1568(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$888:
	leaq	32(%rsp), %rsp
	leaq	1600(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$887:
	leaq	32(%rsp), %rsp
	leaq	1632(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$886:
	leaq	32(%rsp), %rsp
	movb	91(%r12), %cl
	leaq	1664(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$885:
	leaq	32(%rsp), %rsp
	leaq	1696(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$884:
	leaq	32(%rsp), %rsp
	leaq	1728(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$883:
	leaq	32(%rsp), %rsp
	leaq	1760(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$882:
	leaq	32(%rsp), %rsp
	movb	92(%r12), %cl
	leaq	1792(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$881:
	leaq	32(%rsp), %rsp
	leaq	1824(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$880:
	leaq	32(%rsp), %rsp
	leaq	1856(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$879:
	leaq	32(%rsp), %rsp
	leaq	1888(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$878:
	leaq	32(%rsp), %rsp
	movb	93(%r12), %cl
	leaq	1920(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$877:
	leaq	32(%rsp), %rsp
	leaq	1952(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$876:
	leaq	32(%rsp), %rsp
	leaq	1984(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$875:
	leaq	32(%rsp), %rsp
	leaq	2016(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$874:
	leaq	32(%rsp), %rsp
	movb	94(%r12), %cl
	leaq	2048(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$873:
	leaq	32(%rsp), %rsp
	leaq	2080(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$872:
	leaq	32(%rsp), %rsp
	leaq	2112(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$871:
	leaq	32(%rsp), %rsp
	leaq	2144(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$870:
	leaq	32(%rsp), %rsp
	movb	95(%r12), %cl
	leaq	2176(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$869:
	leaq	32(%rsp), %rsp
	leaq	2208(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$868:
	leaq	32(%rsp), %rsp
	leaq	2240(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$867:
	leaq	32(%rsp), %rsp
	leaq	2272(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$866:
	leaq	32(%rsp), %rsp
	movb	96(%r12), %cl
	leaq	2304(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$865:
	leaq	32(%rsp), %rsp
	leaq	2336(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$864:
	leaq	32(%rsp), %rsp
	leaq	2368(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$863:
	leaq	32(%rsp), %rsp
	leaq	2400(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$862:
	leaq	32(%rsp), %rsp
	movb	97(%r12), %cl
	leaq	2432(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$861:
	leaq	32(%rsp), %rsp
	leaq	2464(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$860:
	leaq	32(%rsp), %rsp
	leaq	2496(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$859:
	leaq	32(%rsp), %rsp
	leaq	2528(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$858:
	leaq	32(%rsp), %rsp
	movb	98(%r12), %cl
	leaq	2560(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$857:
	leaq	32(%rsp), %rsp
	leaq	2592(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$856:
	leaq	32(%rsp), %rsp
	leaq	2624(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$855:
	leaq	32(%rsp), %rsp
	leaq	2656(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$854:
	leaq	32(%rsp), %rsp
	movb	99(%r12), %cl
	leaq	2688(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$853:
	leaq	32(%rsp), %rsp
	leaq	2720(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$852:
	leaq	32(%rsp), %rsp
	leaq	2752(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$851:
	leaq	32(%rsp), %rsp
	leaq	2784(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$850:
	leaq	32(%rsp), %rsp
	movb	100(%r12), %cl
	leaq	2816(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$849:
	leaq	32(%rsp), %rsp
	leaq	2848(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$848:
	leaq	32(%rsp), %rsp
	leaq	2880(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$847:
	leaq	32(%rsp), %rsp
	leaq	2912(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$846:
	leaq	32(%rsp), %rsp
	movb	101(%r12), %cl
	leaq	2944(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$845:
	leaq	32(%rsp), %rsp
	leaq	2976(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$844:
	leaq	32(%rsp), %rsp
	leaq	3008(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$843:
	leaq	32(%rsp), %rsp
	leaq	3040(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$842:
	leaq	32(%rsp), %rsp
	movb	102(%r12), %cl
	leaq	3072(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$841:
	leaq	32(%rsp), %rsp
	leaq	3104(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$840:
	leaq	32(%rsp), %rsp
	leaq	3136(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$839:
	leaq	32(%rsp), %rsp
	leaq	3168(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$838:
	leaq	32(%rsp), %rsp
	movb	103(%r12), %cl
	leaq	3200(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$837:
	leaq	32(%rsp), %rsp
	leaq	3232(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$836:
	leaq	32(%rsp), %rsp
	leaq	3264(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$835:
	leaq	32(%rsp), %rsp
	leaq	3296(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$834:
	leaq	32(%rsp), %rsp
	movb	104(%r12), %cl
	leaq	3328(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$833:
	leaq	32(%rsp), %rsp
	leaq	3360(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$832:
	leaq	32(%rsp), %rsp
	leaq	3392(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$831:
	leaq	32(%rsp), %rsp
	leaq	3424(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$830:
	leaq	32(%rsp), %rsp
	movb	105(%r12), %cl
	leaq	3456(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$829:
	leaq	32(%rsp), %rsp
	leaq	3488(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$828:
	leaq	32(%rsp), %rsp
	leaq	3520(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$827:
	leaq	32(%rsp), %rsp
	leaq	3552(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$826:
	leaq	32(%rsp), %rsp
	movb	106(%r12), %cl
	leaq	3584(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$825:
	leaq	32(%rsp), %rsp
	leaq	3616(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$824:
	leaq	32(%rsp), %rsp
	leaq	3648(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$823:
	leaq	32(%rsp), %rsp
	leaq	3680(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$822:
	leaq	32(%rsp), %rsp
	movb	107(%r12), %cl
	leaq	3712(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$821:
	leaq	32(%rsp), %rsp
	leaq	3744(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$820:
	leaq	32(%rsp), %rsp
	leaq	3776(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$819:
	leaq	32(%rsp), %rsp
	leaq	3808(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$818:
	leaq	32(%rsp), %rsp
	movb	108(%r12), %cl
	leaq	3840(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$817:
	leaq	32(%rsp), %rsp
	leaq	3872(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$816:
	leaq	32(%rsp), %rsp
	leaq	3904(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$815:
	leaq	32(%rsp), %rsp
	leaq	3936(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$814:
	leaq	32(%rsp), %rsp
	movb	109(%r12), %cl
	leaq	3968(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$813:
	leaq	32(%rsp), %rsp
	leaq	4000(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$812:
	leaq	32(%rsp), %rsp
	leaq	4032(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$811:
	leaq	32(%rsp), %rsp
	leaq	4064(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$810:
	leaq	32(%rsp), %rsp
	movb	110(%r12), %cl
	leaq	4096(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$809:
	leaq	32(%rsp), %rsp
	leaq	4128(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$808:
	leaq	32(%rsp), %rsp
	leaq	4160(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$807:
	leaq	32(%rsp), %rsp
	leaq	4192(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$806:
	leaq	32(%rsp), %rsp
	movb	111(%r12), %cl
	leaq	4224(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$805:
	leaq	32(%rsp), %rsp
	leaq	4256(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$804:
	leaq	32(%rsp), %rsp
	leaq	4288(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$803:
	leaq	32(%rsp), %rsp
	leaq	4320(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$802:
	leaq	32(%rsp), %rsp
	movb	112(%r12), %cl
	leaq	4352(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$801:
	leaq	32(%rsp), %rsp
	leaq	4384(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$800:
	leaq	32(%rsp), %rsp
	leaq	4416(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$799:
	leaq	32(%rsp), %rsp
	leaq	4448(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$798:
	leaq	32(%rsp), %rsp
	movb	113(%r12), %cl
	leaq	4480(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$797:
	leaq	32(%rsp), %rsp
	leaq	4512(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$796:
	leaq	32(%rsp), %rsp
	leaq	4544(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$795:
	leaq	32(%rsp), %rsp
	leaq	4576(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$794:
	leaq	32(%rsp), %rsp
	movb	114(%r12), %cl
	leaq	4608(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$793:
	leaq	32(%rsp), %rsp
	leaq	4640(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$792:
	leaq	32(%rsp), %rsp
	leaq	4672(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$791:
	leaq	32(%rsp), %rsp
	leaq	4704(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$790:
	leaq	32(%rsp), %rsp
	movb	115(%r12), %cl
	leaq	4736(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$789:
	leaq	32(%rsp), %rsp
	leaq	4768(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$788:
	leaq	32(%rsp), %rsp
	leaq	4800(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$787:
	leaq	32(%rsp), %rsp
	leaq	4832(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$786:
	leaq	32(%rsp), %rsp
	movb	116(%r12), %cl
	leaq	4864(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$785:
	leaq	32(%rsp), %rsp
	leaq	4896(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$784:
	leaq	32(%rsp), %rsp
	leaq	4928(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$783:
	leaq	32(%rsp), %rsp
	leaq	4960(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$782:
	leaq	32(%rsp), %rsp
	movb	117(%r12), %cl
	leaq	4992(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$781:
	leaq	32(%rsp), %rsp
	leaq	5024(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$780:
	leaq	32(%rsp), %rsp
	leaq	5056(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$779:
	leaq	32(%rsp), %rsp
	leaq	5088(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$778:
	leaq	32(%rsp), %rsp
	movb	118(%r12), %cl
	leaq	5120(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$777:
	leaq	32(%rsp), %rsp
	leaq	5152(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$776:
	leaq	32(%rsp), %rsp
	leaq	5184(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$775:
	leaq	32(%rsp), %rsp
	leaq	5216(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$774:
	leaq	32(%rsp), %rsp
	movb	119(%r12), %cl
	leaq	5248(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$773:
	leaq	32(%rsp), %rsp
	leaq	5280(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$772:
	leaq	32(%rsp), %rsp
	leaq	5312(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$771:
	leaq	32(%rsp), %rsp
	leaq	5344(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$770:
	leaq	32(%rsp), %rsp
	movb	120(%r12), %cl
	leaq	5376(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$769:
	leaq	32(%rsp), %rsp
	leaq	5408(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$768:
	leaq	32(%rsp), %rsp
	leaq	5440(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$767:
	leaq	32(%rsp), %rsp
	leaq	5472(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$766:
	leaq	32(%rsp), %rsp
	movb	121(%r12), %cl
	leaq	5504(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$765:
	leaq	32(%rsp), %rsp
	leaq	5536(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$764:
	leaq	32(%rsp), %rsp
	leaq	5568(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$763:
	leaq	32(%rsp), %rsp
	leaq	5600(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$762:
	leaq	32(%rsp), %rsp
	movb	122(%r12), %cl
	leaq	5632(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$761:
	leaq	32(%rsp), %rsp
	leaq	5664(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$760:
	leaq	32(%rsp), %rsp
	leaq	5696(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$759:
	leaq	32(%rsp), %rsp
	leaq	5728(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$758:
	leaq	32(%rsp), %rsp
	movb	123(%r12), %cl
	leaq	5760(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$757:
	leaq	32(%rsp), %rsp
	leaq	5792(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$756:
	leaq	32(%rsp), %rsp
	leaq	5824(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$755:
	leaq	32(%rsp), %rsp
	leaq	5856(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$754:
	leaq	32(%rsp), %rsp
	movb	124(%r12), %cl
	leaq	5888(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$753:
	leaq	32(%rsp), %rsp
	leaq	5920(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$752:
	leaq	32(%rsp), %rsp
	leaq	5952(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$751:
	leaq	32(%rsp), %rsp
	leaq	5984(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$750:
	leaq	32(%rsp), %rsp
	movb	125(%r12), %cl
	leaq	6016(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$749:
	leaq	32(%rsp), %rsp
	leaq	6048(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$748:
	leaq	32(%rsp), %rsp
	leaq	6080(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$747:
	leaq	32(%rsp), %rsp
	leaq	6112(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$746:
	leaq	32(%rsp), %rsp
	movb	126(%r12), %cl
	leaq	6144(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$745:
	leaq	32(%rsp), %rsp
	leaq	6176(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$744:
	leaq	32(%rsp), %rsp
	leaq	6208(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$743:
	leaq	32(%rsp), %rsp
	leaq	6240(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$742:
	leaq	32(%rsp), %rsp
	movb	127(%r12), %cl
	leaq	6272(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$741:
	leaq	32(%rsp), %rsp
	leaq	6304(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$740:
	leaq	32(%rsp), %rsp
	leaq	6336(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$739:
	leaq	32(%rsp), %rsp
	leaq	6368(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$738:
	leaq	32(%rsp), %rsp
	movb	128(%r12), %cl
	leaq	6400(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$737:
	leaq	32(%rsp), %rsp
	leaq	6432(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$736:
	leaq	32(%rsp), %rsp
	leaq	6464(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$735:
	leaq	32(%rsp), %rsp
	leaq	6496(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$734:
	leaq	32(%rsp), %rsp
	movb	129(%r12), %cl
	leaq	6528(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$733:
	leaq	32(%rsp), %rsp
	leaq	6560(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$732:
	leaq	32(%rsp), %rsp
	leaq	6592(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$731:
	leaq	32(%rsp), %rsp
	leaq	6624(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$730:
	leaq	32(%rsp), %rsp
	movb	130(%r12), %cl
	leaq	6656(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$729:
	leaq	32(%rsp), %rsp
	leaq	6688(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$728:
	leaq	32(%rsp), %rsp
	leaq	6720(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$727:
	leaq	32(%rsp), %rsp
	leaq	6752(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$726:
	leaq	32(%rsp), %rsp
	movb	131(%r12), %cl
	leaq	6784(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$725:
	leaq	32(%rsp), %rsp
	leaq	6816(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$724:
	leaq	32(%rsp), %rsp
	leaq	6848(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$723:
	leaq	32(%rsp), %rsp
	leaq	6880(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$722:
	leaq	32(%rsp), %rsp
	movb	132(%r12), %cl
	leaq	6912(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$721:
	leaq	32(%rsp), %rsp
	leaq	6944(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$720:
	leaq	32(%rsp), %rsp
	leaq	6976(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$719:
	leaq	32(%rsp), %rsp
	leaq	7008(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$718:
	leaq	32(%rsp), %rsp
	movb	133(%r12), %cl
	leaq	7040(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$717:
	leaq	32(%rsp), %rsp
	leaq	7072(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$716:
	leaq	32(%rsp), %rsp
	leaq	7104(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$715:
	leaq	32(%rsp), %rsp
	leaq	7136(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$714:
	leaq	32(%rsp), %rsp
	movb	134(%r12), %cl
	leaq	7168(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$713:
	leaq	32(%rsp), %rsp
	leaq	7200(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$712:
	leaq	32(%rsp), %rsp
	leaq	7232(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$711:
	leaq	32(%rsp), %rsp
	leaq	7264(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$710:
	leaq	32(%rsp), %rsp
	movb	135(%r12), %cl
	leaq	7296(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$709:
	leaq	32(%rsp), %rsp
	leaq	7328(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$708:
	leaq	32(%rsp), %rsp
	leaq	7360(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$707:
	leaq	32(%rsp), %rsp
	leaq	7392(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$706:
	leaq	32(%rsp), %rsp
	movb	136(%r12), %cl
	leaq	7424(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$705:
	leaq	32(%rsp), %rsp
	leaq	7456(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$704:
	leaq	32(%rsp), %rsp
	leaq	7488(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$703:
	leaq	32(%rsp), %rsp
	leaq	7520(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$702:
	leaq	32(%rsp), %rsp
	movb	137(%r12), %cl
	leaq	7552(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$701:
	leaq	32(%rsp), %rsp
	leaq	7584(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$700:
	leaq	32(%rsp), %rsp
	leaq	7616(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$699:
	leaq	32(%rsp), %rsp
	leaq	7648(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$698:
	leaq	32(%rsp), %rsp
	movb	138(%r12), %cl
	leaq	7680(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$697:
	leaq	32(%rsp), %rsp
	leaq	7712(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$696:
	leaq	32(%rsp), %rsp
	leaq	7744(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$695:
	leaq	32(%rsp), %rsp
	leaq	7776(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$694:
	leaq	32(%rsp), %rsp
	movb	139(%r12), %cl
	leaq	7808(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$693:
	leaq	32(%rsp), %rsp
	leaq	7840(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$692:
	leaq	32(%rsp), %rsp
	leaq	7872(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$691:
	leaq	32(%rsp), %rsp
	leaq	7904(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$690:
	leaq	32(%rsp), %rsp
	movb	140(%r12), %cl
	leaq	7936(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$689:
	leaq	32(%rsp), %rsp
	leaq	7968(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$688:
	leaq	32(%rsp), %rsp
	leaq	8000(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$687:
	leaq	32(%rsp), %rsp
	leaq	8032(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$686:
	leaq	32(%rsp), %rsp
	movb	141(%r12), %cl
	leaq	8064(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$685:
	leaq	32(%rsp), %rsp
	leaq	8096(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$684:
	leaq	32(%rsp), %rsp
	leaq	8128(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$683:
	leaq	32(%rsp), %rsp
	leaq	8160(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$682:
	leaq	32(%rsp), %rsp
	movb	142(%r12), %cl
	leaq	8192(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$681:
	leaq	32(%rsp), %rsp
	leaq	8224(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$680:
	leaq	32(%rsp), %rsp
	leaq	8256(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$679:
	leaq	32(%rsp), %rsp
	leaq	8288(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$678:
	leaq	32(%rsp), %rsp
	movb	143(%r12), %cl
	leaq	8320(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$677:
	leaq	32(%rsp), %rsp
	leaq	8352(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$676:
	leaq	32(%rsp), %rsp
	leaq	8384(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$675:
	leaq	32(%rsp), %rsp
	leaq	8416(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$674:
	leaq	32(%rsp), %rsp
	movb	144(%r12), %cl
	leaq	8448(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$673:
	leaq	32(%rsp), %rsp
	leaq	8480(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$672:
	leaq	32(%rsp), %rsp
	leaq	8512(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$671:
	leaq	32(%rsp), %rsp
	leaq	8544(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$670:
	leaq	32(%rsp), %rsp
	movb	145(%r12), %cl
	leaq	8576(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$669:
	leaq	32(%rsp), %rsp
	leaq	8608(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$668:
	leaq	32(%rsp), %rsp
	leaq	8640(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$667:
	leaq	32(%rsp), %rsp
	leaq	8672(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$666:
	leaq	32(%rsp), %rsp
	movb	146(%r12), %cl
	leaq	8704(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$665:
	leaq	32(%rsp), %rsp
	leaq	8736(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$664:
	leaq	32(%rsp), %rsp
	leaq	8768(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$663:
	leaq	32(%rsp), %rsp
	leaq	8800(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$662:
	leaq	32(%rsp), %rsp
	movb	147(%r12), %cl
	leaq	8832(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$661:
	leaq	32(%rsp), %rsp
	leaq	8864(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$660:
	leaq	32(%rsp), %rsp
	leaq	8896(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$659:
	leaq	32(%rsp), %rsp
	leaq	8928(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$658:
	leaq	32(%rsp), %rsp
	movb	148(%r12), %cl
	leaq	8960(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$657:
	leaq	32(%rsp), %rsp
	leaq	8992(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$656:
	leaq	32(%rsp), %rsp
	leaq	9024(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$655:
	leaq	32(%rsp), %rsp
	leaq	9056(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$654:
	leaq	32(%rsp), %rsp
	movb	149(%r12), %cl
	leaq	9088(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$653:
	leaq	32(%rsp), %rsp
	leaq	9120(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$652:
	leaq	32(%rsp), %rsp
	leaq	9152(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$651:
	leaq	32(%rsp), %rsp
	leaq	9184(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$650:
	leaq	32(%rsp), %rsp
	movb	150(%r12), %cl
	leaq	9216(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$649:
	leaq	32(%rsp), %rsp
	leaq	9248(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$648:
	leaq	32(%rsp), %rsp
	leaq	9280(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$647:
	leaq	32(%rsp), %rsp
	leaq	9312(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$646:
	leaq	32(%rsp), %rsp
	movb	151(%r12), %cl
	leaq	9344(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$645:
	leaq	32(%rsp), %rsp
	leaq	9376(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$644:
	leaq	32(%rsp), %rsp
	leaq	9408(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$643:
	leaq	32(%rsp), %rsp
	leaq	9440(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$642:
	leaq	32(%rsp), %rsp
	movb	152(%r12), %cl
	leaq	9472(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$641:
	leaq	32(%rsp), %rsp
	leaq	9504(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$640:
	leaq	32(%rsp), %rsp
	leaq	9536(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$639:
	leaq	32(%rsp), %rsp
	leaq	9568(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$638:
	leaq	32(%rsp), %rsp
	movb	153(%r12), %cl
	leaq	9600(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$637:
	leaq	32(%rsp), %rsp
	leaq	9632(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$636:
	leaq	32(%rsp), %rsp
	leaq	9664(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$635:
	leaq	32(%rsp), %rsp
	leaq	9696(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$634:
	leaq	32(%rsp), %rsp
	movb	154(%r12), %cl
	leaq	9728(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$633:
	leaq	32(%rsp), %rsp
	leaq	9760(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$632:
	leaq	32(%rsp), %rsp
	leaq	9792(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$631:
	leaq	32(%rsp), %rsp
	leaq	9824(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$630:
	leaq	32(%rsp), %rsp
	movb	155(%r12), %cl
	leaq	9856(%r14), %rax
	leaq	128(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$629:
	leaq	32(%rsp), %rsp
	leaq	9888(%r14), %rax
	leaq	160(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$628:
	leaq	32(%rsp), %rsp
	leaq	9920(%r14), %rax
	leaq	192(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$627:
	leaq	32(%rsp), %rsp
	leaq	9952(%r14), %rax
	leaq	224(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$626:
	leaq	32(%rsp), %rsp
	movb	156(%r12), %cl
	movq	%r14, %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$625:
	leaq	32(%rsp), %rsp
	leaq	32(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$624:
	leaq	32(%rsp), %rsp
	leaq	64(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$623:
	leaq	32(%rsp), %rsp
	leaq	96(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$622:
	leaq	32(%rsp), %rsp
	movb	157(%r12), %cl
	leaq	128(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$621:
	leaq	32(%rsp), %rsp
	leaq	160(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$620:
	leaq	32(%rsp), %rsp
	leaq	192(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$619:
	leaq	32(%rsp), %rsp
	leaq	224(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$618:
	leaq	32(%rsp), %rsp
	movb	158(%r12), %cl
	leaq	256(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$617:
	leaq	32(%rsp), %rsp
	leaq	288(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$616:
	leaq	32(%rsp), %rsp
	leaq	320(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$615:
	leaq	32(%rsp), %rsp
	leaq	352(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$614:
	leaq	32(%rsp), %rsp
	movb	159(%r12), %cl
	leaq	384(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$613:
	leaq	32(%rsp), %rsp
	leaq	416(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$612:
	leaq	32(%rsp), %rsp
	leaq	448(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$611:
	leaq	32(%rsp), %rsp
	leaq	480(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$610:
	leaq	32(%rsp), %rsp
	movb	160(%r12), %cl
	leaq	512(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$609:
	leaq	32(%rsp), %rsp
	leaq	544(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$608:
	leaq	32(%rsp), %rsp
	leaq	576(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$607:
	leaq	32(%rsp), %rsp
	leaq	608(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$606:
	leaq	32(%rsp), %rsp
	movb	161(%r12), %cl
	leaq	640(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$605:
	leaq	32(%rsp), %rsp
	leaq	672(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$604:
	leaq	32(%rsp), %rsp
	leaq	704(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$603:
	leaq	32(%rsp), %rsp
	leaq	736(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$602:
	leaq	32(%rsp), %rsp
	movb	162(%r12), %cl
	leaq	768(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$601:
	leaq	32(%rsp), %rsp
	leaq	800(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$600:
	leaq	32(%rsp), %rsp
	leaq	832(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$599:
	leaq	32(%rsp), %rsp
	leaq	864(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$598:
	leaq	32(%rsp), %rsp
	movb	163(%r12), %cl
	leaq	896(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$597:
	leaq	32(%rsp), %rsp
	leaq	928(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$596:
	leaq	32(%rsp), %rsp
	leaq	960(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$595:
	leaq	32(%rsp), %rsp
	leaq	992(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$594:
	leaq	32(%rsp), %rsp
	movb	164(%r12), %cl
	leaq	1024(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$593:
	leaq	32(%rsp), %rsp
	leaq	1056(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$592:
	leaq	32(%rsp), %rsp
	leaq	1088(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$591:
	leaq	32(%rsp), %rsp
	leaq	1120(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$590:
	leaq	32(%rsp), %rsp
	movb	165(%r12), %cl
	leaq	1152(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$589:
	leaq	32(%rsp), %rsp
	leaq	1184(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$588:
	leaq	32(%rsp), %rsp
	leaq	1216(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$587:
	leaq	32(%rsp), %rsp
	leaq	1248(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$586:
	leaq	32(%rsp), %rsp
	movb	166(%r12), %cl
	leaq	1280(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$585:
	leaq	32(%rsp), %rsp
	leaq	1312(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$584:
	leaq	32(%rsp), %rsp
	leaq	1344(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$583:
	leaq	32(%rsp), %rsp
	leaq	1376(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$582:
	leaq	32(%rsp), %rsp
	movb	167(%r12), %cl
	leaq	1408(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$581:
	leaq	32(%rsp), %rsp
	leaq	1440(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$580:
	leaq	32(%rsp), %rsp
	leaq	1472(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$579:
	leaq	32(%rsp), %rsp
	leaq	1504(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$578:
	leaq	32(%rsp), %rsp
	movb	168(%r12), %cl
	leaq	1536(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$577:
	leaq	32(%rsp), %rsp
	leaq	1568(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$576:
	leaq	32(%rsp), %rsp
	leaq	1600(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$575:
	leaq	32(%rsp), %rsp
	leaq	1632(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$574:
	leaq	32(%rsp), %rsp
	movb	169(%r12), %cl
	leaq	1664(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$573:
	leaq	32(%rsp), %rsp
	leaq	1696(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$572:
	leaq	32(%rsp), %rsp
	leaq	1728(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$571:
	leaq	32(%rsp), %rsp
	leaq	1760(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$570:
	leaq	32(%rsp), %rsp
	movb	170(%r12), %cl
	leaq	1792(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$569:
	leaq	32(%rsp), %rsp
	leaq	1824(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$568:
	leaq	32(%rsp), %rsp
	leaq	1856(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$567:
	leaq	32(%rsp), %rsp
	leaq	1888(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$566:
	leaq	32(%rsp), %rsp
	movb	171(%r12), %cl
	leaq	1920(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$565:
	leaq	32(%rsp), %rsp
	leaq	1952(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$564:
	leaq	32(%rsp), %rsp
	leaq	1984(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$563:
	leaq	32(%rsp), %rsp
	leaq	2016(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$562:
	leaq	32(%rsp), %rsp
	movb	172(%r12), %cl
	leaq	2048(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$561:
	leaq	32(%rsp), %rsp
	leaq	2080(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$560:
	leaq	32(%rsp), %rsp
	leaq	2112(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$559:
	leaq	32(%rsp), %rsp
	leaq	2144(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$558:
	leaq	32(%rsp), %rsp
	movb	173(%r12), %cl
	leaq	2176(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$557:
	leaq	32(%rsp), %rsp
	leaq	2208(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$556:
	leaq	32(%rsp), %rsp
	leaq	2240(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$555:
	leaq	32(%rsp), %rsp
	leaq	2272(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$554:
	leaq	32(%rsp), %rsp
	movb	174(%r12), %cl
	leaq	2304(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$553:
	leaq	32(%rsp), %rsp
	leaq	2336(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$552:
	leaq	32(%rsp), %rsp
	leaq	2368(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$551:
	leaq	32(%rsp), %rsp
	leaq	2400(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$550:
	leaq	32(%rsp), %rsp
	movb	175(%r12), %cl
	leaq	2432(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$549:
	leaq	32(%rsp), %rsp
	leaq	2464(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$548:
	leaq	32(%rsp), %rsp
	leaq	2496(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$547:
	leaq	32(%rsp), %rsp
	leaq	2528(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$546:
	leaq	32(%rsp), %rsp
	movb	176(%r12), %cl
	leaq	2560(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$545:
	leaq	32(%rsp), %rsp
	leaq	2592(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$544:
	leaq	32(%rsp), %rsp
	leaq	2624(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$543:
	leaq	32(%rsp), %rsp
	leaq	2656(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$542:
	leaq	32(%rsp), %rsp
	movb	177(%r12), %cl
	leaq	2688(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$541:
	leaq	32(%rsp), %rsp
	leaq	2720(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$540:
	leaq	32(%rsp), %rsp
	leaq	2752(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$539:
	leaq	32(%rsp), %rsp
	leaq	2784(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$538:
	leaq	32(%rsp), %rsp
	movb	178(%r12), %cl
	leaq	2816(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$537:
	leaq	32(%rsp), %rsp
	leaq	2848(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$536:
	leaq	32(%rsp), %rsp
	leaq	2880(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$535:
	leaq	32(%rsp), %rsp
	leaq	2912(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$534:
	leaq	32(%rsp), %rsp
	movb	179(%r12), %cl
	leaq	2944(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$533:
	leaq	32(%rsp), %rsp
	leaq	2976(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$532:
	leaq	32(%rsp), %rsp
	leaq	3008(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$531:
	leaq	32(%rsp), %rsp
	leaq	3040(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$530:
	leaq	32(%rsp), %rsp
	movb	180(%r12), %cl
	leaq	3072(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$529:
	leaq	32(%rsp), %rsp
	leaq	3104(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$528:
	leaq	32(%rsp), %rsp
	leaq	3136(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$527:
	leaq	32(%rsp), %rsp
	leaq	3168(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$526:
	leaq	32(%rsp), %rsp
	movb	181(%r12), %cl
	leaq	3200(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$525:
	leaq	32(%rsp), %rsp
	leaq	3232(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$524:
	leaq	32(%rsp), %rsp
	leaq	3264(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$523:
	leaq	32(%rsp), %rsp
	leaq	3296(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$522:
	leaq	32(%rsp), %rsp
	movb	182(%r12), %cl
	leaq	3328(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$521:
	leaq	32(%rsp), %rsp
	leaq	3360(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$520:
	leaq	32(%rsp), %rsp
	leaq	3392(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$519:
	leaq	32(%rsp), %rsp
	leaq	3424(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$518:
	leaq	32(%rsp), %rsp
	movb	183(%r12), %cl
	leaq	3456(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$517:
	leaq	32(%rsp), %rsp
	leaq	3488(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$516:
	leaq	32(%rsp), %rsp
	leaq	3520(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$515:
	leaq	32(%rsp), %rsp
	leaq	3552(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$514:
	leaq	32(%rsp), %rsp
	movb	184(%r12), %cl
	leaq	3584(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$513:
	leaq	32(%rsp), %rsp
	leaq	3616(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$512:
	leaq	32(%rsp), %rsp
	leaq	3648(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$511:
	leaq	32(%rsp), %rsp
	leaq	3680(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$510:
	leaq	32(%rsp), %rsp
	movb	185(%r12), %cl
	leaq	3712(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$509:
	leaq	32(%rsp), %rsp
	leaq	3744(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$508:
	leaq	32(%rsp), %rsp
	leaq	3776(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$507:
	leaq	32(%rsp), %rsp
	leaq	3808(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$506:
	leaq	32(%rsp), %rsp
	movb	186(%r12), %cl
	leaq	3840(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$505:
	leaq	32(%rsp), %rsp
	leaq	3872(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$504:
	leaq	32(%rsp), %rsp
	leaq	3904(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$503:
	leaq	32(%rsp), %rsp
	leaq	3936(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$502:
	leaq	32(%rsp), %rsp
	movb	187(%r12), %cl
	leaq	3968(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$501:
	leaq	32(%rsp), %rsp
	leaq	4000(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$500:
	leaq	32(%rsp), %rsp
	leaq	4032(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$499:
	leaq	32(%rsp), %rsp
	leaq	4064(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$498:
	leaq	32(%rsp), %rsp
	movb	188(%r12), %cl
	leaq	4096(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$497:
	leaq	32(%rsp), %rsp
	leaq	4128(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$496:
	leaq	32(%rsp), %rsp
	leaq	4160(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$495:
	leaq	32(%rsp), %rsp
	leaq	4192(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$494:
	leaq	32(%rsp), %rsp
	movb	189(%r12), %cl
	leaq	4224(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$493:
	leaq	32(%rsp), %rsp
	leaq	4256(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$492:
	leaq	32(%rsp), %rsp
	leaq	4288(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$491:
	leaq	32(%rsp), %rsp
	leaq	4320(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$490:
	leaq	32(%rsp), %rsp
	movb	190(%r12), %cl
	leaq	4352(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$489:
	leaq	32(%rsp), %rsp
	leaq	4384(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$488:
	leaq	32(%rsp), %rsp
	leaq	4416(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$487:
	leaq	32(%rsp), %rsp
	leaq	4448(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$486:
	leaq	32(%rsp), %rsp
	movb	191(%r12), %cl
	leaq	4480(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$485:
	leaq	32(%rsp), %rsp
	leaq	4512(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$484:
	leaq	32(%rsp), %rsp
	leaq	4544(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$483:
	leaq	32(%rsp), %rsp
	leaq	4576(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$482:
	leaq	32(%rsp), %rsp
	movb	192(%r12), %cl
	leaq	4608(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$481:
	leaq	32(%rsp), %rsp
	leaq	4640(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$480:
	leaq	32(%rsp), %rsp
	leaq	4672(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$479:
	leaq	32(%rsp), %rsp
	leaq	4704(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$478:
	leaq	32(%rsp), %rsp
	movb	193(%r12), %cl
	leaq	4736(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$477:
	leaq	32(%rsp), %rsp
	leaq	4768(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$476:
	leaq	32(%rsp), %rsp
	leaq	4800(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$475:
	leaq	32(%rsp), %rsp
	leaq	4832(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$474:
	leaq	32(%rsp), %rsp
	movb	194(%r12), %cl
	leaq	4864(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$473:
	leaq	32(%rsp), %rsp
	leaq	4896(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$472:
	leaq	32(%rsp), %rsp
	leaq	4928(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$471:
	leaq	32(%rsp), %rsp
	leaq	4960(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$470:
	leaq	32(%rsp), %rsp
	movb	195(%r12), %cl
	leaq	4992(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$469:
	leaq	32(%rsp), %rsp
	leaq	5024(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$468:
	leaq	32(%rsp), %rsp
	leaq	5056(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$467:
	leaq	32(%rsp), %rsp
	leaq	5088(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$466:
	leaq	32(%rsp), %rsp
	movb	196(%r12), %cl
	leaq	5120(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$465:
	leaq	32(%rsp), %rsp
	leaq	5152(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$464:
	leaq	32(%rsp), %rsp
	leaq	5184(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$463:
	leaq	32(%rsp), %rsp
	leaq	5216(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$462:
	leaq	32(%rsp), %rsp
	movb	197(%r12), %cl
	leaq	5248(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$461:
	leaq	32(%rsp), %rsp
	leaq	5280(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$460:
	leaq	32(%rsp), %rsp
	leaq	5312(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$459:
	leaq	32(%rsp), %rsp
	leaq	5344(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$458:
	leaq	32(%rsp), %rsp
	movb	198(%r12), %cl
	leaq	5376(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$457:
	leaq	32(%rsp), %rsp
	leaq	5408(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$456:
	leaq	32(%rsp), %rsp
	leaq	5440(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$455:
	leaq	32(%rsp), %rsp
	leaq	5472(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$454:
	leaq	32(%rsp), %rsp
	movb	199(%r12), %cl
	leaq	5504(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$453:
	leaq	32(%rsp), %rsp
	leaq	5536(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$452:
	leaq	32(%rsp), %rsp
	leaq	5568(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$451:
	leaq	32(%rsp), %rsp
	leaq	5600(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$450:
	leaq	32(%rsp), %rsp
	movb	200(%r12), %cl
	leaq	5632(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$449:
	leaq	32(%rsp), %rsp
	leaq	5664(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$448:
	leaq	32(%rsp), %rsp
	leaq	5696(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$447:
	leaq	32(%rsp), %rsp
	leaq	5728(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$446:
	leaq	32(%rsp), %rsp
	movb	201(%r12), %cl
	leaq	5760(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$445:
	leaq	32(%rsp), %rsp
	leaq	5792(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$444:
	leaq	32(%rsp), %rsp
	leaq	5824(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$443:
	leaq	32(%rsp), %rsp
	leaq	5856(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$442:
	leaq	32(%rsp), %rsp
	movb	202(%r12), %cl
	leaq	5888(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$441:
	leaq	32(%rsp), %rsp
	leaq	5920(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$440:
	leaq	32(%rsp), %rsp
	leaq	5952(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$439:
	leaq	32(%rsp), %rsp
	leaq	5984(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$438:
	leaq	32(%rsp), %rsp
	movb	203(%r12), %cl
	leaq	6016(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$437:
	leaq	32(%rsp), %rsp
	leaq	6048(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$436:
	leaq	32(%rsp), %rsp
	leaq	6080(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$435:
	leaq	32(%rsp), %rsp
	leaq	6112(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$434:
	leaq	32(%rsp), %rsp
	movb	204(%r12), %cl
	leaq	6144(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$433:
	leaq	32(%rsp), %rsp
	leaq	6176(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$432:
	leaq	32(%rsp), %rsp
	leaq	6208(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$431:
	leaq	32(%rsp), %rsp
	leaq	6240(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$430:
	leaq	32(%rsp), %rsp
	movb	205(%r12), %cl
	leaq	6272(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$429:
	leaq	32(%rsp), %rsp
	leaq	6304(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$428:
	leaq	32(%rsp), %rsp
	leaq	6336(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$427:
	leaq	32(%rsp), %rsp
	leaq	6368(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$426:
	leaq	32(%rsp), %rsp
	movb	206(%r12), %cl
	leaq	6400(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$425:
	leaq	32(%rsp), %rsp
	leaq	6432(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$424:
	leaq	32(%rsp), %rsp
	leaq	6464(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$423:
	leaq	32(%rsp), %rsp
	leaq	6496(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$422:
	leaq	32(%rsp), %rsp
	movb	207(%r12), %cl
	leaq	6528(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$421:
	leaq	32(%rsp), %rsp
	leaq	6560(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$420:
	leaq	32(%rsp), %rsp
	leaq	6592(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$419:
	leaq	32(%rsp), %rsp
	leaq	6624(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$418:
	leaq	32(%rsp), %rsp
	movb	208(%r12), %cl
	leaq	6656(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$417:
	leaq	32(%rsp), %rsp
	leaq	6688(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$416:
	leaq	32(%rsp), %rsp
	leaq	6720(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$415:
	leaq	32(%rsp), %rsp
	leaq	6752(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$414:
	leaq	32(%rsp), %rsp
	movb	209(%r12), %cl
	leaq	6784(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$413:
	leaq	32(%rsp), %rsp
	leaq	6816(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$412:
	leaq	32(%rsp), %rsp
	leaq	6848(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$411:
	leaq	32(%rsp), %rsp
	leaq	6880(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$410:
	leaq	32(%rsp), %rsp
	movb	210(%r12), %cl
	leaq	6912(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$409:
	leaq	32(%rsp), %rsp
	leaq	6944(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$408:
	leaq	32(%rsp), %rsp
	leaq	6976(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$407:
	leaq	32(%rsp), %rsp
	leaq	7008(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$406:
	leaq	32(%rsp), %rsp
	movb	211(%r12), %cl
	leaq	7040(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$405:
	leaq	32(%rsp), %rsp
	leaq	7072(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$404:
	leaq	32(%rsp), %rsp
	leaq	7104(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$403:
	leaq	32(%rsp), %rsp
	leaq	7136(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$402:
	leaq	32(%rsp), %rsp
	movb	212(%r12), %cl
	leaq	7168(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$401:
	leaq	32(%rsp), %rsp
	leaq	7200(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$400:
	leaq	32(%rsp), %rsp
	leaq	7232(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$399:
	leaq	32(%rsp), %rsp
	leaq	7264(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$398:
	leaq	32(%rsp), %rsp
	movb	213(%r12), %cl
	leaq	7296(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$397:
	leaq	32(%rsp), %rsp
	leaq	7328(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$396:
	leaq	32(%rsp), %rsp
	leaq	7360(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$395:
	leaq	32(%rsp), %rsp
	leaq	7392(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$394:
	leaq	32(%rsp), %rsp
	movb	214(%r12), %cl
	leaq	7424(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$393:
	leaq	32(%rsp), %rsp
	leaq	7456(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$392:
	leaq	32(%rsp), %rsp
	leaq	7488(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$391:
	leaq	32(%rsp), %rsp
	leaq	7520(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$390:
	leaq	32(%rsp), %rsp
	movb	215(%r12), %cl
	leaq	7552(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$389:
	leaq	32(%rsp), %rsp
	leaq	7584(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$388:
	leaq	32(%rsp), %rsp
	leaq	7616(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$387:
	leaq	32(%rsp), %rsp
	leaq	7648(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$386:
	leaq	32(%rsp), %rsp
	movb	216(%r12), %cl
	leaq	7680(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$385:
	leaq	32(%rsp), %rsp
	leaq	7712(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$384:
	leaq	32(%rsp), %rsp
	leaq	7744(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$383:
	leaq	32(%rsp), %rsp
	leaq	7776(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$382:
	leaq	32(%rsp), %rsp
	movb	217(%r12), %cl
	leaq	7808(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$381:
	leaq	32(%rsp), %rsp
	leaq	7840(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$380:
	leaq	32(%rsp), %rsp
	leaq	7872(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$379:
	leaq	32(%rsp), %rsp
	leaq	7904(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$378:
	leaq	32(%rsp), %rsp
	movb	218(%r12), %cl
	leaq	7936(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$377:
	leaq	32(%rsp), %rsp
	leaq	7968(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$376:
	leaq	32(%rsp), %rsp
	leaq	8000(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$375:
	leaq	32(%rsp), %rsp
	leaq	8032(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$374:
	leaq	32(%rsp), %rsp
	movb	219(%r12), %cl
	leaq	8064(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$373:
	leaq	32(%rsp), %rsp
	leaq	8096(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$372:
	leaq	32(%rsp), %rsp
	leaq	8128(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$371:
	leaq	32(%rsp), %rsp
	leaq	8160(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$370:
	leaq	32(%rsp), %rsp
	movb	220(%r12), %cl
	leaq	8192(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$369:
	leaq	32(%rsp), %rsp
	leaq	8224(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$368:
	leaq	32(%rsp), %rsp
	leaq	8256(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$367:
	leaq	32(%rsp), %rsp
	leaq	8288(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$366:
	leaq	32(%rsp), %rsp
	movb	221(%r12), %cl
	leaq	8320(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$365:
	leaq	32(%rsp), %rsp
	leaq	8352(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$364:
	leaq	32(%rsp), %rsp
	leaq	8384(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$363:
	leaq	32(%rsp), %rsp
	leaq	8416(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$362:
	leaq	32(%rsp), %rsp
	movb	222(%r12), %cl
	leaq	8448(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$361:
	leaq	32(%rsp), %rsp
	leaq	8480(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$360:
	leaq	32(%rsp), %rsp
	leaq	8512(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$359:
	leaq	32(%rsp), %rsp
	leaq	8544(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$358:
	leaq	32(%rsp), %rsp
	movb	223(%r12), %cl
	leaq	8576(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$357:
	leaq	32(%rsp), %rsp
	leaq	8608(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$356:
	leaq	32(%rsp), %rsp
	leaq	8640(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$355:
	leaq	32(%rsp), %rsp
	leaq	8672(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$354:
	leaq	32(%rsp), %rsp
	movb	224(%r12), %cl
	leaq	8704(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$353:
	leaq	32(%rsp), %rsp
	leaq	8736(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$352:
	leaq	32(%rsp), %rsp
	leaq	8768(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$351:
	leaq	32(%rsp), %rsp
	leaq	8800(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$350:
	leaq	32(%rsp), %rsp
	movb	225(%r12), %cl
	leaq	8832(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$349:
	leaq	32(%rsp), %rsp
	leaq	8864(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$348:
	leaq	32(%rsp), %rsp
	leaq	8896(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$347:
	leaq	32(%rsp), %rsp
	leaq	8928(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$346:
	leaq	32(%rsp), %rsp
	movb	226(%r12), %cl
	leaq	8960(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$345:
	leaq	32(%rsp), %rsp
	leaq	8992(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$344:
	leaq	32(%rsp), %rsp
	leaq	9024(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$343:
	leaq	32(%rsp), %rsp
	leaq	9056(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$342:
	leaq	32(%rsp), %rsp
	movb	227(%r12), %cl
	leaq	9088(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$341:
	leaq	32(%rsp), %rsp
	leaq	9120(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$340:
	leaq	32(%rsp), %rsp
	leaq	9152(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$339:
	leaq	32(%rsp), %rsp
	leaq	9184(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$338:
	leaq	32(%rsp), %rsp
	movb	228(%r12), %cl
	leaq	9216(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$337:
	leaq	32(%rsp), %rsp
	leaq	9248(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$336:
	leaq	32(%rsp), %rsp
	leaq	9280(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$335:
	leaq	32(%rsp), %rsp
	leaq	9312(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$334:
	leaq	32(%rsp), %rsp
	movb	229(%r12), %cl
	leaq	9344(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$333:
	leaq	32(%rsp), %rsp
	leaq	9376(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$332:
	leaq	32(%rsp), %rsp
	leaq	9408(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$331:
	leaq	32(%rsp), %rsp
	leaq	9440(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$330:
	leaq	32(%rsp), %rsp
	movb	230(%r12), %cl
	leaq	9472(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$329:
	leaq	32(%rsp), %rsp
	leaq	9504(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$328:
	leaq	32(%rsp), %rsp
	leaq	9536(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$327:
	leaq	32(%rsp), %rsp
	leaq	9568(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$326:
	leaq	32(%rsp), %rsp
	movb	231(%r12), %cl
	leaq	9600(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$325:
	leaq	32(%rsp), %rsp
	leaq	9632(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$324:
	leaq	32(%rsp), %rsp
	leaq	9664(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$323:
	leaq	32(%rsp), %rsp
	leaq	9696(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$322:
	leaq	32(%rsp), %rsp
	movb	232(%r12), %cl
	leaq	9728(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$321:
	leaq	32(%rsp), %rsp
	leaq	9760(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$320:
	leaq	32(%rsp), %rsp
	leaq	9792(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$319:
	leaq	32(%rsp), %rsp
	leaq	9824(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$318:
	leaq	32(%rsp), %rsp
	movb	233(%r12), %cl
	leaq	9856(%r14), %rax
	leaq	256(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$317:
	leaq	32(%rsp), %rsp
	leaq	9888(%r14), %rax
	leaq	288(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$316:
	leaq	32(%rsp), %rsp
	leaq	9920(%r14), %rax
	leaq	320(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$315:
	leaq	32(%rsp), %rsp
	leaq	9952(%r14), %rax
	leaq	352(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$314:
	leaq	32(%rsp), %rsp
	movb	234(%r12), %cl
	movq	%r14, %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$313:
	leaq	32(%rsp), %rsp
	leaq	32(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$312:
	leaq	32(%rsp), %rsp
	leaq	64(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$311:
	leaq	32(%rsp), %rsp
	leaq	96(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$310:
	leaq	32(%rsp), %rsp
	movb	235(%r12), %cl
	leaq	128(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$309:
	leaq	32(%rsp), %rsp
	leaq	160(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$308:
	leaq	32(%rsp), %rsp
	leaq	192(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$307:
	leaq	32(%rsp), %rsp
	leaq	224(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$306:
	leaq	32(%rsp), %rsp
	movb	236(%r12), %cl
	leaq	256(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$305:
	leaq	32(%rsp), %rsp
	leaq	288(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$304:
	leaq	32(%rsp), %rsp
	leaq	320(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$303:
	leaq	32(%rsp), %rsp
	leaq	352(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$302:
	leaq	32(%rsp), %rsp
	movb	237(%r12), %cl
	leaq	384(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$301:
	leaq	32(%rsp), %rsp
	leaq	416(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$300:
	leaq	32(%rsp), %rsp
	leaq	448(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$299:
	leaq	32(%rsp), %rsp
	leaq	480(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$298:
	leaq	32(%rsp), %rsp
	movb	238(%r12), %cl
	leaq	512(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$297:
	leaq	32(%rsp), %rsp
	leaq	544(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$296:
	leaq	32(%rsp), %rsp
	leaq	576(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$295:
	leaq	32(%rsp), %rsp
	leaq	608(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$294:
	leaq	32(%rsp), %rsp
	movb	239(%r12), %cl
	leaq	640(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$293:
	leaq	32(%rsp), %rsp
	leaq	672(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$292:
	leaq	32(%rsp), %rsp
	leaq	704(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$291:
	leaq	32(%rsp), %rsp
	leaq	736(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$290:
	leaq	32(%rsp), %rsp
	movb	240(%r12), %cl
	leaq	768(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$289:
	leaq	32(%rsp), %rsp
	leaq	800(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$288:
	leaq	32(%rsp), %rsp
	leaq	832(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$287:
	leaq	32(%rsp), %rsp
	leaq	864(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$286:
	leaq	32(%rsp), %rsp
	movb	241(%r12), %cl
	leaq	896(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$285:
	leaq	32(%rsp), %rsp
	leaq	928(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$284:
	leaq	32(%rsp), %rsp
	leaq	960(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$283:
	leaq	32(%rsp), %rsp
	leaq	992(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$282:
	leaq	32(%rsp), %rsp
	movb	242(%r12), %cl
	leaq	1024(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$281:
	leaq	32(%rsp), %rsp
	leaq	1056(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$280:
	leaq	32(%rsp), %rsp
	leaq	1088(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$279:
	leaq	32(%rsp), %rsp
	leaq	1120(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$278:
	leaq	32(%rsp), %rsp
	movb	243(%r12), %cl
	leaq	1152(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$277:
	leaq	32(%rsp), %rsp
	leaq	1184(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$276:
	leaq	32(%rsp), %rsp
	leaq	1216(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$275:
	leaq	32(%rsp), %rsp
	leaq	1248(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$274:
	leaq	32(%rsp), %rsp
	movb	244(%r12), %cl
	leaq	1280(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$273:
	leaq	32(%rsp), %rsp
	leaq	1312(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$272:
	leaq	32(%rsp), %rsp
	leaq	1344(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$271:
	leaq	32(%rsp), %rsp
	leaq	1376(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$270:
	leaq	32(%rsp), %rsp
	movb	245(%r12), %cl
	leaq	1408(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$269:
	leaq	32(%rsp), %rsp
	leaq	1440(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$268:
	leaq	32(%rsp), %rsp
	leaq	1472(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$267:
	leaq	32(%rsp), %rsp
	leaq	1504(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$266:
	leaq	32(%rsp), %rsp
	movb	246(%r12), %cl
	leaq	1536(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$265:
	leaq	32(%rsp), %rsp
	leaq	1568(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$264:
	leaq	32(%rsp), %rsp
	leaq	1600(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$263:
	leaq	32(%rsp), %rsp
	leaq	1632(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$262:
	leaq	32(%rsp), %rsp
	movb	247(%r12), %cl
	leaq	1664(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$261:
	leaq	32(%rsp), %rsp
	leaq	1696(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$260:
	leaq	32(%rsp), %rsp
	leaq	1728(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$259:
	leaq	32(%rsp), %rsp
	leaq	1760(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$258:
	leaq	32(%rsp), %rsp
	movb	248(%r12), %cl
	leaq	1792(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$257:
	leaq	32(%rsp), %rsp
	leaq	1824(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$256:
	leaq	32(%rsp), %rsp
	leaq	1856(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$255:
	leaq	32(%rsp), %rsp
	leaq	1888(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$254:
	leaq	32(%rsp), %rsp
	movb	249(%r12), %cl
	leaq	1920(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$253:
	leaq	32(%rsp), %rsp
	leaq	1952(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$252:
	leaq	32(%rsp), %rsp
	leaq	1984(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$251:
	leaq	32(%rsp), %rsp
	leaq	2016(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$250:
	leaq	32(%rsp), %rsp
	movb	250(%r12), %cl
	leaq	2048(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$249:
	leaq	32(%rsp), %rsp
	leaq	2080(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$248:
	leaq	32(%rsp), %rsp
	leaq	2112(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$247:
	leaq	32(%rsp), %rsp
	leaq	2144(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$246:
	leaq	32(%rsp), %rsp
	movb	251(%r12), %cl
	leaq	2176(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$245:
	leaq	32(%rsp), %rsp
	leaq	2208(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$244:
	leaq	32(%rsp), %rsp
	leaq	2240(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$243:
	leaq	32(%rsp), %rsp
	leaq	2272(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$242:
	leaq	32(%rsp), %rsp
	movb	252(%r12), %cl
	leaq	2304(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$241:
	leaq	32(%rsp), %rsp
	leaq	2336(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$240:
	leaq	32(%rsp), %rsp
	leaq	2368(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$239:
	leaq	32(%rsp), %rsp
	leaq	2400(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$238:
	leaq	32(%rsp), %rsp
	movb	253(%r12), %cl
	leaq	2432(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$237:
	leaq	32(%rsp), %rsp
	leaq	2464(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$236:
	leaq	32(%rsp), %rsp
	leaq	2496(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$235:
	leaq	32(%rsp), %rsp
	leaq	2528(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$234:
	leaq	32(%rsp), %rsp
	movb	254(%r12), %cl
	leaq	2560(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$233:
	leaq	32(%rsp), %rsp
	leaq	2592(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$232:
	leaq	32(%rsp), %rsp
	leaq	2624(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$231:
	leaq	32(%rsp), %rsp
	leaq	2656(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$230:
	leaq	32(%rsp), %rsp
	movb	255(%r12), %cl
	leaq	2688(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$229:
	leaq	32(%rsp), %rsp
	leaq	2720(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$228:
	leaq	32(%rsp), %rsp
	leaq	2752(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$227:
	leaq	32(%rsp), %rsp
	leaq	2784(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$226:
	leaq	32(%rsp), %rsp
	movb	256(%r12), %cl
	leaq	2816(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$225:
	leaq	32(%rsp), %rsp
	leaq	2848(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$224:
	leaq	32(%rsp), %rsp
	leaq	2880(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$223:
	leaq	32(%rsp), %rsp
	leaq	2912(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$222:
	leaq	32(%rsp), %rsp
	movb	257(%r12), %cl
	leaq	2944(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$221:
	leaq	32(%rsp), %rsp
	leaq	2976(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$220:
	leaq	32(%rsp), %rsp
	leaq	3008(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$219:
	leaq	32(%rsp), %rsp
	leaq	3040(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$218:
	leaq	32(%rsp), %rsp
	movb	258(%r12), %cl
	leaq	3072(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$217:
	leaq	32(%rsp), %rsp
	leaq	3104(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$216:
	leaq	32(%rsp), %rsp
	leaq	3136(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$215:
	leaq	32(%rsp), %rsp
	leaq	3168(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$214:
	leaq	32(%rsp), %rsp
	movb	259(%r12), %cl
	leaq	3200(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$213:
	leaq	32(%rsp), %rsp
	leaq	3232(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$212:
	leaq	32(%rsp), %rsp
	leaq	3264(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$211:
	leaq	32(%rsp), %rsp
	leaq	3296(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$210:
	leaq	32(%rsp), %rsp
	movb	260(%r12), %cl
	leaq	3328(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$209:
	leaq	32(%rsp), %rsp
	leaq	3360(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$208:
	leaq	32(%rsp), %rsp
	leaq	3392(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$207:
	leaq	32(%rsp), %rsp
	leaq	3424(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$206:
	leaq	32(%rsp), %rsp
	movb	261(%r12), %cl
	leaq	3456(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$205:
	leaq	32(%rsp), %rsp
	leaq	3488(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$204:
	leaq	32(%rsp), %rsp
	leaq	3520(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$203:
	leaq	32(%rsp), %rsp
	leaq	3552(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$202:
	leaq	32(%rsp), %rsp
	movb	262(%r12), %cl
	leaq	3584(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$201:
	leaq	32(%rsp), %rsp
	leaq	3616(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$200:
	leaq	32(%rsp), %rsp
	leaq	3648(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$199:
	leaq	32(%rsp), %rsp
	leaq	3680(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$198:
	leaq	32(%rsp), %rsp
	movb	263(%r12), %cl
	leaq	3712(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$197:
	leaq	32(%rsp), %rsp
	leaq	3744(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$196:
	leaq	32(%rsp), %rsp
	leaq	3776(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$195:
	leaq	32(%rsp), %rsp
	leaq	3808(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$194:
	leaq	32(%rsp), %rsp
	movb	264(%r12), %cl
	leaq	3840(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$193:
	leaq	32(%rsp), %rsp
	leaq	3872(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$192:
	leaq	32(%rsp), %rsp
	leaq	3904(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$191:
	leaq	32(%rsp), %rsp
	leaq	3936(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$190:
	leaq	32(%rsp), %rsp
	movb	265(%r12), %cl
	leaq	3968(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$189:
	leaq	32(%rsp), %rsp
	leaq	4000(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$188:
	leaq	32(%rsp), %rsp
	leaq	4032(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$187:
	leaq	32(%rsp), %rsp
	leaq	4064(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$186:
	leaq	32(%rsp), %rsp
	movb	266(%r12), %cl
	leaq	4096(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$185:
	leaq	32(%rsp), %rsp
	leaq	4128(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$184:
	leaq	32(%rsp), %rsp
	leaq	4160(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$183:
	leaq	32(%rsp), %rsp
	leaq	4192(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$182:
	leaq	32(%rsp), %rsp
	movb	267(%r12), %cl
	leaq	4224(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$181:
	leaq	32(%rsp), %rsp
	leaq	4256(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$180:
	leaq	32(%rsp), %rsp
	leaq	4288(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$179:
	leaq	32(%rsp), %rsp
	leaq	4320(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$178:
	leaq	32(%rsp), %rsp
	movb	268(%r12), %cl
	leaq	4352(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$177:
	leaq	32(%rsp), %rsp
	leaq	4384(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$176:
	leaq	32(%rsp), %rsp
	leaq	4416(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$175:
	leaq	32(%rsp), %rsp
	leaq	4448(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$174:
	leaq	32(%rsp), %rsp
	movb	269(%r12), %cl
	leaq	4480(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$173:
	leaq	32(%rsp), %rsp
	leaq	4512(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$172:
	leaq	32(%rsp), %rsp
	leaq	4544(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$171:
	leaq	32(%rsp), %rsp
	leaq	4576(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$170:
	leaq	32(%rsp), %rsp
	movb	270(%r12), %cl
	leaq	4608(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$169:
	leaq	32(%rsp), %rsp
	leaq	4640(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$168:
	leaq	32(%rsp), %rsp
	leaq	4672(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$167:
	leaq	32(%rsp), %rsp
	leaq	4704(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$166:
	leaq	32(%rsp), %rsp
	movb	271(%r12), %cl
	leaq	4736(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$165:
	leaq	32(%rsp), %rsp
	leaq	4768(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$164:
	leaq	32(%rsp), %rsp
	leaq	4800(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$163:
	leaq	32(%rsp), %rsp
	leaq	4832(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$162:
	leaq	32(%rsp), %rsp
	movb	272(%r12), %cl
	leaq	4864(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$161:
	leaq	32(%rsp), %rsp
	leaq	4896(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$160:
	leaq	32(%rsp), %rsp
	leaq	4928(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$159:
	leaq	32(%rsp), %rsp
	leaq	4960(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$158:
	leaq	32(%rsp), %rsp
	movb	273(%r12), %cl
	leaq	4992(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$157:
	leaq	32(%rsp), %rsp
	leaq	5024(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$156:
	leaq	32(%rsp), %rsp
	leaq	5056(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$155:
	leaq	32(%rsp), %rsp
	leaq	5088(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$154:
	leaq	32(%rsp), %rsp
	movb	274(%r12), %cl
	leaq	5120(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$153:
	leaq	32(%rsp), %rsp
	leaq	5152(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$152:
	leaq	32(%rsp), %rsp
	leaq	5184(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$151:
	leaq	32(%rsp), %rsp
	leaq	5216(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$150:
	leaq	32(%rsp), %rsp
	movb	275(%r12), %cl
	leaq	5248(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$149:
	leaq	32(%rsp), %rsp
	leaq	5280(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$148:
	leaq	32(%rsp), %rsp
	leaq	5312(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$147:
	leaq	32(%rsp), %rsp
	leaq	5344(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$146:
	leaq	32(%rsp), %rsp
	movb	276(%r12), %cl
	leaq	5376(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$145:
	leaq	32(%rsp), %rsp
	leaq	5408(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$144:
	leaq	32(%rsp), %rsp
	leaq	5440(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$143:
	leaq	32(%rsp), %rsp
	leaq	5472(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$142:
	leaq	32(%rsp), %rsp
	movb	277(%r12), %cl
	leaq	5504(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$141:
	leaq	32(%rsp), %rsp
	leaq	5536(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$140:
	leaq	32(%rsp), %rsp
	leaq	5568(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$139:
	leaq	32(%rsp), %rsp
	leaq	5600(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$138:
	leaq	32(%rsp), %rsp
	movb	278(%r12), %cl
	leaq	5632(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$137:
	leaq	32(%rsp), %rsp
	leaq	5664(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$136:
	leaq	32(%rsp), %rsp
	leaq	5696(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$135:
	leaq	32(%rsp), %rsp
	leaq	5728(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$134:
	leaq	32(%rsp), %rsp
	movb	279(%r12), %cl
	leaq	5760(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$133:
	leaq	32(%rsp), %rsp
	leaq	5792(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$132:
	leaq	32(%rsp), %rsp
	leaq	5824(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$131:
	leaq	32(%rsp), %rsp
	leaq	5856(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$130:
	leaq	32(%rsp), %rsp
	movb	280(%r12), %cl
	leaq	5888(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$129:
	leaq	32(%rsp), %rsp
	leaq	5920(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$128:
	leaq	32(%rsp), %rsp
	leaq	5952(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$127:
	leaq	32(%rsp), %rsp
	leaq	5984(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$126:
	leaq	32(%rsp), %rsp
	movb	281(%r12), %cl
	leaq	6016(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$125:
	leaq	32(%rsp), %rsp
	leaq	6048(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$124:
	leaq	32(%rsp), %rsp
	leaq	6080(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$123:
	leaq	32(%rsp), %rsp
	leaq	6112(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$122:
	leaq	32(%rsp), %rsp
	movb	282(%r12), %cl
	leaq	6144(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$121:
	leaq	32(%rsp), %rsp
	leaq	6176(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$120:
	leaq	32(%rsp), %rsp
	leaq	6208(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$119:
	leaq	32(%rsp), %rsp
	leaq	6240(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$118:
	leaq	32(%rsp), %rsp
	movb	283(%r12), %cl
	leaq	6272(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$117:
	leaq	32(%rsp), %rsp
	leaq	6304(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$116:
	leaq	32(%rsp), %rsp
	leaq	6336(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$115:
	leaq	32(%rsp), %rsp
	leaq	6368(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$114:
	leaq	32(%rsp), %rsp
	movb	284(%r12), %cl
	leaq	6400(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$113:
	leaq	32(%rsp), %rsp
	leaq	6432(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$112:
	leaq	32(%rsp), %rsp
	leaq	6464(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$111:
	leaq	32(%rsp), %rsp
	leaq	6496(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$110:
	leaq	32(%rsp), %rsp
	movb	285(%r12), %cl
	leaq	6528(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$109:
	leaq	32(%rsp), %rsp
	leaq	6560(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$108:
	leaq	32(%rsp), %rsp
	leaq	6592(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$107:
	leaq	32(%rsp), %rsp
	leaq	6624(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$106:
	leaq	32(%rsp), %rsp
	movb	286(%r12), %cl
	leaq	6656(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$105:
	leaq	32(%rsp), %rsp
	leaq	6688(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$104:
	leaq	32(%rsp), %rsp
	leaq	6720(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$103:
	leaq	32(%rsp), %rsp
	leaq	6752(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$102:
	leaq	32(%rsp), %rsp
	movb	287(%r12), %cl
	leaq	6784(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$101:
	leaq	32(%rsp), %rsp
	leaq	6816(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$100:
	leaq	32(%rsp), %rsp
	leaq	6848(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$99:
	leaq	32(%rsp), %rsp
	leaq	6880(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$98:
	leaq	32(%rsp), %rsp
	movb	288(%r12), %cl
	leaq	6912(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$97:
	leaq	32(%rsp), %rsp
	leaq	6944(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$96:
	leaq	32(%rsp), %rsp
	leaq	6976(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$95:
	leaq	32(%rsp), %rsp
	leaq	7008(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$94:
	leaq	32(%rsp), %rsp
	movb	289(%r12), %cl
	leaq	7040(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$93:
	leaq	32(%rsp), %rsp
	leaq	7072(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$92:
	leaq	32(%rsp), %rsp
	leaq	7104(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$91:
	leaq	32(%rsp), %rsp
	leaq	7136(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$90:
	leaq	32(%rsp), %rsp
	movb	290(%r12), %cl
	leaq	7168(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$89:
	leaq	32(%rsp), %rsp
	leaq	7200(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$88:
	leaq	32(%rsp), %rsp
	leaq	7232(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$87:
	leaq	32(%rsp), %rsp
	leaq	7264(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$86:
	leaq	32(%rsp), %rsp
	movb	291(%r12), %cl
	leaq	7296(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$85:
	leaq	32(%rsp), %rsp
	leaq	7328(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$84:
	leaq	32(%rsp), %rsp
	leaq	7360(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$83:
	leaq	32(%rsp), %rsp
	leaq	7392(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$82:
	leaq	32(%rsp), %rsp
	movb	292(%r12), %cl
	leaq	7424(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$81:
	leaq	32(%rsp), %rsp
	leaq	7456(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$80:
	leaq	32(%rsp), %rsp
	leaq	7488(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$79:
	leaq	32(%rsp), %rsp
	leaq	7520(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$78:
	leaq	32(%rsp), %rsp
	movb	293(%r12), %cl
	leaq	7552(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$77:
	leaq	32(%rsp), %rsp
	leaq	7584(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$76:
	leaq	32(%rsp), %rsp
	leaq	7616(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$75:
	leaq	32(%rsp), %rsp
	leaq	7648(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$74:
	leaq	32(%rsp), %rsp
	movb	294(%r12), %cl
	leaq	7680(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$73:
	leaq	32(%rsp), %rsp
	leaq	7712(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$72:
	leaq	32(%rsp), %rsp
	leaq	7744(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$71:
	leaq	32(%rsp), %rsp
	leaq	7776(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$70:
	leaq	32(%rsp), %rsp
	movb	295(%r12), %cl
	leaq	7808(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$69:
	leaq	32(%rsp), %rsp
	leaq	7840(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$68:
	leaq	32(%rsp), %rsp
	leaq	7872(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$67:
	leaq	32(%rsp), %rsp
	leaq	7904(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$66:
	leaq	32(%rsp), %rsp
	movb	296(%r12), %cl
	leaq	7936(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$65:
	leaq	32(%rsp), %rsp
	leaq	7968(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$64:
	leaq	32(%rsp), %rsp
	leaq	8000(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$63:
	leaq	32(%rsp), %rsp
	leaq	8032(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$62:
	leaq	32(%rsp), %rsp
	movb	297(%r12), %cl
	leaq	8064(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$61:
	leaq	32(%rsp), %rsp
	leaq	8096(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$60:
	leaq	32(%rsp), %rsp
	leaq	8128(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$59:
	leaq	32(%rsp), %rsp
	leaq	8160(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$58:
	leaq	32(%rsp), %rsp
	movb	298(%r12), %cl
	leaq	8192(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$57:
	leaq	32(%rsp), %rsp
	leaq	8224(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$56:
	leaq	32(%rsp), %rsp
	leaq	8256(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$55:
	leaq	32(%rsp), %rsp
	leaq	8288(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$54:
	leaq	32(%rsp), %rsp
	movb	299(%r12), %cl
	leaq	8320(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$53:
	leaq	32(%rsp), %rsp
	leaq	8352(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$52:
	leaq	32(%rsp), %rsp
	leaq	8384(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$51:
	leaq	32(%rsp), %rsp
	leaq	8416(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$50:
	leaq	32(%rsp), %rsp
	movb	300(%r12), %cl
	leaq	8448(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$49:
	leaq	32(%rsp), %rsp
	leaq	8480(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$48:
	leaq	32(%rsp), %rsp
	leaq	8512(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$47:
	leaq	32(%rsp), %rsp
	leaq	8544(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$46:
	leaq	32(%rsp), %rsp
	movb	301(%r12), %cl
	leaq	8576(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$45:
	leaq	32(%rsp), %rsp
	leaq	8608(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$44:
	leaq	32(%rsp), %rsp
	leaq	8640(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$43:
	leaq	32(%rsp), %rsp
	leaq	8672(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$42:
	leaq	32(%rsp), %rsp
	movb	302(%r12), %cl
	leaq	8704(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$41:
	leaq	32(%rsp), %rsp
	leaq	8736(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$40:
	leaq	32(%rsp), %rsp
	leaq	8768(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$39:
	leaq	32(%rsp), %rsp
	leaq	8800(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$38:
	leaq	32(%rsp), %rsp
	movb	303(%r12), %cl
	leaq	8832(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$37:
	leaq	32(%rsp), %rsp
	leaq	8864(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$36:
	leaq	32(%rsp), %rsp
	leaq	8896(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$35:
	leaq	32(%rsp), %rsp
	leaq	8928(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$34:
	leaq	32(%rsp), %rsp
	movb	304(%r12), %cl
	leaq	8960(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$33:
	leaq	32(%rsp), %rsp
	leaq	8992(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$32:
	leaq	32(%rsp), %rsp
	leaq	9024(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$31:
	leaq	32(%rsp), %rsp
	leaq	9056(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$30:
	leaq	32(%rsp), %rsp
	movb	305(%r12), %cl
	leaq	9088(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$29:
	leaq	32(%rsp), %rsp
	leaq	9120(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$28:
	leaq	32(%rsp), %rsp
	leaq	9152(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$27:
	leaq	32(%rsp), %rsp
	leaq	9184(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$26:
	leaq	32(%rsp), %rsp
	movb	306(%r12), %cl
	leaq	9216(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$25:
	leaq	32(%rsp), %rsp
	leaq	9248(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$24:
	leaq	32(%rsp), %rsp
	leaq	9280(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$23:
	leaq	32(%rsp), %rsp
	leaq	9312(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$22:
	leaq	32(%rsp), %rsp
	movb	307(%r12), %cl
	leaq	9344(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$21:
	leaq	32(%rsp), %rsp
	leaq	9376(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$20:
	leaq	32(%rsp), %rsp
	leaq	9408(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$19:
	leaq	32(%rsp), %rsp
	leaq	9440(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$18:
	leaq	32(%rsp), %rsp
	movb	308(%r12), %cl
	leaq	9472(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$17:
	leaq	32(%rsp), %rsp
	leaq	9504(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$16:
	leaq	32(%rsp), %rsp
	leaq	9536(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$15:
	leaq	32(%rsp), %rsp
	leaq	9568(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$14:
	leaq	32(%rsp), %rsp
	movb	309(%r12), %cl
	leaq	9600(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$13:
	leaq	32(%rsp), %rsp
	leaq	9632(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$12:
	leaq	32(%rsp), %rsp
	leaq	9664(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$11:
	leaq	32(%rsp), %rsp
	leaq	9696(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$10:
	leaq	32(%rsp), %rsp
	movb	310(%r12), %cl
	leaq	9728(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$9:
	leaq	32(%rsp), %rsp
	leaq	9760(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$8:
	leaq	32(%rsp), %rsp
	leaq	9792(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$7:
	leaq	32(%rsp), %rsp
	leaq	9824(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$6:
	leaq	32(%rsp), %rsp
	movb	311(%r12), %cl
	leaq	9856(%r14), %rax
	leaq	384(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$5:
	leaq	32(%rsp), %rsp
	leaq	9888(%r14), %rax
	leaq	416(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$4:
	leaq	32(%rsp), %rsp
	leaq	9920(%r14), %rax
	leaq	448(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$3:
	leaq	32(%rsp), %rsp
	leaq	9952(%r14), %rax
	leaq	480(%r13), %rsi
	movzbl	%cl, %edx
	leaq	-32(%rsp), %rsp
	call	Lbitsliced_m_vec_mul_add_2$1
Lmul_add_mat_x_bitsliced_m_mat_ver$2:
	leaq	32(%rsp), %rsp
	ret
Lbitsliced_m_calculate_PS$1:
	movq	$0, %rax
	jmp 	Lbitsliced_m_calculate_PS$5102
Lbitsliced_m_calculate_PS$5103:
	movl	$0, 8(%rsp,%rax,4)
	leaq	1(%rax), %rax
Lbitsliced_m_calculate_PS$5102:
	cmpq	$39936, %rax
	jb  	Lbitsliced_m_calculate_PS$5103
	movq	$0, %r8
	movq	$0, %rdx
	jmp 	Lbitsliced_m_calculate_PS$5096
Lbitsliced_m_calculate_PS$5097:
	movzbq	(%r11,%rdx), %rax
	movq	$0, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$5101:
	movzbq	78(%r11,%rdx), %rax
	movq	$16, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$5100:
	movzbq	156(%r11,%rdx), %rax
	movq	$32, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$5099:
	movzbq	234(%r11,%rdx), %rax
	movq	$48, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$5098:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$5096:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$5097
	movzbq	60(%r11), %rax
	movq	$0, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$0, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5095:
	movzbq	138(%r11), %rax
	movq	$16, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$0, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5094:
	movzbq	216(%r11), %rax
	movq	$32, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$0, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5093:
	movzbq	294(%r11), %rax
	movq	$48, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$0, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5092:
	movzbq	61(%r11), %rax
	movq	$0, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5091:
	movzbq	139(%r11), %rax
	movq	$16, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5090:
	movzbq	217(%r11), %rax
	movq	$32, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5089:
	movzbq	295(%r11), %rax
	movq	$48, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5088:
	movzbq	62(%r11), %rax
	movq	$0, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$2, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5087:
	movzbq	140(%r11), %rax
	movq	$16, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$2, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5086:
	movzbq	218(%r11), %rax
	movq	$32, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$2, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5085:
	movzbq	296(%r11), %rax
	movq	$48, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$2, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5084:
	movzbq	63(%r11), %rax
	movq	$0, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$3, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5083:
	movzbq	141(%r11), %rax
	movq	$16, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$3, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5082:
	movzbq	219(%r11), %rax
	movq	$32, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$3, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5081:
	movzbq	297(%r11), %rax
	movq	$48, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$3, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5080:
	movzbq	64(%r11), %rax
	movq	$0, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$4, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5079:
	movzbq	142(%r11), %rax
	movq	$16, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$4, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5078:
	movzbq	220(%r11), %rax
	movq	$32, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$4, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5077:
	movzbq	298(%r11), %rax
	movq	$48, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$4, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5076:
	movzbq	65(%r11), %rax
	movq	$0, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$5, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5075:
	movzbq	143(%r11), %rax
	movq	$16, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$5, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5074:
	movzbq	221(%r11), %rax
	movq	$32, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$5, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5073:
	movzbq	299(%r11), %rax
	movq	$48, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$5, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5072:
	movzbq	66(%r11), %rax
	movq	$0, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$6, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5071:
	movzbq	144(%r11), %rax
	movq	$16, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$6, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5070:
	movzbq	222(%r11), %rax
	movq	$32, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$6, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5069:
	movzbq	300(%r11), %rax
	movq	$48, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$6, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5068:
	movzbq	67(%r11), %rax
	movq	$0, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$7, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5067:
	movzbq	145(%r11), %rax
	movq	$16, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$7, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5066:
	movzbq	223(%r11), %rax
	movq	$32, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$7, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5065:
	movzbq	301(%r11), %rax
	movq	$48, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$7, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5064:
	movzbq	68(%r11), %rax
	movq	$0, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$8, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5063:
	movzbq	146(%r11), %rax
	movq	$16, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$8, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5062:
	movzbq	224(%r11), %rax
	movq	$32, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$8, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5061:
	movzbq	302(%r11), %rax
	movq	$48, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$8, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5060:
	movzbq	69(%r11), %rax
	movq	$0, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$9, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5059:
	movzbq	147(%r11), %rax
	movq	$16, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$9, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5058:
	movzbq	225(%r11), %rax
	movq	$32, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$9, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5057:
	movzbq	303(%r11), %rax
	movq	$48, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$9, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5056:
	movzbq	70(%r11), %rax
	movq	$0, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$10, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5055:
	movzbq	148(%r11), %rax
	movq	$16, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$10, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5054:
	movzbq	226(%r11), %rax
	movq	$32, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$10, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5053:
	movzbq	304(%r11), %rax
	movq	$48, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$10, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5052:
	movzbq	71(%r11), %rax
	movq	$0, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$11, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5051:
	movzbq	149(%r11), %rax
	movq	$16, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$11, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5050:
	movzbq	227(%r11), %rax
	movq	$32, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$11, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5049:
	movzbq	305(%r11), %rax
	movq	$48, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$11, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5048:
	movzbq	72(%r11), %rax
	movq	$0, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$12, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5047:
	movzbq	150(%r11), %rax
	movq	$16, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$12, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5046:
	movzbq	228(%r11), %rax
	movq	$32, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$12, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5045:
	movzbq	306(%r11), %rax
	movq	$48, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$12, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5044:
	movzbq	73(%r11), %rax
	movq	$0, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$13, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5043:
	movzbq	151(%r11), %rax
	movq	$16, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$13, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5042:
	movzbq	229(%r11), %rax
	movq	$32, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$13, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5041:
	movzbq	307(%r11), %rax
	movq	$48, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$13, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5040:
	movzbq	74(%r11), %rax
	movq	$0, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$14, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5039:
	movzbq	152(%r11), %rax
	movq	$16, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$14, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5038:
	movzbq	230(%r11), %rax
	movq	$32, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$14, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5037:
	movzbq	308(%r11), %rax
	movq	$48, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$14, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5036:
	movzbq	75(%r11), %rax
	movq	$0, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$15, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5035:
	movzbq	153(%r11), %rax
	movq	$16, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$15, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5034:
	movzbq	231(%r11), %rax
	movq	$32, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$15, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5033:
	movzbq	309(%r11), %rax
	movq	$48, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$15, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5032:
	movzbq	76(%r11), %rax
	movq	$0, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$16, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5031:
	movzbq	154(%r11), %rax
	movq	$16, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$16, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5030:
	movzbq	232(%r11), %rax
	movq	$32, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$16, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5029:
	movzbq	310(%r11), %rax
	movq	$48, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$16, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5028:
	movzbq	77(%r11), %rax
	movq	$0, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$17, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5027:
	movzbq	155(%r11), %rax
	movq	$16, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$17, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5026:
	movzbq	233(%r11), %rax
	movq	$32, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$17, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5025:
	movzbq	311(%r11), %rax
	movq	$48, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$17, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5024:
	movq	$1, %rdx
	jmp 	Lbitsliced_m_calculate_PS$5018
Lbitsliced_m_calculate_PS$5019:
	movzbq	(%r11,%rdx), %rax
	movq	$64, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$5023:
	movzbq	78(%r11,%rdx), %rax
	movq	$80, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$5022:
	movzbq	156(%r11,%rdx), %rax
	movq	$96, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$5021:
	movzbq	234(%r11,%rdx), %rax
	movq	$112, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$5020:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$5018:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$5019
	movzbq	60(%r11), %rax
	movq	$64, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$18, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5017:
	movzbq	138(%r11), %rax
	movq	$80, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$18, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5016:
	movzbq	216(%r11), %rax
	movq	$96, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$18, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5015:
	movzbq	294(%r11), %rax
	movq	$112, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$18, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5014:
	movzbq	61(%r11), %rax
	movq	$64, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$19, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5013:
	movzbq	139(%r11), %rax
	movq	$80, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$19, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5012:
	movzbq	217(%r11), %rax
	movq	$96, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$19, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5011:
	movzbq	295(%r11), %rax
	movq	$112, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$19, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5010:
	movzbq	62(%r11), %rax
	movq	$64, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$20, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5009:
	movzbq	140(%r11), %rax
	movq	$80, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$20, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5008:
	movzbq	218(%r11), %rax
	movq	$96, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$20, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5007:
	movzbq	296(%r11), %rax
	movq	$112, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$20, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5006:
	movzbq	63(%r11), %rax
	movq	$64, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$21, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5005:
	movzbq	141(%r11), %rax
	movq	$80, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$21, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5004:
	movzbq	219(%r11), %rax
	movq	$96, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$21, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5003:
	movzbq	297(%r11), %rax
	movq	$112, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$21, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5002:
	movzbq	64(%r11), %rax
	movq	$64, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$22, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5001:
	movzbq	142(%r11), %rax
	movq	$80, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$22, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$5000:
	movzbq	220(%r11), %rax
	movq	$96, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$22, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4999:
	movzbq	298(%r11), %rax
	movq	$112, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$22, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4998:
	movzbq	65(%r11), %rax
	movq	$64, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$23, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4997:
	movzbq	143(%r11), %rax
	movq	$80, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$23, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4996:
	movzbq	221(%r11), %rax
	movq	$96, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$23, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4995:
	movzbq	299(%r11), %rax
	movq	$112, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$23, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4994:
	movzbq	66(%r11), %rax
	movq	$64, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$24, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4993:
	movzbq	144(%r11), %rax
	movq	$80, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$24, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4992:
	movzbq	222(%r11), %rax
	movq	$96, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$24, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4991:
	movzbq	300(%r11), %rax
	movq	$112, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$24, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4990:
	movzbq	67(%r11), %rax
	movq	$64, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$25, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4989:
	movzbq	145(%r11), %rax
	movq	$80, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$25, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4988:
	movzbq	223(%r11), %rax
	movq	$96, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$25, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4987:
	movzbq	301(%r11), %rax
	movq	$112, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$25, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4986:
	movzbq	68(%r11), %rax
	movq	$64, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$26, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4985:
	movzbq	146(%r11), %rax
	movq	$80, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$26, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4984:
	movzbq	224(%r11), %rax
	movq	$96, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$26, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4983:
	movzbq	302(%r11), %rax
	movq	$112, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$26, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4982:
	movzbq	69(%r11), %rax
	movq	$64, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$27, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4981:
	movzbq	147(%r11), %rax
	movq	$80, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$27, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4980:
	movzbq	225(%r11), %rax
	movq	$96, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$27, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4979:
	movzbq	303(%r11), %rax
	movq	$112, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$27, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4978:
	movzbq	70(%r11), %rax
	movq	$64, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$28, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4977:
	movzbq	148(%r11), %rax
	movq	$80, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$28, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4976:
	movzbq	226(%r11), %rax
	movq	$96, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$28, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4975:
	movzbq	304(%r11), %rax
	movq	$112, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$28, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4974:
	movzbq	71(%r11), %rax
	movq	$64, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$29, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4973:
	movzbq	149(%r11), %rax
	movq	$80, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$29, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4972:
	movzbq	227(%r11), %rax
	movq	$96, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$29, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4971:
	movzbq	305(%r11), %rax
	movq	$112, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$29, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4970:
	movzbq	72(%r11), %rax
	movq	$64, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$30, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4969:
	movzbq	150(%r11), %rax
	movq	$80, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$30, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4968:
	movzbq	228(%r11), %rax
	movq	$96, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$30, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4967:
	movzbq	306(%r11), %rax
	movq	$112, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$30, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4966:
	movzbq	73(%r11), %rax
	movq	$64, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$31, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4965:
	movzbq	151(%r11), %rax
	movq	$80, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$31, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4964:
	movzbq	229(%r11), %rax
	movq	$96, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$31, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4963:
	movzbq	307(%r11), %rax
	movq	$112, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$31, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4962:
	movzbq	74(%r11), %rax
	movq	$64, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$32, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4961:
	movzbq	152(%r11), %rax
	movq	$80, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$32, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4960:
	movzbq	230(%r11), %rax
	movq	$96, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$32, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4959:
	movzbq	308(%r11), %rax
	movq	$112, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$32, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4958:
	movzbq	75(%r11), %rax
	movq	$64, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$33, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4957:
	movzbq	153(%r11), %rax
	movq	$80, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$33, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4956:
	movzbq	231(%r11), %rax
	movq	$96, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$33, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4955:
	movzbq	309(%r11), %rax
	movq	$112, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$33, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4954:
	movzbq	76(%r11), %rax
	movq	$64, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$34, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4953:
	movzbq	154(%r11), %rax
	movq	$80, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$34, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4952:
	movzbq	232(%r11), %rax
	movq	$96, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$34, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4951:
	movzbq	310(%r11), %rax
	movq	$112, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$34, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4950:
	movzbq	77(%r11), %rax
	movq	$64, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$35, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4949:
	movzbq	155(%r11), %rax
	movq	$80, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$35, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4948:
	movzbq	233(%r11), %rax
	movq	$96, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$35, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4947:
	movzbq	311(%r11), %rax
	movq	$112, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$35, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4946:
	movq	$2, %rdx
	jmp 	Lbitsliced_m_calculate_PS$4940
Lbitsliced_m_calculate_PS$4941:
	movzbq	(%r11,%rdx), %rax
	movq	$128, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$4945:
	movzbq	78(%r11,%rdx), %rax
	movq	$144, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$4944:
	movzbq	156(%r11,%rdx), %rax
	movq	$160, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$4943:
	movzbq	234(%r11,%rdx), %rax
	movq	$176, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$4942:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$4940:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$4941
	movzbq	60(%r11), %rax
	movq	$128, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$36, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4939:
	movzbq	138(%r11), %rax
	movq	$144, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$36, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4938:
	movzbq	216(%r11), %rax
	movq	$160, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$36, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4937:
	movzbq	294(%r11), %rax
	movq	$176, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$36, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4936:
	movzbq	61(%r11), %rax
	movq	$128, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$37, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4935:
	movzbq	139(%r11), %rax
	movq	$144, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$37, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4934:
	movzbq	217(%r11), %rax
	movq	$160, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$37, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4933:
	movzbq	295(%r11), %rax
	movq	$176, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$37, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4932:
	movzbq	62(%r11), %rax
	movq	$128, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$38, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4931:
	movzbq	140(%r11), %rax
	movq	$144, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$38, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4930:
	movzbq	218(%r11), %rax
	movq	$160, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$38, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4929:
	movzbq	296(%r11), %rax
	movq	$176, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$38, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4928:
	movzbq	63(%r11), %rax
	movq	$128, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$39, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4927:
	movzbq	141(%r11), %rax
	movq	$144, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$39, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4926:
	movzbq	219(%r11), %rax
	movq	$160, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$39, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4925:
	movzbq	297(%r11), %rax
	movq	$176, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$39, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4924:
	movzbq	64(%r11), %rax
	movq	$128, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$40, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4923:
	movzbq	142(%r11), %rax
	movq	$144, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$40, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4922:
	movzbq	220(%r11), %rax
	movq	$160, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$40, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4921:
	movzbq	298(%r11), %rax
	movq	$176, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$40, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4920:
	movzbq	65(%r11), %rax
	movq	$128, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$41, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4919:
	movzbq	143(%r11), %rax
	movq	$144, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$41, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4918:
	movzbq	221(%r11), %rax
	movq	$160, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$41, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4917:
	movzbq	299(%r11), %rax
	movq	$176, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$41, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4916:
	movzbq	66(%r11), %rax
	movq	$128, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$42, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4915:
	movzbq	144(%r11), %rax
	movq	$144, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$42, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4914:
	movzbq	222(%r11), %rax
	movq	$160, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$42, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4913:
	movzbq	300(%r11), %rax
	movq	$176, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$42, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4912:
	movzbq	67(%r11), %rax
	movq	$128, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$43, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4911:
	movzbq	145(%r11), %rax
	movq	$144, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$43, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4910:
	movzbq	223(%r11), %rax
	movq	$160, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$43, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4909:
	movzbq	301(%r11), %rax
	movq	$176, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$43, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4908:
	movzbq	68(%r11), %rax
	movq	$128, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$44, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4907:
	movzbq	146(%r11), %rax
	movq	$144, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$44, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4906:
	movzbq	224(%r11), %rax
	movq	$160, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$44, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4905:
	movzbq	302(%r11), %rax
	movq	$176, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$44, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4904:
	movzbq	69(%r11), %rax
	movq	$128, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$45, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4903:
	movzbq	147(%r11), %rax
	movq	$144, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$45, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4902:
	movzbq	225(%r11), %rax
	movq	$160, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$45, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4901:
	movzbq	303(%r11), %rax
	movq	$176, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$45, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4900:
	movzbq	70(%r11), %rax
	movq	$128, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$46, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4899:
	movzbq	148(%r11), %rax
	movq	$144, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$46, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4898:
	movzbq	226(%r11), %rax
	movq	$160, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$46, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4897:
	movzbq	304(%r11), %rax
	movq	$176, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$46, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4896:
	movzbq	71(%r11), %rax
	movq	$128, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$47, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4895:
	movzbq	149(%r11), %rax
	movq	$144, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$47, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4894:
	movzbq	227(%r11), %rax
	movq	$160, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$47, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4893:
	movzbq	305(%r11), %rax
	movq	$176, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$47, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4892:
	movzbq	72(%r11), %rax
	movq	$128, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$48, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4891:
	movzbq	150(%r11), %rax
	movq	$144, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$48, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4890:
	movzbq	228(%r11), %rax
	movq	$160, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$48, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4889:
	movzbq	306(%r11), %rax
	movq	$176, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$48, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4888:
	movzbq	73(%r11), %rax
	movq	$128, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$49, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4887:
	movzbq	151(%r11), %rax
	movq	$144, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$49, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4886:
	movzbq	229(%r11), %rax
	movq	$160, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$49, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4885:
	movzbq	307(%r11), %rax
	movq	$176, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$49, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4884:
	movzbq	74(%r11), %rax
	movq	$128, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$50, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4883:
	movzbq	152(%r11), %rax
	movq	$144, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$50, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4882:
	movzbq	230(%r11), %rax
	movq	$160, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$50, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4881:
	movzbq	308(%r11), %rax
	movq	$176, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$50, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4880:
	movzbq	75(%r11), %rax
	movq	$128, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$51, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4879:
	movzbq	153(%r11), %rax
	movq	$144, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$51, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4878:
	movzbq	231(%r11), %rax
	movq	$160, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$51, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4877:
	movzbq	309(%r11), %rax
	movq	$176, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$51, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4876:
	movzbq	76(%r11), %rax
	movq	$128, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$52, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4875:
	movzbq	154(%r11), %rax
	movq	$144, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$52, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4874:
	movzbq	232(%r11), %rax
	movq	$160, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$52, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4873:
	movzbq	310(%r11), %rax
	movq	$176, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$52, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4872:
	movzbq	77(%r11), %rax
	movq	$128, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$53, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4871:
	movzbq	155(%r11), %rax
	movq	$144, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$53, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4870:
	movzbq	233(%r11), %rax
	movq	$160, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$53, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4869:
	movzbq	311(%r11), %rax
	movq	$176, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$53, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4868:
	movq	$3, %rdx
	jmp 	Lbitsliced_m_calculate_PS$4862
Lbitsliced_m_calculate_PS$4863:
	movzbq	(%r11,%rdx), %rax
	movq	$192, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$4867:
	movzbq	78(%r11,%rdx), %rax
	movq	$208, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$4866:
	movzbq	156(%r11,%rdx), %rax
	movq	$224, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$4865:
	movzbq	234(%r11,%rdx), %rax
	movq	$240, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$4864:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$4862:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$4863
	movzbq	60(%r11), %rax
	movq	$192, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$54, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4861:
	movzbq	138(%r11), %rax
	movq	$208, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$54, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4860:
	movzbq	216(%r11), %rax
	movq	$224, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$54, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4859:
	movzbq	294(%r11), %rax
	movq	$240, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$54, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4858:
	movzbq	61(%r11), %rax
	movq	$192, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$55, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4857:
	movzbq	139(%r11), %rax
	movq	$208, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$55, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4856:
	movzbq	217(%r11), %rax
	movq	$224, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$55, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4855:
	movzbq	295(%r11), %rax
	movq	$240, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$55, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4854:
	movzbq	62(%r11), %rax
	movq	$192, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$56, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4853:
	movzbq	140(%r11), %rax
	movq	$208, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$56, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4852:
	movzbq	218(%r11), %rax
	movq	$224, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$56, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4851:
	movzbq	296(%r11), %rax
	movq	$240, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$56, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4850:
	movzbq	63(%r11), %rax
	movq	$192, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$57, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4849:
	movzbq	141(%r11), %rax
	movq	$208, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$57, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4848:
	movzbq	219(%r11), %rax
	movq	$224, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$57, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4847:
	movzbq	297(%r11), %rax
	movq	$240, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$57, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4846:
	movzbq	64(%r11), %rax
	movq	$192, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$58, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4845:
	movzbq	142(%r11), %rax
	movq	$208, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$58, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4844:
	movzbq	220(%r11), %rax
	movq	$224, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$58, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4843:
	movzbq	298(%r11), %rax
	movq	$240, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$58, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4842:
	movzbq	65(%r11), %rax
	movq	$192, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$59, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4841:
	movzbq	143(%r11), %rax
	movq	$208, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$59, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4840:
	movzbq	221(%r11), %rax
	movq	$224, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$59, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4839:
	movzbq	299(%r11), %rax
	movq	$240, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$59, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4838:
	movzbq	66(%r11), %rax
	movq	$192, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$60, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4837:
	movzbq	144(%r11), %rax
	movq	$208, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$60, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4836:
	movzbq	222(%r11), %rax
	movq	$224, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$60, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4835:
	movzbq	300(%r11), %rax
	movq	$240, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$60, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4834:
	movzbq	67(%r11), %rax
	movq	$192, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$61, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4833:
	movzbq	145(%r11), %rax
	movq	$208, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$61, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4832:
	movzbq	223(%r11), %rax
	movq	$224, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$61, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4831:
	movzbq	301(%r11), %rax
	movq	$240, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$61, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4830:
	movzbq	68(%r11), %rax
	movq	$192, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$62, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4829:
	movzbq	146(%r11), %rax
	movq	$208, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$62, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4828:
	movzbq	224(%r11), %rax
	movq	$224, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$62, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4827:
	movzbq	302(%r11), %rax
	movq	$240, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$62, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4826:
	movzbq	69(%r11), %rax
	movq	$192, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$63, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4825:
	movzbq	147(%r11), %rax
	movq	$208, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$63, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4824:
	movzbq	225(%r11), %rax
	movq	$224, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$63, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4823:
	movzbq	303(%r11), %rax
	movq	$240, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$63, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4822:
	movzbq	70(%r11), %rax
	movq	$192, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$64, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4821:
	movzbq	148(%r11), %rax
	movq	$208, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$64, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4820:
	movzbq	226(%r11), %rax
	movq	$224, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$64, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4819:
	movzbq	304(%r11), %rax
	movq	$240, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$64, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4818:
	movzbq	71(%r11), %rax
	movq	$192, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$65, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4817:
	movzbq	149(%r11), %rax
	movq	$208, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$65, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4816:
	movzbq	227(%r11), %rax
	movq	$224, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$65, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4815:
	movzbq	305(%r11), %rax
	movq	$240, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$65, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4814:
	movzbq	72(%r11), %rax
	movq	$192, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$66, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4813:
	movzbq	150(%r11), %rax
	movq	$208, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$66, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4812:
	movzbq	228(%r11), %rax
	movq	$224, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$66, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4811:
	movzbq	306(%r11), %rax
	movq	$240, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$66, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4810:
	movzbq	73(%r11), %rax
	movq	$192, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$67, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4809:
	movzbq	151(%r11), %rax
	movq	$208, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$67, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4808:
	movzbq	229(%r11), %rax
	movq	$224, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$67, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4807:
	movzbq	307(%r11), %rax
	movq	$240, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$67, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4806:
	movzbq	74(%r11), %rax
	movq	$192, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$68, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4805:
	movzbq	152(%r11), %rax
	movq	$208, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$68, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4804:
	movzbq	230(%r11), %rax
	movq	$224, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$68, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4803:
	movzbq	308(%r11), %rax
	movq	$240, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$68, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4802:
	movzbq	75(%r11), %rax
	movq	$192, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$69, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4801:
	movzbq	153(%r11), %rax
	movq	$208, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$69, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4800:
	movzbq	231(%r11), %rax
	movq	$224, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$69, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4799:
	movzbq	309(%r11), %rax
	movq	$240, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$69, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4798:
	movzbq	76(%r11), %rax
	movq	$192, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$70, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4797:
	movzbq	154(%r11), %rax
	movq	$208, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$70, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4796:
	movzbq	232(%r11), %rax
	movq	$224, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$70, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4795:
	movzbq	310(%r11), %rax
	movq	$240, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$70, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4794:
	movzbq	77(%r11), %rax
	movq	$192, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$71, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4793:
	movzbq	155(%r11), %rax
	movq	$208, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$71, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4792:
	movzbq	233(%r11), %rax
	movq	$224, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$71, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4791:
	movzbq	311(%r11), %rax
	movq	$240, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$71, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4790:
	movq	$4, %rdx
	jmp 	Lbitsliced_m_calculate_PS$4784
Lbitsliced_m_calculate_PS$4785:
	movzbq	(%r11,%rdx), %rax
	movq	$256, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$4789:
	movzbq	78(%r11,%rdx), %rax
	movq	$272, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$4788:
	movzbq	156(%r11,%rdx), %rax
	movq	$288, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$4787:
	movzbq	234(%r11,%rdx), %rax
	movq	$304, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$4786:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$4784:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$4785
	movzbq	60(%r11), %rax
	movq	$256, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$72, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4783:
	movzbq	138(%r11), %rax
	movq	$272, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$72, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4782:
	movzbq	216(%r11), %rax
	movq	$288, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$72, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4781:
	movzbq	294(%r11), %rax
	movq	$304, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$72, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4780:
	movzbq	61(%r11), %rax
	movq	$256, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$73, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4779:
	movzbq	139(%r11), %rax
	movq	$272, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$73, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4778:
	movzbq	217(%r11), %rax
	movq	$288, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$73, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4777:
	movzbq	295(%r11), %rax
	movq	$304, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$73, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4776:
	movzbq	62(%r11), %rax
	movq	$256, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$74, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4775:
	movzbq	140(%r11), %rax
	movq	$272, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$74, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4774:
	movzbq	218(%r11), %rax
	movq	$288, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$74, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4773:
	movzbq	296(%r11), %rax
	movq	$304, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$74, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4772:
	movzbq	63(%r11), %rax
	movq	$256, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$75, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4771:
	movzbq	141(%r11), %rax
	movq	$272, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$75, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4770:
	movzbq	219(%r11), %rax
	movq	$288, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$75, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4769:
	movzbq	297(%r11), %rax
	movq	$304, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$75, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4768:
	movzbq	64(%r11), %rax
	movq	$256, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$76, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4767:
	movzbq	142(%r11), %rax
	movq	$272, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$76, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4766:
	movzbq	220(%r11), %rax
	movq	$288, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$76, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4765:
	movzbq	298(%r11), %rax
	movq	$304, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$76, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4764:
	movzbq	65(%r11), %rax
	movq	$256, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$77, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4763:
	movzbq	143(%r11), %rax
	movq	$272, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$77, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4762:
	movzbq	221(%r11), %rax
	movq	$288, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$77, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4761:
	movzbq	299(%r11), %rax
	movq	$304, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$77, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4760:
	movzbq	66(%r11), %rax
	movq	$256, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$78, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4759:
	movzbq	144(%r11), %rax
	movq	$272, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$78, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4758:
	movzbq	222(%r11), %rax
	movq	$288, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$78, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4757:
	movzbq	300(%r11), %rax
	movq	$304, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$78, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4756:
	movzbq	67(%r11), %rax
	movq	$256, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$79, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4755:
	movzbq	145(%r11), %rax
	movq	$272, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$79, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4754:
	movzbq	223(%r11), %rax
	movq	$288, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$79, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4753:
	movzbq	301(%r11), %rax
	movq	$304, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$79, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4752:
	movzbq	68(%r11), %rax
	movq	$256, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$80, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4751:
	movzbq	146(%r11), %rax
	movq	$272, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$80, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4750:
	movzbq	224(%r11), %rax
	movq	$288, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$80, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4749:
	movzbq	302(%r11), %rax
	movq	$304, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$80, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4748:
	movzbq	69(%r11), %rax
	movq	$256, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$81, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4747:
	movzbq	147(%r11), %rax
	movq	$272, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$81, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4746:
	movzbq	225(%r11), %rax
	movq	$288, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$81, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4745:
	movzbq	303(%r11), %rax
	movq	$304, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$81, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4744:
	movzbq	70(%r11), %rax
	movq	$256, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$82, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4743:
	movzbq	148(%r11), %rax
	movq	$272, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$82, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4742:
	movzbq	226(%r11), %rax
	movq	$288, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$82, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4741:
	movzbq	304(%r11), %rax
	movq	$304, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$82, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4740:
	movzbq	71(%r11), %rax
	movq	$256, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$83, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4739:
	movzbq	149(%r11), %rax
	movq	$272, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$83, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4738:
	movzbq	227(%r11), %rax
	movq	$288, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$83, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4737:
	movzbq	305(%r11), %rax
	movq	$304, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$83, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4736:
	movzbq	72(%r11), %rax
	movq	$256, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$84, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4735:
	movzbq	150(%r11), %rax
	movq	$272, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$84, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4734:
	movzbq	228(%r11), %rax
	movq	$288, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$84, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4733:
	movzbq	306(%r11), %rax
	movq	$304, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$84, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4732:
	movzbq	73(%r11), %rax
	movq	$256, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$85, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4731:
	movzbq	151(%r11), %rax
	movq	$272, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$85, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4730:
	movzbq	229(%r11), %rax
	movq	$288, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$85, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4729:
	movzbq	307(%r11), %rax
	movq	$304, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$85, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4728:
	movzbq	74(%r11), %rax
	movq	$256, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$86, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4727:
	movzbq	152(%r11), %rax
	movq	$272, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$86, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4726:
	movzbq	230(%r11), %rax
	movq	$288, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$86, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4725:
	movzbq	308(%r11), %rax
	movq	$304, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$86, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4724:
	movzbq	75(%r11), %rax
	movq	$256, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$87, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4723:
	movzbq	153(%r11), %rax
	movq	$272, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$87, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4722:
	movzbq	231(%r11), %rax
	movq	$288, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$87, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4721:
	movzbq	309(%r11), %rax
	movq	$304, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$87, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4720:
	movzbq	76(%r11), %rax
	movq	$256, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$88, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4719:
	movzbq	154(%r11), %rax
	movq	$272, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$88, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4718:
	movzbq	232(%r11), %rax
	movq	$288, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$88, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4717:
	movzbq	310(%r11), %rax
	movq	$304, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$88, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4716:
	movzbq	77(%r11), %rax
	movq	$256, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$89, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4715:
	movzbq	155(%r11), %rax
	movq	$272, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$89, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4714:
	movzbq	233(%r11), %rax
	movq	$288, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$89, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4713:
	movzbq	311(%r11), %rax
	movq	$304, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$89, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4712:
	movq	$5, %rdx
	jmp 	Lbitsliced_m_calculate_PS$4706
Lbitsliced_m_calculate_PS$4707:
	movzbq	(%r11,%rdx), %rax
	movq	$320, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$4711:
	movzbq	78(%r11,%rdx), %rax
	movq	$336, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$4710:
	movzbq	156(%r11,%rdx), %rax
	movq	$352, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$4709:
	movzbq	234(%r11,%rdx), %rax
	movq	$368, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$4708:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$4706:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$4707
	movzbq	60(%r11), %rax
	movq	$320, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$90, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4705:
	movzbq	138(%r11), %rax
	movq	$336, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$90, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4704:
	movzbq	216(%r11), %rax
	movq	$352, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$90, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4703:
	movzbq	294(%r11), %rax
	movq	$368, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$90, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4702:
	movzbq	61(%r11), %rax
	movq	$320, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$91, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4701:
	movzbq	139(%r11), %rax
	movq	$336, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$91, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4700:
	movzbq	217(%r11), %rax
	movq	$352, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$91, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4699:
	movzbq	295(%r11), %rax
	movq	$368, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$91, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4698:
	movzbq	62(%r11), %rax
	movq	$320, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$92, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4697:
	movzbq	140(%r11), %rax
	movq	$336, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$92, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4696:
	movzbq	218(%r11), %rax
	movq	$352, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$92, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4695:
	movzbq	296(%r11), %rax
	movq	$368, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$92, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4694:
	movzbq	63(%r11), %rax
	movq	$320, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$93, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4693:
	movzbq	141(%r11), %rax
	movq	$336, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$93, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4692:
	movzbq	219(%r11), %rax
	movq	$352, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$93, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4691:
	movzbq	297(%r11), %rax
	movq	$368, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$93, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4690:
	movzbq	64(%r11), %rax
	movq	$320, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$94, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4689:
	movzbq	142(%r11), %rax
	movq	$336, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$94, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4688:
	movzbq	220(%r11), %rax
	movq	$352, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$94, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4687:
	movzbq	298(%r11), %rax
	movq	$368, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$94, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4686:
	movzbq	65(%r11), %rax
	movq	$320, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$95, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4685:
	movzbq	143(%r11), %rax
	movq	$336, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$95, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4684:
	movzbq	221(%r11), %rax
	movq	$352, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$95, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4683:
	movzbq	299(%r11), %rax
	movq	$368, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$95, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4682:
	movzbq	66(%r11), %rax
	movq	$320, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$96, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4681:
	movzbq	144(%r11), %rax
	movq	$336, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$96, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4680:
	movzbq	222(%r11), %rax
	movq	$352, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$96, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4679:
	movzbq	300(%r11), %rax
	movq	$368, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$96, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4678:
	movzbq	67(%r11), %rax
	movq	$320, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$97, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4677:
	movzbq	145(%r11), %rax
	movq	$336, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$97, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4676:
	movzbq	223(%r11), %rax
	movq	$352, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$97, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4675:
	movzbq	301(%r11), %rax
	movq	$368, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$97, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4674:
	movzbq	68(%r11), %rax
	movq	$320, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$98, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4673:
	movzbq	146(%r11), %rax
	movq	$336, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$98, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4672:
	movzbq	224(%r11), %rax
	movq	$352, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$98, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4671:
	movzbq	302(%r11), %rax
	movq	$368, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$98, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4670:
	movzbq	69(%r11), %rax
	movq	$320, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$99, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4669:
	movzbq	147(%r11), %rax
	movq	$336, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$99, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4668:
	movzbq	225(%r11), %rax
	movq	$352, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$99, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4667:
	movzbq	303(%r11), %rax
	movq	$368, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$99, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4666:
	movzbq	70(%r11), %rax
	movq	$320, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$100, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4665:
	movzbq	148(%r11), %rax
	movq	$336, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$100, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4664:
	movzbq	226(%r11), %rax
	movq	$352, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$100, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4663:
	movzbq	304(%r11), %rax
	movq	$368, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$100, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4662:
	movzbq	71(%r11), %rax
	movq	$320, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$101, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4661:
	movzbq	149(%r11), %rax
	movq	$336, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$101, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4660:
	movzbq	227(%r11), %rax
	movq	$352, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$101, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4659:
	movzbq	305(%r11), %rax
	movq	$368, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$101, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4658:
	movzbq	72(%r11), %rax
	movq	$320, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$102, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4657:
	movzbq	150(%r11), %rax
	movq	$336, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$102, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4656:
	movzbq	228(%r11), %rax
	movq	$352, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$102, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4655:
	movzbq	306(%r11), %rax
	movq	$368, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$102, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4654:
	movzbq	73(%r11), %rax
	movq	$320, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$103, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4653:
	movzbq	151(%r11), %rax
	movq	$336, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$103, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4652:
	movzbq	229(%r11), %rax
	movq	$352, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$103, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4651:
	movzbq	307(%r11), %rax
	movq	$368, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$103, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4650:
	movzbq	74(%r11), %rax
	movq	$320, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$104, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4649:
	movzbq	152(%r11), %rax
	movq	$336, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$104, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4648:
	movzbq	230(%r11), %rax
	movq	$352, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$104, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4647:
	movzbq	308(%r11), %rax
	movq	$368, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$104, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4646:
	movzbq	75(%r11), %rax
	movq	$320, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$105, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4645:
	movzbq	153(%r11), %rax
	movq	$336, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$105, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4644:
	movzbq	231(%r11), %rax
	movq	$352, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$105, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4643:
	movzbq	309(%r11), %rax
	movq	$368, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$105, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4642:
	movzbq	76(%r11), %rax
	movq	$320, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$106, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4641:
	movzbq	154(%r11), %rax
	movq	$336, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$106, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4640:
	movzbq	232(%r11), %rax
	movq	$352, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$106, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4639:
	movzbq	310(%r11), %rax
	movq	$368, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$106, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4638:
	movzbq	77(%r11), %rax
	movq	$320, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$107, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4637:
	movzbq	155(%r11), %rax
	movq	$336, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$107, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4636:
	movzbq	233(%r11), %rax
	movq	$352, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$107, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4635:
	movzbq	311(%r11), %rax
	movq	$368, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$107, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4634:
	movq	$6, %rdx
	jmp 	Lbitsliced_m_calculate_PS$4628
Lbitsliced_m_calculate_PS$4629:
	movzbq	(%r11,%rdx), %rax
	movq	$384, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$4633:
	movzbq	78(%r11,%rdx), %rax
	movq	$400, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$4632:
	movzbq	156(%r11,%rdx), %rax
	movq	$416, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$4631:
	movzbq	234(%r11,%rdx), %rax
	movq	$432, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$4630:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$4628:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$4629
	movzbq	60(%r11), %rax
	movq	$384, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$108, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4627:
	movzbq	138(%r11), %rax
	movq	$400, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$108, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4626:
	movzbq	216(%r11), %rax
	movq	$416, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$108, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4625:
	movzbq	294(%r11), %rax
	movq	$432, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$108, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4624:
	movzbq	61(%r11), %rax
	movq	$384, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$109, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4623:
	movzbq	139(%r11), %rax
	movq	$400, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$109, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4622:
	movzbq	217(%r11), %rax
	movq	$416, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$109, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4621:
	movzbq	295(%r11), %rax
	movq	$432, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$109, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4620:
	movzbq	62(%r11), %rax
	movq	$384, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$110, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4619:
	movzbq	140(%r11), %rax
	movq	$400, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$110, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4618:
	movzbq	218(%r11), %rax
	movq	$416, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$110, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4617:
	movzbq	296(%r11), %rax
	movq	$432, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$110, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4616:
	movzbq	63(%r11), %rax
	movq	$384, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$111, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4615:
	movzbq	141(%r11), %rax
	movq	$400, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$111, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4614:
	movzbq	219(%r11), %rax
	movq	$416, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$111, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4613:
	movzbq	297(%r11), %rax
	movq	$432, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$111, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4612:
	movzbq	64(%r11), %rax
	movq	$384, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$112, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4611:
	movzbq	142(%r11), %rax
	movq	$400, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$112, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4610:
	movzbq	220(%r11), %rax
	movq	$416, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$112, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4609:
	movzbq	298(%r11), %rax
	movq	$432, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$112, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4608:
	movzbq	65(%r11), %rax
	movq	$384, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$113, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4607:
	movzbq	143(%r11), %rax
	movq	$400, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$113, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4606:
	movzbq	221(%r11), %rax
	movq	$416, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$113, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4605:
	movzbq	299(%r11), %rax
	movq	$432, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$113, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4604:
	movzbq	66(%r11), %rax
	movq	$384, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$114, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4603:
	movzbq	144(%r11), %rax
	movq	$400, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$114, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4602:
	movzbq	222(%r11), %rax
	movq	$416, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$114, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4601:
	movzbq	300(%r11), %rax
	movq	$432, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$114, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4600:
	movzbq	67(%r11), %rax
	movq	$384, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$115, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4599:
	movzbq	145(%r11), %rax
	movq	$400, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$115, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4598:
	movzbq	223(%r11), %rax
	movq	$416, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$115, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4597:
	movzbq	301(%r11), %rax
	movq	$432, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$115, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4596:
	movzbq	68(%r11), %rax
	movq	$384, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$116, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4595:
	movzbq	146(%r11), %rax
	movq	$400, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$116, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4594:
	movzbq	224(%r11), %rax
	movq	$416, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$116, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4593:
	movzbq	302(%r11), %rax
	movq	$432, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$116, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4592:
	movzbq	69(%r11), %rax
	movq	$384, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$117, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4591:
	movzbq	147(%r11), %rax
	movq	$400, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$117, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4590:
	movzbq	225(%r11), %rax
	movq	$416, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$117, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4589:
	movzbq	303(%r11), %rax
	movq	$432, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$117, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4588:
	movzbq	70(%r11), %rax
	movq	$384, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$118, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4587:
	movzbq	148(%r11), %rax
	movq	$400, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$118, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4586:
	movzbq	226(%r11), %rax
	movq	$416, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$118, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4585:
	movzbq	304(%r11), %rax
	movq	$432, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$118, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4584:
	movzbq	71(%r11), %rax
	movq	$384, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$119, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4583:
	movzbq	149(%r11), %rax
	movq	$400, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$119, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4582:
	movzbq	227(%r11), %rax
	movq	$416, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$119, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4581:
	movzbq	305(%r11), %rax
	movq	$432, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$119, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4580:
	movzbq	72(%r11), %rax
	movq	$384, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$120, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4579:
	movzbq	150(%r11), %rax
	movq	$400, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$120, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4578:
	movzbq	228(%r11), %rax
	movq	$416, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$120, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4577:
	movzbq	306(%r11), %rax
	movq	$432, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$120, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4576:
	movzbq	73(%r11), %rax
	movq	$384, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$121, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4575:
	movzbq	151(%r11), %rax
	movq	$400, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$121, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4574:
	movzbq	229(%r11), %rax
	movq	$416, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$121, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4573:
	movzbq	307(%r11), %rax
	movq	$432, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$121, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4572:
	movzbq	74(%r11), %rax
	movq	$384, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$122, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4571:
	movzbq	152(%r11), %rax
	movq	$400, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$122, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4570:
	movzbq	230(%r11), %rax
	movq	$416, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$122, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4569:
	movzbq	308(%r11), %rax
	movq	$432, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$122, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4568:
	movzbq	75(%r11), %rax
	movq	$384, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$123, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4567:
	movzbq	153(%r11), %rax
	movq	$400, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$123, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4566:
	movzbq	231(%r11), %rax
	movq	$416, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$123, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4565:
	movzbq	309(%r11), %rax
	movq	$432, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$123, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4564:
	movzbq	76(%r11), %rax
	movq	$384, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$124, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4563:
	movzbq	154(%r11), %rax
	movq	$400, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$124, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4562:
	movzbq	232(%r11), %rax
	movq	$416, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$124, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4561:
	movzbq	310(%r11), %rax
	movq	$432, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$124, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4560:
	movzbq	77(%r11), %rax
	movq	$384, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$125, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4559:
	movzbq	155(%r11), %rax
	movq	$400, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$125, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4558:
	movzbq	233(%r11), %rax
	movq	$416, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$125, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4557:
	movzbq	311(%r11), %rax
	movq	$432, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$125, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4556:
	movq	$7, %rdx
	jmp 	Lbitsliced_m_calculate_PS$4550
Lbitsliced_m_calculate_PS$4551:
	movzbq	(%r11,%rdx), %rax
	movq	$448, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$4555:
	movzbq	78(%r11,%rdx), %rax
	movq	$464, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$4554:
	movzbq	156(%r11,%rdx), %rax
	movq	$480, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$4553:
	movzbq	234(%r11,%rdx), %rax
	movq	$496, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$4552:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$4550:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$4551
	movzbq	60(%r11), %rax
	movq	$448, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$126, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4549:
	movzbq	138(%r11), %rax
	movq	$464, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$126, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4548:
	movzbq	216(%r11), %rax
	movq	$480, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$126, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4547:
	movzbq	294(%r11), %rax
	movq	$496, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$126, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4546:
	movzbq	61(%r11), %rax
	movq	$448, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$127, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4545:
	movzbq	139(%r11), %rax
	movq	$464, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$127, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4544:
	movzbq	217(%r11), %rax
	movq	$480, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$127, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4543:
	movzbq	295(%r11), %rax
	movq	$496, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$127, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4542:
	movzbq	62(%r11), %rax
	movq	$448, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$128, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4541:
	movzbq	140(%r11), %rax
	movq	$464, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$128, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4540:
	movzbq	218(%r11), %rax
	movq	$480, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$128, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4539:
	movzbq	296(%r11), %rax
	movq	$496, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$128, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4538:
	movzbq	63(%r11), %rax
	movq	$448, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$129, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4537:
	movzbq	141(%r11), %rax
	movq	$464, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$129, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4536:
	movzbq	219(%r11), %rax
	movq	$480, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$129, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4535:
	movzbq	297(%r11), %rax
	movq	$496, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$129, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4534:
	movzbq	64(%r11), %rax
	movq	$448, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$130, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4533:
	movzbq	142(%r11), %rax
	movq	$464, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$130, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4532:
	movzbq	220(%r11), %rax
	movq	$480, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$130, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4531:
	movzbq	298(%r11), %rax
	movq	$496, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$130, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4530:
	movzbq	65(%r11), %rax
	movq	$448, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$131, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4529:
	movzbq	143(%r11), %rax
	movq	$464, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$131, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4528:
	movzbq	221(%r11), %rax
	movq	$480, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$131, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4527:
	movzbq	299(%r11), %rax
	movq	$496, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$131, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4526:
	movzbq	66(%r11), %rax
	movq	$448, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$132, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4525:
	movzbq	144(%r11), %rax
	movq	$464, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$132, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4524:
	movzbq	222(%r11), %rax
	movq	$480, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$132, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4523:
	movzbq	300(%r11), %rax
	movq	$496, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$132, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4522:
	movzbq	67(%r11), %rax
	movq	$448, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$133, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4521:
	movzbq	145(%r11), %rax
	movq	$464, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$133, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4520:
	movzbq	223(%r11), %rax
	movq	$480, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$133, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4519:
	movzbq	301(%r11), %rax
	movq	$496, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$133, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4518:
	movzbq	68(%r11), %rax
	movq	$448, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$134, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4517:
	movzbq	146(%r11), %rax
	movq	$464, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$134, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4516:
	movzbq	224(%r11), %rax
	movq	$480, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$134, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4515:
	movzbq	302(%r11), %rax
	movq	$496, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$134, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4514:
	movzbq	69(%r11), %rax
	movq	$448, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$135, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4513:
	movzbq	147(%r11), %rax
	movq	$464, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$135, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4512:
	movzbq	225(%r11), %rax
	movq	$480, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$135, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4511:
	movzbq	303(%r11), %rax
	movq	$496, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$135, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4510:
	movzbq	70(%r11), %rax
	movq	$448, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$136, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4509:
	movzbq	148(%r11), %rax
	movq	$464, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$136, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4508:
	movzbq	226(%r11), %rax
	movq	$480, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$136, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4507:
	movzbq	304(%r11), %rax
	movq	$496, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$136, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4506:
	movzbq	71(%r11), %rax
	movq	$448, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$137, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4505:
	movzbq	149(%r11), %rax
	movq	$464, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$137, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4504:
	movzbq	227(%r11), %rax
	movq	$480, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$137, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4503:
	movzbq	305(%r11), %rax
	movq	$496, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$137, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4502:
	movzbq	72(%r11), %rax
	movq	$448, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$138, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4501:
	movzbq	150(%r11), %rax
	movq	$464, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$138, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4500:
	movzbq	228(%r11), %rax
	movq	$480, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$138, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4499:
	movzbq	306(%r11), %rax
	movq	$496, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$138, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4498:
	movzbq	73(%r11), %rax
	movq	$448, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$139, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4497:
	movzbq	151(%r11), %rax
	movq	$464, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$139, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4496:
	movzbq	229(%r11), %rax
	movq	$480, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$139, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4495:
	movzbq	307(%r11), %rax
	movq	$496, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$139, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4494:
	movzbq	74(%r11), %rax
	movq	$448, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$140, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4493:
	movzbq	152(%r11), %rax
	movq	$464, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$140, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4492:
	movzbq	230(%r11), %rax
	movq	$480, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$140, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4491:
	movzbq	308(%r11), %rax
	movq	$496, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$140, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4490:
	movzbq	75(%r11), %rax
	movq	$448, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$141, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4489:
	movzbq	153(%r11), %rax
	movq	$464, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$141, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4488:
	movzbq	231(%r11), %rax
	movq	$480, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$141, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4487:
	movzbq	309(%r11), %rax
	movq	$496, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$141, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4486:
	movzbq	76(%r11), %rax
	movq	$448, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$142, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4485:
	movzbq	154(%r11), %rax
	movq	$464, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$142, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4484:
	movzbq	232(%r11), %rax
	movq	$480, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$142, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4483:
	movzbq	310(%r11), %rax
	movq	$496, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$142, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4482:
	movzbq	77(%r11), %rax
	movq	$448, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$143, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4481:
	movzbq	155(%r11), %rax
	movq	$464, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$143, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4480:
	movzbq	233(%r11), %rax
	movq	$480, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$143, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4479:
	movzbq	311(%r11), %rax
	movq	$496, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$143, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4478:
	movq	$8, %rdx
	jmp 	Lbitsliced_m_calculate_PS$4472
Lbitsliced_m_calculate_PS$4473:
	movzbq	(%r11,%rdx), %rax
	movq	$512, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$4477:
	movzbq	78(%r11,%rdx), %rax
	movq	$528, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$4476:
	movzbq	156(%r11,%rdx), %rax
	movq	$544, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$4475:
	movzbq	234(%r11,%rdx), %rax
	movq	$560, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$4474:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$4472:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$4473
	movzbq	60(%r11), %rax
	movq	$512, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$144, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4471:
	movzbq	138(%r11), %rax
	movq	$528, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$144, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4470:
	movzbq	216(%r11), %rax
	movq	$544, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$144, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4469:
	movzbq	294(%r11), %rax
	movq	$560, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$144, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4468:
	movzbq	61(%r11), %rax
	movq	$512, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$145, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4467:
	movzbq	139(%r11), %rax
	movq	$528, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$145, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4466:
	movzbq	217(%r11), %rax
	movq	$544, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$145, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4465:
	movzbq	295(%r11), %rax
	movq	$560, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$145, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4464:
	movzbq	62(%r11), %rax
	movq	$512, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$146, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4463:
	movzbq	140(%r11), %rax
	movq	$528, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$146, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4462:
	movzbq	218(%r11), %rax
	movq	$544, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$146, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4461:
	movzbq	296(%r11), %rax
	movq	$560, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$146, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4460:
	movzbq	63(%r11), %rax
	movq	$512, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$147, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4459:
	movzbq	141(%r11), %rax
	movq	$528, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$147, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4458:
	movzbq	219(%r11), %rax
	movq	$544, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$147, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4457:
	movzbq	297(%r11), %rax
	movq	$560, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$147, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4456:
	movzbq	64(%r11), %rax
	movq	$512, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$148, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4455:
	movzbq	142(%r11), %rax
	movq	$528, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$148, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4454:
	movzbq	220(%r11), %rax
	movq	$544, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$148, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4453:
	movzbq	298(%r11), %rax
	movq	$560, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$148, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4452:
	movzbq	65(%r11), %rax
	movq	$512, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$149, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4451:
	movzbq	143(%r11), %rax
	movq	$528, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$149, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4450:
	movzbq	221(%r11), %rax
	movq	$544, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$149, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4449:
	movzbq	299(%r11), %rax
	movq	$560, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$149, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4448:
	movzbq	66(%r11), %rax
	movq	$512, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$150, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4447:
	movzbq	144(%r11), %rax
	movq	$528, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$150, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4446:
	movzbq	222(%r11), %rax
	movq	$544, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$150, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4445:
	movzbq	300(%r11), %rax
	movq	$560, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$150, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4444:
	movzbq	67(%r11), %rax
	movq	$512, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$151, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4443:
	movzbq	145(%r11), %rax
	movq	$528, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$151, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4442:
	movzbq	223(%r11), %rax
	movq	$544, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$151, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4441:
	movzbq	301(%r11), %rax
	movq	$560, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$151, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4440:
	movzbq	68(%r11), %rax
	movq	$512, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$152, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4439:
	movzbq	146(%r11), %rax
	movq	$528, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$152, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4438:
	movzbq	224(%r11), %rax
	movq	$544, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$152, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4437:
	movzbq	302(%r11), %rax
	movq	$560, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$152, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4436:
	movzbq	69(%r11), %rax
	movq	$512, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$153, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4435:
	movzbq	147(%r11), %rax
	movq	$528, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$153, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4434:
	movzbq	225(%r11), %rax
	movq	$544, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$153, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4433:
	movzbq	303(%r11), %rax
	movq	$560, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$153, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4432:
	movzbq	70(%r11), %rax
	movq	$512, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$154, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4431:
	movzbq	148(%r11), %rax
	movq	$528, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$154, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4430:
	movzbq	226(%r11), %rax
	movq	$544, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$154, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4429:
	movzbq	304(%r11), %rax
	movq	$560, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$154, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4428:
	movzbq	71(%r11), %rax
	movq	$512, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$155, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4427:
	movzbq	149(%r11), %rax
	movq	$528, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$155, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4426:
	movzbq	227(%r11), %rax
	movq	$544, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$155, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4425:
	movzbq	305(%r11), %rax
	movq	$560, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$155, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4424:
	movzbq	72(%r11), %rax
	movq	$512, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$156, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4423:
	movzbq	150(%r11), %rax
	movq	$528, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$156, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4422:
	movzbq	228(%r11), %rax
	movq	$544, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$156, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4421:
	movzbq	306(%r11), %rax
	movq	$560, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$156, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4420:
	movzbq	73(%r11), %rax
	movq	$512, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$157, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4419:
	movzbq	151(%r11), %rax
	movq	$528, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$157, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4418:
	movzbq	229(%r11), %rax
	movq	$544, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$157, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4417:
	movzbq	307(%r11), %rax
	movq	$560, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$157, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4416:
	movzbq	74(%r11), %rax
	movq	$512, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$158, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4415:
	movzbq	152(%r11), %rax
	movq	$528, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$158, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4414:
	movzbq	230(%r11), %rax
	movq	$544, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$158, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4413:
	movzbq	308(%r11), %rax
	movq	$560, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$158, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4412:
	movzbq	75(%r11), %rax
	movq	$512, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$159, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4411:
	movzbq	153(%r11), %rax
	movq	$528, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$159, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4410:
	movzbq	231(%r11), %rax
	movq	$544, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$159, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4409:
	movzbq	309(%r11), %rax
	movq	$560, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$159, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4408:
	movzbq	76(%r11), %rax
	movq	$512, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$160, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4407:
	movzbq	154(%r11), %rax
	movq	$528, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$160, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4406:
	movzbq	232(%r11), %rax
	movq	$544, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$160, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4405:
	movzbq	310(%r11), %rax
	movq	$560, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$160, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4404:
	movzbq	77(%r11), %rax
	movq	$512, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$161, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4403:
	movzbq	155(%r11), %rax
	movq	$528, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$161, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4402:
	movzbq	233(%r11), %rax
	movq	$544, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$161, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4401:
	movzbq	311(%r11), %rax
	movq	$560, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$161, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4400:
	movq	$9, %rdx
	jmp 	Lbitsliced_m_calculate_PS$4394
Lbitsliced_m_calculate_PS$4395:
	movzbq	(%r11,%rdx), %rax
	movq	$576, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$4399:
	movzbq	78(%r11,%rdx), %rax
	movq	$592, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$4398:
	movzbq	156(%r11,%rdx), %rax
	movq	$608, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$4397:
	movzbq	234(%r11,%rdx), %rax
	movq	$624, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$4396:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$4394:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$4395
	movzbq	60(%r11), %rax
	movq	$576, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$162, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4393:
	movzbq	138(%r11), %rax
	movq	$592, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$162, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4392:
	movzbq	216(%r11), %rax
	movq	$608, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$162, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4391:
	movzbq	294(%r11), %rax
	movq	$624, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$162, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4390:
	movzbq	61(%r11), %rax
	movq	$576, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$163, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4389:
	movzbq	139(%r11), %rax
	movq	$592, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$163, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4388:
	movzbq	217(%r11), %rax
	movq	$608, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$163, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4387:
	movzbq	295(%r11), %rax
	movq	$624, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$163, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4386:
	movzbq	62(%r11), %rax
	movq	$576, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$164, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4385:
	movzbq	140(%r11), %rax
	movq	$592, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$164, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4384:
	movzbq	218(%r11), %rax
	movq	$608, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$164, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4383:
	movzbq	296(%r11), %rax
	movq	$624, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$164, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4382:
	movzbq	63(%r11), %rax
	movq	$576, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$165, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4381:
	movzbq	141(%r11), %rax
	movq	$592, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$165, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4380:
	movzbq	219(%r11), %rax
	movq	$608, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$165, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4379:
	movzbq	297(%r11), %rax
	movq	$624, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$165, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4378:
	movzbq	64(%r11), %rax
	movq	$576, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$166, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4377:
	movzbq	142(%r11), %rax
	movq	$592, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$166, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4376:
	movzbq	220(%r11), %rax
	movq	$608, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$166, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4375:
	movzbq	298(%r11), %rax
	movq	$624, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$166, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4374:
	movzbq	65(%r11), %rax
	movq	$576, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$167, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4373:
	movzbq	143(%r11), %rax
	movq	$592, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$167, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4372:
	movzbq	221(%r11), %rax
	movq	$608, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$167, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4371:
	movzbq	299(%r11), %rax
	movq	$624, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$167, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4370:
	movzbq	66(%r11), %rax
	movq	$576, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$168, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4369:
	movzbq	144(%r11), %rax
	movq	$592, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$168, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4368:
	movzbq	222(%r11), %rax
	movq	$608, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$168, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4367:
	movzbq	300(%r11), %rax
	movq	$624, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$168, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4366:
	movzbq	67(%r11), %rax
	movq	$576, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$169, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4365:
	movzbq	145(%r11), %rax
	movq	$592, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$169, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4364:
	movzbq	223(%r11), %rax
	movq	$608, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$169, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4363:
	movzbq	301(%r11), %rax
	movq	$624, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$169, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4362:
	movzbq	68(%r11), %rax
	movq	$576, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$170, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4361:
	movzbq	146(%r11), %rax
	movq	$592, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$170, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4360:
	movzbq	224(%r11), %rax
	movq	$608, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$170, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4359:
	movzbq	302(%r11), %rax
	movq	$624, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$170, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4358:
	movzbq	69(%r11), %rax
	movq	$576, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$171, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4357:
	movzbq	147(%r11), %rax
	movq	$592, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$171, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4356:
	movzbq	225(%r11), %rax
	movq	$608, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$171, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4355:
	movzbq	303(%r11), %rax
	movq	$624, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$171, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4354:
	movzbq	70(%r11), %rax
	movq	$576, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$172, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4353:
	movzbq	148(%r11), %rax
	movq	$592, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$172, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4352:
	movzbq	226(%r11), %rax
	movq	$608, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$172, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4351:
	movzbq	304(%r11), %rax
	movq	$624, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$172, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4350:
	movzbq	71(%r11), %rax
	movq	$576, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$173, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4349:
	movzbq	149(%r11), %rax
	movq	$592, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$173, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4348:
	movzbq	227(%r11), %rax
	movq	$608, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$173, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4347:
	movzbq	305(%r11), %rax
	movq	$624, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$173, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4346:
	movzbq	72(%r11), %rax
	movq	$576, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$174, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4345:
	movzbq	150(%r11), %rax
	movq	$592, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$174, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4344:
	movzbq	228(%r11), %rax
	movq	$608, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$174, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4343:
	movzbq	306(%r11), %rax
	movq	$624, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$174, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4342:
	movzbq	73(%r11), %rax
	movq	$576, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$175, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4341:
	movzbq	151(%r11), %rax
	movq	$592, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$175, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4340:
	movzbq	229(%r11), %rax
	movq	$608, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$175, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4339:
	movzbq	307(%r11), %rax
	movq	$624, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$175, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4338:
	movzbq	74(%r11), %rax
	movq	$576, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$176, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4337:
	movzbq	152(%r11), %rax
	movq	$592, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$176, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4336:
	movzbq	230(%r11), %rax
	movq	$608, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$176, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4335:
	movzbq	308(%r11), %rax
	movq	$624, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$176, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4334:
	movzbq	75(%r11), %rax
	movq	$576, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$177, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4333:
	movzbq	153(%r11), %rax
	movq	$592, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$177, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4332:
	movzbq	231(%r11), %rax
	movq	$608, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$177, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4331:
	movzbq	309(%r11), %rax
	movq	$624, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$177, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4330:
	movzbq	76(%r11), %rax
	movq	$576, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$178, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4329:
	movzbq	154(%r11), %rax
	movq	$592, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$178, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4328:
	movzbq	232(%r11), %rax
	movq	$608, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$178, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4327:
	movzbq	310(%r11), %rax
	movq	$624, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$178, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4326:
	movzbq	77(%r11), %rax
	movq	$576, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$179, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4325:
	movzbq	155(%r11), %rax
	movq	$592, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$179, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4324:
	movzbq	233(%r11), %rax
	movq	$608, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$179, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4323:
	movzbq	311(%r11), %rax
	movq	$624, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$179, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4322:
	movq	$10, %rdx
	jmp 	Lbitsliced_m_calculate_PS$4316
Lbitsliced_m_calculate_PS$4317:
	movzbq	(%r11,%rdx), %rax
	movq	$640, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$4321:
	movzbq	78(%r11,%rdx), %rax
	movq	$656, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$4320:
	movzbq	156(%r11,%rdx), %rax
	movq	$672, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$4319:
	movzbq	234(%r11,%rdx), %rax
	movq	$688, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$4318:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$4316:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$4317
	movzbq	60(%r11), %rax
	movq	$640, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$180, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4315:
	movzbq	138(%r11), %rax
	movq	$656, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$180, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4314:
	movzbq	216(%r11), %rax
	movq	$672, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$180, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4313:
	movzbq	294(%r11), %rax
	movq	$688, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$180, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4312:
	movzbq	61(%r11), %rax
	movq	$640, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$181, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4311:
	movzbq	139(%r11), %rax
	movq	$656, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$181, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4310:
	movzbq	217(%r11), %rax
	movq	$672, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$181, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4309:
	movzbq	295(%r11), %rax
	movq	$688, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$181, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4308:
	movzbq	62(%r11), %rax
	movq	$640, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$182, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4307:
	movzbq	140(%r11), %rax
	movq	$656, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$182, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4306:
	movzbq	218(%r11), %rax
	movq	$672, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$182, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4305:
	movzbq	296(%r11), %rax
	movq	$688, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$182, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4304:
	movzbq	63(%r11), %rax
	movq	$640, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$183, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4303:
	movzbq	141(%r11), %rax
	movq	$656, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$183, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4302:
	movzbq	219(%r11), %rax
	movq	$672, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$183, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4301:
	movzbq	297(%r11), %rax
	movq	$688, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$183, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4300:
	movzbq	64(%r11), %rax
	movq	$640, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$184, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4299:
	movzbq	142(%r11), %rax
	movq	$656, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$184, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4298:
	movzbq	220(%r11), %rax
	movq	$672, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$184, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4297:
	movzbq	298(%r11), %rax
	movq	$688, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$184, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4296:
	movzbq	65(%r11), %rax
	movq	$640, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$185, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4295:
	movzbq	143(%r11), %rax
	movq	$656, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$185, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4294:
	movzbq	221(%r11), %rax
	movq	$672, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$185, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4293:
	movzbq	299(%r11), %rax
	movq	$688, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$185, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4292:
	movzbq	66(%r11), %rax
	movq	$640, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$186, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4291:
	movzbq	144(%r11), %rax
	movq	$656, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$186, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4290:
	movzbq	222(%r11), %rax
	movq	$672, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$186, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4289:
	movzbq	300(%r11), %rax
	movq	$688, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$186, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4288:
	movzbq	67(%r11), %rax
	movq	$640, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$187, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4287:
	movzbq	145(%r11), %rax
	movq	$656, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$187, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4286:
	movzbq	223(%r11), %rax
	movq	$672, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$187, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4285:
	movzbq	301(%r11), %rax
	movq	$688, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$187, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4284:
	movzbq	68(%r11), %rax
	movq	$640, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$188, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4283:
	movzbq	146(%r11), %rax
	movq	$656, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$188, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4282:
	movzbq	224(%r11), %rax
	movq	$672, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$188, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4281:
	movzbq	302(%r11), %rax
	movq	$688, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$188, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4280:
	movzbq	69(%r11), %rax
	movq	$640, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$189, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4279:
	movzbq	147(%r11), %rax
	movq	$656, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$189, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4278:
	movzbq	225(%r11), %rax
	movq	$672, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$189, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4277:
	movzbq	303(%r11), %rax
	movq	$688, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$189, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4276:
	movzbq	70(%r11), %rax
	movq	$640, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$190, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4275:
	movzbq	148(%r11), %rax
	movq	$656, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$190, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4274:
	movzbq	226(%r11), %rax
	movq	$672, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$190, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4273:
	movzbq	304(%r11), %rax
	movq	$688, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$190, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4272:
	movzbq	71(%r11), %rax
	movq	$640, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$191, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4271:
	movzbq	149(%r11), %rax
	movq	$656, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$191, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4270:
	movzbq	227(%r11), %rax
	movq	$672, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$191, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4269:
	movzbq	305(%r11), %rax
	movq	$688, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$191, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4268:
	movzbq	72(%r11), %rax
	movq	$640, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$192, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4267:
	movzbq	150(%r11), %rax
	movq	$656, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$192, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4266:
	movzbq	228(%r11), %rax
	movq	$672, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$192, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4265:
	movzbq	306(%r11), %rax
	movq	$688, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$192, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4264:
	movzbq	73(%r11), %rax
	movq	$640, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$193, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4263:
	movzbq	151(%r11), %rax
	movq	$656, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$193, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4262:
	movzbq	229(%r11), %rax
	movq	$672, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$193, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4261:
	movzbq	307(%r11), %rax
	movq	$688, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$193, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4260:
	movzbq	74(%r11), %rax
	movq	$640, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$194, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4259:
	movzbq	152(%r11), %rax
	movq	$656, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$194, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4258:
	movzbq	230(%r11), %rax
	movq	$672, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$194, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4257:
	movzbq	308(%r11), %rax
	movq	$688, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$194, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4256:
	movzbq	75(%r11), %rax
	movq	$640, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$195, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4255:
	movzbq	153(%r11), %rax
	movq	$656, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$195, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4254:
	movzbq	231(%r11), %rax
	movq	$672, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$195, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4253:
	movzbq	309(%r11), %rax
	movq	$688, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$195, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4252:
	movzbq	76(%r11), %rax
	movq	$640, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$196, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4251:
	movzbq	154(%r11), %rax
	movq	$656, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$196, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4250:
	movzbq	232(%r11), %rax
	movq	$672, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$196, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4249:
	movzbq	310(%r11), %rax
	movq	$688, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$196, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4248:
	movzbq	77(%r11), %rax
	movq	$640, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$197, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4247:
	movzbq	155(%r11), %rax
	movq	$656, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$197, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4246:
	movzbq	233(%r11), %rax
	movq	$672, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$197, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4245:
	movzbq	311(%r11), %rax
	movq	$688, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$197, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4244:
	movq	$11, %rdx
	jmp 	Lbitsliced_m_calculate_PS$4238
Lbitsliced_m_calculate_PS$4239:
	movzbq	(%r11,%rdx), %rax
	movq	$704, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$4243:
	movzbq	78(%r11,%rdx), %rax
	movq	$720, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$4242:
	movzbq	156(%r11,%rdx), %rax
	movq	$736, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$4241:
	movzbq	234(%r11,%rdx), %rax
	movq	$752, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$4240:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$4238:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$4239
	movzbq	60(%r11), %rax
	movq	$704, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$198, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4237:
	movzbq	138(%r11), %rax
	movq	$720, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$198, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4236:
	movzbq	216(%r11), %rax
	movq	$736, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$198, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4235:
	movzbq	294(%r11), %rax
	movq	$752, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$198, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4234:
	movzbq	61(%r11), %rax
	movq	$704, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$199, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4233:
	movzbq	139(%r11), %rax
	movq	$720, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$199, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4232:
	movzbq	217(%r11), %rax
	movq	$736, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$199, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4231:
	movzbq	295(%r11), %rax
	movq	$752, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$199, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4230:
	movzbq	62(%r11), %rax
	movq	$704, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$200, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4229:
	movzbq	140(%r11), %rax
	movq	$720, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$200, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4228:
	movzbq	218(%r11), %rax
	movq	$736, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$200, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4227:
	movzbq	296(%r11), %rax
	movq	$752, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$200, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4226:
	movzbq	63(%r11), %rax
	movq	$704, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$201, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4225:
	movzbq	141(%r11), %rax
	movq	$720, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$201, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4224:
	movzbq	219(%r11), %rax
	movq	$736, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$201, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4223:
	movzbq	297(%r11), %rax
	movq	$752, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$201, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4222:
	movzbq	64(%r11), %rax
	movq	$704, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$202, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4221:
	movzbq	142(%r11), %rax
	movq	$720, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$202, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4220:
	movzbq	220(%r11), %rax
	movq	$736, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$202, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4219:
	movzbq	298(%r11), %rax
	movq	$752, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$202, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4218:
	movzbq	65(%r11), %rax
	movq	$704, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$203, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4217:
	movzbq	143(%r11), %rax
	movq	$720, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$203, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4216:
	movzbq	221(%r11), %rax
	movq	$736, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$203, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4215:
	movzbq	299(%r11), %rax
	movq	$752, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$203, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4214:
	movzbq	66(%r11), %rax
	movq	$704, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$204, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4213:
	movzbq	144(%r11), %rax
	movq	$720, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$204, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4212:
	movzbq	222(%r11), %rax
	movq	$736, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$204, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4211:
	movzbq	300(%r11), %rax
	movq	$752, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$204, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4210:
	movzbq	67(%r11), %rax
	movq	$704, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$205, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4209:
	movzbq	145(%r11), %rax
	movq	$720, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$205, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4208:
	movzbq	223(%r11), %rax
	movq	$736, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$205, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4207:
	movzbq	301(%r11), %rax
	movq	$752, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$205, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4206:
	movzbq	68(%r11), %rax
	movq	$704, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$206, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4205:
	movzbq	146(%r11), %rax
	movq	$720, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$206, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4204:
	movzbq	224(%r11), %rax
	movq	$736, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$206, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4203:
	movzbq	302(%r11), %rax
	movq	$752, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$206, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4202:
	movzbq	69(%r11), %rax
	movq	$704, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$207, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4201:
	movzbq	147(%r11), %rax
	movq	$720, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$207, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4200:
	movzbq	225(%r11), %rax
	movq	$736, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$207, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4199:
	movzbq	303(%r11), %rax
	movq	$752, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$207, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4198:
	movzbq	70(%r11), %rax
	movq	$704, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$208, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4197:
	movzbq	148(%r11), %rax
	movq	$720, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$208, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4196:
	movzbq	226(%r11), %rax
	movq	$736, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$208, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4195:
	movzbq	304(%r11), %rax
	movq	$752, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$208, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4194:
	movzbq	71(%r11), %rax
	movq	$704, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$209, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4193:
	movzbq	149(%r11), %rax
	movq	$720, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$209, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4192:
	movzbq	227(%r11), %rax
	movq	$736, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$209, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4191:
	movzbq	305(%r11), %rax
	movq	$752, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$209, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4190:
	movzbq	72(%r11), %rax
	movq	$704, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$210, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4189:
	movzbq	150(%r11), %rax
	movq	$720, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$210, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4188:
	movzbq	228(%r11), %rax
	movq	$736, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$210, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4187:
	movzbq	306(%r11), %rax
	movq	$752, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$210, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4186:
	movzbq	73(%r11), %rax
	movq	$704, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$211, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4185:
	movzbq	151(%r11), %rax
	movq	$720, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$211, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4184:
	movzbq	229(%r11), %rax
	movq	$736, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$211, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4183:
	movzbq	307(%r11), %rax
	movq	$752, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$211, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4182:
	movzbq	74(%r11), %rax
	movq	$704, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$212, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4181:
	movzbq	152(%r11), %rax
	movq	$720, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$212, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4180:
	movzbq	230(%r11), %rax
	movq	$736, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$212, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4179:
	movzbq	308(%r11), %rax
	movq	$752, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$212, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4178:
	movzbq	75(%r11), %rax
	movq	$704, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$213, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4177:
	movzbq	153(%r11), %rax
	movq	$720, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$213, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4176:
	movzbq	231(%r11), %rax
	movq	$736, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$213, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4175:
	movzbq	309(%r11), %rax
	movq	$752, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$213, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4174:
	movzbq	76(%r11), %rax
	movq	$704, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$214, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4173:
	movzbq	154(%r11), %rax
	movq	$720, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$214, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4172:
	movzbq	232(%r11), %rax
	movq	$736, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$214, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4171:
	movzbq	310(%r11), %rax
	movq	$752, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$214, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4170:
	movzbq	77(%r11), %rax
	movq	$704, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$215, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4169:
	movzbq	155(%r11), %rax
	movq	$720, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$215, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4168:
	movzbq	233(%r11), %rax
	movq	$736, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$215, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4167:
	movzbq	311(%r11), %rax
	movq	$752, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$215, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4166:
	movq	$12, %rdx
	jmp 	Lbitsliced_m_calculate_PS$4160
Lbitsliced_m_calculate_PS$4161:
	movzbq	(%r11,%rdx), %rax
	movq	$768, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$4165:
	movzbq	78(%r11,%rdx), %rax
	movq	$784, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$4164:
	movzbq	156(%r11,%rdx), %rax
	movq	$800, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$4163:
	movzbq	234(%r11,%rdx), %rax
	movq	$816, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$4162:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$4160:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$4161
	movzbq	60(%r11), %rax
	movq	$768, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$216, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4159:
	movzbq	138(%r11), %rax
	movq	$784, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$216, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4158:
	movzbq	216(%r11), %rax
	movq	$800, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$216, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4157:
	movzbq	294(%r11), %rax
	movq	$816, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$216, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4156:
	movzbq	61(%r11), %rax
	movq	$768, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$217, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4155:
	movzbq	139(%r11), %rax
	movq	$784, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$217, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4154:
	movzbq	217(%r11), %rax
	movq	$800, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$217, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4153:
	movzbq	295(%r11), %rax
	movq	$816, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$217, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4152:
	movzbq	62(%r11), %rax
	movq	$768, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$218, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4151:
	movzbq	140(%r11), %rax
	movq	$784, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$218, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4150:
	movzbq	218(%r11), %rax
	movq	$800, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$218, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4149:
	movzbq	296(%r11), %rax
	movq	$816, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$218, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4148:
	movzbq	63(%r11), %rax
	movq	$768, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$219, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4147:
	movzbq	141(%r11), %rax
	movq	$784, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$219, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4146:
	movzbq	219(%r11), %rax
	movq	$800, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$219, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4145:
	movzbq	297(%r11), %rax
	movq	$816, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$219, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4144:
	movzbq	64(%r11), %rax
	movq	$768, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$220, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4143:
	movzbq	142(%r11), %rax
	movq	$784, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$220, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4142:
	movzbq	220(%r11), %rax
	movq	$800, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$220, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4141:
	movzbq	298(%r11), %rax
	movq	$816, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$220, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4140:
	movzbq	65(%r11), %rax
	movq	$768, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$221, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4139:
	movzbq	143(%r11), %rax
	movq	$784, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$221, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4138:
	movzbq	221(%r11), %rax
	movq	$800, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$221, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4137:
	movzbq	299(%r11), %rax
	movq	$816, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$221, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4136:
	movzbq	66(%r11), %rax
	movq	$768, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$222, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4135:
	movzbq	144(%r11), %rax
	movq	$784, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$222, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4134:
	movzbq	222(%r11), %rax
	movq	$800, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$222, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4133:
	movzbq	300(%r11), %rax
	movq	$816, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$222, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4132:
	movzbq	67(%r11), %rax
	movq	$768, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$223, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4131:
	movzbq	145(%r11), %rax
	movq	$784, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$223, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4130:
	movzbq	223(%r11), %rax
	movq	$800, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$223, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4129:
	movzbq	301(%r11), %rax
	movq	$816, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$223, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4128:
	movzbq	68(%r11), %rax
	movq	$768, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$224, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4127:
	movzbq	146(%r11), %rax
	movq	$784, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$224, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4126:
	movzbq	224(%r11), %rax
	movq	$800, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$224, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4125:
	movzbq	302(%r11), %rax
	movq	$816, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$224, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4124:
	movzbq	69(%r11), %rax
	movq	$768, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$225, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4123:
	movzbq	147(%r11), %rax
	movq	$784, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$225, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4122:
	movzbq	225(%r11), %rax
	movq	$800, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$225, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4121:
	movzbq	303(%r11), %rax
	movq	$816, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$225, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4120:
	movzbq	70(%r11), %rax
	movq	$768, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$226, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4119:
	movzbq	148(%r11), %rax
	movq	$784, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$226, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4118:
	movzbq	226(%r11), %rax
	movq	$800, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$226, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4117:
	movzbq	304(%r11), %rax
	movq	$816, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$226, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4116:
	movzbq	71(%r11), %rax
	movq	$768, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$227, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4115:
	movzbq	149(%r11), %rax
	movq	$784, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$227, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4114:
	movzbq	227(%r11), %rax
	movq	$800, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$227, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4113:
	movzbq	305(%r11), %rax
	movq	$816, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$227, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4112:
	movzbq	72(%r11), %rax
	movq	$768, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$228, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4111:
	movzbq	150(%r11), %rax
	movq	$784, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$228, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4110:
	movzbq	228(%r11), %rax
	movq	$800, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$228, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4109:
	movzbq	306(%r11), %rax
	movq	$816, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$228, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4108:
	movzbq	73(%r11), %rax
	movq	$768, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$229, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4107:
	movzbq	151(%r11), %rax
	movq	$784, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$229, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4106:
	movzbq	229(%r11), %rax
	movq	$800, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$229, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4105:
	movzbq	307(%r11), %rax
	movq	$816, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$229, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4104:
	movzbq	74(%r11), %rax
	movq	$768, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$230, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4103:
	movzbq	152(%r11), %rax
	movq	$784, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$230, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4102:
	movzbq	230(%r11), %rax
	movq	$800, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$230, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4101:
	movzbq	308(%r11), %rax
	movq	$816, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$230, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4100:
	movzbq	75(%r11), %rax
	movq	$768, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$231, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4099:
	movzbq	153(%r11), %rax
	movq	$784, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$231, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4098:
	movzbq	231(%r11), %rax
	movq	$800, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$231, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4097:
	movzbq	309(%r11), %rax
	movq	$816, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$231, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4096:
	movzbq	76(%r11), %rax
	movq	$768, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$232, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4095:
	movzbq	154(%r11), %rax
	movq	$784, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$232, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4094:
	movzbq	232(%r11), %rax
	movq	$800, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$232, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4093:
	movzbq	310(%r11), %rax
	movq	$816, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$232, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4092:
	movzbq	77(%r11), %rax
	movq	$768, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$233, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4091:
	movzbq	155(%r11), %rax
	movq	$784, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$233, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4090:
	movzbq	233(%r11), %rax
	movq	$800, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$233, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4089:
	movzbq	311(%r11), %rax
	movq	$816, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$233, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4088:
	movq	$13, %rdx
	jmp 	Lbitsliced_m_calculate_PS$4082
Lbitsliced_m_calculate_PS$4083:
	movzbq	(%r11,%rdx), %rax
	movq	$832, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$4087:
	movzbq	78(%r11,%rdx), %rax
	movq	$848, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$4086:
	movzbq	156(%r11,%rdx), %rax
	movq	$864, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$4085:
	movzbq	234(%r11,%rdx), %rax
	movq	$880, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$4084:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$4082:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$4083
	movzbq	60(%r11), %rax
	movq	$832, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$234, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4081:
	movzbq	138(%r11), %rax
	movq	$848, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$234, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4080:
	movzbq	216(%r11), %rax
	movq	$864, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$234, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4079:
	movzbq	294(%r11), %rax
	movq	$880, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$234, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4078:
	movzbq	61(%r11), %rax
	movq	$832, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$235, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4077:
	movzbq	139(%r11), %rax
	movq	$848, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$235, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4076:
	movzbq	217(%r11), %rax
	movq	$864, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$235, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4075:
	movzbq	295(%r11), %rax
	movq	$880, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$235, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4074:
	movzbq	62(%r11), %rax
	movq	$832, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$236, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4073:
	movzbq	140(%r11), %rax
	movq	$848, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$236, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4072:
	movzbq	218(%r11), %rax
	movq	$864, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$236, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4071:
	movzbq	296(%r11), %rax
	movq	$880, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$236, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4070:
	movzbq	63(%r11), %rax
	movq	$832, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$237, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4069:
	movzbq	141(%r11), %rax
	movq	$848, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$237, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4068:
	movzbq	219(%r11), %rax
	movq	$864, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$237, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4067:
	movzbq	297(%r11), %rax
	movq	$880, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$237, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4066:
	movzbq	64(%r11), %rax
	movq	$832, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$238, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4065:
	movzbq	142(%r11), %rax
	movq	$848, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$238, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4064:
	movzbq	220(%r11), %rax
	movq	$864, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$238, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4063:
	movzbq	298(%r11), %rax
	movq	$880, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$238, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4062:
	movzbq	65(%r11), %rax
	movq	$832, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$239, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4061:
	movzbq	143(%r11), %rax
	movq	$848, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$239, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4060:
	movzbq	221(%r11), %rax
	movq	$864, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$239, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4059:
	movzbq	299(%r11), %rax
	movq	$880, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$239, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4058:
	movzbq	66(%r11), %rax
	movq	$832, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$240, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4057:
	movzbq	144(%r11), %rax
	movq	$848, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$240, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4056:
	movzbq	222(%r11), %rax
	movq	$864, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$240, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4055:
	movzbq	300(%r11), %rax
	movq	$880, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$240, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4054:
	movzbq	67(%r11), %rax
	movq	$832, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$241, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4053:
	movzbq	145(%r11), %rax
	movq	$848, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$241, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4052:
	movzbq	223(%r11), %rax
	movq	$864, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$241, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4051:
	movzbq	301(%r11), %rax
	movq	$880, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$241, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4050:
	movzbq	68(%r11), %rax
	movq	$832, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$242, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4049:
	movzbq	146(%r11), %rax
	movq	$848, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$242, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4048:
	movzbq	224(%r11), %rax
	movq	$864, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$242, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4047:
	movzbq	302(%r11), %rax
	movq	$880, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$242, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4046:
	movzbq	69(%r11), %rax
	movq	$832, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$243, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4045:
	movzbq	147(%r11), %rax
	movq	$848, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$243, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4044:
	movzbq	225(%r11), %rax
	movq	$864, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$243, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4043:
	movzbq	303(%r11), %rax
	movq	$880, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$243, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4042:
	movzbq	70(%r11), %rax
	movq	$832, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$244, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4041:
	movzbq	148(%r11), %rax
	movq	$848, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$244, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4040:
	movzbq	226(%r11), %rax
	movq	$864, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$244, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4039:
	movzbq	304(%r11), %rax
	movq	$880, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$244, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4038:
	movzbq	71(%r11), %rax
	movq	$832, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$245, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4037:
	movzbq	149(%r11), %rax
	movq	$848, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$245, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4036:
	movzbq	227(%r11), %rax
	movq	$864, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$245, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4035:
	movzbq	305(%r11), %rax
	movq	$880, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$245, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4034:
	movzbq	72(%r11), %rax
	movq	$832, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$246, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4033:
	movzbq	150(%r11), %rax
	movq	$848, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$246, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4032:
	movzbq	228(%r11), %rax
	movq	$864, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$246, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4031:
	movzbq	306(%r11), %rax
	movq	$880, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$246, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4030:
	movzbq	73(%r11), %rax
	movq	$832, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$247, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4029:
	movzbq	151(%r11), %rax
	movq	$848, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$247, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4028:
	movzbq	229(%r11), %rax
	movq	$864, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$247, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4027:
	movzbq	307(%r11), %rax
	movq	$880, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$247, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4026:
	movzbq	74(%r11), %rax
	movq	$832, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$248, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4025:
	movzbq	152(%r11), %rax
	movq	$848, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$248, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4024:
	movzbq	230(%r11), %rax
	movq	$864, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$248, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4023:
	movzbq	308(%r11), %rax
	movq	$880, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$248, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4022:
	movzbq	75(%r11), %rax
	movq	$832, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$249, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4021:
	movzbq	153(%r11), %rax
	movq	$848, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$249, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4020:
	movzbq	231(%r11), %rax
	movq	$864, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$249, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4019:
	movzbq	309(%r11), %rax
	movq	$880, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$249, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4018:
	movzbq	76(%r11), %rax
	movq	$832, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$250, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4017:
	movzbq	154(%r11), %rax
	movq	$848, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$250, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4016:
	movzbq	232(%r11), %rax
	movq	$864, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$250, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4015:
	movzbq	310(%r11), %rax
	movq	$880, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$250, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4014:
	movzbq	77(%r11), %rax
	movq	$832, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$251, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4013:
	movzbq	155(%r11), %rax
	movq	$848, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$251, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4012:
	movzbq	233(%r11), %rax
	movq	$864, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$251, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4011:
	movzbq	311(%r11), %rax
	movq	$880, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$251, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4010:
	movq	$14, %rdx
	jmp 	Lbitsliced_m_calculate_PS$4004
Lbitsliced_m_calculate_PS$4005:
	movzbq	(%r11,%rdx), %rax
	movq	$896, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$4009:
	movzbq	78(%r11,%rdx), %rax
	movq	$912, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$4008:
	movzbq	156(%r11,%rdx), %rax
	movq	$928, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$4007:
	movzbq	234(%r11,%rdx), %rax
	movq	$944, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$4006:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$4004:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$4005
	movzbq	60(%r11), %rax
	movq	$896, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$252, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4003:
	movzbq	138(%r11), %rax
	movq	$912, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$252, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4002:
	movzbq	216(%r11), %rax
	movq	$928, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$252, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4001:
	movzbq	294(%r11), %rax
	movq	$944, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$252, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$4000:
	movzbq	61(%r11), %rax
	movq	$896, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$253, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3999:
	movzbq	139(%r11), %rax
	movq	$912, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$253, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3998:
	movzbq	217(%r11), %rax
	movq	$928, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$253, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3997:
	movzbq	295(%r11), %rax
	movq	$944, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$253, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3996:
	movzbq	62(%r11), %rax
	movq	$896, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$254, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3995:
	movzbq	140(%r11), %rax
	movq	$912, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$254, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3994:
	movzbq	218(%r11), %rax
	movq	$928, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$254, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3993:
	movzbq	296(%r11), %rax
	movq	$944, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$254, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3992:
	movzbq	63(%r11), %rax
	movq	$896, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$255, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3991:
	movzbq	141(%r11), %rax
	movq	$912, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$255, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3990:
	movzbq	219(%r11), %rax
	movq	$928, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$255, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3989:
	movzbq	297(%r11), %rax
	movq	$944, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$255, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3988:
	movzbq	64(%r11), %rax
	movq	$896, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$256, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3987:
	movzbq	142(%r11), %rax
	movq	$912, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$256, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3986:
	movzbq	220(%r11), %rax
	movq	$928, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$256, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3985:
	movzbq	298(%r11), %rax
	movq	$944, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$256, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3984:
	movzbq	65(%r11), %rax
	movq	$896, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$257, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3983:
	movzbq	143(%r11), %rax
	movq	$912, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$257, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3982:
	movzbq	221(%r11), %rax
	movq	$928, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$257, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3981:
	movzbq	299(%r11), %rax
	movq	$944, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$257, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3980:
	movzbq	66(%r11), %rax
	movq	$896, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$258, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3979:
	movzbq	144(%r11), %rax
	movq	$912, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$258, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3978:
	movzbq	222(%r11), %rax
	movq	$928, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$258, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3977:
	movzbq	300(%r11), %rax
	movq	$944, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$258, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3976:
	movzbq	67(%r11), %rax
	movq	$896, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$259, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3975:
	movzbq	145(%r11), %rax
	movq	$912, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$259, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3974:
	movzbq	223(%r11), %rax
	movq	$928, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$259, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3973:
	movzbq	301(%r11), %rax
	movq	$944, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$259, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3972:
	movzbq	68(%r11), %rax
	movq	$896, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$260, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3971:
	movzbq	146(%r11), %rax
	movq	$912, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$260, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3970:
	movzbq	224(%r11), %rax
	movq	$928, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$260, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3969:
	movzbq	302(%r11), %rax
	movq	$944, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$260, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3968:
	movzbq	69(%r11), %rax
	movq	$896, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$261, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3967:
	movzbq	147(%r11), %rax
	movq	$912, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$261, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3966:
	movzbq	225(%r11), %rax
	movq	$928, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$261, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3965:
	movzbq	303(%r11), %rax
	movq	$944, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$261, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3964:
	movzbq	70(%r11), %rax
	movq	$896, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$262, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3963:
	movzbq	148(%r11), %rax
	movq	$912, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$262, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3962:
	movzbq	226(%r11), %rax
	movq	$928, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$262, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3961:
	movzbq	304(%r11), %rax
	movq	$944, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$262, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3960:
	movzbq	71(%r11), %rax
	movq	$896, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$263, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3959:
	movzbq	149(%r11), %rax
	movq	$912, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$263, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3958:
	movzbq	227(%r11), %rax
	movq	$928, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$263, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3957:
	movzbq	305(%r11), %rax
	movq	$944, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$263, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3956:
	movzbq	72(%r11), %rax
	movq	$896, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$264, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3955:
	movzbq	150(%r11), %rax
	movq	$912, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$264, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3954:
	movzbq	228(%r11), %rax
	movq	$928, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$264, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3953:
	movzbq	306(%r11), %rax
	movq	$944, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$264, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3952:
	movzbq	73(%r11), %rax
	movq	$896, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$265, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3951:
	movzbq	151(%r11), %rax
	movq	$912, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$265, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3950:
	movzbq	229(%r11), %rax
	movq	$928, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$265, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3949:
	movzbq	307(%r11), %rax
	movq	$944, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$265, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3948:
	movzbq	74(%r11), %rax
	movq	$896, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$266, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3947:
	movzbq	152(%r11), %rax
	movq	$912, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$266, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3946:
	movzbq	230(%r11), %rax
	movq	$928, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$266, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3945:
	movzbq	308(%r11), %rax
	movq	$944, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$266, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3944:
	movzbq	75(%r11), %rax
	movq	$896, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$267, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3943:
	movzbq	153(%r11), %rax
	movq	$912, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$267, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3942:
	movzbq	231(%r11), %rax
	movq	$928, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$267, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3941:
	movzbq	309(%r11), %rax
	movq	$944, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$267, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3940:
	movzbq	76(%r11), %rax
	movq	$896, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$268, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3939:
	movzbq	154(%r11), %rax
	movq	$912, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$268, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3938:
	movzbq	232(%r11), %rax
	movq	$928, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$268, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3937:
	movzbq	310(%r11), %rax
	movq	$944, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$268, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3936:
	movzbq	77(%r11), %rax
	movq	$896, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$269, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3935:
	movzbq	155(%r11), %rax
	movq	$912, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$269, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3934:
	movzbq	233(%r11), %rax
	movq	$928, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$269, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3933:
	movzbq	311(%r11), %rax
	movq	$944, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$269, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3932:
	movq	$15, %rdx
	jmp 	Lbitsliced_m_calculate_PS$3926
Lbitsliced_m_calculate_PS$3927:
	movzbq	(%r11,%rdx), %rax
	movq	$960, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$3931:
	movzbq	78(%r11,%rdx), %rax
	movq	$976, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$3930:
	movzbq	156(%r11,%rdx), %rax
	movq	$992, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$3929:
	movzbq	234(%r11,%rdx), %rax
	movq	$1008, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$3928:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$3926:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$3927
	movzbq	60(%r11), %rax
	movq	$960, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$270, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3925:
	movzbq	138(%r11), %rax
	movq	$976, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$270, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3924:
	movzbq	216(%r11), %rax
	movq	$992, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$270, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3923:
	movzbq	294(%r11), %rax
	movq	$1008, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$270, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3922:
	movzbq	61(%r11), %rax
	movq	$960, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$271, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3921:
	movzbq	139(%r11), %rax
	movq	$976, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$271, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3920:
	movzbq	217(%r11), %rax
	movq	$992, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$271, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3919:
	movzbq	295(%r11), %rax
	movq	$1008, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$271, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3918:
	movzbq	62(%r11), %rax
	movq	$960, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$272, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3917:
	movzbq	140(%r11), %rax
	movq	$976, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$272, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3916:
	movzbq	218(%r11), %rax
	movq	$992, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$272, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3915:
	movzbq	296(%r11), %rax
	movq	$1008, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$272, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3914:
	movzbq	63(%r11), %rax
	movq	$960, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$273, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3913:
	movzbq	141(%r11), %rax
	movq	$976, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$273, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3912:
	movzbq	219(%r11), %rax
	movq	$992, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$273, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3911:
	movzbq	297(%r11), %rax
	movq	$1008, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$273, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3910:
	movzbq	64(%r11), %rax
	movq	$960, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$274, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3909:
	movzbq	142(%r11), %rax
	movq	$976, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$274, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3908:
	movzbq	220(%r11), %rax
	movq	$992, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$274, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3907:
	movzbq	298(%r11), %rax
	movq	$1008, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$274, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3906:
	movzbq	65(%r11), %rax
	movq	$960, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$275, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3905:
	movzbq	143(%r11), %rax
	movq	$976, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$275, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3904:
	movzbq	221(%r11), %rax
	movq	$992, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$275, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3903:
	movzbq	299(%r11), %rax
	movq	$1008, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$275, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3902:
	movzbq	66(%r11), %rax
	movq	$960, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$276, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3901:
	movzbq	144(%r11), %rax
	movq	$976, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$276, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3900:
	movzbq	222(%r11), %rax
	movq	$992, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$276, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3899:
	movzbq	300(%r11), %rax
	movq	$1008, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$276, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3898:
	movzbq	67(%r11), %rax
	movq	$960, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$277, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3897:
	movzbq	145(%r11), %rax
	movq	$976, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$277, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3896:
	movzbq	223(%r11), %rax
	movq	$992, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$277, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3895:
	movzbq	301(%r11), %rax
	movq	$1008, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$277, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3894:
	movzbq	68(%r11), %rax
	movq	$960, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$278, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3893:
	movzbq	146(%r11), %rax
	movq	$976, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$278, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3892:
	movzbq	224(%r11), %rax
	movq	$992, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$278, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3891:
	movzbq	302(%r11), %rax
	movq	$1008, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$278, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3890:
	movzbq	69(%r11), %rax
	movq	$960, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$279, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3889:
	movzbq	147(%r11), %rax
	movq	$976, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$279, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3888:
	movzbq	225(%r11), %rax
	movq	$992, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$279, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3887:
	movzbq	303(%r11), %rax
	movq	$1008, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$279, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3886:
	movzbq	70(%r11), %rax
	movq	$960, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$280, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3885:
	movzbq	148(%r11), %rax
	movq	$976, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$280, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3884:
	movzbq	226(%r11), %rax
	movq	$992, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$280, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3883:
	movzbq	304(%r11), %rax
	movq	$1008, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$280, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3882:
	movzbq	71(%r11), %rax
	movq	$960, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$281, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3881:
	movzbq	149(%r11), %rax
	movq	$976, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$281, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3880:
	movzbq	227(%r11), %rax
	movq	$992, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$281, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3879:
	movzbq	305(%r11), %rax
	movq	$1008, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$281, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3878:
	movzbq	72(%r11), %rax
	movq	$960, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$282, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3877:
	movzbq	150(%r11), %rax
	movq	$976, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$282, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3876:
	movzbq	228(%r11), %rax
	movq	$992, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$282, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3875:
	movzbq	306(%r11), %rax
	movq	$1008, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$282, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3874:
	movzbq	73(%r11), %rax
	movq	$960, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$283, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3873:
	movzbq	151(%r11), %rax
	movq	$976, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$283, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3872:
	movzbq	229(%r11), %rax
	movq	$992, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$283, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3871:
	movzbq	307(%r11), %rax
	movq	$1008, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$283, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3870:
	movzbq	74(%r11), %rax
	movq	$960, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$284, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3869:
	movzbq	152(%r11), %rax
	movq	$976, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$284, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3868:
	movzbq	230(%r11), %rax
	movq	$992, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$284, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3867:
	movzbq	308(%r11), %rax
	movq	$1008, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$284, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3866:
	movzbq	75(%r11), %rax
	movq	$960, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$285, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3865:
	movzbq	153(%r11), %rax
	movq	$976, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$285, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3864:
	movzbq	231(%r11), %rax
	movq	$992, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$285, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3863:
	movzbq	309(%r11), %rax
	movq	$1008, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$285, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3862:
	movzbq	76(%r11), %rax
	movq	$960, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$286, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3861:
	movzbq	154(%r11), %rax
	movq	$976, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$286, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3860:
	movzbq	232(%r11), %rax
	movq	$992, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$286, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3859:
	movzbq	310(%r11), %rax
	movq	$1008, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$286, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3858:
	movzbq	77(%r11), %rax
	movq	$960, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$287, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3857:
	movzbq	155(%r11), %rax
	movq	$976, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$287, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3856:
	movzbq	233(%r11), %rax
	movq	$992, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$287, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3855:
	movzbq	311(%r11), %rax
	movq	$1008, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$287, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3854:
	movq	$16, %rdx
	jmp 	Lbitsliced_m_calculate_PS$3848
Lbitsliced_m_calculate_PS$3849:
	movzbq	(%r11,%rdx), %rax
	movq	$1024, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$3853:
	movzbq	78(%r11,%rdx), %rax
	movq	$1040, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$3852:
	movzbq	156(%r11,%rdx), %rax
	movq	$1056, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$3851:
	movzbq	234(%r11,%rdx), %rax
	movq	$1072, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$3850:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$3848:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$3849
	movzbq	60(%r11), %rax
	movq	$1024, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$288, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3847:
	movzbq	138(%r11), %rax
	movq	$1040, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$288, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3846:
	movzbq	216(%r11), %rax
	movq	$1056, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$288, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3845:
	movzbq	294(%r11), %rax
	movq	$1072, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$288, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3844:
	movzbq	61(%r11), %rax
	movq	$1024, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$289, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3843:
	movzbq	139(%r11), %rax
	movq	$1040, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$289, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3842:
	movzbq	217(%r11), %rax
	movq	$1056, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$289, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3841:
	movzbq	295(%r11), %rax
	movq	$1072, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$289, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3840:
	movzbq	62(%r11), %rax
	movq	$1024, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$290, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3839:
	movzbq	140(%r11), %rax
	movq	$1040, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$290, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3838:
	movzbq	218(%r11), %rax
	movq	$1056, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$290, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3837:
	movzbq	296(%r11), %rax
	movq	$1072, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$290, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3836:
	movzbq	63(%r11), %rax
	movq	$1024, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$291, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3835:
	movzbq	141(%r11), %rax
	movq	$1040, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$291, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3834:
	movzbq	219(%r11), %rax
	movq	$1056, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$291, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3833:
	movzbq	297(%r11), %rax
	movq	$1072, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$291, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3832:
	movzbq	64(%r11), %rax
	movq	$1024, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$292, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3831:
	movzbq	142(%r11), %rax
	movq	$1040, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$292, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3830:
	movzbq	220(%r11), %rax
	movq	$1056, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$292, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3829:
	movzbq	298(%r11), %rax
	movq	$1072, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$292, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3828:
	movzbq	65(%r11), %rax
	movq	$1024, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$293, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3827:
	movzbq	143(%r11), %rax
	movq	$1040, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$293, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3826:
	movzbq	221(%r11), %rax
	movq	$1056, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$293, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3825:
	movzbq	299(%r11), %rax
	movq	$1072, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$293, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3824:
	movzbq	66(%r11), %rax
	movq	$1024, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$294, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3823:
	movzbq	144(%r11), %rax
	movq	$1040, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$294, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3822:
	movzbq	222(%r11), %rax
	movq	$1056, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$294, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3821:
	movzbq	300(%r11), %rax
	movq	$1072, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$294, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3820:
	movzbq	67(%r11), %rax
	movq	$1024, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$295, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3819:
	movzbq	145(%r11), %rax
	movq	$1040, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$295, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3818:
	movzbq	223(%r11), %rax
	movq	$1056, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$295, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3817:
	movzbq	301(%r11), %rax
	movq	$1072, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$295, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3816:
	movzbq	68(%r11), %rax
	movq	$1024, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$296, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3815:
	movzbq	146(%r11), %rax
	movq	$1040, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$296, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3814:
	movzbq	224(%r11), %rax
	movq	$1056, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$296, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3813:
	movzbq	302(%r11), %rax
	movq	$1072, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$296, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3812:
	movzbq	69(%r11), %rax
	movq	$1024, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$297, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3811:
	movzbq	147(%r11), %rax
	movq	$1040, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$297, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3810:
	movzbq	225(%r11), %rax
	movq	$1056, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$297, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3809:
	movzbq	303(%r11), %rax
	movq	$1072, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$297, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3808:
	movzbq	70(%r11), %rax
	movq	$1024, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$298, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3807:
	movzbq	148(%r11), %rax
	movq	$1040, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$298, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3806:
	movzbq	226(%r11), %rax
	movq	$1056, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$298, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3805:
	movzbq	304(%r11), %rax
	movq	$1072, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$298, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3804:
	movzbq	71(%r11), %rax
	movq	$1024, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$299, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3803:
	movzbq	149(%r11), %rax
	movq	$1040, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$299, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3802:
	movzbq	227(%r11), %rax
	movq	$1056, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$299, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3801:
	movzbq	305(%r11), %rax
	movq	$1072, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$299, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3800:
	movzbq	72(%r11), %rax
	movq	$1024, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$300, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3799:
	movzbq	150(%r11), %rax
	movq	$1040, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$300, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3798:
	movzbq	228(%r11), %rax
	movq	$1056, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$300, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3797:
	movzbq	306(%r11), %rax
	movq	$1072, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$300, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3796:
	movzbq	73(%r11), %rax
	movq	$1024, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$301, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3795:
	movzbq	151(%r11), %rax
	movq	$1040, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$301, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3794:
	movzbq	229(%r11), %rax
	movq	$1056, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$301, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3793:
	movzbq	307(%r11), %rax
	movq	$1072, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$301, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3792:
	movzbq	74(%r11), %rax
	movq	$1024, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$302, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3791:
	movzbq	152(%r11), %rax
	movq	$1040, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$302, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3790:
	movzbq	230(%r11), %rax
	movq	$1056, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$302, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3789:
	movzbq	308(%r11), %rax
	movq	$1072, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$302, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3788:
	movzbq	75(%r11), %rax
	movq	$1024, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$303, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3787:
	movzbq	153(%r11), %rax
	movq	$1040, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$303, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3786:
	movzbq	231(%r11), %rax
	movq	$1056, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$303, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3785:
	movzbq	309(%r11), %rax
	movq	$1072, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$303, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3784:
	movzbq	76(%r11), %rax
	movq	$1024, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$304, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3783:
	movzbq	154(%r11), %rax
	movq	$1040, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$304, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3782:
	movzbq	232(%r11), %rax
	movq	$1056, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$304, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3781:
	movzbq	310(%r11), %rax
	movq	$1072, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$304, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3780:
	movzbq	77(%r11), %rax
	movq	$1024, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$305, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3779:
	movzbq	155(%r11), %rax
	movq	$1040, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$305, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3778:
	movzbq	233(%r11), %rax
	movq	$1056, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$305, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3777:
	movzbq	311(%r11), %rax
	movq	$1072, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$305, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3776:
	movq	$17, %rdx
	jmp 	Lbitsliced_m_calculate_PS$3770
Lbitsliced_m_calculate_PS$3771:
	movzbq	(%r11,%rdx), %rax
	movq	$1088, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$3775:
	movzbq	78(%r11,%rdx), %rax
	movq	$1104, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$3774:
	movzbq	156(%r11,%rdx), %rax
	movq	$1120, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$3773:
	movzbq	234(%r11,%rdx), %rax
	movq	$1136, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$3772:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$3770:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$3771
	movzbq	60(%r11), %rax
	movq	$1088, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$306, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3769:
	movzbq	138(%r11), %rax
	movq	$1104, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$306, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3768:
	movzbq	216(%r11), %rax
	movq	$1120, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$306, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3767:
	movzbq	294(%r11), %rax
	movq	$1136, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$306, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3766:
	movzbq	61(%r11), %rax
	movq	$1088, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$307, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3765:
	movzbq	139(%r11), %rax
	movq	$1104, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$307, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3764:
	movzbq	217(%r11), %rax
	movq	$1120, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$307, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3763:
	movzbq	295(%r11), %rax
	movq	$1136, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$307, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3762:
	movzbq	62(%r11), %rax
	movq	$1088, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$308, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3761:
	movzbq	140(%r11), %rax
	movq	$1104, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$308, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3760:
	movzbq	218(%r11), %rax
	movq	$1120, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$308, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3759:
	movzbq	296(%r11), %rax
	movq	$1136, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$308, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3758:
	movzbq	63(%r11), %rax
	movq	$1088, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$309, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3757:
	movzbq	141(%r11), %rax
	movq	$1104, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$309, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3756:
	movzbq	219(%r11), %rax
	movq	$1120, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$309, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3755:
	movzbq	297(%r11), %rax
	movq	$1136, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$309, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3754:
	movzbq	64(%r11), %rax
	movq	$1088, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$310, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3753:
	movzbq	142(%r11), %rax
	movq	$1104, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$310, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3752:
	movzbq	220(%r11), %rax
	movq	$1120, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$310, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3751:
	movzbq	298(%r11), %rax
	movq	$1136, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$310, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3750:
	movzbq	65(%r11), %rax
	movq	$1088, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$311, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3749:
	movzbq	143(%r11), %rax
	movq	$1104, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$311, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3748:
	movzbq	221(%r11), %rax
	movq	$1120, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$311, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3747:
	movzbq	299(%r11), %rax
	movq	$1136, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$311, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3746:
	movzbq	66(%r11), %rax
	movq	$1088, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$312, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3745:
	movzbq	144(%r11), %rax
	movq	$1104, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$312, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3744:
	movzbq	222(%r11), %rax
	movq	$1120, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$312, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3743:
	movzbq	300(%r11), %rax
	movq	$1136, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$312, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3742:
	movzbq	67(%r11), %rax
	movq	$1088, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$313, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3741:
	movzbq	145(%r11), %rax
	movq	$1104, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$313, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3740:
	movzbq	223(%r11), %rax
	movq	$1120, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$313, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3739:
	movzbq	301(%r11), %rax
	movq	$1136, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$313, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3738:
	movzbq	68(%r11), %rax
	movq	$1088, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$314, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3737:
	movzbq	146(%r11), %rax
	movq	$1104, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$314, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3736:
	movzbq	224(%r11), %rax
	movq	$1120, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$314, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3735:
	movzbq	302(%r11), %rax
	movq	$1136, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$314, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3734:
	movzbq	69(%r11), %rax
	movq	$1088, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$315, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3733:
	movzbq	147(%r11), %rax
	movq	$1104, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$315, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3732:
	movzbq	225(%r11), %rax
	movq	$1120, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$315, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3731:
	movzbq	303(%r11), %rax
	movq	$1136, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$315, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3730:
	movzbq	70(%r11), %rax
	movq	$1088, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$316, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3729:
	movzbq	148(%r11), %rax
	movq	$1104, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$316, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3728:
	movzbq	226(%r11), %rax
	movq	$1120, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$316, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3727:
	movzbq	304(%r11), %rax
	movq	$1136, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$316, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3726:
	movzbq	71(%r11), %rax
	movq	$1088, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$317, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3725:
	movzbq	149(%r11), %rax
	movq	$1104, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$317, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3724:
	movzbq	227(%r11), %rax
	movq	$1120, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$317, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3723:
	movzbq	305(%r11), %rax
	movq	$1136, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$317, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3722:
	movzbq	72(%r11), %rax
	movq	$1088, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$318, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3721:
	movzbq	150(%r11), %rax
	movq	$1104, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$318, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3720:
	movzbq	228(%r11), %rax
	movq	$1120, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$318, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3719:
	movzbq	306(%r11), %rax
	movq	$1136, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$318, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3718:
	movzbq	73(%r11), %rax
	movq	$1088, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$319, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3717:
	movzbq	151(%r11), %rax
	movq	$1104, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$319, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3716:
	movzbq	229(%r11), %rax
	movq	$1120, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$319, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3715:
	movzbq	307(%r11), %rax
	movq	$1136, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$319, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3714:
	movzbq	74(%r11), %rax
	movq	$1088, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$320, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3713:
	movzbq	152(%r11), %rax
	movq	$1104, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$320, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3712:
	movzbq	230(%r11), %rax
	movq	$1120, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$320, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3711:
	movzbq	308(%r11), %rax
	movq	$1136, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$320, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3710:
	movzbq	75(%r11), %rax
	movq	$1088, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$321, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3709:
	movzbq	153(%r11), %rax
	movq	$1104, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$321, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3708:
	movzbq	231(%r11), %rax
	movq	$1120, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$321, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3707:
	movzbq	309(%r11), %rax
	movq	$1136, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$321, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3706:
	movzbq	76(%r11), %rax
	movq	$1088, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$322, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3705:
	movzbq	154(%r11), %rax
	movq	$1104, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$322, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3704:
	movzbq	232(%r11), %rax
	movq	$1120, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$322, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3703:
	movzbq	310(%r11), %rax
	movq	$1136, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$322, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3702:
	movzbq	77(%r11), %rax
	movq	$1088, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$323, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3701:
	movzbq	155(%r11), %rax
	movq	$1104, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$323, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3700:
	movzbq	233(%r11), %rax
	movq	$1120, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$323, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3699:
	movzbq	311(%r11), %rax
	movq	$1136, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$323, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3698:
	movq	$18, %rdx
	jmp 	Lbitsliced_m_calculate_PS$3692
Lbitsliced_m_calculate_PS$3693:
	movzbq	(%r11,%rdx), %rax
	movq	$1152, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$3697:
	movzbq	78(%r11,%rdx), %rax
	movq	$1168, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$3696:
	movzbq	156(%r11,%rdx), %rax
	movq	$1184, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$3695:
	movzbq	234(%r11,%rdx), %rax
	movq	$1200, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$3694:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$3692:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$3693
	movzbq	60(%r11), %rax
	movq	$1152, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$324, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3691:
	movzbq	138(%r11), %rax
	movq	$1168, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$324, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3690:
	movzbq	216(%r11), %rax
	movq	$1184, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$324, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3689:
	movzbq	294(%r11), %rax
	movq	$1200, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$324, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3688:
	movzbq	61(%r11), %rax
	movq	$1152, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$325, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3687:
	movzbq	139(%r11), %rax
	movq	$1168, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$325, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3686:
	movzbq	217(%r11), %rax
	movq	$1184, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$325, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3685:
	movzbq	295(%r11), %rax
	movq	$1200, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$325, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3684:
	movzbq	62(%r11), %rax
	movq	$1152, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$326, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3683:
	movzbq	140(%r11), %rax
	movq	$1168, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$326, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3682:
	movzbq	218(%r11), %rax
	movq	$1184, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$326, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3681:
	movzbq	296(%r11), %rax
	movq	$1200, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$326, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3680:
	movzbq	63(%r11), %rax
	movq	$1152, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$327, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3679:
	movzbq	141(%r11), %rax
	movq	$1168, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$327, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3678:
	movzbq	219(%r11), %rax
	movq	$1184, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$327, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3677:
	movzbq	297(%r11), %rax
	movq	$1200, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$327, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3676:
	movzbq	64(%r11), %rax
	movq	$1152, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$328, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3675:
	movzbq	142(%r11), %rax
	movq	$1168, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$328, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3674:
	movzbq	220(%r11), %rax
	movq	$1184, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$328, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3673:
	movzbq	298(%r11), %rax
	movq	$1200, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$328, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3672:
	movzbq	65(%r11), %rax
	movq	$1152, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$329, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3671:
	movzbq	143(%r11), %rax
	movq	$1168, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$329, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3670:
	movzbq	221(%r11), %rax
	movq	$1184, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$329, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3669:
	movzbq	299(%r11), %rax
	movq	$1200, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$329, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3668:
	movzbq	66(%r11), %rax
	movq	$1152, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$330, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3667:
	movzbq	144(%r11), %rax
	movq	$1168, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$330, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3666:
	movzbq	222(%r11), %rax
	movq	$1184, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$330, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3665:
	movzbq	300(%r11), %rax
	movq	$1200, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$330, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3664:
	movzbq	67(%r11), %rax
	movq	$1152, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$331, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3663:
	movzbq	145(%r11), %rax
	movq	$1168, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$331, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3662:
	movzbq	223(%r11), %rax
	movq	$1184, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$331, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3661:
	movzbq	301(%r11), %rax
	movq	$1200, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$331, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3660:
	movzbq	68(%r11), %rax
	movq	$1152, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$332, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3659:
	movzbq	146(%r11), %rax
	movq	$1168, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$332, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3658:
	movzbq	224(%r11), %rax
	movq	$1184, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$332, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3657:
	movzbq	302(%r11), %rax
	movq	$1200, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$332, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3656:
	movzbq	69(%r11), %rax
	movq	$1152, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$333, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3655:
	movzbq	147(%r11), %rax
	movq	$1168, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$333, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3654:
	movzbq	225(%r11), %rax
	movq	$1184, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$333, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3653:
	movzbq	303(%r11), %rax
	movq	$1200, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$333, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3652:
	movzbq	70(%r11), %rax
	movq	$1152, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$334, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3651:
	movzbq	148(%r11), %rax
	movq	$1168, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$334, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3650:
	movzbq	226(%r11), %rax
	movq	$1184, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$334, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3649:
	movzbq	304(%r11), %rax
	movq	$1200, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$334, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3648:
	movzbq	71(%r11), %rax
	movq	$1152, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$335, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3647:
	movzbq	149(%r11), %rax
	movq	$1168, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$335, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3646:
	movzbq	227(%r11), %rax
	movq	$1184, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$335, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3645:
	movzbq	305(%r11), %rax
	movq	$1200, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$335, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3644:
	movzbq	72(%r11), %rax
	movq	$1152, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$336, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3643:
	movzbq	150(%r11), %rax
	movq	$1168, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$336, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3642:
	movzbq	228(%r11), %rax
	movq	$1184, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$336, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3641:
	movzbq	306(%r11), %rax
	movq	$1200, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$336, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3640:
	movzbq	73(%r11), %rax
	movq	$1152, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$337, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3639:
	movzbq	151(%r11), %rax
	movq	$1168, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$337, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3638:
	movzbq	229(%r11), %rax
	movq	$1184, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$337, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3637:
	movzbq	307(%r11), %rax
	movq	$1200, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$337, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3636:
	movzbq	74(%r11), %rax
	movq	$1152, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$338, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3635:
	movzbq	152(%r11), %rax
	movq	$1168, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$338, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3634:
	movzbq	230(%r11), %rax
	movq	$1184, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$338, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3633:
	movzbq	308(%r11), %rax
	movq	$1200, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$338, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3632:
	movzbq	75(%r11), %rax
	movq	$1152, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$339, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3631:
	movzbq	153(%r11), %rax
	movq	$1168, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$339, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3630:
	movzbq	231(%r11), %rax
	movq	$1184, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$339, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3629:
	movzbq	309(%r11), %rax
	movq	$1200, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$339, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3628:
	movzbq	76(%r11), %rax
	movq	$1152, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$340, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3627:
	movzbq	154(%r11), %rax
	movq	$1168, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$340, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3626:
	movzbq	232(%r11), %rax
	movq	$1184, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$340, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3625:
	movzbq	310(%r11), %rax
	movq	$1200, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$340, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3624:
	movzbq	77(%r11), %rax
	movq	$1152, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$341, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3623:
	movzbq	155(%r11), %rax
	movq	$1168, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$341, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3622:
	movzbq	233(%r11), %rax
	movq	$1184, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$341, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3621:
	movzbq	311(%r11), %rax
	movq	$1200, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$341, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3620:
	movq	$19, %rdx
	jmp 	Lbitsliced_m_calculate_PS$3614
Lbitsliced_m_calculate_PS$3615:
	movzbq	(%r11,%rdx), %rax
	movq	$1216, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$3619:
	movzbq	78(%r11,%rdx), %rax
	movq	$1232, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$3618:
	movzbq	156(%r11,%rdx), %rax
	movq	$1248, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$3617:
	movzbq	234(%r11,%rdx), %rax
	movq	$1264, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$3616:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$3614:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$3615
	movzbq	60(%r11), %rax
	movq	$1216, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$342, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3613:
	movzbq	138(%r11), %rax
	movq	$1232, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$342, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3612:
	movzbq	216(%r11), %rax
	movq	$1248, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$342, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3611:
	movzbq	294(%r11), %rax
	movq	$1264, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$342, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3610:
	movzbq	61(%r11), %rax
	movq	$1216, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$343, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3609:
	movzbq	139(%r11), %rax
	movq	$1232, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$343, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3608:
	movzbq	217(%r11), %rax
	movq	$1248, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$343, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3607:
	movzbq	295(%r11), %rax
	movq	$1264, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$343, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3606:
	movzbq	62(%r11), %rax
	movq	$1216, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$344, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3605:
	movzbq	140(%r11), %rax
	movq	$1232, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$344, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3604:
	movzbq	218(%r11), %rax
	movq	$1248, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$344, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3603:
	movzbq	296(%r11), %rax
	movq	$1264, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$344, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3602:
	movzbq	63(%r11), %rax
	movq	$1216, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$345, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3601:
	movzbq	141(%r11), %rax
	movq	$1232, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$345, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3600:
	movzbq	219(%r11), %rax
	movq	$1248, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$345, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3599:
	movzbq	297(%r11), %rax
	movq	$1264, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$345, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3598:
	movzbq	64(%r11), %rax
	movq	$1216, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$346, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3597:
	movzbq	142(%r11), %rax
	movq	$1232, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$346, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3596:
	movzbq	220(%r11), %rax
	movq	$1248, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$346, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3595:
	movzbq	298(%r11), %rax
	movq	$1264, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$346, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3594:
	movzbq	65(%r11), %rax
	movq	$1216, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$347, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3593:
	movzbq	143(%r11), %rax
	movq	$1232, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$347, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3592:
	movzbq	221(%r11), %rax
	movq	$1248, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$347, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3591:
	movzbq	299(%r11), %rax
	movq	$1264, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$347, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3590:
	movzbq	66(%r11), %rax
	movq	$1216, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$348, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3589:
	movzbq	144(%r11), %rax
	movq	$1232, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$348, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3588:
	movzbq	222(%r11), %rax
	movq	$1248, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$348, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3587:
	movzbq	300(%r11), %rax
	movq	$1264, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$348, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3586:
	movzbq	67(%r11), %rax
	movq	$1216, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$349, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3585:
	movzbq	145(%r11), %rax
	movq	$1232, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$349, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3584:
	movzbq	223(%r11), %rax
	movq	$1248, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$349, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3583:
	movzbq	301(%r11), %rax
	movq	$1264, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$349, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3582:
	movzbq	68(%r11), %rax
	movq	$1216, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$350, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3581:
	movzbq	146(%r11), %rax
	movq	$1232, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$350, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3580:
	movzbq	224(%r11), %rax
	movq	$1248, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$350, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3579:
	movzbq	302(%r11), %rax
	movq	$1264, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$350, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3578:
	movzbq	69(%r11), %rax
	movq	$1216, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$351, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3577:
	movzbq	147(%r11), %rax
	movq	$1232, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$351, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3576:
	movzbq	225(%r11), %rax
	movq	$1248, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$351, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3575:
	movzbq	303(%r11), %rax
	movq	$1264, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$351, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3574:
	movzbq	70(%r11), %rax
	movq	$1216, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$352, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3573:
	movzbq	148(%r11), %rax
	movq	$1232, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$352, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3572:
	movzbq	226(%r11), %rax
	movq	$1248, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$352, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3571:
	movzbq	304(%r11), %rax
	movq	$1264, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$352, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3570:
	movzbq	71(%r11), %rax
	movq	$1216, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$353, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3569:
	movzbq	149(%r11), %rax
	movq	$1232, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$353, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3568:
	movzbq	227(%r11), %rax
	movq	$1248, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$353, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3567:
	movzbq	305(%r11), %rax
	movq	$1264, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$353, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3566:
	movzbq	72(%r11), %rax
	movq	$1216, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$354, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3565:
	movzbq	150(%r11), %rax
	movq	$1232, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$354, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3564:
	movzbq	228(%r11), %rax
	movq	$1248, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$354, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3563:
	movzbq	306(%r11), %rax
	movq	$1264, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$354, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3562:
	movzbq	73(%r11), %rax
	movq	$1216, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$355, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3561:
	movzbq	151(%r11), %rax
	movq	$1232, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$355, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3560:
	movzbq	229(%r11), %rax
	movq	$1248, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$355, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3559:
	movzbq	307(%r11), %rax
	movq	$1264, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$355, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3558:
	movzbq	74(%r11), %rax
	movq	$1216, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$356, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3557:
	movzbq	152(%r11), %rax
	movq	$1232, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$356, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3556:
	movzbq	230(%r11), %rax
	movq	$1248, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$356, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3555:
	movzbq	308(%r11), %rax
	movq	$1264, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$356, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3554:
	movzbq	75(%r11), %rax
	movq	$1216, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$357, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3553:
	movzbq	153(%r11), %rax
	movq	$1232, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$357, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3552:
	movzbq	231(%r11), %rax
	movq	$1248, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$357, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3551:
	movzbq	309(%r11), %rax
	movq	$1264, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$357, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3550:
	movzbq	76(%r11), %rax
	movq	$1216, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$358, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3549:
	movzbq	154(%r11), %rax
	movq	$1232, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$358, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3548:
	movzbq	232(%r11), %rax
	movq	$1248, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$358, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3547:
	movzbq	310(%r11), %rax
	movq	$1264, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$358, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3546:
	movzbq	77(%r11), %rax
	movq	$1216, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$359, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3545:
	movzbq	155(%r11), %rax
	movq	$1232, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$359, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3544:
	movzbq	233(%r11), %rax
	movq	$1248, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$359, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3543:
	movzbq	311(%r11), %rax
	movq	$1264, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$359, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3542:
	movq	$20, %rdx
	jmp 	Lbitsliced_m_calculate_PS$3536
Lbitsliced_m_calculate_PS$3537:
	movzbq	(%r11,%rdx), %rax
	movq	$1280, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$3541:
	movzbq	78(%r11,%rdx), %rax
	movq	$1296, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$3540:
	movzbq	156(%r11,%rdx), %rax
	movq	$1312, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$3539:
	movzbq	234(%r11,%rdx), %rax
	movq	$1328, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$3538:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$3536:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$3537
	movzbq	60(%r11), %rax
	movq	$1280, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$360, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3535:
	movzbq	138(%r11), %rax
	movq	$1296, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$360, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3534:
	movzbq	216(%r11), %rax
	movq	$1312, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$360, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3533:
	movzbq	294(%r11), %rax
	movq	$1328, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$360, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3532:
	movzbq	61(%r11), %rax
	movq	$1280, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$361, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3531:
	movzbq	139(%r11), %rax
	movq	$1296, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$361, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3530:
	movzbq	217(%r11), %rax
	movq	$1312, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$361, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3529:
	movzbq	295(%r11), %rax
	movq	$1328, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$361, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3528:
	movzbq	62(%r11), %rax
	movq	$1280, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$362, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3527:
	movzbq	140(%r11), %rax
	movq	$1296, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$362, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3526:
	movzbq	218(%r11), %rax
	movq	$1312, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$362, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3525:
	movzbq	296(%r11), %rax
	movq	$1328, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$362, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3524:
	movzbq	63(%r11), %rax
	movq	$1280, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$363, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3523:
	movzbq	141(%r11), %rax
	movq	$1296, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$363, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3522:
	movzbq	219(%r11), %rax
	movq	$1312, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$363, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3521:
	movzbq	297(%r11), %rax
	movq	$1328, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$363, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3520:
	movzbq	64(%r11), %rax
	movq	$1280, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$364, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3519:
	movzbq	142(%r11), %rax
	movq	$1296, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$364, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3518:
	movzbq	220(%r11), %rax
	movq	$1312, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$364, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3517:
	movzbq	298(%r11), %rax
	movq	$1328, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$364, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3516:
	movzbq	65(%r11), %rax
	movq	$1280, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$365, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3515:
	movzbq	143(%r11), %rax
	movq	$1296, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$365, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3514:
	movzbq	221(%r11), %rax
	movq	$1312, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$365, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3513:
	movzbq	299(%r11), %rax
	movq	$1328, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$365, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3512:
	movzbq	66(%r11), %rax
	movq	$1280, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$366, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3511:
	movzbq	144(%r11), %rax
	movq	$1296, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$366, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3510:
	movzbq	222(%r11), %rax
	movq	$1312, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$366, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3509:
	movzbq	300(%r11), %rax
	movq	$1328, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$366, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3508:
	movzbq	67(%r11), %rax
	movq	$1280, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$367, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3507:
	movzbq	145(%r11), %rax
	movq	$1296, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$367, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3506:
	movzbq	223(%r11), %rax
	movq	$1312, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$367, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3505:
	movzbq	301(%r11), %rax
	movq	$1328, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$367, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3504:
	movzbq	68(%r11), %rax
	movq	$1280, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$368, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3503:
	movzbq	146(%r11), %rax
	movq	$1296, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$368, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3502:
	movzbq	224(%r11), %rax
	movq	$1312, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$368, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3501:
	movzbq	302(%r11), %rax
	movq	$1328, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$368, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3500:
	movzbq	69(%r11), %rax
	movq	$1280, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$369, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3499:
	movzbq	147(%r11), %rax
	movq	$1296, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$369, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3498:
	movzbq	225(%r11), %rax
	movq	$1312, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$369, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3497:
	movzbq	303(%r11), %rax
	movq	$1328, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$369, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3496:
	movzbq	70(%r11), %rax
	movq	$1280, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$370, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3495:
	movzbq	148(%r11), %rax
	movq	$1296, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$370, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3494:
	movzbq	226(%r11), %rax
	movq	$1312, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$370, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3493:
	movzbq	304(%r11), %rax
	movq	$1328, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$370, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3492:
	movzbq	71(%r11), %rax
	movq	$1280, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$371, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3491:
	movzbq	149(%r11), %rax
	movq	$1296, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$371, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3490:
	movzbq	227(%r11), %rax
	movq	$1312, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$371, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3489:
	movzbq	305(%r11), %rax
	movq	$1328, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$371, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3488:
	movzbq	72(%r11), %rax
	movq	$1280, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$372, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3487:
	movzbq	150(%r11), %rax
	movq	$1296, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$372, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3486:
	movzbq	228(%r11), %rax
	movq	$1312, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$372, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3485:
	movzbq	306(%r11), %rax
	movq	$1328, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$372, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3484:
	movzbq	73(%r11), %rax
	movq	$1280, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$373, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3483:
	movzbq	151(%r11), %rax
	movq	$1296, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$373, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3482:
	movzbq	229(%r11), %rax
	movq	$1312, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$373, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3481:
	movzbq	307(%r11), %rax
	movq	$1328, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$373, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3480:
	movzbq	74(%r11), %rax
	movq	$1280, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$374, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3479:
	movzbq	152(%r11), %rax
	movq	$1296, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$374, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3478:
	movzbq	230(%r11), %rax
	movq	$1312, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$374, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3477:
	movzbq	308(%r11), %rax
	movq	$1328, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$374, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3476:
	movzbq	75(%r11), %rax
	movq	$1280, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$375, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3475:
	movzbq	153(%r11), %rax
	movq	$1296, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$375, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3474:
	movzbq	231(%r11), %rax
	movq	$1312, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$375, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3473:
	movzbq	309(%r11), %rax
	movq	$1328, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$375, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3472:
	movzbq	76(%r11), %rax
	movq	$1280, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$376, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3471:
	movzbq	154(%r11), %rax
	movq	$1296, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$376, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3470:
	movzbq	232(%r11), %rax
	movq	$1312, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$376, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3469:
	movzbq	310(%r11), %rax
	movq	$1328, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$376, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3468:
	movzbq	77(%r11), %rax
	movq	$1280, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$377, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3467:
	movzbq	155(%r11), %rax
	movq	$1296, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$377, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3466:
	movzbq	233(%r11), %rax
	movq	$1312, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$377, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3465:
	movzbq	311(%r11), %rax
	movq	$1328, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$377, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3464:
	movq	$21, %rdx
	jmp 	Lbitsliced_m_calculate_PS$3458
Lbitsliced_m_calculate_PS$3459:
	movzbq	(%r11,%rdx), %rax
	movq	$1344, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$3463:
	movzbq	78(%r11,%rdx), %rax
	movq	$1360, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$3462:
	movzbq	156(%r11,%rdx), %rax
	movq	$1376, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$3461:
	movzbq	234(%r11,%rdx), %rax
	movq	$1392, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$3460:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$3458:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$3459
	movzbq	60(%r11), %rax
	movq	$1344, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$378, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3457:
	movzbq	138(%r11), %rax
	movq	$1360, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$378, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3456:
	movzbq	216(%r11), %rax
	movq	$1376, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$378, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3455:
	movzbq	294(%r11), %rax
	movq	$1392, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$378, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3454:
	movzbq	61(%r11), %rax
	movq	$1344, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$379, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3453:
	movzbq	139(%r11), %rax
	movq	$1360, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$379, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3452:
	movzbq	217(%r11), %rax
	movq	$1376, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$379, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3451:
	movzbq	295(%r11), %rax
	movq	$1392, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$379, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3450:
	movzbq	62(%r11), %rax
	movq	$1344, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$380, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3449:
	movzbq	140(%r11), %rax
	movq	$1360, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$380, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3448:
	movzbq	218(%r11), %rax
	movq	$1376, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$380, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3447:
	movzbq	296(%r11), %rax
	movq	$1392, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$380, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3446:
	movzbq	63(%r11), %rax
	movq	$1344, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$381, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3445:
	movzbq	141(%r11), %rax
	movq	$1360, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$381, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3444:
	movzbq	219(%r11), %rax
	movq	$1376, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$381, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3443:
	movzbq	297(%r11), %rax
	movq	$1392, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$381, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3442:
	movzbq	64(%r11), %rax
	movq	$1344, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$382, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3441:
	movzbq	142(%r11), %rax
	movq	$1360, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$382, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3440:
	movzbq	220(%r11), %rax
	movq	$1376, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$382, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3439:
	movzbq	298(%r11), %rax
	movq	$1392, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$382, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3438:
	movzbq	65(%r11), %rax
	movq	$1344, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$383, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3437:
	movzbq	143(%r11), %rax
	movq	$1360, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$383, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3436:
	movzbq	221(%r11), %rax
	movq	$1376, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$383, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3435:
	movzbq	299(%r11), %rax
	movq	$1392, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$383, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3434:
	movzbq	66(%r11), %rax
	movq	$1344, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$384, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3433:
	movzbq	144(%r11), %rax
	movq	$1360, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$384, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3432:
	movzbq	222(%r11), %rax
	movq	$1376, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$384, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3431:
	movzbq	300(%r11), %rax
	movq	$1392, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$384, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3430:
	movzbq	67(%r11), %rax
	movq	$1344, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$385, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3429:
	movzbq	145(%r11), %rax
	movq	$1360, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$385, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3428:
	movzbq	223(%r11), %rax
	movq	$1376, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$385, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3427:
	movzbq	301(%r11), %rax
	movq	$1392, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$385, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3426:
	movzbq	68(%r11), %rax
	movq	$1344, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$386, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3425:
	movzbq	146(%r11), %rax
	movq	$1360, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$386, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3424:
	movzbq	224(%r11), %rax
	movq	$1376, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$386, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3423:
	movzbq	302(%r11), %rax
	movq	$1392, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$386, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3422:
	movzbq	69(%r11), %rax
	movq	$1344, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$387, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3421:
	movzbq	147(%r11), %rax
	movq	$1360, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$387, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3420:
	movzbq	225(%r11), %rax
	movq	$1376, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$387, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3419:
	movzbq	303(%r11), %rax
	movq	$1392, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$387, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3418:
	movzbq	70(%r11), %rax
	movq	$1344, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$388, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3417:
	movzbq	148(%r11), %rax
	movq	$1360, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$388, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3416:
	movzbq	226(%r11), %rax
	movq	$1376, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$388, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3415:
	movzbq	304(%r11), %rax
	movq	$1392, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$388, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3414:
	movzbq	71(%r11), %rax
	movq	$1344, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$389, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3413:
	movzbq	149(%r11), %rax
	movq	$1360, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$389, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3412:
	movzbq	227(%r11), %rax
	movq	$1376, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$389, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3411:
	movzbq	305(%r11), %rax
	movq	$1392, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$389, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3410:
	movzbq	72(%r11), %rax
	movq	$1344, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$390, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3409:
	movzbq	150(%r11), %rax
	movq	$1360, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$390, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3408:
	movzbq	228(%r11), %rax
	movq	$1376, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$390, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3407:
	movzbq	306(%r11), %rax
	movq	$1392, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$390, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3406:
	movzbq	73(%r11), %rax
	movq	$1344, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$391, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3405:
	movzbq	151(%r11), %rax
	movq	$1360, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$391, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3404:
	movzbq	229(%r11), %rax
	movq	$1376, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$391, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3403:
	movzbq	307(%r11), %rax
	movq	$1392, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$391, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3402:
	movzbq	74(%r11), %rax
	movq	$1344, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$392, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3401:
	movzbq	152(%r11), %rax
	movq	$1360, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$392, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3400:
	movzbq	230(%r11), %rax
	movq	$1376, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$392, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3399:
	movzbq	308(%r11), %rax
	movq	$1392, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$392, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3398:
	movzbq	75(%r11), %rax
	movq	$1344, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$393, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3397:
	movzbq	153(%r11), %rax
	movq	$1360, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$393, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3396:
	movzbq	231(%r11), %rax
	movq	$1376, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$393, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3395:
	movzbq	309(%r11), %rax
	movq	$1392, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$393, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3394:
	movzbq	76(%r11), %rax
	movq	$1344, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$394, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3393:
	movzbq	154(%r11), %rax
	movq	$1360, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$394, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3392:
	movzbq	232(%r11), %rax
	movq	$1376, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$394, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3391:
	movzbq	310(%r11), %rax
	movq	$1392, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$394, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3390:
	movzbq	77(%r11), %rax
	movq	$1344, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$395, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3389:
	movzbq	155(%r11), %rax
	movq	$1360, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$395, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3388:
	movzbq	233(%r11), %rax
	movq	$1376, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$395, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3387:
	movzbq	311(%r11), %rax
	movq	$1392, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$395, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3386:
	movq	$22, %rdx
	jmp 	Lbitsliced_m_calculate_PS$3380
Lbitsliced_m_calculate_PS$3381:
	movzbq	(%r11,%rdx), %rax
	movq	$1408, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$3385:
	movzbq	78(%r11,%rdx), %rax
	movq	$1424, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$3384:
	movzbq	156(%r11,%rdx), %rax
	movq	$1440, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$3383:
	movzbq	234(%r11,%rdx), %rax
	movq	$1456, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$3382:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$3380:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$3381
	movzbq	60(%r11), %rax
	movq	$1408, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$396, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3379:
	movzbq	138(%r11), %rax
	movq	$1424, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$396, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3378:
	movzbq	216(%r11), %rax
	movq	$1440, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$396, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3377:
	movzbq	294(%r11), %rax
	movq	$1456, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$396, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3376:
	movzbq	61(%r11), %rax
	movq	$1408, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$397, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3375:
	movzbq	139(%r11), %rax
	movq	$1424, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$397, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3374:
	movzbq	217(%r11), %rax
	movq	$1440, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$397, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3373:
	movzbq	295(%r11), %rax
	movq	$1456, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$397, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3372:
	movzbq	62(%r11), %rax
	movq	$1408, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$398, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3371:
	movzbq	140(%r11), %rax
	movq	$1424, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$398, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3370:
	movzbq	218(%r11), %rax
	movq	$1440, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$398, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3369:
	movzbq	296(%r11), %rax
	movq	$1456, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$398, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3368:
	movzbq	63(%r11), %rax
	movq	$1408, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$399, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3367:
	movzbq	141(%r11), %rax
	movq	$1424, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$399, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3366:
	movzbq	219(%r11), %rax
	movq	$1440, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$399, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3365:
	movzbq	297(%r11), %rax
	movq	$1456, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$399, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3364:
	movzbq	64(%r11), %rax
	movq	$1408, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$400, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3363:
	movzbq	142(%r11), %rax
	movq	$1424, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$400, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3362:
	movzbq	220(%r11), %rax
	movq	$1440, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$400, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3361:
	movzbq	298(%r11), %rax
	movq	$1456, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$400, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3360:
	movzbq	65(%r11), %rax
	movq	$1408, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$401, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3359:
	movzbq	143(%r11), %rax
	movq	$1424, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$401, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3358:
	movzbq	221(%r11), %rax
	movq	$1440, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$401, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3357:
	movzbq	299(%r11), %rax
	movq	$1456, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$401, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3356:
	movzbq	66(%r11), %rax
	movq	$1408, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$402, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3355:
	movzbq	144(%r11), %rax
	movq	$1424, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$402, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3354:
	movzbq	222(%r11), %rax
	movq	$1440, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$402, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3353:
	movzbq	300(%r11), %rax
	movq	$1456, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$402, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3352:
	movzbq	67(%r11), %rax
	movq	$1408, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$403, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3351:
	movzbq	145(%r11), %rax
	movq	$1424, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$403, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3350:
	movzbq	223(%r11), %rax
	movq	$1440, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$403, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3349:
	movzbq	301(%r11), %rax
	movq	$1456, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$403, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3348:
	movzbq	68(%r11), %rax
	movq	$1408, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$404, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3347:
	movzbq	146(%r11), %rax
	movq	$1424, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$404, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3346:
	movzbq	224(%r11), %rax
	movq	$1440, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$404, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3345:
	movzbq	302(%r11), %rax
	movq	$1456, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$404, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3344:
	movzbq	69(%r11), %rax
	movq	$1408, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$405, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3343:
	movzbq	147(%r11), %rax
	movq	$1424, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$405, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3342:
	movzbq	225(%r11), %rax
	movq	$1440, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$405, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3341:
	movzbq	303(%r11), %rax
	movq	$1456, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$405, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3340:
	movzbq	70(%r11), %rax
	movq	$1408, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$406, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3339:
	movzbq	148(%r11), %rax
	movq	$1424, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$406, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3338:
	movzbq	226(%r11), %rax
	movq	$1440, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$406, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3337:
	movzbq	304(%r11), %rax
	movq	$1456, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$406, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3336:
	movzbq	71(%r11), %rax
	movq	$1408, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$407, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3335:
	movzbq	149(%r11), %rax
	movq	$1424, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$407, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3334:
	movzbq	227(%r11), %rax
	movq	$1440, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$407, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3333:
	movzbq	305(%r11), %rax
	movq	$1456, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$407, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3332:
	movzbq	72(%r11), %rax
	movq	$1408, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$408, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3331:
	movzbq	150(%r11), %rax
	movq	$1424, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$408, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3330:
	movzbq	228(%r11), %rax
	movq	$1440, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$408, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3329:
	movzbq	306(%r11), %rax
	movq	$1456, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$408, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3328:
	movzbq	73(%r11), %rax
	movq	$1408, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$409, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3327:
	movzbq	151(%r11), %rax
	movq	$1424, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$409, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3326:
	movzbq	229(%r11), %rax
	movq	$1440, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$409, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3325:
	movzbq	307(%r11), %rax
	movq	$1456, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$409, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3324:
	movzbq	74(%r11), %rax
	movq	$1408, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$410, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3323:
	movzbq	152(%r11), %rax
	movq	$1424, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$410, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3322:
	movzbq	230(%r11), %rax
	movq	$1440, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$410, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3321:
	movzbq	308(%r11), %rax
	movq	$1456, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$410, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3320:
	movzbq	75(%r11), %rax
	movq	$1408, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$411, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3319:
	movzbq	153(%r11), %rax
	movq	$1424, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$411, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3318:
	movzbq	231(%r11), %rax
	movq	$1440, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$411, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3317:
	movzbq	309(%r11), %rax
	movq	$1456, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$411, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3316:
	movzbq	76(%r11), %rax
	movq	$1408, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$412, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3315:
	movzbq	154(%r11), %rax
	movq	$1424, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$412, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3314:
	movzbq	232(%r11), %rax
	movq	$1440, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$412, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3313:
	movzbq	310(%r11), %rax
	movq	$1456, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$412, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3312:
	movzbq	77(%r11), %rax
	movq	$1408, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$413, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3311:
	movzbq	155(%r11), %rax
	movq	$1424, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$413, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3310:
	movzbq	233(%r11), %rax
	movq	$1440, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$413, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3309:
	movzbq	311(%r11), %rax
	movq	$1456, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$413, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3308:
	movq	$23, %rdx
	jmp 	Lbitsliced_m_calculate_PS$3302
Lbitsliced_m_calculate_PS$3303:
	movzbq	(%r11,%rdx), %rax
	movq	$1472, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$3307:
	movzbq	78(%r11,%rdx), %rax
	movq	$1488, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$3306:
	movzbq	156(%r11,%rdx), %rax
	movq	$1504, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$3305:
	movzbq	234(%r11,%rdx), %rax
	movq	$1520, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$3304:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$3302:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$3303
	movzbq	60(%r11), %rax
	movq	$1472, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$414, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3301:
	movzbq	138(%r11), %rax
	movq	$1488, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$414, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3300:
	movzbq	216(%r11), %rax
	movq	$1504, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$414, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3299:
	movzbq	294(%r11), %rax
	movq	$1520, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$414, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3298:
	movzbq	61(%r11), %rax
	movq	$1472, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$415, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3297:
	movzbq	139(%r11), %rax
	movq	$1488, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$415, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3296:
	movzbq	217(%r11), %rax
	movq	$1504, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$415, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3295:
	movzbq	295(%r11), %rax
	movq	$1520, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$415, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3294:
	movzbq	62(%r11), %rax
	movq	$1472, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$416, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3293:
	movzbq	140(%r11), %rax
	movq	$1488, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$416, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3292:
	movzbq	218(%r11), %rax
	movq	$1504, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$416, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3291:
	movzbq	296(%r11), %rax
	movq	$1520, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$416, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3290:
	movzbq	63(%r11), %rax
	movq	$1472, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$417, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3289:
	movzbq	141(%r11), %rax
	movq	$1488, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$417, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3288:
	movzbq	219(%r11), %rax
	movq	$1504, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$417, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3287:
	movzbq	297(%r11), %rax
	movq	$1520, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$417, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3286:
	movzbq	64(%r11), %rax
	movq	$1472, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$418, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3285:
	movzbq	142(%r11), %rax
	movq	$1488, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$418, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3284:
	movzbq	220(%r11), %rax
	movq	$1504, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$418, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3283:
	movzbq	298(%r11), %rax
	movq	$1520, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$418, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3282:
	movzbq	65(%r11), %rax
	movq	$1472, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$419, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3281:
	movzbq	143(%r11), %rax
	movq	$1488, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$419, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3280:
	movzbq	221(%r11), %rax
	movq	$1504, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$419, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3279:
	movzbq	299(%r11), %rax
	movq	$1520, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$419, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3278:
	movzbq	66(%r11), %rax
	movq	$1472, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$420, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3277:
	movzbq	144(%r11), %rax
	movq	$1488, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$420, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3276:
	movzbq	222(%r11), %rax
	movq	$1504, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$420, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3275:
	movzbq	300(%r11), %rax
	movq	$1520, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$420, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3274:
	movzbq	67(%r11), %rax
	movq	$1472, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$421, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3273:
	movzbq	145(%r11), %rax
	movq	$1488, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$421, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3272:
	movzbq	223(%r11), %rax
	movq	$1504, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$421, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3271:
	movzbq	301(%r11), %rax
	movq	$1520, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$421, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3270:
	movzbq	68(%r11), %rax
	movq	$1472, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$422, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3269:
	movzbq	146(%r11), %rax
	movq	$1488, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$422, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3268:
	movzbq	224(%r11), %rax
	movq	$1504, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$422, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3267:
	movzbq	302(%r11), %rax
	movq	$1520, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$422, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3266:
	movzbq	69(%r11), %rax
	movq	$1472, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$423, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3265:
	movzbq	147(%r11), %rax
	movq	$1488, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$423, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3264:
	movzbq	225(%r11), %rax
	movq	$1504, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$423, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3263:
	movzbq	303(%r11), %rax
	movq	$1520, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$423, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3262:
	movzbq	70(%r11), %rax
	movq	$1472, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$424, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3261:
	movzbq	148(%r11), %rax
	movq	$1488, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$424, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3260:
	movzbq	226(%r11), %rax
	movq	$1504, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$424, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3259:
	movzbq	304(%r11), %rax
	movq	$1520, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$424, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3258:
	movzbq	71(%r11), %rax
	movq	$1472, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$425, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3257:
	movzbq	149(%r11), %rax
	movq	$1488, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$425, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3256:
	movzbq	227(%r11), %rax
	movq	$1504, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$425, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3255:
	movzbq	305(%r11), %rax
	movq	$1520, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$425, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3254:
	movzbq	72(%r11), %rax
	movq	$1472, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$426, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3253:
	movzbq	150(%r11), %rax
	movq	$1488, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$426, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3252:
	movzbq	228(%r11), %rax
	movq	$1504, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$426, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3251:
	movzbq	306(%r11), %rax
	movq	$1520, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$426, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3250:
	movzbq	73(%r11), %rax
	movq	$1472, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$427, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3249:
	movzbq	151(%r11), %rax
	movq	$1488, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$427, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3248:
	movzbq	229(%r11), %rax
	movq	$1504, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$427, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3247:
	movzbq	307(%r11), %rax
	movq	$1520, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$427, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3246:
	movzbq	74(%r11), %rax
	movq	$1472, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$428, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3245:
	movzbq	152(%r11), %rax
	movq	$1488, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$428, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3244:
	movzbq	230(%r11), %rax
	movq	$1504, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$428, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3243:
	movzbq	308(%r11), %rax
	movq	$1520, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$428, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3242:
	movzbq	75(%r11), %rax
	movq	$1472, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$429, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3241:
	movzbq	153(%r11), %rax
	movq	$1488, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$429, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3240:
	movzbq	231(%r11), %rax
	movq	$1504, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$429, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3239:
	movzbq	309(%r11), %rax
	movq	$1520, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$429, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3238:
	movzbq	76(%r11), %rax
	movq	$1472, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$430, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3237:
	movzbq	154(%r11), %rax
	movq	$1488, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$430, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3236:
	movzbq	232(%r11), %rax
	movq	$1504, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$430, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3235:
	movzbq	310(%r11), %rax
	movq	$1520, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$430, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3234:
	movzbq	77(%r11), %rax
	movq	$1472, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$431, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3233:
	movzbq	155(%r11), %rax
	movq	$1488, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$431, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3232:
	movzbq	233(%r11), %rax
	movq	$1504, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$431, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3231:
	movzbq	311(%r11), %rax
	movq	$1520, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$431, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3230:
	movq	$24, %rdx
	jmp 	Lbitsliced_m_calculate_PS$3224
Lbitsliced_m_calculate_PS$3225:
	movzbq	(%r11,%rdx), %rax
	movq	$1536, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$3229:
	movzbq	78(%r11,%rdx), %rax
	movq	$1552, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$3228:
	movzbq	156(%r11,%rdx), %rax
	movq	$1568, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$3227:
	movzbq	234(%r11,%rdx), %rax
	movq	$1584, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$3226:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$3224:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$3225
	movzbq	60(%r11), %rax
	movq	$1536, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$432, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3223:
	movzbq	138(%r11), %rax
	movq	$1552, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$432, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3222:
	movzbq	216(%r11), %rax
	movq	$1568, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$432, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3221:
	movzbq	294(%r11), %rax
	movq	$1584, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$432, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3220:
	movzbq	61(%r11), %rax
	movq	$1536, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$433, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3219:
	movzbq	139(%r11), %rax
	movq	$1552, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$433, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3218:
	movzbq	217(%r11), %rax
	movq	$1568, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$433, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3217:
	movzbq	295(%r11), %rax
	movq	$1584, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$433, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3216:
	movzbq	62(%r11), %rax
	movq	$1536, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$434, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3215:
	movzbq	140(%r11), %rax
	movq	$1552, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$434, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3214:
	movzbq	218(%r11), %rax
	movq	$1568, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$434, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3213:
	movzbq	296(%r11), %rax
	movq	$1584, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$434, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3212:
	movzbq	63(%r11), %rax
	movq	$1536, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$435, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3211:
	movzbq	141(%r11), %rax
	movq	$1552, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$435, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3210:
	movzbq	219(%r11), %rax
	movq	$1568, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$435, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3209:
	movzbq	297(%r11), %rax
	movq	$1584, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$435, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3208:
	movzbq	64(%r11), %rax
	movq	$1536, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$436, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3207:
	movzbq	142(%r11), %rax
	movq	$1552, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$436, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3206:
	movzbq	220(%r11), %rax
	movq	$1568, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$436, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3205:
	movzbq	298(%r11), %rax
	movq	$1584, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$436, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3204:
	movzbq	65(%r11), %rax
	movq	$1536, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$437, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3203:
	movzbq	143(%r11), %rax
	movq	$1552, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$437, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3202:
	movzbq	221(%r11), %rax
	movq	$1568, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$437, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3201:
	movzbq	299(%r11), %rax
	movq	$1584, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$437, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3200:
	movzbq	66(%r11), %rax
	movq	$1536, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$438, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3199:
	movzbq	144(%r11), %rax
	movq	$1552, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$438, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3198:
	movzbq	222(%r11), %rax
	movq	$1568, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$438, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3197:
	movzbq	300(%r11), %rax
	movq	$1584, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$438, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3196:
	movzbq	67(%r11), %rax
	movq	$1536, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$439, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3195:
	movzbq	145(%r11), %rax
	movq	$1552, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$439, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3194:
	movzbq	223(%r11), %rax
	movq	$1568, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$439, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3193:
	movzbq	301(%r11), %rax
	movq	$1584, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$439, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3192:
	movzbq	68(%r11), %rax
	movq	$1536, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$440, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3191:
	movzbq	146(%r11), %rax
	movq	$1552, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$440, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3190:
	movzbq	224(%r11), %rax
	movq	$1568, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$440, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3189:
	movzbq	302(%r11), %rax
	movq	$1584, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$440, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3188:
	movzbq	69(%r11), %rax
	movq	$1536, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$441, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3187:
	movzbq	147(%r11), %rax
	movq	$1552, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$441, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3186:
	movzbq	225(%r11), %rax
	movq	$1568, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$441, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3185:
	movzbq	303(%r11), %rax
	movq	$1584, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$441, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3184:
	movzbq	70(%r11), %rax
	movq	$1536, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$442, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3183:
	movzbq	148(%r11), %rax
	movq	$1552, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$442, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3182:
	movzbq	226(%r11), %rax
	movq	$1568, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$442, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3181:
	movzbq	304(%r11), %rax
	movq	$1584, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$442, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3180:
	movzbq	71(%r11), %rax
	movq	$1536, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$443, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3179:
	movzbq	149(%r11), %rax
	movq	$1552, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$443, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3178:
	movzbq	227(%r11), %rax
	movq	$1568, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$443, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3177:
	movzbq	305(%r11), %rax
	movq	$1584, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$443, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3176:
	movzbq	72(%r11), %rax
	movq	$1536, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$444, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3175:
	movzbq	150(%r11), %rax
	movq	$1552, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$444, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3174:
	movzbq	228(%r11), %rax
	movq	$1568, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$444, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3173:
	movzbq	306(%r11), %rax
	movq	$1584, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$444, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3172:
	movzbq	73(%r11), %rax
	movq	$1536, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$445, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3171:
	movzbq	151(%r11), %rax
	movq	$1552, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$445, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3170:
	movzbq	229(%r11), %rax
	movq	$1568, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$445, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3169:
	movzbq	307(%r11), %rax
	movq	$1584, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$445, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3168:
	movzbq	74(%r11), %rax
	movq	$1536, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$446, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3167:
	movzbq	152(%r11), %rax
	movq	$1552, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$446, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3166:
	movzbq	230(%r11), %rax
	movq	$1568, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$446, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3165:
	movzbq	308(%r11), %rax
	movq	$1584, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$446, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3164:
	movzbq	75(%r11), %rax
	movq	$1536, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$447, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3163:
	movzbq	153(%r11), %rax
	movq	$1552, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$447, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3162:
	movzbq	231(%r11), %rax
	movq	$1568, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$447, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3161:
	movzbq	309(%r11), %rax
	movq	$1584, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$447, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3160:
	movzbq	76(%r11), %rax
	movq	$1536, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$448, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3159:
	movzbq	154(%r11), %rax
	movq	$1552, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$448, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3158:
	movzbq	232(%r11), %rax
	movq	$1568, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$448, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3157:
	movzbq	310(%r11), %rax
	movq	$1584, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$448, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3156:
	movzbq	77(%r11), %rax
	movq	$1536, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$449, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3155:
	movzbq	155(%r11), %rax
	movq	$1552, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$449, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3154:
	movzbq	233(%r11), %rax
	movq	$1568, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$449, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3153:
	movzbq	311(%r11), %rax
	movq	$1584, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$449, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3152:
	movq	$25, %rdx
	jmp 	Lbitsliced_m_calculate_PS$3146
Lbitsliced_m_calculate_PS$3147:
	movzbq	(%r11,%rdx), %rax
	movq	$1600, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$3151:
	movzbq	78(%r11,%rdx), %rax
	movq	$1616, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$3150:
	movzbq	156(%r11,%rdx), %rax
	movq	$1632, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$3149:
	movzbq	234(%r11,%rdx), %rax
	movq	$1648, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$3148:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$3146:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$3147
	movzbq	60(%r11), %rax
	movq	$1600, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$450, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3145:
	movzbq	138(%r11), %rax
	movq	$1616, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$450, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3144:
	movzbq	216(%r11), %rax
	movq	$1632, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$450, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3143:
	movzbq	294(%r11), %rax
	movq	$1648, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$450, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3142:
	movzbq	61(%r11), %rax
	movq	$1600, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$451, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3141:
	movzbq	139(%r11), %rax
	movq	$1616, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$451, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3140:
	movzbq	217(%r11), %rax
	movq	$1632, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$451, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3139:
	movzbq	295(%r11), %rax
	movq	$1648, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$451, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3138:
	movzbq	62(%r11), %rax
	movq	$1600, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$452, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3137:
	movzbq	140(%r11), %rax
	movq	$1616, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$452, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3136:
	movzbq	218(%r11), %rax
	movq	$1632, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$452, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3135:
	movzbq	296(%r11), %rax
	movq	$1648, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$452, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3134:
	movzbq	63(%r11), %rax
	movq	$1600, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$453, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3133:
	movzbq	141(%r11), %rax
	movq	$1616, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$453, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3132:
	movzbq	219(%r11), %rax
	movq	$1632, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$453, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3131:
	movzbq	297(%r11), %rax
	movq	$1648, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$453, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3130:
	movzbq	64(%r11), %rax
	movq	$1600, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$454, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3129:
	movzbq	142(%r11), %rax
	movq	$1616, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$454, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3128:
	movzbq	220(%r11), %rax
	movq	$1632, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$454, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3127:
	movzbq	298(%r11), %rax
	movq	$1648, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$454, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3126:
	movzbq	65(%r11), %rax
	movq	$1600, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$455, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3125:
	movzbq	143(%r11), %rax
	movq	$1616, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$455, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3124:
	movzbq	221(%r11), %rax
	movq	$1632, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$455, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3123:
	movzbq	299(%r11), %rax
	movq	$1648, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$455, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3122:
	movzbq	66(%r11), %rax
	movq	$1600, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$456, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3121:
	movzbq	144(%r11), %rax
	movq	$1616, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$456, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3120:
	movzbq	222(%r11), %rax
	movq	$1632, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$456, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3119:
	movzbq	300(%r11), %rax
	movq	$1648, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$456, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3118:
	movzbq	67(%r11), %rax
	movq	$1600, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$457, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3117:
	movzbq	145(%r11), %rax
	movq	$1616, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$457, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3116:
	movzbq	223(%r11), %rax
	movq	$1632, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$457, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3115:
	movzbq	301(%r11), %rax
	movq	$1648, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$457, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3114:
	movzbq	68(%r11), %rax
	movq	$1600, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$458, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3113:
	movzbq	146(%r11), %rax
	movq	$1616, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$458, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3112:
	movzbq	224(%r11), %rax
	movq	$1632, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$458, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3111:
	movzbq	302(%r11), %rax
	movq	$1648, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$458, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3110:
	movzbq	69(%r11), %rax
	movq	$1600, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$459, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3109:
	movzbq	147(%r11), %rax
	movq	$1616, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$459, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3108:
	movzbq	225(%r11), %rax
	movq	$1632, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$459, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3107:
	movzbq	303(%r11), %rax
	movq	$1648, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$459, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3106:
	movzbq	70(%r11), %rax
	movq	$1600, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$460, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3105:
	movzbq	148(%r11), %rax
	movq	$1616, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$460, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3104:
	movzbq	226(%r11), %rax
	movq	$1632, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$460, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3103:
	movzbq	304(%r11), %rax
	movq	$1648, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$460, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3102:
	movzbq	71(%r11), %rax
	movq	$1600, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$461, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3101:
	movzbq	149(%r11), %rax
	movq	$1616, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$461, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3100:
	movzbq	227(%r11), %rax
	movq	$1632, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$461, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3099:
	movzbq	305(%r11), %rax
	movq	$1648, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$461, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3098:
	movzbq	72(%r11), %rax
	movq	$1600, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$462, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3097:
	movzbq	150(%r11), %rax
	movq	$1616, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$462, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3096:
	movzbq	228(%r11), %rax
	movq	$1632, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$462, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3095:
	movzbq	306(%r11), %rax
	movq	$1648, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$462, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3094:
	movzbq	73(%r11), %rax
	movq	$1600, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$463, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3093:
	movzbq	151(%r11), %rax
	movq	$1616, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$463, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3092:
	movzbq	229(%r11), %rax
	movq	$1632, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$463, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3091:
	movzbq	307(%r11), %rax
	movq	$1648, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$463, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3090:
	movzbq	74(%r11), %rax
	movq	$1600, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$464, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3089:
	movzbq	152(%r11), %rax
	movq	$1616, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$464, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3088:
	movzbq	230(%r11), %rax
	movq	$1632, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$464, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3087:
	movzbq	308(%r11), %rax
	movq	$1648, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$464, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3086:
	movzbq	75(%r11), %rax
	movq	$1600, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$465, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3085:
	movzbq	153(%r11), %rax
	movq	$1616, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$465, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3084:
	movzbq	231(%r11), %rax
	movq	$1632, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$465, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3083:
	movzbq	309(%r11), %rax
	movq	$1648, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$465, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3082:
	movzbq	76(%r11), %rax
	movq	$1600, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$466, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3081:
	movzbq	154(%r11), %rax
	movq	$1616, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$466, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3080:
	movzbq	232(%r11), %rax
	movq	$1632, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$466, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3079:
	movzbq	310(%r11), %rax
	movq	$1648, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$466, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3078:
	movzbq	77(%r11), %rax
	movq	$1600, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$467, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3077:
	movzbq	155(%r11), %rax
	movq	$1616, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$467, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3076:
	movzbq	233(%r11), %rax
	movq	$1632, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$467, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3075:
	movzbq	311(%r11), %rax
	movq	$1648, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$467, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3074:
	movq	$26, %rdx
	jmp 	Lbitsliced_m_calculate_PS$3068
Lbitsliced_m_calculate_PS$3069:
	movzbq	(%r11,%rdx), %rax
	movq	$1664, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$3073:
	movzbq	78(%r11,%rdx), %rax
	movq	$1680, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$3072:
	movzbq	156(%r11,%rdx), %rax
	movq	$1696, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$3071:
	movzbq	234(%r11,%rdx), %rax
	movq	$1712, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$3070:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$3068:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$3069
	movzbq	60(%r11), %rax
	movq	$1664, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$468, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3067:
	movzbq	138(%r11), %rax
	movq	$1680, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$468, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3066:
	movzbq	216(%r11), %rax
	movq	$1696, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$468, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3065:
	movzbq	294(%r11), %rax
	movq	$1712, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$468, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3064:
	movzbq	61(%r11), %rax
	movq	$1664, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$469, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3063:
	movzbq	139(%r11), %rax
	movq	$1680, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$469, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3062:
	movzbq	217(%r11), %rax
	movq	$1696, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$469, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3061:
	movzbq	295(%r11), %rax
	movq	$1712, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$469, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3060:
	movzbq	62(%r11), %rax
	movq	$1664, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$470, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3059:
	movzbq	140(%r11), %rax
	movq	$1680, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$470, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3058:
	movzbq	218(%r11), %rax
	movq	$1696, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$470, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3057:
	movzbq	296(%r11), %rax
	movq	$1712, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$470, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3056:
	movzbq	63(%r11), %rax
	movq	$1664, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$471, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3055:
	movzbq	141(%r11), %rax
	movq	$1680, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$471, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3054:
	movzbq	219(%r11), %rax
	movq	$1696, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$471, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3053:
	movzbq	297(%r11), %rax
	movq	$1712, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$471, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3052:
	movzbq	64(%r11), %rax
	movq	$1664, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$472, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3051:
	movzbq	142(%r11), %rax
	movq	$1680, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$472, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3050:
	movzbq	220(%r11), %rax
	movq	$1696, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$472, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3049:
	movzbq	298(%r11), %rax
	movq	$1712, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$472, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3048:
	movzbq	65(%r11), %rax
	movq	$1664, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$473, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3047:
	movzbq	143(%r11), %rax
	movq	$1680, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$473, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3046:
	movzbq	221(%r11), %rax
	movq	$1696, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$473, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3045:
	movzbq	299(%r11), %rax
	movq	$1712, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$473, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3044:
	movzbq	66(%r11), %rax
	movq	$1664, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$474, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3043:
	movzbq	144(%r11), %rax
	movq	$1680, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$474, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3042:
	movzbq	222(%r11), %rax
	movq	$1696, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$474, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3041:
	movzbq	300(%r11), %rax
	movq	$1712, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$474, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3040:
	movzbq	67(%r11), %rax
	movq	$1664, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$475, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3039:
	movzbq	145(%r11), %rax
	movq	$1680, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$475, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3038:
	movzbq	223(%r11), %rax
	movq	$1696, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$475, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3037:
	movzbq	301(%r11), %rax
	movq	$1712, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$475, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3036:
	movzbq	68(%r11), %rax
	movq	$1664, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$476, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3035:
	movzbq	146(%r11), %rax
	movq	$1680, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$476, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3034:
	movzbq	224(%r11), %rax
	movq	$1696, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$476, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3033:
	movzbq	302(%r11), %rax
	movq	$1712, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$476, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3032:
	movzbq	69(%r11), %rax
	movq	$1664, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$477, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3031:
	movzbq	147(%r11), %rax
	movq	$1680, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$477, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3030:
	movzbq	225(%r11), %rax
	movq	$1696, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$477, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3029:
	movzbq	303(%r11), %rax
	movq	$1712, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$477, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3028:
	movzbq	70(%r11), %rax
	movq	$1664, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$478, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3027:
	movzbq	148(%r11), %rax
	movq	$1680, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$478, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3026:
	movzbq	226(%r11), %rax
	movq	$1696, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$478, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3025:
	movzbq	304(%r11), %rax
	movq	$1712, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$478, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3024:
	movzbq	71(%r11), %rax
	movq	$1664, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$479, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3023:
	movzbq	149(%r11), %rax
	movq	$1680, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$479, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3022:
	movzbq	227(%r11), %rax
	movq	$1696, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$479, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3021:
	movzbq	305(%r11), %rax
	movq	$1712, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$479, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3020:
	movzbq	72(%r11), %rax
	movq	$1664, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$480, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3019:
	movzbq	150(%r11), %rax
	movq	$1680, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$480, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3018:
	movzbq	228(%r11), %rax
	movq	$1696, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$480, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3017:
	movzbq	306(%r11), %rax
	movq	$1712, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$480, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3016:
	movzbq	73(%r11), %rax
	movq	$1664, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$481, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3015:
	movzbq	151(%r11), %rax
	movq	$1680, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$481, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3014:
	movzbq	229(%r11), %rax
	movq	$1696, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$481, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3013:
	movzbq	307(%r11), %rax
	movq	$1712, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$481, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3012:
	movzbq	74(%r11), %rax
	movq	$1664, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$482, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3011:
	movzbq	152(%r11), %rax
	movq	$1680, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$482, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3010:
	movzbq	230(%r11), %rax
	movq	$1696, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$482, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3009:
	movzbq	308(%r11), %rax
	movq	$1712, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$482, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3008:
	movzbq	75(%r11), %rax
	movq	$1664, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$483, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3007:
	movzbq	153(%r11), %rax
	movq	$1680, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$483, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3006:
	movzbq	231(%r11), %rax
	movq	$1696, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$483, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3005:
	movzbq	309(%r11), %rax
	movq	$1712, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$483, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3004:
	movzbq	76(%r11), %rax
	movq	$1664, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$484, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3003:
	movzbq	154(%r11), %rax
	movq	$1680, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$484, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3002:
	movzbq	232(%r11), %rax
	movq	$1696, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$484, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3001:
	movzbq	310(%r11), %rax
	movq	$1712, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$484, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$3000:
	movzbq	77(%r11), %rax
	movq	$1664, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$485, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2999:
	movzbq	155(%r11), %rax
	movq	$1680, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$485, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2998:
	movzbq	233(%r11), %rax
	movq	$1696, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$485, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2997:
	movzbq	311(%r11), %rax
	movq	$1712, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$485, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2996:
	movq	$27, %rdx
	jmp 	Lbitsliced_m_calculate_PS$2990
Lbitsliced_m_calculate_PS$2991:
	movzbq	(%r11,%rdx), %rax
	movq	$1728, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$2995:
	movzbq	78(%r11,%rdx), %rax
	movq	$1744, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$2994:
	movzbq	156(%r11,%rdx), %rax
	movq	$1760, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$2993:
	movzbq	234(%r11,%rdx), %rax
	movq	$1776, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$2992:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$2990:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$2991
	movzbq	60(%r11), %rax
	movq	$1728, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$486, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2989:
	movzbq	138(%r11), %rax
	movq	$1744, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$486, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2988:
	movzbq	216(%r11), %rax
	movq	$1760, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$486, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2987:
	movzbq	294(%r11), %rax
	movq	$1776, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$486, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2986:
	movzbq	61(%r11), %rax
	movq	$1728, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$487, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2985:
	movzbq	139(%r11), %rax
	movq	$1744, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$487, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2984:
	movzbq	217(%r11), %rax
	movq	$1760, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$487, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2983:
	movzbq	295(%r11), %rax
	movq	$1776, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$487, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2982:
	movzbq	62(%r11), %rax
	movq	$1728, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$488, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2981:
	movzbq	140(%r11), %rax
	movq	$1744, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$488, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2980:
	movzbq	218(%r11), %rax
	movq	$1760, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$488, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2979:
	movzbq	296(%r11), %rax
	movq	$1776, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$488, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2978:
	movzbq	63(%r11), %rax
	movq	$1728, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$489, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2977:
	movzbq	141(%r11), %rax
	movq	$1744, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$489, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2976:
	movzbq	219(%r11), %rax
	movq	$1760, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$489, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2975:
	movzbq	297(%r11), %rax
	movq	$1776, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$489, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2974:
	movzbq	64(%r11), %rax
	movq	$1728, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$490, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2973:
	movzbq	142(%r11), %rax
	movq	$1744, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$490, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2972:
	movzbq	220(%r11), %rax
	movq	$1760, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$490, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2971:
	movzbq	298(%r11), %rax
	movq	$1776, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$490, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2970:
	movzbq	65(%r11), %rax
	movq	$1728, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$491, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2969:
	movzbq	143(%r11), %rax
	movq	$1744, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$491, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2968:
	movzbq	221(%r11), %rax
	movq	$1760, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$491, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2967:
	movzbq	299(%r11), %rax
	movq	$1776, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$491, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2966:
	movzbq	66(%r11), %rax
	movq	$1728, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$492, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2965:
	movzbq	144(%r11), %rax
	movq	$1744, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$492, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2964:
	movzbq	222(%r11), %rax
	movq	$1760, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$492, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2963:
	movzbq	300(%r11), %rax
	movq	$1776, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$492, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2962:
	movzbq	67(%r11), %rax
	movq	$1728, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$493, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2961:
	movzbq	145(%r11), %rax
	movq	$1744, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$493, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2960:
	movzbq	223(%r11), %rax
	movq	$1760, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$493, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2959:
	movzbq	301(%r11), %rax
	movq	$1776, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$493, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2958:
	movzbq	68(%r11), %rax
	movq	$1728, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$494, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2957:
	movzbq	146(%r11), %rax
	movq	$1744, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$494, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2956:
	movzbq	224(%r11), %rax
	movq	$1760, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$494, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2955:
	movzbq	302(%r11), %rax
	movq	$1776, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$494, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2954:
	movzbq	69(%r11), %rax
	movq	$1728, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$495, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2953:
	movzbq	147(%r11), %rax
	movq	$1744, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$495, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2952:
	movzbq	225(%r11), %rax
	movq	$1760, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$495, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2951:
	movzbq	303(%r11), %rax
	movq	$1776, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$495, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2950:
	movzbq	70(%r11), %rax
	movq	$1728, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$496, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2949:
	movzbq	148(%r11), %rax
	movq	$1744, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$496, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2948:
	movzbq	226(%r11), %rax
	movq	$1760, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$496, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2947:
	movzbq	304(%r11), %rax
	movq	$1776, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$496, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2946:
	movzbq	71(%r11), %rax
	movq	$1728, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$497, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2945:
	movzbq	149(%r11), %rax
	movq	$1744, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$497, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2944:
	movzbq	227(%r11), %rax
	movq	$1760, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$497, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2943:
	movzbq	305(%r11), %rax
	movq	$1776, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$497, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2942:
	movzbq	72(%r11), %rax
	movq	$1728, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$498, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2941:
	movzbq	150(%r11), %rax
	movq	$1744, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$498, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2940:
	movzbq	228(%r11), %rax
	movq	$1760, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$498, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2939:
	movzbq	306(%r11), %rax
	movq	$1776, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$498, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2938:
	movzbq	73(%r11), %rax
	movq	$1728, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$499, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2937:
	movzbq	151(%r11), %rax
	movq	$1744, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$499, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2936:
	movzbq	229(%r11), %rax
	movq	$1760, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$499, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2935:
	movzbq	307(%r11), %rax
	movq	$1776, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$499, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2934:
	movzbq	74(%r11), %rax
	movq	$1728, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$500, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2933:
	movzbq	152(%r11), %rax
	movq	$1744, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$500, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2932:
	movzbq	230(%r11), %rax
	movq	$1760, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$500, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2931:
	movzbq	308(%r11), %rax
	movq	$1776, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$500, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2930:
	movzbq	75(%r11), %rax
	movq	$1728, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$501, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2929:
	movzbq	153(%r11), %rax
	movq	$1744, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$501, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2928:
	movzbq	231(%r11), %rax
	movq	$1760, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$501, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2927:
	movzbq	309(%r11), %rax
	movq	$1776, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$501, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2926:
	movzbq	76(%r11), %rax
	movq	$1728, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$502, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2925:
	movzbq	154(%r11), %rax
	movq	$1744, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$502, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2924:
	movzbq	232(%r11), %rax
	movq	$1760, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$502, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2923:
	movzbq	310(%r11), %rax
	movq	$1776, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$502, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2922:
	movzbq	77(%r11), %rax
	movq	$1728, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$503, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2921:
	movzbq	155(%r11), %rax
	movq	$1744, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$503, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2920:
	movzbq	233(%r11), %rax
	movq	$1760, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$503, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2919:
	movzbq	311(%r11), %rax
	movq	$1776, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$503, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2918:
	movq	$28, %rdx
	jmp 	Lbitsliced_m_calculate_PS$2912
Lbitsliced_m_calculate_PS$2913:
	movzbq	(%r11,%rdx), %rax
	movq	$1792, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$2917:
	movzbq	78(%r11,%rdx), %rax
	movq	$1808, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$2916:
	movzbq	156(%r11,%rdx), %rax
	movq	$1824, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$2915:
	movzbq	234(%r11,%rdx), %rax
	movq	$1840, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$2914:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$2912:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$2913
	movzbq	60(%r11), %rax
	movq	$1792, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$504, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2911:
	movzbq	138(%r11), %rax
	movq	$1808, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$504, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2910:
	movzbq	216(%r11), %rax
	movq	$1824, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$504, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2909:
	movzbq	294(%r11), %rax
	movq	$1840, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$504, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2908:
	movzbq	61(%r11), %rax
	movq	$1792, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$505, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2907:
	movzbq	139(%r11), %rax
	movq	$1808, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$505, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2906:
	movzbq	217(%r11), %rax
	movq	$1824, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$505, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2905:
	movzbq	295(%r11), %rax
	movq	$1840, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$505, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2904:
	movzbq	62(%r11), %rax
	movq	$1792, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$506, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2903:
	movzbq	140(%r11), %rax
	movq	$1808, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$506, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2902:
	movzbq	218(%r11), %rax
	movq	$1824, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$506, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2901:
	movzbq	296(%r11), %rax
	movq	$1840, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$506, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2900:
	movzbq	63(%r11), %rax
	movq	$1792, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$507, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2899:
	movzbq	141(%r11), %rax
	movq	$1808, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$507, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2898:
	movzbq	219(%r11), %rax
	movq	$1824, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$507, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2897:
	movzbq	297(%r11), %rax
	movq	$1840, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$507, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2896:
	movzbq	64(%r11), %rax
	movq	$1792, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$508, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2895:
	movzbq	142(%r11), %rax
	movq	$1808, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$508, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2894:
	movzbq	220(%r11), %rax
	movq	$1824, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$508, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2893:
	movzbq	298(%r11), %rax
	movq	$1840, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$508, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2892:
	movzbq	65(%r11), %rax
	movq	$1792, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$509, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2891:
	movzbq	143(%r11), %rax
	movq	$1808, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$509, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2890:
	movzbq	221(%r11), %rax
	movq	$1824, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$509, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2889:
	movzbq	299(%r11), %rax
	movq	$1840, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$509, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2888:
	movzbq	66(%r11), %rax
	movq	$1792, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$510, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2887:
	movzbq	144(%r11), %rax
	movq	$1808, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$510, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2886:
	movzbq	222(%r11), %rax
	movq	$1824, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$510, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2885:
	movzbq	300(%r11), %rax
	movq	$1840, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$510, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2884:
	movzbq	67(%r11), %rax
	movq	$1792, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$511, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2883:
	movzbq	145(%r11), %rax
	movq	$1808, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$511, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2882:
	movzbq	223(%r11), %rax
	movq	$1824, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$511, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2881:
	movzbq	301(%r11), %rax
	movq	$1840, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$511, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2880:
	movzbq	68(%r11), %rax
	movq	$1792, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$512, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2879:
	movzbq	146(%r11), %rax
	movq	$1808, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$512, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2878:
	movzbq	224(%r11), %rax
	movq	$1824, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$512, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2877:
	movzbq	302(%r11), %rax
	movq	$1840, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$512, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2876:
	movzbq	69(%r11), %rax
	movq	$1792, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$513, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2875:
	movzbq	147(%r11), %rax
	movq	$1808, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$513, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2874:
	movzbq	225(%r11), %rax
	movq	$1824, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$513, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2873:
	movzbq	303(%r11), %rax
	movq	$1840, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$513, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2872:
	movzbq	70(%r11), %rax
	movq	$1792, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$514, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2871:
	movzbq	148(%r11), %rax
	movq	$1808, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$514, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2870:
	movzbq	226(%r11), %rax
	movq	$1824, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$514, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2869:
	movzbq	304(%r11), %rax
	movq	$1840, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$514, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2868:
	movzbq	71(%r11), %rax
	movq	$1792, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$515, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2867:
	movzbq	149(%r11), %rax
	movq	$1808, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$515, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2866:
	movzbq	227(%r11), %rax
	movq	$1824, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$515, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2865:
	movzbq	305(%r11), %rax
	movq	$1840, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$515, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2864:
	movzbq	72(%r11), %rax
	movq	$1792, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$516, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2863:
	movzbq	150(%r11), %rax
	movq	$1808, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$516, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2862:
	movzbq	228(%r11), %rax
	movq	$1824, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$516, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2861:
	movzbq	306(%r11), %rax
	movq	$1840, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$516, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2860:
	movzbq	73(%r11), %rax
	movq	$1792, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$517, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2859:
	movzbq	151(%r11), %rax
	movq	$1808, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$517, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2858:
	movzbq	229(%r11), %rax
	movq	$1824, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$517, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2857:
	movzbq	307(%r11), %rax
	movq	$1840, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$517, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2856:
	movzbq	74(%r11), %rax
	movq	$1792, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$518, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2855:
	movzbq	152(%r11), %rax
	movq	$1808, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$518, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2854:
	movzbq	230(%r11), %rax
	movq	$1824, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$518, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2853:
	movzbq	308(%r11), %rax
	movq	$1840, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$518, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2852:
	movzbq	75(%r11), %rax
	movq	$1792, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$519, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2851:
	movzbq	153(%r11), %rax
	movq	$1808, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$519, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2850:
	movzbq	231(%r11), %rax
	movq	$1824, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$519, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2849:
	movzbq	309(%r11), %rax
	movq	$1840, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$519, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2848:
	movzbq	76(%r11), %rax
	movq	$1792, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$520, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2847:
	movzbq	154(%r11), %rax
	movq	$1808, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$520, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2846:
	movzbq	232(%r11), %rax
	movq	$1824, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$520, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2845:
	movzbq	310(%r11), %rax
	movq	$1840, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$520, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2844:
	movzbq	77(%r11), %rax
	movq	$1792, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$521, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2843:
	movzbq	155(%r11), %rax
	movq	$1808, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$521, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2842:
	movzbq	233(%r11), %rax
	movq	$1824, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$521, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2841:
	movzbq	311(%r11), %rax
	movq	$1840, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$521, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2840:
	movq	$29, %rdx
	jmp 	Lbitsliced_m_calculate_PS$2834
Lbitsliced_m_calculate_PS$2835:
	movzbq	(%r11,%rdx), %rax
	movq	$1856, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$2839:
	movzbq	78(%r11,%rdx), %rax
	movq	$1872, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$2838:
	movzbq	156(%r11,%rdx), %rax
	movq	$1888, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$2837:
	movzbq	234(%r11,%rdx), %rax
	movq	$1904, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$2836:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$2834:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$2835
	movzbq	60(%r11), %rax
	movq	$1856, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$522, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2833:
	movzbq	138(%r11), %rax
	movq	$1872, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$522, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2832:
	movzbq	216(%r11), %rax
	movq	$1888, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$522, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2831:
	movzbq	294(%r11), %rax
	movq	$1904, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$522, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2830:
	movzbq	61(%r11), %rax
	movq	$1856, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$523, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2829:
	movzbq	139(%r11), %rax
	movq	$1872, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$523, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2828:
	movzbq	217(%r11), %rax
	movq	$1888, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$523, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2827:
	movzbq	295(%r11), %rax
	movq	$1904, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$523, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2826:
	movzbq	62(%r11), %rax
	movq	$1856, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$524, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2825:
	movzbq	140(%r11), %rax
	movq	$1872, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$524, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2824:
	movzbq	218(%r11), %rax
	movq	$1888, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$524, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2823:
	movzbq	296(%r11), %rax
	movq	$1904, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$524, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2822:
	movzbq	63(%r11), %rax
	movq	$1856, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$525, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2821:
	movzbq	141(%r11), %rax
	movq	$1872, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$525, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2820:
	movzbq	219(%r11), %rax
	movq	$1888, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$525, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2819:
	movzbq	297(%r11), %rax
	movq	$1904, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$525, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2818:
	movzbq	64(%r11), %rax
	movq	$1856, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$526, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2817:
	movzbq	142(%r11), %rax
	movq	$1872, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$526, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2816:
	movzbq	220(%r11), %rax
	movq	$1888, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$526, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2815:
	movzbq	298(%r11), %rax
	movq	$1904, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$526, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2814:
	movzbq	65(%r11), %rax
	movq	$1856, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$527, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2813:
	movzbq	143(%r11), %rax
	movq	$1872, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$527, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2812:
	movzbq	221(%r11), %rax
	movq	$1888, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$527, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2811:
	movzbq	299(%r11), %rax
	movq	$1904, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$527, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2810:
	movzbq	66(%r11), %rax
	movq	$1856, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$528, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2809:
	movzbq	144(%r11), %rax
	movq	$1872, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$528, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2808:
	movzbq	222(%r11), %rax
	movq	$1888, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$528, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2807:
	movzbq	300(%r11), %rax
	movq	$1904, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$528, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2806:
	movzbq	67(%r11), %rax
	movq	$1856, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$529, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2805:
	movzbq	145(%r11), %rax
	movq	$1872, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$529, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2804:
	movzbq	223(%r11), %rax
	movq	$1888, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$529, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2803:
	movzbq	301(%r11), %rax
	movq	$1904, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$529, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2802:
	movzbq	68(%r11), %rax
	movq	$1856, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$530, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2801:
	movzbq	146(%r11), %rax
	movq	$1872, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$530, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2800:
	movzbq	224(%r11), %rax
	movq	$1888, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$530, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2799:
	movzbq	302(%r11), %rax
	movq	$1904, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$530, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2798:
	movzbq	69(%r11), %rax
	movq	$1856, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$531, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2797:
	movzbq	147(%r11), %rax
	movq	$1872, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$531, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2796:
	movzbq	225(%r11), %rax
	movq	$1888, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$531, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2795:
	movzbq	303(%r11), %rax
	movq	$1904, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$531, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2794:
	movzbq	70(%r11), %rax
	movq	$1856, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$532, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2793:
	movzbq	148(%r11), %rax
	movq	$1872, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$532, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2792:
	movzbq	226(%r11), %rax
	movq	$1888, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$532, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2791:
	movzbq	304(%r11), %rax
	movq	$1904, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$532, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2790:
	movzbq	71(%r11), %rax
	movq	$1856, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$533, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2789:
	movzbq	149(%r11), %rax
	movq	$1872, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$533, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2788:
	movzbq	227(%r11), %rax
	movq	$1888, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$533, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2787:
	movzbq	305(%r11), %rax
	movq	$1904, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$533, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2786:
	movzbq	72(%r11), %rax
	movq	$1856, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$534, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2785:
	movzbq	150(%r11), %rax
	movq	$1872, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$534, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2784:
	movzbq	228(%r11), %rax
	movq	$1888, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$534, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2783:
	movzbq	306(%r11), %rax
	movq	$1904, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$534, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2782:
	movzbq	73(%r11), %rax
	movq	$1856, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$535, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2781:
	movzbq	151(%r11), %rax
	movq	$1872, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$535, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2780:
	movzbq	229(%r11), %rax
	movq	$1888, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$535, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2779:
	movzbq	307(%r11), %rax
	movq	$1904, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$535, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2778:
	movzbq	74(%r11), %rax
	movq	$1856, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$536, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2777:
	movzbq	152(%r11), %rax
	movq	$1872, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$536, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2776:
	movzbq	230(%r11), %rax
	movq	$1888, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$536, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2775:
	movzbq	308(%r11), %rax
	movq	$1904, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$536, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2774:
	movzbq	75(%r11), %rax
	movq	$1856, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$537, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2773:
	movzbq	153(%r11), %rax
	movq	$1872, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$537, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2772:
	movzbq	231(%r11), %rax
	movq	$1888, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$537, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2771:
	movzbq	309(%r11), %rax
	movq	$1904, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$537, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2770:
	movzbq	76(%r11), %rax
	movq	$1856, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$538, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2769:
	movzbq	154(%r11), %rax
	movq	$1872, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$538, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2768:
	movzbq	232(%r11), %rax
	movq	$1888, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$538, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2767:
	movzbq	310(%r11), %rax
	movq	$1904, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$538, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2766:
	movzbq	77(%r11), %rax
	movq	$1856, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$539, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2765:
	movzbq	155(%r11), %rax
	movq	$1872, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$539, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2764:
	movzbq	233(%r11), %rax
	movq	$1888, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$539, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2763:
	movzbq	311(%r11), %rax
	movq	$1904, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$539, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2762:
	movq	$30, %rdx
	jmp 	Lbitsliced_m_calculate_PS$2756
Lbitsliced_m_calculate_PS$2757:
	movzbq	(%r11,%rdx), %rax
	movq	$1920, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$2761:
	movzbq	78(%r11,%rdx), %rax
	movq	$1936, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$2760:
	movzbq	156(%r11,%rdx), %rax
	movq	$1952, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$2759:
	movzbq	234(%r11,%rdx), %rax
	movq	$1968, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$2758:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$2756:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$2757
	movzbq	60(%r11), %rax
	movq	$1920, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$540, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2755:
	movzbq	138(%r11), %rax
	movq	$1936, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$540, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2754:
	movzbq	216(%r11), %rax
	movq	$1952, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$540, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2753:
	movzbq	294(%r11), %rax
	movq	$1968, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$540, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2752:
	movzbq	61(%r11), %rax
	movq	$1920, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$541, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2751:
	movzbq	139(%r11), %rax
	movq	$1936, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$541, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2750:
	movzbq	217(%r11), %rax
	movq	$1952, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$541, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2749:
	movzbq	295(%r11), %rax
	movq	$1968, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$541, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2748:
	movzbq	62(%r11), %rax
	movq	$1920, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$542, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2747:
	movzbq	140(%r11), %rax
	movq	$1936, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$542, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2746:
	movzbq	218(%r11), %rax
	movq	$1952, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$542, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2745:
	movzbq	296(%r11), %rax
	movq	$1968, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$542, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2744:
	movzbq	63(%r11), %rax
	movq	$1920, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$543, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2743:
	movzbq	141(%r11), %rax
	movq	$1936, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$543, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2742:
	movzbq	219(%r11), %rax
	movq	$1952, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$543, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2741:
	movzbq	297(%r11), %rax
	movq	$1968, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$543, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2740:
	movzbq	64(%r11), %rax
	movq	$1920, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$544, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2739:
	movzbq	142(%r11), %rax
	movq	$1936, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$544, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2738:
	movzbq	220(%r11), %rax
	movq	$1952, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$544, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2737:
	movzbq	298(%r11), %rax
	movq	$1968, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$544, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2736:
	movzbq	65(%r11), %rax
	movq	$1920, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$545, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2735:
	movzbq	143(%r11), %rax
	movq	$1936, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$545, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2734:
	movzbq	221(%r11), %rax
	movq	$1952, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$545, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2733:
	movzbq	299(%r11), %rax
	movq	$1968, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$545, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2732:
	movzbq	66(%r11), %rax
	movq	$1920, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$546, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2731:
	movzbq	144(%r11), %rax
	movq	$1936, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$546, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2730:
	movzbq	222(%r11), %rax
	movq	$1952, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$546, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2729:
	movzbq	300(%r11), %rax
	movq	$1968, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$546, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2728:
	movzbq	67(%r11), %rax
	movq	$1920, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$547, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2727:
	movzbq	145(%r11), %rax
	movq	$1936, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$547, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2726:
	movzbq	223(%r11), %rax
	movq	$1952, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$547, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2725:
	movzbq	301(%r11), %rax
	movq	$1968, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$547, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2724:
	movzbq	68(%r11), %rax
	movq	$1920, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$548, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2723:
	movzbq	146(%r11), %rax
	movq	$1936, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$548, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2722:
	movzbq	224(%r11), %rax
	movq	$1952, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$548, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2721:
	movzbq	302(%r11), %rax
	movq	$1968, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$548, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2720:
	movzbq	69(%r11), %rax
	movq	$1920, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$549, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2719:
	movzbq	147(%r11), %rax
	movq	$1936, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$549, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2718:
	movzbq	225(%r11), %rax
	movq	$1952, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$549, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2717:
	movzbq	303(%r11), %rax
	movq	$1968, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$549, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2716:
	movzbq	70(%r11), %rax
	movq	$1920, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$550, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2715:
	movzbq	148(%r11), %rax
	movq	$1936, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$550, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2714:
	movzbq	226(%r11), %rax
	movq	$1952, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$550, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2713:
	movzbq	304(%r11), %rax
	movq	$1968, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$550, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2712:
	movzbq	71(%r11), %rax
	movq	$1920, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$551, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2711:
	movzbq	149(%r11), %rax
	movq	$1936, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$551, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2710:
	movzbq	227(%r11), %rax
	movq	$1952, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$551, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2709:
	movzbq	305(%r11), %rax
	movq	$1968, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$551, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2708:
	movzbq	72(%r11), %rax
	movq	$1920, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$552, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2707:
	movzbq	150(%r11), %rax
	movq	$1936, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$552, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2706:
	movzbq	228(%r11), %rax
	movq	$1952, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$552, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2705:
	movzbq	306(%r11), %rax
	movq	$1968, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$552, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2704:
	movzbq	73(%r11), %rax
	movq	$1920, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$553, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2703:
	movzbq	151(%r11), %rax
	movq	$1936, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$553, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2702:
	movzbq	229(%r11), %rax
	movq	$1952, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$553, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2701:
	movzbq	307(%r11), %rax
	movq	$1968, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$553, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2700:
	movzbq	74(%r11), %rax
	movq	$1920, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$554, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2699:
	movzbq	152(%r11), %rax
	movq	$1936, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$554, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2698:
	movzbq	230(%r11), %rax
	movq	$1952, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$554, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2697:
	movzbq	308(%r11), %rax
	movq	$1968, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$554, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2696:
	movzbq	75(%r11), %rax
	movq	$1920, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$555, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2695:
	movzbq	153(%r11), %rax
	movq	$1936, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$555, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2694:
	movzbq	231(%r11), %rax
	movq	$1952, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$555, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2693:
	movzbq	309(%r11), %rax
	movq	$1968, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$555, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2692:
	movzbq	76(%r11), %rax
	movq	$1920, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$556, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2691:
	movzbq	154(%r11), %rax
	movq	$1936, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$556, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2690:
	movzbq	232(%r11), %rax
	movq	$1952, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$556, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2689:
	movzbq	310(%r11), %rax
	movq	$1968, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$556, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2688:
	movzbq	77(%r11), %rax
	movq	$1920, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$557, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2687:
	movzbq	155(%r11), %rax
	movq	$1936, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$557, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2686:
	movzbq	233(%r11), %rax
	movq	$1952, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$557, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2685:
	movzbq	311(%r11), %rax
	movq	$1968, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$557, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2684:
	movq	$31, %rdx
	jmp 	Lbitsliced_m_calculate_PS$2678
Lbitsliced_m_calculate_PS$2679:
	movzbq	(%r11,%rdx), %rax
	movq	$1984, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$2683:
	movzbq	78(%r11,%rdx), %rax
	movq	$2000, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$2682:
	movzbq	156(%r11,%rdx), %rax
	movq	$2016, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$2681:
	movzbq	234(%r11,%rdx), %rax
	movq	$2032, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$2680:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$2678:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$2679
	movzbq	60(%r11), %rax
	movq	$1984, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$558, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2677:
	movzbq	138(%r11), %rax
	movq	$2000, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$558, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2676:
	movzbq	216(%r11), %rax
	movq	$2016, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$558, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2675:
	movzbq	294(%r11), %rax
	movq	$2032, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$558, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2674:
	movzbq	61(%r11), %rax
	movq	$1984, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$559, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2673:
	movzbq	139(%r11), %rax
	movq	$2000, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$559, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2672:
	movzbq	217(%r11), %rax
	movq	$2016, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$559, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2671:
	movzbq	295(%r11), %rax
	movq	$2032, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$559, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2670:
	movzbq	62(%r11), %rax
	movq	$1984, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$560, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2669:
	movzbq	140(%r11), %rax
	movq	$2000, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$560, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2668:
	movzbq	218(%r11), %rax
	movq	$2016, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$560, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2667:
	movzbq	296(%r11), %rax
	movq	$2032, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$560, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2666:
	movzbq	63(%r11), %rax
	movq	$1984, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$561, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2665:
	movzbq	141(%r11), %rax
	movq	$2000, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$561, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2664:
	movzbq	219(%r11), %rax
	movq	$2016, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$561, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2663:
	movzbq	297(%r11), %rax
	movq	$2032, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$561, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2662:
	movzbq	64(%r11), %rax
	movq	$1984, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$562, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2661:
	movzbq	142(%r11), %rax
	movq	$2000, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$562, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2660:
	movzbq	220(%r11), %rax
	movq	$2016, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$562, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2659:
	movzbq	298(%r11), %rax
	movq	$2032, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$562, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2658:
	movzbq	65(%r11), %rax
	movq	$1984, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$563, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2657:
	movzbq	143(%r11), %rax
	movq	$2000, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$563, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2656:
	movzbq	221(%r11), %rax
	movq	$2016, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$563, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2655:
	movzbq	299(%r11), %rax
	movq	$2032, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$563, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2654:
	movzbq	66(%r11), %rax
	movq	$1984, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$564, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2653:
	movzbq	144(%r11), %rax
	movq	$2000, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$564, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2652:
	movzbq	222(%r11), %rax
	movq	$2016, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$564, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2651:
	movzbq	300(%r11), %rax
	movq	$2032, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$564, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2650:
	movzbq	67(%r11), %rax
	movq	$1984, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$565, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2649:
	movzbq	145(%r11), %rax
	movq	$2000, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$565, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2648:
	movzbq	223(%r11), %rax
	movq	$2016, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$565, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2647:
	movzbq	301(%r11), %rax
	movq	$2032, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$565, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2646:
	movzbq	68(%r11), %rax
	movq	$1984, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$566, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2645:
	movzbq	146(%r11), %rax
	movq	$2000, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$566, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2644:
	movzbq	224(%r11), %rax
	movq	$2016, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$566, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2643:
	movzbq	302(%r11), %rax
	movq	$2032, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$566, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2642:
	movzbq	69(%r11), %rax
	movq	$1984, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$567, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2641:
	movzbq	147(%r11), %rax
	movq	$2000, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$567, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2640:
	movzbq	225(%r11), %rax
	movq	$2016, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$567, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2639:
	movzbq	303(%r11), %rax
	movq	$2032, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$567, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2638:
	movzbq	70(%r11), %rax
	movq	$1984, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$568, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2637:
	movzbq	148(%r11), %rax
	movq	$2000, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$568, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2636:
	movzbq	226(%r11), %rax
	movq	$2016, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$568, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2635:
	movzbq	304(%r11), %rax
	movq	$2032, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$568, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2634:
	movzbq	71(%r11), %rax
	movq	$1984, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$569, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2633:
	movzbq	149(%r11), %rax
	movq	$2000, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$569, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2632:
	movzbq	227(%r11), %rax
	movq	$2016, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$569, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2631:
	movzbq	305(%r11), %rax
	movq	$2032, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$569, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2630:
	movzbq	72(%r11), %rax
	movq	$1984, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$570, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2629:
	movzbq	150(%r11), %rax
	movq	$2000, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$570, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2628:
	movzbq	228(%r11), %rax
	movq	$2016, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$570, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2627:
	movzbq	306(%r11), %rax
	movq	$2032, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$570, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2626:
	movzbq	73(%r11), %rax
	movq	$1984, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$571, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2625:
	movzbq	151(%r11), %rax
	movq	$2000, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$571, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2624:
	movzbq	229(%r11), %rax
	movq	$2016, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$571, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2623:
	movzbq	307(%r11), %rax
	movq	$2032, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$571, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2622:
	movzbq	74(%r11), %rax
	movq	$1984, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$572, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2621:
	movzbq	152(%r11), %rax
	movq	$2000, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$572, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2620:
	movzbq	230(%r11), %rax
	movq	$2016, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$572, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2619:
	movzbq	308(%r11), %rax
	movq	$2032, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$572, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2618:
	movzbq	75(%r11), %rax
	movq	$1984, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$573, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2617:
	movzbq	153(%r11), %rax
	movq	$2000, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$573, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2616:
	movzbq	231(%r11), %rax
	movq	$2016, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$573, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2615:
	movzbq	309(%r11), %rax
	movq	$2032, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$573, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2614:
	movzbq	76(%r11), %rax
	movq	$1984, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$574, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2613:
	movzbq	154(%r11), %rax
	movq	$2000, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$574, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2612:
	movzbq	232(%r11), %rax
	movq	$2016, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$574, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2611:
	movzbq	310(%r11), %rax
	movq	$2032, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$574, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2610:
	movzbq	77(%r11), %rax
	movq	$1984, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$575, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2609:
	movzbq	155(%r11), %rax
	movq	$2000, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$575, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2608:
	movzbq	233(%r11), %rax
	movq	$2016, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$575, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2607:
	movzbq	311(%r11), %rax
	movq	$2032, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$575, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2606:
	movq	$32, %rdx
	jmp 	Lbitsliced_m_calculate_PS$2600
Lbitsliced_m_calculate_PS$2601:
	movzbq	(%r11,%rdx), %rax
	movq	$2048, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$2605:
	movzbq	78(%r11,%rdx), %rax
	movq	$2064, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$2604:
	movzbq	156(%r11,%rdx), %rax
	movq	$2080, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$2603:
	movzbq	234(%r11,%rdx), %rax
	movq	$2096, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$2602:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$2600:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$2601
	movzbq	60(%r11), %rax
	movq	$2048, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$576, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2599:
	movzbq	138(%r11), %rax
	movq	$2064, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$576, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2598:
	movzbq	216(%r11), %rax
	movq	$2080, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$576, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2597:
	movzbq	294(%r11), %rax
	movq	$2096, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$576, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2596:
	movzbq	61(%r11), %rax
	movq	$2048, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$577, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2595:
	movzbq	139(%r11), %rax
	movq	$2064, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$577, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2594:
	movzbq	217(%r11), %rax
	movq	$2080, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$577, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2593:
	movzbq	295(%r11), %rax
	movq	$2096, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$577, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2592:
	movzbq	62(%r11), %rax
	movq	$2048, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$578, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2591:
	movzbq	140(%r11), %rax
	movq	$2064, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$578, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2590:
	movzbq	218(%r11), %rax
	movq	$2080, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$578, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2589:
	movzbq	296(%r11), %rax
	movq	$2096, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$578, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2588:
	movzbq	63(%r11), %rax
	movq	$2048, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$579, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2587:
	movzbq	141(%r11), %rax
	movq	$2064, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$579, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2586:
	movzbq	219(%r11), %rax
	movq	$2080, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$579, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2585:
	movzbq	297(%r11), %rax
	movq	$2096, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$579, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2584:
	movzbq	64(%r11), %rax
	movq	$2048, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$580, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2583:
	movzbq	142(%r11), %rax
	movq	$2064, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$580, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2582:
	movzbq	220(%r11), %rax
	movq	$2080, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$580, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2581:
	movzbq	298(%r11), %rax
	movq	$2096, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$580, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2580:
	movzbq	65(%r11), %rax
	movq	$2048, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$581, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2579:
	movzbq	143(%r11), %rax
	movq	$2064, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$581, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2578:
	movzbq	221(%r11), %rax
	movq	$2080, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$581, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2577:
	movzbq	299(%r11), %rax
	movq	$2096, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$581, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2576:
	movzbq	66(%r11), %rax
	movq	$2048, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$582, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2575:
	movzbq	144(%r11), %rax
	movq	$2064, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$582, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2574:
	movzbq	222(%r11), %rax
	movq	$2080, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$582, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2573:
	movzbq	300(%r11), %rax
	movq	$2096, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$582, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2572:
	movzbq	67(%r11), %rax
	movq	$2048, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$583, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2571:
	movzbq	145(%r11), %rax
	movq	$2064, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$583, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2570:
	movzbq	223(%r11), %rax
	movq	$2080, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$583, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2569:
	movzbq	301(%r11), %rax
	movq	$2096, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$583, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2568:
	movzbq	68(%r11), %rax
	movq	$2048, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$584, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2567:
	movzbq	146(%r11), %rax
	movq	$2064, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$584, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2566:
	movzbq	224(%r11), %rax
	movq	$2080, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$584, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2565:
	movzbq	302(%r11), %rax
	movq	$2096, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$584, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2564:
	movzbq	69(%r11), %rax
	movq	$2048, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$585, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2563:
	movzbq	147(%r11), %rax
	movq	$2064, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$585, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2562:
	movzbq	225(%r11), %rax
	movq	$2080, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$585, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2561:
	movzbq	303(%r11), %rax
	movq	$2096, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$585, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2560:
	movzbq	70(%r11), %rax
	movq	$2048, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$586, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2559:
	movzbq	148(%r11), %rax
	movq	$2064, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$586, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2558:
	movzbq	226(%r11), %rax
	movq	$2080, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$586, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2557:
	movzbq	304(%r11), %rax
	movq	$2096, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$586, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2556:
	movzbq	71(%r11), %rax
	movq	$2048, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$587, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2555:
	movzbq	149(%r11), %rax
	movq	$2064, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$587, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2554:
	movzbq	227(%r11), %rax
	movq	$2080, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$587, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2553:
	movzbq	305(%r11), %rax
	movq	$2096, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$587, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2552:
	movzbq	72(%r11), %rax
	movq	$2048, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$588, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2551:
	movzbq	150(%r11), %rax
	movq	$2064, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$588, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2550:
	movzbq	228(%r11), %rax
	movq	$2080, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$588, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2549:
	movzbq	306(%r11), %rax
	movq	$2096, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$588, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2548:
	movzbq	73(%r11), %rax
	movq	$2048, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$589, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2547:
	movzbq	151(%r11), %rax
	movq	$2064, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$589, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2546:
	movzbq	229(%r11), %rax
	movq	$2080, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$589, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2545:
	movzbq	307(%r11), %rax
	movq	$2096, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$589, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2544:
	movzbq	74(%r11), %rax
	movq	$2048, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$590, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2543:
	movzbq	152(%r11), %rax
	movq	$2064, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$590, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2542:
	movzbq	230(%r11), %rax
	movq	$2080, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$590, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2541:
	movzbq	308(%r11), %rax
	movq	$2096, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$590, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2540:
	movzbq	75(%r11), %rax
	movq	$2048, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$591, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2539:
	movzbq	153(%r11), %rax
	movq	$2064, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$591, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2538:
	movzbq	231(%r11), %rax
	movq	$2080, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$591, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2537:
	movzbq	309(%r11), %rax
	movq	$2096, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$591, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2536:
	movzbq	76(%r11), %rax
	movq	$2048, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$592, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2535:
	movzbq	154(%r11), %rax
	movq	$2064, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$592, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2534:
	movzbq	232(%r11), %rax
	movq	$2080, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$592, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2533:
	movzbq	310(%r11), %rax
	movq	$2096, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$592, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2532:
	movzbq	77(%r11), %rax
	movq	$2048, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$593, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2531:
	movzbq	155(%r11), %rax
	movq	$2064, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$593, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2530:
	movzbq	233(%r11), %rax
	movq	$2080, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$593, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2529:
	movzbq	311(%r11), %rax
	movq	$2096, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$593, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2528:
	movq	$33, %rdx
	jmp 	Lbitsliced_m_calculate_PS$2522
Lbitsliced_m_calculate_PS$2523:
	movzbq	(%r11,%rdx), %rax
	movq	$2112, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$2527:
	movzbq	78(%r11,%rdx), %rax
	movq	$2128, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$2526:
	movzbq	156(%r11,%rdx), %rax
	movq	$2144, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$2525:
	movzbq	234(%r11,%rdx), %rax
	movq	$2160, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$2524:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$2522:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$2523
	movzbq	60(%r11), %rax
	movq	$2112, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$594, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2521:
	movzbq	138(%r11), %rax
	movq	$2128, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$594, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2520:
	movzbq	216(%r11), %rax
	movq	$2144, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$594, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2519:
	movzbq	294(%r11), %rax
	movq	$2160, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$594, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2518:
	movzbq	61(%r11), %rax
	movq	$2112, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$595, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2517:
	movzbq	139(%r11), %rax
	movq	$2128, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$595, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2516:
	movzbq	217(%r11), %rax
	movq	$2144, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$595, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2515:
	movzbq	295(%r11), %rax
	movq	$2160, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$595, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2514:
	movzbq	62(%r11), %rax
	movq	$2112, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$596, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2513:
	movzbq	140(%r11), %rax
	movq	$2128, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$596, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2512:
	movzbq	218(%r11), %rax
	movq	$2144, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$596, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2511:
	movzbq	296(%r11), %rax
	movq	$2160, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$596, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2510:
	movzbq	63(%r11), %rax
	movq	$2112, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$597, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2509:
	movzbq	141(%r11), %rax
	movq	$2128, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$597, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2508:
	movzbq	219(%r11), %rax
	movq	$2144, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$597, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2507:
	movzbq	297(%r11), %rax
	movq	$2160, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$597, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2506:
	movzbq	64(%r11), %rax
	movq	$2112, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$598, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2505:
	movzbq	142(%r11), %rax
	movq	$2128, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$598, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2504:
	movzbq	220(%r11), %rax
	movq	$2144, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$598, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2503:
	movzbq	298(%r11), %rax
	movq	$2160, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$598, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2502:
	movzbq	65(%r11), %rax
	movq	$2112, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$599, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2501:
	movzbq	143(%r11), %rax
	movq	$2128, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$599, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2500:
	movzbq	221(%r11), %rax
	movq	$2144, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$599, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2499:
	movzbq	299(%r11), %rax
	movq	$2160, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$599, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2498:
	movzbq	66(%r11), %rax
	movq	$2112, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$600, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2497:
	movzbq	144(%r11), %rax
	movq	$2128, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$600, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2496:
	movzbq	222(%r11), %rax
	movq	$2144, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$600, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2495:
	movzbq	300(%r11), %rax
	movq	$2160, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$600, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2494:
	movzbq	67(%r11), %rax
	movq	$2112, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$601, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2493:
	movzbq	145(%r11), %rax
	movq	$2128, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$601, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2492:
	movzbq	223(%r11), %rax
	movq	$2144, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$601, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2491:
	movzbq	301(%r11), %rax
	movq	$2160, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$601, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2490:
	movzbq	68(%r11), %rax
	movq	$2112, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$602, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2489:
	movzbq	146(%r11), %rax
	movq	$2128, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$602, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2488:
	movzbq	224(%r11), %rax
	movq	$2144, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$602, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2487:
	movzbq	302(%r11), %rax
	movq	$2160, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$602, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2486:
	movzbq	69(%r11), %rax
	movq	$2112, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$603, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2485:
	movzbq	147(%r11), %rax
	movq	$2128, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$603, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2484:
	movzbq	225(%r11), %rax
	movq	$2144, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$603, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2483:
	movzbq	303(%r11), %rax
	movq	$2160, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$603, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2482:
	movzbq	70(%r11), %rax
	movq	$2112, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$604, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2481:
	movzbq	148(%r11), %rax
	movq	$2128, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$604, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2480:
	movzbq	226(%r11), %rax
	movq	$2144, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$604, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2479:
	movzbq	304(%r11), %rax
	movq	$2160, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$604, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2478:
	movzbq	71(%r11), %rax
	movq	$2112, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$605, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2477:
	movzbq	149(%r11), %rax
	movq	$2128, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$605, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2476:
	movzbq	227(%r11), %rax
	movq	$2144, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$605, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2475:
	movzbq	305(%r11), %rax
	movq	$2160, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$605, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2474:
	movzbq	72(%r11), %rax
	movq	$2112, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$606, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2473:
	movzbq	150(%r11), %rax
	movq	$2128, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$606, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2472:
	movzbq	228(%r11), %rax
	movq	$2144, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$606, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2471:
	movzbq	306(%r11), %rax
	movq	$2160, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$606, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2470:
	movzbq	73(%r11), %rax
	movq	$2112, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$607, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2469:
	movzbq	151(%r11), %rax
	movq	$2128, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$607, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2468:
	movzbq	229(%r11), %rax
	movq	$2144, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$607, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2467:
	movzbq	307(%r11), %rax
	movq	$2160, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$607, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2466:
	movzbq	74(%r11), %rax
	movq	$2112, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$608, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2465:
	movzbq	152(%r11), %rax
	movq	$2128, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$608, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2464:
	movzbq	230(%r11), %rax
	movq	$2144, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$608, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2463:
	movzbq	308(%r11), %rax
	movq	$2160, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$608, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2462:
	movzbq	75(%r11), %rax
	movq	$2112, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$609, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2461:
	movzbq	153(%r11), %rax
	movq	$2128, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$609, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2460:
	movzbq	231(%r11), %rax
	movq	$2144, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$609, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2459:
	movzbq	309(%r11), %rax
	movq	$2160, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$609, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2458:
	movzbq	76(%r11), %rax
	movq	$2112, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$610, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2457:
	movzbq	154(%r11), %rax
	movq	$2128, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$610, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2456:
	movzbq	232(%r11), %rax
	movq	$2144, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$610, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2455:
	movzbq	310(%r11), %rax
	movq	$2160, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$610, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2454:
	movzbq	77(%r11), %rax
	movq	$2112, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$611, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2453:
	movzbq	155(%r11), %rax
	movq	$2128, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$611, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2452:
	movzbq	233(%r11), %rax
	movq	$2144, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$611, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2451:
	movzbq	311(%r11), %rax
	movq	$2160, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$611, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2450:
	movq	$34, %rdx
	jmp 	Lbitsliced_m_calculate_PS$2444
Lbitsliced_m_calculate_PS$2445:
	movzbq	(%r11,%rdx), %rax
	movq	$2176, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$2449:
	movzbq	78(%r11,%rdx), %rax
	movq	$2192, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$2448:
	movzbq	156(%r11,%rdx), %rax
	movq	$2208, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$2447:
	movzbq	234(%r11,%rdx), %rax
	movq	$2224, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$2446:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$2444:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$2445
	movzbq	60(%r11), %rax
	movq	$2176, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$612, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2443:
	movzbq	138(%r11), %rax
	movq	$2192, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$612, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2442:
	movzbq	216(%r11), %rax
	movq	$2208, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$612, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2441:
	movzbq	294(%r11), %rax
	movq	$2224, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$612, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2440:
	movzbq	61(%r11), %rax
	movq	$2176, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$613, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2439:
	movzbq	139(%r11), %rax
	movq	$2192, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$613, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2438:
	movzbq	217(%r11), %rax
	movq	$2208, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$613, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2437:
	movzbq	295(%r11), %rax
	movq	$2224, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$613, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2436:
	movzbq	62(%r11), %rax
	movq	$2176, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$614, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2435:
	movzbq	140(%r11), %rax
	movq	$2192, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$614, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2434:
	movzbq	218(%r11), %rax
	movq	$2208, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$614, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2433:
	movzbq	296(%r11), %rax
	movq	$2224, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$614, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2432:
	movzbq	63(%r11), %rax
	movq	$2176, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$615, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2431:
	movzbq	141(%r11), %rax
	movq	$2192, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$615, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2430:
	movzbq	219(%r11), %rax
	movq	$2208, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$615, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2429:
	movzbq	297(%r11), %rax
	movq	$2224, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$615, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2428:
	movzbq	64(%r11), %rax
	movq	$2176, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$616, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2427:
	movzbq	142(%r11), %rax
	movq	$2192, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$616, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2426:
	movzbq	220(%r11), %rax
	movq	$2208, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$616, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2425:
	movzbq	298(%r11), %rax
	movq	$2224, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$616, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2424:
	movzbq	65(%r11), %rax
	movq	$2176, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$617, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2423:
	movzbq	143(%r11), %rax
	movq	$2192, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$617, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2422:
	movzbq	221(%r11), %rax
	movq	$2208, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$617, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2421:
	movzbq	299(%r11), %rax
	movq	$2224, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$617, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2420:
	movzbq	66(%r11), %rax
	movq	$2176, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$618, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2419:
	movzbq	144(%r11), %rax
	movq	$2192, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$618, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2418:
	movzbq	222(%r11), %rax
	movq	$2208, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$618, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2417:
	movzbq	300(%r11), %rax
	movq	$2224, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$618, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2416:
	movzbq	67(%r11), %rax
	movq	$2176, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$619, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2415:
	movzbq	145(%r11), %rax
	movq	$2192, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$619, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2414:
	movzbq	223(%r11), %rax
	movq	$2208, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$619, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2413:
	movzbq	301(%r11), %rax
	movq	$2224, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$619, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2412:
	movzbq	68(%r11), %rax
	movq	$2176, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$620, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2411:
	movzbq	146(%r11), %rax
	movq	$2192, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$620, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2410:
	movzbq	224(%r11), %rax
	movq	$2208, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$620, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2409:
	movzbq	302(%r11), %rax
	movq	$2224, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$620, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2408:
	movzbq	69(%r11), %rax
	movq	$2176, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$621, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2407:
	movzbq	147(%r11), %rax
	movq	$2192, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$621, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2406:
	movzbq	225(%r11), %rax
	movq	$2208, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$621, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2405:
	movzbq	303(%r11), %rax
	movq	$2224, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$621, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2404:
	movzbq	70(%r11), %rax
	movq	$2176, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$622, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2403:
	movzbq	148(%r11), %rax
	movq	$2192, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$622, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2402:
	movzbq	226(%r11), %rax
	movq	$2208, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$622, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2401:
	movzbq	304(%r11), %rax
	movq	$2224, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$622, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2400:
	movzbq	71(%r11), %rax
	movq	$2176, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$623, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2399:
	movzbq	149(%r11), %rax
	movq	$2192, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$623, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2398:
	movzbq	227(%r11), %rax
	movq	$2208, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$623, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2397:
	movzbq	305(%r11), %rax
	movq	$2224, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$623, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2396:
	movzbq	72(%r11), %rax
	movq	$2176, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$624, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2395:
	movzbq	150(%r11), %rax
	movq	$2192, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$624, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2394:
	movzbq	228(%r11), %rax
	movq	$2208, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$624, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2393:
	movzbq	306(%r11), %rax
	movq	$2224, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$624, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2392:
	movzbq	73(%r11), %rax
	movq	$2176, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$625, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2391:
	movzbq	151(%r11), %rax
	movq	$2192, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$625, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2390:
	movzbq	229(%r11), %rax
	movq	$2208, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$625, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2389:
	movzbq	307(%r11), %rax
	movq	$2224, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$625, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2388:
	movzbq	74(%r11), %rax
	movq	$2176, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$626, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2387:
	movzbq	152(%r11), %rax
	movq	$2192, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$626, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2386:
	movzbq	230(%r11), %rax
	movq	$2208, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$626, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2385:
	movzbq	308(%r11), %rax
	movq	$2224, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$626, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2384:
	movzbq	75(%r11), %rax
	movq	$2176, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$627, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2383:
	movzbq	153(%r11), %rax
	movq	$2192, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$627, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2382:
	movzbq	231(%r11), %rax
	movq	$2208, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$627, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2381:
	movzbq	309(%r11), %rax
	movq	$2224, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$627, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2380:
	movzbq	76(%r11), %rax
	movq	$2176, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$628, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2379:
	movzbq	154(%r11), %rax
	movq	$2192, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$628, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2378:
	movzbq	232(%r11), %rax
	movq	$2208, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$628, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2377:
	movzbq	310(%r11), %rax
	movq	$2224, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$628, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2376:
	movzbq	77(%r11), %rax
	movq	$2176, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$629, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2375:
	movzbq	155(%r11), %rax
	movq	$2192, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$629, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2374:
	movzbq	233(%r11), %rax
	movq	$2208, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$629, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2373:
	movzbq	311(%r11), %rax
	movq	$2224, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$629, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2372:
	movq	$35, %rdx
	jmp 	Lbitsliced_m_calculate_PS$2366
Lbitsliced_m_calculate_PS$2367:
	movzbq	(%r11,%rdx), %rax
	movq	$2240, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$2371:
	movzbq	78(%r11,%rdx), %rax
	movq	$2256, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$2370:
	movzbq	156(%r11,%rdx), %rax
	movq	$2272, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$2369:
	movzbq	234(%r11,%rdx), %rax
	movq	$2288, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$2368:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$2366:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$2367
	movzbq	60(%r11), %rax
	movq	$2240, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$630, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2365:
	movzbq	138(%r11), %rax
	movq	$2256, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$630, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2364:
	movzbq	216(%r11), %rax
	movq	$2272, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$630, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2363:
	movzbq	294(%r11), %rax
	movq	$2288, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$630, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2362:
	movzbq	61(%r11), %rax
	movq	$2240, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$631, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2361:
	movzbq	139(%r11), %rax
	movq	$2256, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$631, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2360:
	movzbq	217(%r11), %rax
	movq	$2272, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$631, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2359:
	movzbq	295(%r11), %rax
	movq	$2288, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$631, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2358:
	movzbq	62(%r11), %rax
	movq	$2240, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$632, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2357:
	movzbq	140(%r11), %rax
	movq	$2256, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$632, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2356:
	movzbq	218(%r11), %rax
	movq	$2272, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$632, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2355:
	movzbq	296(%r11), %rax
	movq	$2288, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$632, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2354:
	movzbq	63(%r11), %rax
	movq	$2240, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$633, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2353:
	movzbq	141(%r11), %rax
	movq	$2256, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$633, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2352:
	movzbq	219(%r11), %rax
	movq	$2272, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$633, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2351:
	movzbq	297(%r11), %rax
	movq	$2288, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$633, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2350:
	movzbq	64(%r11), %rax
	movq	$2240, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$634, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2349:
	movzbq	142(%r11), %rax
	movq	$2256, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$634, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2348:
	movzbq	220(%r11), %rax
	movq	$2272, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$634, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2347:
	movzbq	298(%r11), %rax
	movq	$2288, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$634, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2346:
	movzbq	65(%r11), %rax
	movq	$2240, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$635, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2345:
	movzbq	143(%r11), %rax
	movq	$2256, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$635, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2344:
	movzbq	221(%r11), %rax
	movq	$2272, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$635, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2343:
	movzbq	299(%r11), %rax
	movq	$2288, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$635, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2342:
	movzbq	66(%r11), %rax
	movq	$2240, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$636, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2341:
	movzbq	144(%r11), %rax
	movq	$2256, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$636, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2340:
	movzbq	222(%r11), %rax
	movq	$2272, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$636, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2339:
	movzbq	300(%r11), %rax
	movq	$2288, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$636, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2338:
	movzbq	67(%r11), %rax
	movq	$2240, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$637, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2337:
	movzbq	145(%r11), %rax
	movq	$2256, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$637, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2336:
	movzbq	223(%r11), %rax
	movq	$2272, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$637, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2335:
	movzbq	301(%r11), %rax
	movq	$2288, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$637, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2334:
	movzbq	68(%r11), %rax
	movq	$2240, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$638, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2333:
	movzbq	146(%r11), %rax
	movq	$2256, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$638, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2332:
	movzbq	224(%r11), %rax
	movq	$2272, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$638, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2331:
	movzbq	302(%r11), %rax
	movq	$2288, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$638, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2330:
	movzbq	69(%r11), %rax
	movq	$2240, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$639, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2329:
	movzbq	147(%r11), %rax
	movq	$2256, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$639, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2328:
	movzbq	225(%r11), %rax
	movq	$2272, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$639, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2327:
	movzbq	303(%r11), %rax
	movq	$2288, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$639, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2326:
	movzbq	70(%r11), %rax
	movq	$2240, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$640, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2325:
	movzbq	148(%r11), %rax
	movq	$2256, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$640, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2324:
	movzbq	226(%r11), %rax
	movq	$2272, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$640, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2323:
	movzbq	304(%r11), %rax
	movq	$2288, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$640, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2322:
	movzbq	71(%r11), %rax
	movq	$2240, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$641, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2321:
	movzbq	149(%r11), %rax
	movq	$2256, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$641, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2320:
	movzbq	227(%r11), %rax
	movq	$2272, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$641, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2319:
	movzbq	305(%r11), %rax
	movq	$2288, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$641, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2318:
	movzbq	72(%r11), %rax
	movq	$2240, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$642, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2317:
	movzbq	150(%r11), %rax
	movq	$2256, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$642, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2316:
	movzbq	228(%r11), %rax
	movq	$2272, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$642, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2315:
	movzbq	306(%r11), %rax
	movq	$2288, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$642, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2314:
	movzbq	73(%r11), %rax
	movq	$2240, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$643, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2313:
	movzbq	151(%r11), %rax
	movq	$2256, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$643, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2312:
	movzbq	229(%r11), %rax
	movq	$2272, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$643, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2311:
	movzbq	307(%r11), %rax
	movq	$2288, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$643, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2310:
	movzbq	74(%r11), %rax
	movq	$2240, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$644, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2309:
	movzbq	152(%r11), %rax
	movq	$2256, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$644, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2308:
	movzbq	230(%r11), %rax
	movq	$2272, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$644, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2307:
	movzbq	308(%r11), %rax
	movq	$2288, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$644, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2306:
	movzbq	75(%r11), %rax
	movq	$2240, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$645, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2305:
	movzbq	153(%r11), %rax
	movq	$2256, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$645, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2304:
	movzbq	231(%r11), %rax
	movq	$2272, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$645, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2303:
	movzbq	309(%r11), %rax
	movq	$2288, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$645, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2302:
	movzbq	76(%r11), %rax
	movq	$2240, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$646, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2301:
	movzbq	154(%r11), %rax
	movq	$2256, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$646, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2300:
	movzbq	232(%r11), %rax
	movq	$2272, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$646, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2299:
	movzbq	310(%r11), %rax
	movq	$2288, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$646, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2298:
	movzbq	77(%r11), %rax
	movq	$2240, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$647, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2297:
	movzbq	155(%r11), %rax
	movq	$2256, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$647, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2296:
	movzbq	233(%r11), %rax
	movq	$2272, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$647, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2295:
	movzbq	311(%r11), %rax
	movq	$2288, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$647, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2294:
	movq	$36, %rdx
	jmp 	Lbitsliced_m_calculate_PS$2288
Lbitsliced_m_calculate_PS$2289:
	movzbq	(%r11,%rdx), %rax
	movq	$2304, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$2293:
	movzbq	78(%r11,%rdx), %rax
	movq	$2320, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$2292:
	movzbq	156(%r11,%rdx), %rax
	movq	$2336, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$2291:
	movzbq	234(%r11,%rdx), %rax
	movq	$2352, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$2290:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$2288:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$2289
	movzbq	60(%r11), %rax
	movq	$2304, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$648, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2287:
	movzbq	138(%r11), %rax
	movq	$2320, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$648, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2286:
	movzbq	216(%r11), %rax
	movq	$2336, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$648, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2285:
	movzbq	294(%r11), %rax
	movq	$2352, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$648, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2284:
	movzbq	61(%r11), %rax
	movq	$2304, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$649, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2283:
	movzbq	139(%r11), %rax
	movq	$2320, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$649, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2282:
	movzbq	217(%r11), %rax
	movq	$2336, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$649, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2281:
	movzbq	295(%r11), %rax
	movq	$2352, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$649, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2280:
	movzbq	62(%r11), %rax
	movq	$2304, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$650, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2279:
	movzbq	140(%r11), %rax
	movq	$2320, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$650, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2278:
	movzbq	218(%r11), %rax
	movq	$2336, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$650, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2277:
	movzbq	296(%r11), %rax
	movq	$2352, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$650, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2276:
	movzbq	63(%r11), %rax
	movq	$2304, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$651, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2275:
	movzbq	141(%r11), %rax
	movq	$2320, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$651, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2274:
	movzbq	219(%r11), %rax
	movq	$2336, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$651, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2273:
	movzbq	297(%r11), %rax
	movq	$2352, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$651, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2272:
	movzbq	64(%r11), %rax
	movq	$2304, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$652, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2271:
	movzbq	142(%r11), %rax
	movq	$2320, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$652, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2270:
	movzbq	220(%r11), %rax
	movq	$2336, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$652, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2269:
	movzbq	298(%r11), %rax
	movq	$2352, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$652, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2268:
	movzbq	65(%r11), %rax
	movq	$2304, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$653, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2267:
	movzbq	143(%r11), %rax
	movq	$2320, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$653, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2266:
	movzbq	221(%r11), %rax
	movq	$2336, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$653, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2265:
	movzbq	299(%r11), %rax
	movq	$2352, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$653, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2264:
	movzbq	66(%r11), %rax
	movq	$2304, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$654, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2263:
	movzbq	144(%r11), %rax
	movq	$2320, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$654, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2262:
	movzbq	222(%r11), %rax
	movq	$2336, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$654, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2261:
	movzbq	300(%r11), %rax
	movq	$2352, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$654, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2260:
	movzbq	67(%r11), %rax
	movq	$2304, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$655, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2259:
	movzbq	145(%r11), %rax
	movq	$2320, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$655, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2258:
	movzbq	223(%r11), %rax
	movq	$2336, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$655, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2257:
	movzbq	301(%r11), %rax
	movq	$2352, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$655, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2256:
	movzbq	68(%r11), %rax
	movq	$2304, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$656, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2255:
	movzbq	146(%r11), %rax
	movq	$2320, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$656, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2254:
	movzbq	224(%r11), %rax
	movq	$2336, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$656, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2253:
	movzbq	302(%r11), %rax
	movq	$2352, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$656, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2252:
	movzbq	69(%r11), %rax
	movq	$2304, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$657, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2251:
	movzbq	147(%r11), %rax
	movq	$2320, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$657, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2250:
	movzbq	225(%r11), %rax
	movq	$2336, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$657, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2249:
	movzbq	303(%r11), %rax
	movq	$2352, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$657, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2248:
	movzbq	70(%r11), %rax
	movq	$2304, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$658, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2247:
	movzbq	148(%r11), %rax
	movq	$2320, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$658, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2246:
	movzbq	226(%r11), %rax
	movq	$2336, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$658, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2245:
	movzbq	304(%r11), %rax
	movq	$2352, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$658, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2244:
	movzbq	71(%r11), %rax
	movq	$2304, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$659, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2243:
	movzbq	149(%r11), %rax
	movq	$2320, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$659, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2242:
	movzbq	227(%r11), %rax
	movq	$2336, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$659, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2241:
	movzbq	305(%r11), %rax
	movq	$2352, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$659, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2240:
	movzbq	72(%r11), %rax
	movq	$2304, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$660, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2239:
	movzbq	150(%r11), %rax
	movq	$2320, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$660, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2238:
	movzbq	228(%r11), %rax
	movq	$2336, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$660, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2237:
	movzbq	306(%r11), %rax
	movq	$2352, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$660, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2236:
	movzbq	73(%r11), %rax
	movq	$2304, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$661, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2235:
	movzbq	151(%r11), %rax
	movq	$2320, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$661, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2234:
	movzbq	229(%r11), %rax
	movq	$2336, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$661, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2233:
	movzbq	307(%r11), %rax
	movq	$2352, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$661, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2232:
	movzbq	74(%r11), %rax
	movq	$2304, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$662, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2231:
	movzbq	152(%r11), %rax
	movq	$2320, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$662, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2230:
	movzbq	230(%r11), %rax
	movq	$2336, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$662, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2229:
	movzbq	308(%r11), %rax
	movq	$2352, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$662, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2228:
	movzbq	75(%r11), %rax
	movq	$2304, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$663, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2227:
	movzbq	153(%r11), %rax
	movq	$2320, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$663, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2226:
	movzbq	231(%r11), %rax
	movq	$2336, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$663, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2225:
	movzbq	309(%r11), %rax
	movq	$2352, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$663, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2224:
	movzbq	76(%r11), %rax
	movq	$2304, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$664, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2223:
	movzbq	154(%r11), %rax
	movq	$2320, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$664, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2222:
	movzbq	232(%r11), %rax
	movq	$2336, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$664, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2221:
	movzbq	310(%r11), %rax
	movq	$2352, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$664, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2220:
	movzbq	77(%r11), %rax
	movq	$2304, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$665, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2219:
	movzbq	155(%r11), %rax
	movq	$2320, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$665, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2218:
	movzbq	233(%r11), %rax
	movq	$2336, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$665, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2217:
	movzbq	311(%r11), %rax
	movq	$2352, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$665, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2216:
	movq	$37, %rdx
	jmp 	Lbitsliced_m_calculate_PS$2210
Lbitsliced_m_calculate_PS$2211:
	movzbq	(%r11,%rdx), %rax
	movq	$2368, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$2215:
	movzbq	78(%r11,%rdx), %rax
	movq	$2384, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$2214:
	movzbq	156(%r11,%rdx), %rax
	movq	$2400, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$2213:
	movzbq	234(%r11,%rdx), %rax
	movq	$2416, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$2212:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$2210:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$2211
	movzbq	60(%r11), %rax
	movq	$2368, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$666, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2209:
	movzbq	138(%r11), %rax
	movq	$2384, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$666, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2208:
	movzbq	216(%r11), %rax
	movq	$2400, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$666, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2207:
	movzbq	294(%r11), %rax
	movq	$2416, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$666, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2206:
	movzbq	61(%r11), %rax
	movq	$2368, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$667, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2205:
	movzbq	139(%r11), %rax
	movq	$2384, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$667, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2204:
	movzbq	217(%r11), %rax
	movq	$2400, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$667, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2203:
	movzbq	295(%r11), %rax
	movq	$2416, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$667, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2202:
	movzbq	62(%r11), %rax
	movq	$2368, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$668, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2201:
	movzbq	140(%r11), %rax
	movq	$2384, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$668, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2200:
	movzbq	218(%r11), %rax
	movq	$2400, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$668, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2199:
	movzbq	296(%r11), %rax
	movq	$2416, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$668, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2198:
	movzbq	63(%r11), %rax
	movq	$2368, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$669, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2197:
	movzbq	141(%r11), %rax
	movq	$2384, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$669, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2196:
	movzbq	219(%r11), %rax
	movq	$2400, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$669, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2195:
	movzbq	297(%r11), %rax
	movq	$2416, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$669, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2194:
	movzbq	64(%r11), %rax
	movq	$2368, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$670, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2193:
	movzbq	142(%r11), %rax
	movq	$2384, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$670, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2192:
	movzbq	220(%r11), %rax
	movq	$2400, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$670, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2191:
	movzbq	298(%r11), %rax
	movq	$2416, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$670, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2190:
	movzbq	65(%r11), %rax
	movq	$2368, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$671, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2189:
	movzbq	143(%r11), %rax
	movq	$2384, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$671, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2188:
	movzbq	221(%r11), %rax
	movq	$2400, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$671, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2187:
	movzbq	299(%r11), %rax
	movq	$2416, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$671, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2186:
	movzbq	66(%r11), %rax
	movq	$2368, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$672, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2185:
	movzbq	144(%r11), %rax
	movq	$2384, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$672, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2184:
	movzbq	222(%r11), %rax
	movq	$2400, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$672, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2183:
	movzbq	300(%r11), %rax
	movq	$2416, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$672, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2182:
	movzbq	67(%r11), %rax
	movq	$2368, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$673, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2181:
	movzbq	145(%r11), %rax
	movq	$2384, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$673, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2180:
	movzbq	223(%r11), %rax
	movq	$2400, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$673, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2179:
	movzbq	301(%r11), %rax
	movq	$2416, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$673, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2178:
	movzbq	68(%r11), %rax
	movq	$2368, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$674, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2177:
	movzbq	146(%r11), %rax
	movq	$2384, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$674, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2176:
	movzbq	224(%r11), %rax
	movq	$2400, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$674, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2175:
	movzbq	302(%r11), %rax
	movq	$2416, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$674, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2174:
	movzbq	69(%r11), %rax
	movq	$2368, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$675, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2173:
	movzbq	147(%r11), %rax
	movq	$2384, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$675, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2172:
	movzbq	225(%r11), %rax
	movq	$2400, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$675, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2171:
	movzbq	303(%r11), %rax
	movq	$2416, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$675, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2170:
	movzbq	70(%r11), %rax
	movq	$2368, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$676, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2169:
	movzbq	148(%r11), %rax
	movq	$2384, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$676, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2168:
	movzbq	226(%r11), %rax
	movq	$2400, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$676, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2167:
	movzbq	304(%r11), %rax
	movq	$2416, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$676, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2166:
	movzbq	71(%r11), %rax
	movq	$2368, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$677, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2165:
	movzbq	149(%r11), %rax
	movq	$2384, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$677, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2164:
	movzbq	227(%r11), %rax
	movq	$2400, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$677, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2163:
	movzbq	305(%r11), %rax
	movq	$2416, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$677, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2162:
	movzbq	72(%r11), %rax
	movq	$2368, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$678, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2161:
	movzbq	150(%r11), %rax
	movq	$2384, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$678, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2160:
	movzbq	228(%r11), %rax
	movq	$2400, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$678, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2159:
	movzbq	306(%r11), %rax
	movq	$2416, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$678, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2158:
	movzbq	73(%r11), %rax
	movq	$2368, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$679, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2157:
	movzbq	151(%r11), %rax
	movq	$2384, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$679, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2156:
	movzbq	229(%r11), %rax
	movq	$2400, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$679, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2155:
	movzbq	307(%r11), %rax
	movq	$2416, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$679, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2154:
	movzbq	74(%r11), %rax
	movq	$2368, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$680, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2153:
	movzbq	152(%r11), %rax
	movq	$2384, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$680, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2152:
	movzbq	230(%r11), %rax
	movq	$2400, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$680, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2151:
	movzbq	308(%r11), %rax
	movq	$2416, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$680, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2150:
	movzbq	75(%r11), %rax
	movq	$2368, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$681, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2149:
	movzbq	153(%r11), %rax
	movq	$2384, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$681, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2148:
	movzbq	231(%r11), %rax
	movq	$2400, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$681, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2147:
	movzbq	309(%r11), %rax
	movq	$2416, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$681, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2146:
	movzbq	76(%r11), %rax
	movq	$2368, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$682, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2145:
	movzbq	154(%r11), %rax
	movq	$2384, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$682, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2144:
	movzbq	232(%r11), %rax
	movq	$2400, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$682, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2143:
	movzbq	310(%r11), %rax
	movq	$2416, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$682, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2142:
	movzbq	77(%r11), %rax
	movq	$2368, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$683, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2141:
	movzbq	155(%r11), %rax
	movq	$2384, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$683, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2140:
	movzbq	233(%r11), %rax
	movq	$2400, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$683, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2139:
	movzbq	311(%r11), %rax
	movq	$2416, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$683, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2138:
	movq	$38, %rdx
	jmp 	Lbitsliced_m_calculate_PS$2132
Lbitsliced_m_calculate_PS$2133:
	movzbq	(%r11,%rdx), %rax
	movq	$2432, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$2137:
	movzbq	78(%r11,%rdx), %rax
	movq	$2448, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$2136:
	movzbq	156(%r11,%rdx), %rax
	movq	$2464, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$2135:
	movzbq	234(%r11,%rdx), %rax
	movq	$2480, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$2134:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$2132:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$2133
	movzbq	60(%r11), %rax
	movq	$2432, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$684, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2131:
	movzbq	138(%r11), %rax
	movq	$2448, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$684, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2130:
	movzbq	216(%r11), %rax
	movq	$2464, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$684, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2129:
	movzbq	294(%r11), %rax
	movq	$2480, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$684, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2128:
	movzbq	61(%r11), %rax
	movq	$2432, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$685, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2127:
	movzbq	139(%r11), %rax
	movq	$2448, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$685, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2126:
	movzbq	217(%r11), %rax
	movq	$2464, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$685, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2125:
	movzbq	295(%r11), %rax
	movq	$2480, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$685, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2124:
	movzbq	62(%r11), %rax
	movq	$2432, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$686, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2123:
	movzbq	140(%r11), %rax
	movq	$2448, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$686, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2122:
	movzbq	218(%r11), %rax
	movq	$2464, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$686, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2121:
	movzbq	296(%r11), %rax
	movq	$2480, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$686, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2120:
	movzbq	63(%r11), %rax
	movq	$2432, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$687, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2119:
	movzbq	141(%r11), %rax
	movq	$2448, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$687, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2118:
	movzbq	219(%r11), %rax
	movq	$2464, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$687, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2117:
	movzbq	297(%r11), %rax
	movq	$2480, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$687, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2116:
	movzbq	64(%r11), %rax
	movq	$2432, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$688, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2115:
	movzbq	142(%r11), %rax
	movq	$2448, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$688, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2114:
	movzbq	220(%r11), %rax
	movq	$2464, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$688, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2113:
	movzbq	298(%r11), %rax
	movq	$2480, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$688, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2112:
	movzbq	65(%r11), %rax
	movq	$2432, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$689, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2111:
	movzbq	143(%r11), %rax
	movq	$2448, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$689, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2110:
	movzbq	221(%r11), %rax
	movq	$2464, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$689, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2109:
	movzbq	299(%r11), %rax
	movq	$2480, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$689, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2108:
	movzbq	66(%r11), %rax
	movq	$2432, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$690, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2107:
	movzbq	144(%r11), %rax
	movq	$2448, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$690, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2106:
	movzbq	222(%r11), %rax
	movq	$2464, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$690, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2105:
	movzbq	300(%r11), %rax
	movq	$2480, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$690, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2104:
	movzbq	67(%r11), %rax
	movq	$2432, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$691, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2103:
	movzbq	145(%r11), %rax
	movq	$2448, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$691, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2102:
	movzbq	223(%r11), %rax
	movq	$2464, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$691, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2101:
	movzbq	301(%r11), %rax
	movq	$2480, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$691, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2100:
	movzbq	68(%r11), %rax
	movq	$2432, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$692, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2099:
	movzbq	146(%r11), %rax
	movq	$2448, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$692, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2098:
	movzbq	224(%r11), %rax
	movq	$2464, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$692, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2097:
	movzbq	302(%r11), %rax
	movq	$2480, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$692, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2096:
	movzbq	69(%r11), %rax
	movq	$2432, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$693, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2095:
	movzbq	147(%r11), %rax
	movq	$2448, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$693, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2094:
	movzbq	225(%r11), %rax
	movq	$2464, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$693, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2093:
	movzbq	303(%r11), %rax
	movq	$2480, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$693, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2092:
	movzbq	70(%r11), %rax
	movq	$2432, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$694, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2091:
	movzbq	148(%r11), %rax
	movq	$2448, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$694, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2090:
	movzbq	226(%r11), %rax
	movq	$2464, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$694, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2089:
	movzbq	304(%r11), %rax
	movq	$2480, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$694, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2088:
	movzbq	71(%r11), %rax
	movq	$2432, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$695, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2087:
	movzbq	149(%r11), %rax
	movq	$2448, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$695, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2086:
	movzbq	227(%r11), %rax
	movq	$2464, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$695, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2085:
	movzbq	305(%r11), %rax
	movq	$2480, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$695, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2084:
	movzbq	72(%r11), %rax
	movq	$2432, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$696, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2083:
	movzbq	150(%r11), %rax
	movq	$2448, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$696, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2082:
	movzbq	228(%r11), %rax
	movq	$2464, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$696, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2081:
	movzbq	306(%r11), %rax
	movq	$2480, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$696, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2080:
	movzbq	73(%r11), %rax
	movq	$2432, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$697, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2079:
	movzbq	151(%r11), %rax
	movq	$2448, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$697, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2078:
	movzbq	229(%r11), %rax
	movq	$2464, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$697, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2077:
	movzbq	307(%r11), %rax
	movq	$2480, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$697, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2076:
	movzbq	74(%r11), %rax
	movq	$2432, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$698, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2075:
	movzbq	152(%r11), %rax
	movq	$2448, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$698, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2074:
	movzbq	230(%r11), %rax
	movq	$2464, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$698, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2073:
	movzbq	308(%r11), %rax
	movq	$2480, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$698, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2072:
	movzbq	75(%r11), %rax
	movq	$2432, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$699, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2071:
	movzbq	153(%r11), %rax
	movq	$2448, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$699, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2070:
	movzbq	231(%r11), %rax
	movq	$2464, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$699, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2069:
	movzbq	309(%r11), %rax
	movq	$2480, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$699, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2068:
	movzbq	76(%r11), %rax
	movq	$2432, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$700, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2067:
	movzbq	154(%r11), %rax
	movq	$2448, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$700, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2066:
	movzbq	232(%r11), %rax
	movq	$2464, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$700, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2065:
	movzbq	310(%r11), %rax
	movq	$2480, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$700, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2064:
	movzbq	77(%r11), %rax
	movq	$2432, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$701, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2063:
	movzbq	155(%r11), %rax
	movq	$2448, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$701, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2062:
	movzbq	233(%r11), %rax
	movq	$2464, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$701, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2061:
	movzbq	311(%r11), %rax
	movq	$2480, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$701, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2060:
	movq	$39, %rdx
	jmp 	Lbitsliced_m_calculate_PS$2054
Lbitsliced_m_calculate_PS$2055:
	movzbq	(%r11,%rdx), %rax
	movq	$2496, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$2059:
	movzbq	78(%r11,%rdx), %rax
	movq	$2512, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$2058:
	movzbq	156(%r11,%rdx), %rax
	movq	$2528, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$2057:
	movzbq	234(%r11,%rdx), %rax
	movq	$2544, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$2056:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$2054:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$2055
	movzbq	60(%r11), %rax
	movq	$2496, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$702, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2053:
	movzbq	138(%r11), %rax
	movq	$2512, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$702, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2052:
	movzbq	216(%r11), %rax
	movq	$2528, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$702, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2051:
	movzbq	294(%r11), %rax
	movq	$2544, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$702, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2050:
	movzbq	61(%r11), %rax
	movq	$2496, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$703, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2049:
	movzbq	139(%r11), %rax
	movq	$2512, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$703, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2048:
	movzbq	217(%r11), %rax
	movq	$2528, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$703, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2047:
	movzbq	295(%r11), %rax
	movq	$2544, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$703, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2046:
	movzbq	62(%r11), %rax
	movq	$2496, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$704, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2045:
	movzbq	140(%r11), %rax
	movq	$2512, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$704, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2044:
	movzbq	218(%r11), %rax
	movq	$2528, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$704, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2043:
	movzbq	296(%r11), %rax
	movq	$2544, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$704, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2042:
	movzbq	63(%r11), %rax
	movq	$2496, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$705, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2041:
	movzbq	141(%r11), %rax
	movq	$2512, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$705, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2040:
	movzbq	219(%r11), %rax
	movq	$2528, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$705, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2039:
	movzbq	297(%r11), %rax
	movq	$2544, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$705, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2038:
	movzbq	64(%r11), %rax
	movq	$2496, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$706, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2037:
	movzbq	142(%r11), %rax
	movq	$2512, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$706, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2036:
	movzbq	220(%r11), %rax
	movq	$2528, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$706, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2035:
	movzbq	298(%r11), %rax
	movq	$2544, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$706, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2034:
	movzbq	65(%r11), %rax
	movq	$2496, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$707, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2033:
	movzbq	143(%r11), %rax
	movq	$2512, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$707, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2032:
	movzbq	221(%r11), %rax
	movq	$2528, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$707, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2031:
	movzbq	299(%r11), %rax
	movq	$2544, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$707, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2030:
	movzbq	66(%r11), %rax
	movq	$2496, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$708, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2029:
	movzbq	144(%r11), %rax
	movq	$2512, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$708, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2028:
	movzbq	222(%r11), %rax
	movq	$2528, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$708, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2027:
	movzbq	300(%r11), %rax
	movq	$2544, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$708, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2026:
	movzbq	67(%r11), %rax
	movq	$2496, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$709, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2025:
	movzbq	145(%r11), %rax
	movq	$2512, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$709, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2024:
	movzbq	223(%r11), %rax
	movq	$2528, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$709, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2023:
	movzbq	301(%r11), %rax
	movq	$2544, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$709, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2022:
	movzbq	68(%r11), %rax
	movq	$2496, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$710, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2021:
	movzbq	146(%r11), %rax
	movq	$2512, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$710, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2020:
	movzbq	224(%r11), %rax
	movq	$2528, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$710, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2019:
	movzbq	302(%r11), %rax
	movq	$2544, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$710, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2018:
	movzbq	69(%r11), %rax
	movq	$2496, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$711, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2017:
	movzbq	147(%r11), %rax
	movq	$2512, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$711, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2016:
	movzbq	225(%r11), %rax
	movq	$2528, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$711, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2015:
	movzbq	303(%r11), %rax
	movq	$2544, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$711, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2014:
	movzbq	70(%r11), %rax
	movq	$2496, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$712, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2013:
	movzbq	148(%r11), %rax
	movq	$2512, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$712, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2012:
	movzbq	226(%r11), %rax
	movq	$2528, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$712, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2011:
	movzbq	304(%r11), %rax
	movq	$2544, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$712, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2010:
	movzbq	71(%r11), %rax
	movq	$2496, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$713, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2009:
	movzbq	149(%r11), %rax
	movq	$2512, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$713, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2008:
	movzbq	227(%r11), %rax
	movq	$2528, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$713, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2007:
	movzbq	305(%r11), %rax
	movq	$2544, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$713, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2006:
	movzbq	72(%r11), %rax
	movq	$2496, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$714, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2005:
	movzbq	150(%r11), %rax
	movq	$2512, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$714, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2004:
	movzbq	228(%r11), %rax
	movq	$2528, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$714, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2003:
	movzbq	306(%r11), %rax
	movq	$2544, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$714, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2002:
	movzbq	73(%r11), %rax
	movq	$2496, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$715, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2001:
	movzbq	151(%r11), %rax
	movq	$2512, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$715, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$2000:
	movzbq	229(%r11), %rax
	movq	$2528, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$715, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1999:
	movzbq	307(%r11), %rax
	movq	$2544, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$715, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1998:
	movzbq	74(%r11), %rax
	movq	$2496, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$716, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1997:
	movzbq	152(%r11), %rax
	movq	$2512, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$716, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1996:
	movzbq	230(%r11), %rax
	movq	$2528, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$716, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1995:
	movzbq	308(%r11), %rax
	movq	$2544, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$716, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1994:
	movzbq	75(%r11), %rax
	movq	$2496, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$717, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1993:
	movzbq	153(%r11), %rax
	movq	$2512, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$717, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1992:
	movzbq	231(%r11), %rax
	movq	$2528, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$717, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1991:
	movzbq	309(%r11), %rax
	movq	$2544, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$717, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1990:
	movzbq	76(%r11), %rax
	movq	$2496, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$718, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1989:
	movzbq	154(%r11), %rax
	movq	$2512, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$718, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1988:
	movzbq	232(%r11), %rax
	movq	$2528, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$718, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1987:
	movzbq	310(%r11), %rax
	movq	$2544, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$718, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1986:
	movzbq	77(%r11), %rax
	movq	$2496, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$719, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1985:
	movzbq	155(%r11), %rax
	movq	$2512, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$719, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1984:
	movzbq	233(%r11), %rax
	movq	$2528, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$719, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1983:
	movzbq	311(%r11), %rax
	movq	$2544, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$719, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1982:
	movq	$40, %rdx
	jmp 	Lbitsliced_m_calculate_PS$1976
Lbitsliced_m_calculate_PS$1977:
	movzbq	(%r11,%rdx), %rax
	movq	$2560, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$1981:
	movzbq	78(%r11,%rdx), %rax
	movq	$2576, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$1980:
	movzbq	156(%r11,%rdx), %rax
	movq	$2592, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$1979:
	movzbq	234(%r11,%rdx), %rax
	movq	$2608, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$1978:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$1976:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$1977
	movzbq	60(%r11), %rax
	movq	$2560, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$720, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1975:
	movzbq	138(%r11), %rax
	movq	$2576, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$720, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1974:
	movzbq	216(%r11), %rax
	movq	$2592, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$720, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1973:
	movzbq	294(%r11), %rax
	movq	$2608, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$720, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1972:
	movzbq	61(%r11), %rax
	movq	$2560, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$721, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1971:
	movzbq	139(%r11), %rax
	movq	$2576, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$721, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1970:
	movzbq	217(%r11), %rax
	movq	$2592, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$721, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1969:
	movzbq	295(%r11), %rax
	movq	$2608, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$721, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1968:
	movzbq	62(%r11), %rax
	movq	$2560, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$722, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1967:
	movzbq	140(%r11), %rax
	movq	$2576, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$722, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1966:
	movzbq	218(%r11), %rax
	movq	$2592, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$722, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1965:
	movzbq	296(%r11), %rax
	movq	$2608, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$722, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1964:
	movzbq	63(%r11), %rax
	movq	$2560, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$723, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1963:
	movzbq	141(%r11), %rax
	movq	$2576, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$723, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1962:
	movzbq	219(%r11), %rax
	movq	$2592, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$723, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1961:
	movzbq	297(%r11), %rax
	movq	$2608, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$723, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1960:
	movzbq	64(%r11), %rax
	movq	$2560, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$724, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1959:
	movzbq	142(%r11), %rax
	movq	$2576, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$724, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1958:
	movzbq	220(%r11), %rax
	movq	$2592, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$724, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1957:
	movzbq	298(%r11), %rax
	movq	$2608, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$724, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1956:
	movzbq	65(%r11), %rax
	movq	$2560, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$725, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1955:
	movzbq	143(%r11), %rax
	movq	$2576, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$725, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1954:
	movzbq	221(%r11), %rax
	movq	$2592, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$725, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1953:
	movzbq	299(%r11), %rax
	movq	$2608, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$725, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1952:
	movzbq	66(%r11), %rax
	movq	$2560, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$726, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1951:
	movzbq	144(%r11), %rax
	movq	$2576, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$726, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1950:
	movzbq	222(%r11), %rax
	movq	$2592, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$726, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1949:
	movzbq	300(%r11), %rax
	movq	$2608, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$726, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1948:
	movzbq	67(%r11), %rax
	movq	$2560, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$727, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1947:
	movzbq	145(%r11), %rax
	movq	$2576, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$727, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1946:
	movzbq	223(%r11), %rax
	movq	$2592, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$727, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1945:
	movzbq	301(%r11), %rax
	movq	$2608, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$727, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1944:
	movzbq	68(%r11), %rax
	movq	$2560, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$728, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1943:
	movzbq	146(%r11), %rax
	movq	$2576, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$728, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1942:
	movzbq	224(%r11), %rax
	movq	$2592, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$728, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1941:
	movzbq	302(%r11), %rax
	movq	$2608, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$728, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1940:
	movzbq	69(%r11), %rax
	movq	$2560, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$729, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1939:
	movzbq	147(%r11), %rax
	movq	$2576, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$729, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1938:
	movzbq	225(%r11), %rax
	movq	$2592, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$729, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1937:
	movzbq	303(%r11), %rax
	movq	$2608, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$729, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1936:
	movzbq	70(%r11), %rax
	movq	$2560, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$730, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1935:
	movzbq	148(%r11), %rax
	movq	$2576, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$730, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1934:
	movzbq	226(%r11), %rax
	movq	$2592, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$730, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1933:
	movzbq	304(%r11), %rax
	movq	$2608, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$730, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1932:
	movzbq	71(%r11), %rax
	movq	$2560, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$731, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1931:
	movzbq	149(%r11), %rax
	movq	$2576, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$731, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1930:
	movzbq	227(%r11), %rax
	movq	$2592, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$731, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1929:
	movzbq	305(%r11), %rax
	movq	$2608, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$731, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1928:
	movzbq	72(%r11), %rax
	movq	$2560, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$732, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1927:
	movzbq	150(%r11), %rax
	movq	$2576, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$732, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1926:
	movzbq	228(%r11), %rax
	movq	$2592, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$732, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1925:
	movzbq	306(%r11), %rax
	movq	$2608, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$732, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1924:
	movzbq	73(%r11), %rax
	movq	$2560, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$733, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1923:
	movzbq	151(%r11), %rax
	movq	$2576, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$733, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1922:
	movzbq	229(%r11), %rax
	movq	$2592, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$733, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1921:
	movzbq	307(%r11), %rax
	movq	$2608, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$733, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1920:
	movzbq	74(%r11), %rax
	movq	$2560, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$734, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1919:
	movzbq	152(%r11), %rax
	movq	$2576, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$734, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1918:
	movzbq	230(%r11), %rax
	movq	$2592, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$734, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1917:
	movzbq	308(%r11), %rax
	movq	$2608, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$734, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1916:
	movzbq	75(%r11), %rax
	movq	$2560, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$735, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1915:
	movzbq	153(%r11), %rax
	movq	$2576, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$735, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1914:
	movzbq	231(%r11), %rax
	movq	$2592, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$735, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1913:
	movzbq	309(%r11), %rax
	movq	$2608, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$735, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1912:
	movzbq	76(%r11), %rax
	movq	$2560, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$736, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1911:
	movzbq	154(%r11), %rax
	movq	$2576, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$736, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1910:
	movzbq	232(%r11), %rax
	movq	$2592, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$736, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1909:
	movzbq	310(%r11), %rax
	movq	$2608, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$736, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1908:
	movzbq	77(%r11), %rax
	movq	$2560, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$737, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1907:
	movzbq	155(%r11), %rax
	movq	$2576, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$737, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1906:
	movzbq	233(%r11), %rax
	movq	$2592, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$737, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1905:
	movzbq	311(%r11), %rax
	movq	$2608, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$737, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1904:
	movq	$41, %rdx
	jmp 	Lbitsliced_m_calculate_PS$1898
Lbitsliced_m_calculate_PS$1899:
	movzbq	(%r11,%rdx), %rax
	movq	$2624, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$1903:
	movzbq	78(%r11,%rdx), %rax
	movq	$2640, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$1902:
	movzbq	156(%r11,%rdx), %rax
	movq	$2656, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$1901:
	movzbq	234(%r11,%rdx), %rax
	movq	$2672, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$1900:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$1898:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$1899
	movzbq	60(%r11), %rax
	movq	$2624, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$738, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1897:
	movzbq	138(%r11), %rax
	movq	$2640, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$738, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1896:
	movzbq	216(%r11), %rax
	movq	$2656, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$738, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1895:
	movzbq	294(%r11), %rax
	movq	$2672, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$738, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1894:
	movzbq	61(%r11), %rax
	movq	$2624, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$739, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1893:
	movzbq	139(%r11), %rax
	movq	$2640, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$739, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1892:
	movzbq	217(%r11), %rax
	movq	$2656, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$739, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1891:
	movzbq	295(%r11), %rax
	movq	$2672, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$739, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1890:
	movzbq	62(%r11), %rax
	movq	$2624, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$740, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1889:
	movzbq	140(%r11), %rax
	movq	$2640, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$740, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1888:
	movzbq	218(%r11), %rax
	movq	$2656, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$740, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1887:
	movzbq	296(%r11), %rax
	movq	$2672, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$740, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1886:
	movzbq	63(%r11), %rax
	movq	$2624, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$741, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1885:
	movzbq	141(%r11), %rax
	movq	$2640, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$741, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1884:
	movzbq	219(%r11), %rax
	movq	$2656, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$741, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1883:
	movzbq	297(%r11), %rax
	movq	$2672, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$741, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1882:
	movzbq	64(%r11), %rax
	movq	$2624, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$742, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1881:
	movzbq	142(%r11), %rax
	movq	$2640, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$742, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1880:
	movzbq	220(%r11), %rax
	movq	$2656, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$742, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1879:
	movzbq	298(%r11), %rax
	movq	$2672, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$742, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1878:
	movzbq	65(%r11), %rax
	movq	$2624, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$743, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1877:
	movzbq	143(%r11), %rax
	movq	$2640, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$743, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1876:
	movzbq	221(%r11), %rax
	movq	$2656, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$743, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1875:
	movzbq	299(%r11), %rax
	movq	$2672, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$743, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1874:
	movzbq	66(%r11), %rax
	movq	$2624, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$744, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1873:
	movzbq	144(%r11), %rax
	movq	$2640, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$744, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1872:
	movzbq	222(%r11), %rax
	movq	$2656, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$744, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1871:
	movzbq	300(%r11), %rax
	movq	$2672, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$744, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1870:
	movzbq	67(%r11), %rax
	movq	$2624, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$745, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1869:
	movzbq	145(%r11), %rax
	movq	$2640, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$745, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1868:
	movzbq	223(%r11), %rax
	movq	$2656, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$745, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1867:
	movzbq	301(%r11), %rax
	movq	$2672, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$745, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1866:
	movzbq	68(%r11), %rax
	movq	$2624, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$746, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1865:
	movzbq	146(%r11), %rax
	movq	$2640, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$746, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1864:
	movzbq	224(%r11), %rax
	movq	$2656, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$746, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1863:
	movzbq	302(%r11), %rax
	movq	$2672, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$746, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1862:
	movzbq	69(%r11), %rax
	movq	$2624, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$747, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1861:
	movzbq	147(%r11), %rax
	movq	$2640, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$747, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1860:
	movzbq	225(%r11), %rax
	movq	$2656, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$747, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1859:
	movzbq	303(%r11), %rax
	movq	$2672, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$747, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1858:
	movzbq	70(%r11), %rax
	movq	$2624, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$748, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1857:
	movzbq	148(%r11), %rax
	movq	$2640, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$748, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1856:
	movzbq	226(%r11), %rax
	movq	$2656, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$748, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1855:
	movzbq	304(%r11), %rax
	movq	$2672, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$748, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1854:
	movzbq	71(%r11), %rax
	movq	$2624, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$749, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1853:
	movzbq	149(%r11), %rax
	movq	$2640, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$749, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1852:
	movzbq	227(%r11), %rax
	movq	$2656, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$749, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1851:
	movzbq	305(%r11), %rax
	movq	$2672, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$749, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1850:
	movzbq	72(%r11), %rax
	movq	$2624, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$750, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1849:
	movzbq	150(%r11), %rax
	movq	$2640, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$750, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1848:
	movzbq	228(%r11), %rax
	movq	$2656, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$750, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1847:
	movzbq	306(%r11), %rax
	movq	$2672, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$750, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1846:
	movzbq	73(%r11), %rax
	movq	$2624, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$751, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1845:
	movzbq	151(%r11), %rax
	movq	$2640, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$751, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1844:
	movzbq	229(%r11), %rax
	movq	$2656, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$751, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1843:
	movzbq	307(%r11), %rax
	movq	$2672, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$751, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1842:
	movzbq	74(%r11), %rax
	movq	$2624, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$752, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1841:
	movzbq	152(%r11), %rax
	movq	$2640, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$752, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1840:
	movzbq	230(%r11), %rax
	movq	$2656, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$752, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1839:
	movzbq	308(%r11), %rax
	movq	$2672, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$752, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1838:
	movzbq	75(%r11), %rax
	movq	$2624, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$753, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1837:
	movzbq	153(%r11), %rax
	movq	$2640, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$753, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1836:
	movzbq	231(%r11), %rax
	movq	$2656, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$753, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1835:
	movzbq	309(%r11), %rax
	movq	$2672, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$753, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1834:
	movzbq	76(%r11), %rax
	movq	$2624, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$754, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1833:
	movzbq	154(%r11), %rax
	movq	$2640, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$754, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1832:
	movzbq	232(%r11), %rax
	movq	$2656, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$754, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1831:
	movzbq	310(%r11), %rax
	movq	$2672, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$754, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1830:
	movzbq	77(%r11), %rax
	movq	$2624, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$755, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1829:
	movzbq	155(%r11), %rax
	movq	$2640, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$755, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1828:
	movzbq	233(%r11), %rax
	movq	$2656, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$755, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1827:
	movzbq	311(%r11), %rax
	movq	$2672, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$755, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1826:
	movq	$42, %rdx
	jmp 	Lbitsliced_m_calculate_PS$1820
Lbitsliced_m_calculate_PS$1821:
	movzbq	(%r11,%rdx), %rax
	movq	$2688, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$1825:
	movzbq	78(%r11,%rdx), %rax
	movq	$2704, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$1824:
	movzbq	156(%r11,%rdx), %rax
	movq	$2720, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$1823:
	movzbq	234(%r11,%rdx), %rax
	movq	$2736, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$1822:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$1820:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$1821
	movzbq	60(%r11), %rax
	movq	$2688, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$756, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1819:
	movzbq	138(%r11), %rax
	movq	$2704, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$756, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1818:
	movzbq	216(%r11), %rax
	movq	$2720, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$756, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1817:
	movzbq	294(%r11), %rax
	movq	$2736, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$756, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1816:
	movzbq	61(%r11), %rax
	movq	$2688, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$757, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1815:
	movzbq	139(%r11), %rax
	movq	$2704, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$757, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1814:
	movzbq	217(%r11), %rax
	movq	$2720, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$757, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1813:
	movzbq	295(%r11), %rax
	movq	$2736, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$757, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1812:
	movzbq	62(%r11), %rax
	movq	$2688, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$758, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1811:
	movzbq	140(%r11), %rax
	movq	$2704, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$758, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1810:
	movzbq	218(%r11), %rax
	movq	$2720, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$758, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1809:
	movzbq	296(%r11), %rax
	movq	$2736, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$758, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1808:
	movzbq	63(%r11), %rax
	movq	$2688, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$759, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1807:
	movzbq	141(%r11), %rax
	movq	$2704, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$759, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1806:
	movzbq	219(%r11), %rax
	movq	$2720, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$759, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1805:
	movzbq	297(%r11), %rax
	movq	$2736, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$759, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1804:
	movzbq	64(%r11), %rax
	movq	$2688, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$760, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1803:
	movzbq	142(%r11), %rax
	movq	$2704, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$760, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1802:
	movzbq	220(%r11), %rax
	movq	$2720, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$760, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1801:
	movzbq	298(%r11), %rax
	movq	$2736, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$760, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1800:
	movzbq	65(%r11), %rax
	movq	$2688, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$761, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1799:
	movzbq	143(%r11), %rax
	movq	$2704, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$761, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1798:
	movzbq	221(%r11), %rax
	movq	$2720, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$761, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1797:
	movzbq	299(%r11), %rax
	movq	$2736, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$761, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1796:
	movzbq	66(%r11), %rax
	movq	$2688, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$762, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1795:
	movzbq	144(%r11), %rax
	movq	$2704, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$762, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1794:
	movzbq	222(%r11), %rax
	movq	$2720, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$762, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1793:
	movzbq	300(%r11), %rax
	movq	$2736, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$762, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1792:
	movzbq	67(%r11), %rax
	movq	$2688, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$763, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1791:
	movzbq	145(%r11), %rax
	movq	$2704, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$763, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1790:
	movzbq	223(%r11), %rax
	movq	$2720, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$763, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1789:
	movzbq	301(%r11), %rax
	movq	$2736, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$763, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1788:
	movzbq	68(%r11), %rax
	movq	$2688, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$764, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1787:
	movzbq	146(%r11), %rax
	movq	$2704, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$764, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1786:
	movzbq	224(%r11), %rax
	movq	$2720, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$764, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1785:
	movzbq	302(%r11), %rax
	movq	$2736, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$764, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1784:
	movzbq	69(%r11), %rax
	movq	$2688, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$765, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1783:
	movzbq	147(%r11), %rax
	movq	$2704, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$765, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1782:
	movzbq	225(%r11), %rax
	movq	$2720, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$765, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1781:
	movzbq	303(%r11), %rax
	movq	$2736, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$765, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1780:
	movzbq	70(%r11), %rax
	movq	$2688, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$766, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1779:
	movzbq	148(%r11), %rax
	movq	$2704, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$766, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1778:
	movzbq	226(%r11), %rax
	movq	$2720, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$766, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1777:
	movzbq	304(%r11), %rax
	movq	$2736, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$766, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1776:
	movzbq	71(%r11), %rax
	movq	$2688, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$767, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1775:
	movzbq	149(%r11), %rax
	movq	$2704, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$767, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1774:
	movzbq	227(%r11), %rax
	movq	$2720, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$767, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1773:
	movzbq	305(%r11), %rax
	movq	$2736, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$767, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1772:
	movzbq	72(%r11), %rax
	movq	$2688, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$768, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1771:
	movzbq	150(%r11), %rax
	movq	$2704, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$768, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1770:
	movzbq	228(%r11), %rax
	movq	$2720, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$768, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1769:
	movzbq	306(%r11), %rax
	movq	$2736, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$768, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1768:
	movzbq	73(%r11), %rax
	movq	$2688, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$769, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1767:
	movzbq	151(%r11), %rax
	movq	$2704, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$769, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1766:
	movzbq	229(%r11), %rax
	movq	$2720, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$769, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1765:
	movzbq	307(%r11), %rax
	movq	$2736, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$769, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1764:
	movzbq	74(%r11), %rax
	movq	$2688, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$770, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1763:
	movzbq	152(%r11), %rax
	movq	$2704, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$770, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1762:
	movzbq	230(%r11), %rax
	movq	$2720, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$770, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1761:
	movzbq	308(%r11), %rax
	movq	$2736, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$770, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1760:
	movzbq	75(%r11), %rax
	movq	$2688, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$771, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1759:
	movzbq	153(%r11), %rax
	movq	$2704, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$771, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1758:
	movzbq	231(%r11), %rax
	movq	$2720, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$771, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1757:
	movzbq	309(%r11), %rax
	movq	$2736, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$771, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1756:
	movzbq	76(%r11), %rax
	movq	$2688, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$772, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1755:
	movzbq	154(%r11), %rax
	movq	$2704, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$772, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1754:
	movzbq	232(%r11), %rax
	movq	$2720, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$772, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1753:
	movzbq	310(%r11), %rax
	movq	$2736, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$772, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1752:
	movzbq	77(%r11), %rax
	movq	$2688, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$773, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1751:
	movzbq	155(%r11), %rax
	movq	$2704, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$773, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1750:
	movzbq	233(%r11), %rax
	movq	$2720, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$773, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1749:
	movzbq	311(%r11), %rax
	movq	$2736, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$773, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1748:
	movq	$43, %rdx
	jmp 	Lbitsliced_m_calculate_PS$1742
Lbitsliced_m_calculate_PS$1743:
	movzbq	(%r11,%rdx), %rax
	movq	$2752, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$1747:
	movzbq	78(%r11,%rdx), %rax
	movq	$2768, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$1746:
	movzbq	156(%r11,%rdx), %rax
	movq	$2784, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$1745:
	movzbq	234(%r11,%rdx), %rax
	movq	$2800, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$1744:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$1742:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$1743
	movzbq	60(%r11), %rax
	movq	$2752, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$774, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1741:
	movzbq	138(%r11), %rax
	movq	$2768, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$774, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1740:
	movzbq	216(%r11), %rax
	movq	$2784, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$774, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1739:
	movzbq	294(%r11), %rax
	movq	$2800, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$774, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1738:
	movzbq	61(%r11), %rax
	movq	$2752, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$775, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1737:
	movzbq	139(%r11), %rax
	movq	$2768, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$775, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1736:
	movzbq	217(%r11), %rax
	movq	$2784, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$775, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1735:
	movzbq	295(%r11), %rax
	movq	$2800, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$775, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1734:
	movzbq	62(%r11), %rax
	movq	$2752, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$776, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1733:
	movzbq	140(%r11), %rax
	movq	$2768, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$776, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1732:
	movzbq	218(%r11), %rax
	movq	$2784, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$776, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1731:
	movzbq	296(%r11), %rax
	movq	$2800, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$776, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1730:
	movzbq	63(%r11), %rax
	movq	$2752, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$777, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1729:
	movzbq	141(%r11), %rax
	movq	$2768, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$777, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1728:
	movzbq	219(%r11), %rax
	movq	$2784, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$777, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1727:
	movzbq	297(%r11), %rax
	movq	$2800, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$777, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1726:
	movzbq	64(%r11), %rax
	movq	$2752, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$778, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1725:
	movzbq	142(%r11), %rax
	movq	$2768, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$778, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1724:
	movzbq	220(%r11), %rax
	movq	$2784, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$778, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1723:
	movzbq	298(%r11), %rax
	movq	$2800, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$778, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1722:
	movzbq	65(%r11), %rax
	movq	$2752, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$779, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1721:
	movzbq	143(%r11), %rax
	movq	$2768, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$779, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1720:
	movzbq	221(%r11), %rax
	movq	$2784, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$779, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1719:
	movzbq	299(%r11), %rax
	movq	$2800, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$779, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1718:
	movzbq	66(%r11), %rax
	movq	$2752, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$780, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1717:
	movzbq	144(%r11), %rax
	movq	$2768, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$780, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1716:
	movzbq	222(%r11), %rax
	movq	$2784, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$780, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1715:
	movzbq	300(%r11), %rax
	movq	$2800, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$780, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1714:
	movzbq	67(%r11), %rax
	movq	$2752, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$781, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1713:
	movzbq	145(%r11), %rax
	movq	$2768, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$781, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1712:
	movzbq	223(%r11), %rax
	movq	$2784, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$781, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1711:
	movzbq	301(%r11), %rax
	movq	$2800, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$781, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1710:
	movzbq	68(%r11), %rax
	movq	$2752, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$782, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1709:
	movzbq	146(%r11), %rax
	movq	$2768, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$782, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1708:
	movzbq	224(%r11), %rax
	movq	$2784, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$782, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1707:
	movzbq	302(%r11), %rax
	movq	$2800, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$782, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1706:
	movzbq	69(%r11), %rax
	movq	$2752, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$783, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1705:
	movzbq	147(%r11), %rax
	movq	$2768, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$783, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1704:
	movzbq	225(%r11), %rax
	movq	$2784, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$783, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1703:
	movzbq	303(%r11), %rax
	movq	$2800, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$783, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1702:
	movzbq	70(%r11), %rax
	movq	$2752, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$784, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1701:
	movzbq	148(%r11), %rax
	movq	$2768, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$784, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1700:
	movzbq	226(%r11), %rax
	movq	$2784, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$784, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1699:
	movzbq	304(%r11), %rax
	movq	$2800, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$784, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1698:
	movzbq	71(%r11), %rax
	movq	$2752, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$785, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1697:
	movzbq	149(%r11), %rax
	movq	$2768, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$785, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1696:
	movzbq	227(%r11), %rax
	movq	$2784, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$785, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1695:
	movzbq	305(%r11), %rax
	movq	$2800, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$785, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1694:
	movzbq	72(%r11), %rax
	movq	$2752, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$786, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1693:
	movzbq	150(%r11), %rax
	movq	$2768, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$786, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1692:
	movzbq	228(%r11), %rax
	movq	$2784, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$786, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1691:
	movzbq	306(%r11), %rax
	movq	$2800, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$786, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1690:
	movzbq	73(%r11), %rax
	movq	$2752, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$787, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1689:
	movzbq	151(%r11), %rax
	movq	$2768, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$787, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1688:
	movzbq	229(%r11), %rax
	movq	$2784, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$787, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1687:
	movzbq	307(%r11), %rax
	movq	$2800, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$787, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1686:
	movzbq	74(%r11), %rax
	movq	$2752, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$788, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1685:
	movzbq	152(%r11), %rax
	movq	$2768, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$788, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1684:
	movzbq	230(%r11), %rax
	movq	$2784, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$788, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1683:
	movzbq	308(%r11), %rax
	movq	$2800, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$788, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1682:
	movzbq	75(%r11), %rax
	movq	$2752, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$789, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1681:
	movzbq	153(%r11), %rax
	movq	$2768, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$789, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1680:
	movzbq	231(%r11), %rax
	movq	$2784, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$789, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1679:
	movzbq	309(%r11), %rax
	movq	$2800, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$789, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1678:
	movzbq	76(%r11), %rax
	movq	$2752, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$790, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1677:
	movzbq	154(%r11), %rax
	movq	$2768, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$790, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1676:
	movzbq	232(%r11), %rax
	movq	$2784, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$790, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1675:
	movzbq	310(%r11), %rax
	movq	$2800, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$790, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1674:
	movzbq	77(%r11), %rax
	movq	$2752, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$791, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1673:
	movzbq	155(%r11), %rax
	movq	$2768, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$791, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1672:
	movzbq	233(%r11), %rax
	movq	$2784, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$791, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1671:
	movzbq	311(%r11), %rax
	movq	$2800, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$791, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1670:
	movq	$44, %rdx
	jmp 	Lbitsliced_m_calculate_PS$1664
Lbitsliced_m_calculate_PS$1665:
	movzbq	(%r11,%rdx), %rax
	movq	$2816, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$1669:
	movzbq	78(%r11,%rdx), %rax
	movq	$2832, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$1668:
	movzbq	156(%r11,%rdx), %rax
	movq	$2848, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$1667:
	movzbq	234(%r11,%rdx), %rax
	movq	$2864, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$1666:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$1664:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$1665
	movzbq	60(%r11), %rax
	movq	$2816, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$792, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1663:
	movzbq	138(%r11), %rax
	movq	$2832, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$792, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1662:
	movzbq	216(%r11), %rax
	movq	$2848, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$792, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1661:
	movzbq	294(%r11), %rax
	movq	$2864, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$792, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1660:
	movzbq	61(%r11), %rax
	movq	$2816, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$793, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1659:
	movzbq	139(%r11), %rax
	movq	$2832, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$793, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1658:
	movzbq	217(%r11), %rax
	movq	$2848, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$793, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1657:
	movzbq	295(%r11), %rax
	movq	$2864, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$793, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1656:
	movzbq	62(%r11), %rax
	movq	$2816, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$794, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1655:
	movzbq	140(%r11), %rax
	movq	$2832, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$794, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1654:
	movzbq	218(%r11), %rax
	movq	$2848, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$794, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1653:
	movzbq	296(%r11), %rax
	movq	$2864, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$794, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1652:
	movzbq	63(%r11), %rax
	movq	$2816, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$795, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1651:
	movzbq	141(%r11), %rax
	movq	$2832, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$795, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1650:
	movzbq	219(%r11), %rax
	movq	$2848, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$795, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1649:
	movzbq	297(%r11), %rax
	movq	$2864, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$795, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1648:
	movzbq	64(%r11), %rax
	movq	$2816, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$796, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1647:
	movzbq	142(%r11), %rax
	movq	$2832, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$796, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1646:
	movzbq	220(%r11), %rax
	movq	$2848, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$796, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1645:
	movzbq	298(%r11), %rax
	movq	$2864, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$796, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1644:
	movzbq	65(%r11), %rax
	movq	$2816, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$797, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1643:
	movzbq	143(%r11), %rax
	movq	$2832, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$797, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1642:
	movzbq	221(%r11), %rax
	movq	$2848, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$797, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1641:
	movzbq	299(%r11), %rax
	movq	$2864, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$797, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1640:
	movzbq	66(%r11), %rax
	movq	$2816, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$798, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1639:
	movzbq	144(%r11), %rax
	movq	$2832, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$798, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1638:
	movzbq	222(%r11), %rax
	movq	$2848, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$798, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1637:
	movzbq	300(%r11), %rax
	movq	$2864, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$798, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1636:
	movzbq	67(%r11), %rax
	movq	$2816, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$799, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1635:
	movzbq	145(%r11), %rax
	movq	$2832, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$799, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1634:
	movzbq	223(%r11), %rax
	movq	$2848, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$799, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1633:
	movzbq	301(%r11), %rax
	movq	$2864, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$799, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1632:
	movzbq	68(%r11), %rax
	movq	$2816, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$800, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1631:
	movzbq	146(%r11), %rax
	movq	$2832, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$800, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1630:
	movzbq	224(%r11), %rax
	movq	$2848, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$800, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1629:
	movzbq	302(%r11), %rax
	movq	$2864, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$800, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1628:
	movzbq	69(%r11), %rax
	movq	$2816, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$801, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1627:
	movzbq	147(%r11), %rax
	movq	$2832, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$801, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1626:
	movzbq	225(%r11), %rax
	movq	$2848, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$801, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1625:
	movzbq	303(%r11), %rax
	movq	$2864, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$801, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1624:
	movzbq	70(%r11), %rax
	movq	$2816, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$802, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1623:
	movzbq	148(%r11), %rax
	movq	$2832, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$802, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1622:
	movzbq	226(%r11), %rax
	movq	$2848, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$802, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1621:
	movzbq	304(%r11), %rax
	movq	$2864, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$802, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1620:
	movzbq	71(%r11), %rax
	movq	$2816, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$803, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1619:
	movzbq	149(%r11), %rax
	movq	$2832, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$803, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1618:
	movzbq	227(%r11), %rax
	movq	$2848, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$803, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1617:
	movzbq	305(%r11), %rax
	movq	$2864, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$803, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1616:
	movzbq	72(%r11), %rax
	movq	$2816, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$804, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1615:
	movzbq	150(%r11), %rax
	movq	$2832, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$804, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1614:
	movzbq	228(%r11), %rax
	movq	$2848, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$804, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1613:
	movzbq	306(%r11), %rax
	movq	$2864, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$804, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1612:
	movzbq	73(%r11), %rax
	movq	$2816, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$805, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1611:
	movzbq	151(%r11), %rax
	movq	$2832, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$805, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1610:
	movzbq	229(%r11), %rax
	movq	$2848, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$805, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1609:
	movzbq	307(%r11), %rax
	movq	$2864, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$805, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1608:
	movzbq	74(%r11), %rax
	movq	$2816, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$806, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1607:
	movzbq	152(%r11), %rax
	movq	$2832, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$806, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1606:
	movzbq	230(%r11), %rax
	movq	$2848, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$806, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1605:
	movzbq	308(%r11), %rax
	movq	$2864, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$806, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1604:
	movzbq	75(%r11), %rax
	movq	$2816, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$807, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1603:
	movzbq	153(%r11), %rax
	movq	$2832, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$807, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1602:
	movzbq	231(%r11), %rax
	movq	$2848, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$807, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1601:
	movzbq	309(%r11), %rax
	movq	$2864, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$807, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1600:
	movzbq	76(%r11), %rax
	movq	$2816, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$808, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1599:
	movzbq	154(%r11), %rax
	movq	$2832, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$808, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1598:
	movzbq	232(%r11), %rax
	movq	$2848, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$808, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1597:
	movzbq	310(%r11), %rax
	movq	$2864, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$808, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1596:
	movzbq	77(%r11), %rax
	movq	$2816, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$809, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1595:
	movzbq	155(%r11), %rax
	movq	$2832, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$809, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1594:
	movzbq	233(%r11), %rax
	movq	$2848, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$809, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1593:
	movzbq	311(%r11), %rax
	movq	$2864, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$809, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1592:
	movq	$45, %rdx
	jmp 	Lbitsliced_m_calculate_PS$1586
Lbitsliced_m_calculate_PS$1587:
	movzbq	(%r11,%rdx), %rax
	movq	$2880, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$1591:
	movzbq	78(%r11,%rdx), %rax
	movq	$2896, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$1590:
	movzbq	156(%r11,%rdx), %rax
	movq	$2912, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$1589:
	movzbq	234(%r11,%rdx), %rax
	movq	$2928, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$1588:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$1586:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$1587
	movzbq	60(%r11), %rax
	movq	$2880, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$810, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1585:
	movzbq	138(%r11), %rax
	movq	$2896, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$810, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1584:
	movzbq	216(%r11), %rax
	movq	$2912, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$810, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1583:
	movzbq	294(%r11), %rax
	movq	$2928, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$810, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1582:
	movzbq	61(%r11), %rax
	movq	$2880, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$811, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1581:
	movzbq	139(%r11), %rax
	movq	$2896, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$811, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1580:
	movzbq	217(%r11), %rax
	movq	$2912, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$811, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1579:
	movzbq	295(%r11), %rax
	movq	$2928, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$811, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1578:
	movzbq	62(%r11), %rax
	movq	$2880, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$812, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1577:
	movzbq	140(%r11), %rax
	movq	$2896, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$812, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1576:
	movzbq	218(%r11), %rax
	movq	$2912, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$812, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1575:
	movzbq	296(%r11), %rax
	movq	$2928, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$812, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1574:
	movzbq	63(%r11), %rax
	movq	$2880, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$813, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1573:
	movzbq	141(%r11), %rax
	movq	$2896, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$813, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1572:
	movzbq	219(%r11), %rax
	movq	$2912, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$813, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1571:
	movzbq	297(%r11), %rax
	movq	$2928, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$813, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1570:
	movzbq	64(%r11), %rax
	movq	$2880, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$814, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1569:
	movzbq	142(%r11), %rax
	movq	$2896, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$814, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1568:
	movzbq	220(%r11), %rax
	movq	$2912, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$814, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1567:
	movzbq	298(%r11), %rax
	movq	$2928, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$814, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1566:
	movzbq	65(%r11), %rax
	movq	$2880, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$815, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1565:
	movzbq	143(%r11), %rax
	movq	$2896, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$815, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1564:
	movzbq	221(%r11), %rax
	movq	$2912, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$815, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1563:
	movzbq	299(%r11), %rax
	movq	$2928, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$815, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1562:
	movzbq	66(%r11), %rax
	movq	$2880, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$816, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1561:
	movzbq	144(%r11), %rax
	movq	$2896, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$816, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1560:
	movzbq	222(%r11), %rax
	movq	$2912, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$816, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1559:
	movzbq	300(%r11), %rax
	movq	$2928, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$816, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1558:
	movzbq	67(%r11), %rax
	movq	$2880, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$817, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1557:
	movzbq	145(%r11), %rax
	movq	$2896, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$817, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1556:
	movzbq	223(%r11), %rax
	movq	$2912, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$817, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1555:
	movzbq	301(%r11), %rax
	movq	$2928, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$817, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1554:
	movzbq	68(%r11), %rax
	movq	$2880, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$818, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1553:
	movzbq	146(%r11), %rax
	movq	$2896, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$818, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1552:
	movzbq	224(%r11), %rax
	movq	$2912, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$818, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1551:
	movzbq	302(%r11), %rax
	movq	$2928, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$818, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1550:
	movzbq	69(%r11), %rax
	movq	$2880, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$819, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1549:
	movzbq	147(%r11), %rax
	movq	$2896, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$819, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1548:
	movzbq	225(%r11), %rax
	movq	$2912, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$819, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1547:
	movzbq	303(%r11), %rax
	movq	$2928, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$819, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1546:
	movzbq	70(%r11), %rax
	movq	$2880, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$820, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1545:
	movzbq	148(%r11), %rax
	movq	$2896, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$820, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1544:
	movzbq	226(%r11), %rax
	movq	$2912, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$820, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1543:
	movzbq	304(%r11), %rax
	movq	$2928, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$820, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1542:
	movzbq	71(%r11), %rax
	movq	$2880, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$821, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1541:
	movzbq	149(%r11), %rax
	movq	$2896, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$821, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1540:
	movzbq	227(%r11), %rax
	movq	$2912, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$821, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1539:
	movzbq	305(%r11), %rax
	movq	$2928, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$821, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1538:
	movzbq	72(%r11), %rax
	movq	$2880, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$822, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1537:
	movzbq	150(%r11), %rax
	movq	$2896, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$822, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1536:
	movzbq	228(%r11), %rax
	movq	$2912, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$822, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1535:
	movzbq	306(%r11), %rax
	movq	$2928, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$822, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1534:
	movzbq	73(%r11), %rax
	movq	$2880, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$823, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1533:
	movzbq	151(%r11), %rax
	movq	$2896, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$823, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1532:
	movzbq	229(%r11), %rax
	movq	$2912, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$823, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1531:
	movzbq	307(%r11), %rax
	movq	$2928, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$823, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1530:
	movzbq	74(%r11), %rax
	movq	$2880, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$824, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1529:
	movzbq	152(%r11), %rax
	movq	$2896, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$824, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1528:
	movzbq	230(%r11), %rax
	movq	$2912, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$824, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1527:
	movzbq	308(%r11), %rax
	movq	$2928, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$824, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1526:
	movzbq	75(%r11), %rax
	movq	$2880, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$825, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1525:
	movzbq	153(%r11), %rax
	movq	$2896, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$825, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1524:
	movzbq	231(%r11), %rax
	movq	$2912, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$825, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1523:
	movzbq	309(%r11), %rax
	movq	$2928, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$825, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1522:
	movzbq	76(%r11), %rax
	movq	$2880, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$826, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1521:
	movzbq	154(%r11), %rax
	movq	$2896, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$826, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1520:
	movzbq	232(%r11), %rax
	movq	$2912, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$826, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1519:
	movzbq	310(%r11), %rax
	movq	$2928, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$826, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1518:
	movzbq	77(%r11), %rax
	movq	$2880, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$827, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1517:
	movzbq	155(%r11), %rax
	movq	$2896, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$827, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1516:
	movzbq	233(%r11), %rax
	movq	$2912, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$827, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1515:
	movzbq	311(%r11), %rax
	movq	$2928, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$827, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1514:
	movq	$46, %rdx
	jmp 	Lbitsliced_m_calculate_PS$1508
Lbitsliced_m_calculate_PS$1509:
	movzbq	(%r11,%rdx), %rax
	movq	$2944, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$1513:
	movzbq	78(%r11,%rdx), %rax
	movq	$2960, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$1512:
	movzbq	156(%r11,%rdx), %rax
	movq	$2976, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$1511:
	movzbq	234(%r11,%rdx), %rax
	movq	$2992, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$1510:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$1508:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$1509
	movzbq	60(%r11), %rax
	movq	$2944, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$828, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1507:
	movzbq	138(%r11), %rax
	movq	$2960, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$828, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1506:
	movzbq	216(%r11), %rax
	movq	$2976, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$828, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1505:
	movzbq	294(%r11), %rax
	movq	$2992, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$828, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1504:
	movzbq	61(%r11), %rax
	movq	$2944, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$829, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1503:
	movzbq	139(%r11), %rax
	movq	$2960, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$829, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1502:
	movzbq	217(%r11), %rax
	movq	$2976, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$829, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1501:
	movzbq	295(%r11), %rax
	movq	$2992, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$829, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1500:
	movzbq	62(%r11), %rax
	movq	$2944, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$830, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1499:
	movzbq	140(%r11), %rax
	movq	$2960, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$830, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1498:
	movzbq	218(%r11), %rax
	movq	$2976, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$830, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1497:
	movzbq	296(%r11), %rax
	movq	$2992, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$830, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1496:
	movzbq	63(%r11), %rax
	movq	$2944, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$831, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1495:
	movzbq	141(%r11), %rax
	movq	$2960, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$831, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1494:
	movzbq	219(%r11), %rax
	movq	$2976, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$831, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1493:
	movzbq	297(%r11), %rax
	movq	$2992, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$831, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1492:
	movzbq	64(%r11), %rax
	movq	$2944, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$832, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1491:
	movzbq	142(%r11), %rax
	movq	$2960, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$832, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1490:
	movzbq	220(%r11), %rax
	movq	$2976, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$832, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1489:
	movzbq	298(%r11), %rax
	movq	$2992, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$832, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1488:
	movzbq	65(%r11), %rax
	movq	$2944, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$833, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1487:
	movzbq	143(%r11), %rax
	movq	$2960, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$833, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1486:
	movzbq	221(%r11), %rax
	movq	$2976, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$833, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1485:
	movzbq	299(%r11), %rax
	movq	$2992, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$833, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1484:
	movzbq	66(%r11), %rax
	movq	$2944, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$834, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1483:
	movzbq	144(%r11), %rax
	movq	$2960, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$834, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1482:
	movzbq	222(%r11), %rax
	movq	$2976, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$834, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1481:
	movzbq	300(%r11), %rax
	movq	$2992, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$834, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1480:
	movzbq	67(%r11), %rax
	movq	$2944, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$835, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1479:
	movzbq	145(%r11), %rax
	movq	$2960, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$835, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1478:
	movzbq	223(%r11), %rax
	movq	$2976, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$835, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1477:
	movzbq	301(%r11), %rax
	movq	$2992, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$835, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1476:
	movzbq	68(%r11), %rax
	movq	$2944, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$836, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1475:
	movzbq	146(%r11), %rax
	movq	$2960, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$836, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1474:
	movzbq	224(%r11), %rax
	movq	$2976, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$836, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1473:
	movzbq	302(%r11), %rax
	movq	$2992, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$836, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1472:
	movzbq	69(%r11), %rax
	movq	$2944, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$837, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1471:
	movzbq	147(%r11), %rax
	movq	$2960, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$837, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1470:
	movzbq	225(%r11), %rax
	movq	$2976, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$837, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1469:
	movzbq	303(%r11), %rax
	movq	$2992, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$837, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1468:
	movzbq	70(%r11), %rax
	movq	$2944, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$838, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1467:
	movzbq	148(%r11), %rax
	movq	$2960, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$838, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1466:
	movzbq	226(%r11), %rax
	movq	$2976, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$838, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1465:
	movzbq	304(%r11), %rax
	movq	$2992, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$838, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1464:
	movzbq	71(%r11), %rax
	movq	$2944, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$839, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1463:
	movzbq	149(%r11), %rax
	movq	$2960, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$839, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1462:
	movzbq	227(%r11), %rax
	movq	$2976, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$839, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1461:
	movzbq	305(%r11), %rax
	movq	$2992, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$839, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1460:
	movzbq	72(%r11), %rax
	movq	$2944, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$840, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1459:
	movzbq	150(%r11), %rax
	movq	$2960, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$840, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1458:
	movzbq	228(%r11), %rax
	movq	$2976, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$840, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1457:
	movzbq	306(%r11), %rax
	movq	$2992, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$840, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1456:
	movzbq	73(%r11), %rax
	movq	$2944, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$841, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1455:
	movzbq	151(%r11), %rax
	movq	$2960, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$841, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1454:
	movzbq	229(%r11), %rax
	movq	$2976, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$841, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1453:
	movzbq	307(%r11), %rax
	movq	$2992, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$841, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1452:
	movzbq	74(%r11), %rax
	movq	$2944, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$842, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1451:
	movzbq	152(%r11), %rax
	movq	$2960, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$842, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1450:
	movzbq	230(%r11), %rax
	movq	$2976, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$842, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1449:
	movzbq	308(%r11), %rax
	movq	$2992, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$842, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1448:
	movzbq	75(%r11), %rax
	movq	$2944, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$843, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1447:
	movzbq	153(%r11), %rax
	movq	$2960, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$843, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1446:
	movzbq	231(%r11), %rax
	movq	$2976, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$843, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1445:
	movzbq	309(%r11), %rax
	movq	$2992, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$843, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1444:
	movzbq	76(%r11), %rax
	movq	$2944, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$844, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1443:
	movzbq	154(%r11), %rax
	movq	$2960, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$844, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1442:
	movzbq	232(%r11), %rax
	movq	$2976, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$844, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1441:
	movzbq	310(%r11), %rax
	movq	$2992, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$844, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1440:
	movzbq	77(%r11), %rax
	movq	$2944, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$845, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1439:
	movzbq	155(%r11), %rax
	movq	$2960, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$845, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1438:
	movzbq	233(%r11), %rax
	movq	$2976, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$845, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1437:
	movzbq	311(%r11), %rax
	movq	$2992, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$845, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1436:
	movq	$47, %rdx
	jmp 	Lbitsliced_m_calculate_PS$1430
Lbitsliced_m_calculate_PS$1431:
	movzbq	(%r11,%rdx), %rax
	movq	$3008, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$1435:
	movzbq	78(%r11,%rdx), %rax
	movq	$3024, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$1434:
	movzbq	156(%r11,%rdx), %rax
	movq	$3040, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$1433:
	movzbq	234(%r11,%rdx), %rax
	movq	$3056, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$1432:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$1430:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$1431
	movzbq	60(%r11), %rax
	movq	$3008, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$846, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1429:
	movzbq	138(%r11), %rax
	movq	$3024, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$846, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1428:
	movzbq	216(%r11), %rax
	movq	$3040, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$846, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1427:
	movzbq	294(%r11), %rax
	movq	$3056, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$846, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1426:
	movzbq	61(%r11), %rax
	movq	$3008, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$847, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1425:
	movzbq	139(%r11), %rax
	movq	$3024, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$847, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1424:
	movzbq	217(%r11), %rax
	movq	$3040, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$847, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1423:
	movzbq	295(%r11), %rax
	movq	$3056, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$847, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1422:
	movzbq	62(%r11), %rax
	movq	$3008, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$848, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1421:
	movzbq	140(%r11), %rax
	movq	$3024, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$848, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1420:
	movzbq	218(%r11), %rax
	movq	$3040, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$848, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1419:
	movzbq	296(%r11), %rax
	movq	$3056, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$848, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1418:
	movzbq	63(%r11), %rax
	movq	$3008, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$849, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1417:
	movzbq	141(%r11), %rax
	movq	$3024, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$849, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1416:
	movzbq	219(%r11), %rax
	movq	$3040, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$849, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1415:
	movzbq	297(%r11), %rax
	movq	$3056, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$849, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1414:
	movzbq	64(%r11), %rax
	movq	$3008, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$850, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1413:
	movzbq	142(%r11), %rax
	movq	$3024, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$850, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1412:
	movzbq	220(%r11), %rax
	movq	$3040, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$850, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1411:
	movzbq	298(%r11), %rax
	movq	$3056, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$850, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1410:
	movzbq	65(%r11), %rax
	movq	$3008, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$851, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1409:
	movzbq	143(%r11), %rax
	movq	$3024, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$851, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1408:
	movzbq	221(%r11), %rax
	movq	$3040, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$851, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1407:
	movzbq	299(%r11), %rax
	movq	$3056, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$851, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1406:
	movzbq	66(%r11), %rax
	movq	$3008, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$852, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1405:
	movzbq	144(%r11), %rax
	movq	$3024, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$852, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1404:
	movzbq	222(%r11), %rax
	movq	$3040, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$852, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1403:
	movzbq	300(%r11), %rax
	movq	$3056, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$852, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1402:
	movzbq	67(%r11), %rax
	movq	$3008, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$853, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1401:
	movzbq	145(%r11), %rax
	movq	$3024, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$853, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1400:
	movzbq	223(%r11), %rax
	movq	$3040, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$853, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1399:
	movzbq	301(%r11), %rax
	movq	$3056, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$853, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1398:
	movzbq	68(%r11), %rax
	movq	$3008, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$854, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1397:
	movzbq	146(%r11), %rax
	movq	$3024, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$854, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1396:
	movzbq	224(%r11), %rax
	movq	$3040, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$854, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1395:
	movzbq	302(%r11), %rax
	movq	$3056, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$854, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1394:
	movzbq	69(%r11), %rax
	movq	$3008, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$855, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1393:
	movzbq	147(%r11), %rax
	movq	$3024, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$855, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1392:
	movzbq	225(%r11), %rax
	movq	$3040, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$855, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1391:
	movzbq	303(%r11), %rax
	movq	$3056, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$855, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1390:
	movzbq	70(%r11), %rax
	movq	$3008, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$856, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1389:
	movzbq	148(%r11), %rax
	movq	$3024, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$856, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1388:
	movzbq	226(%r11), %rax
	movq	$3040, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$856, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1387:
	movzbq	304(%r11), %rax
	movq	$3056, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$856, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1386:
	movzbq	71(%r11), %rax
	movq	$3008, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$857, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1385:
	movzbq	149(%r11), %rax
	movq	$3024, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$857, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1384:
	movzbq	227(%r11), %rax
	movq	$3040, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$857, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1383:
	movzbq	305(%r11), %rax
	movq	$3056, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$857, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1382:
	movzbq	72(%r11), %rax
	movq	$3008, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$858, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1381:
	movzbq	150(%r11), %rax
	movq	$3024, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$858, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1380:
	movzbq	228(%r11), %rax
	movq	$3040, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$858, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1379:
	movzbq	306(%r11), %rax
	movq	$3056, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$858, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1378:
	movzbq	73(%r11), %rax
	movq	$3008, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$859, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1377:
	movzbq	151(%r11), %rax
	movq	$3024, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$859, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1376:
	movzbq	229(%r11), %rax
	movq	$3040, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$859, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1375:
	movzbq	307(%r11), %rax
	movq	$3056, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$859, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1374:
	movzbq	74(%r11), %rax
	movq	$3008, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$860, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1373:
	movzbq	152(%r11), %rax
	movq	$3024, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$860, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1372:
	movzbq	230(%r11), %rax
	movq	$3040, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$860, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1371:
	movzbq	308(%r11), %rax
	movq	$3056, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$860, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1370:
	movzbq	75(%r11), %rax
	movq	$3008, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$861, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1369:
	movzbq	153(%r11), %rax
	movq	$3024, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$861, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1368:
	movzbq	231(%r11), %rax
	movq	$3040, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$861, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1367:
	movzbq	309(%r11), %rax
	movq	$3056, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$861, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1366:
	movzbq	76(%r11), %rax
	movq	$3008, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$862, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1365:
	movzbq	154(%r11), %rax
	movq	$3024, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$862, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1364:
	movzbq	232(%r11), %rax
	movq	$3040, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$862, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1363:
	movzbq	310(%r11), %rax
	movq	$3056, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$862, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1362:
	movzbq	77(%r11), %rax
	movq	$3008, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$863, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1361:
	movzbq	155(%r11), %rax
	movq	$3024, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$863, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1360:
	movzbq	233(%r11), %rax
	movq	$3040, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$863, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1359:
	movzbq	311(%r11), %rax
	movq	$3056, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$863, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1358:
	movq	$48, %rdx
	jmp 	Lbitsliced_m_calculate_PS$1352
Lbitsliced_m_calculate_PS$1353:
	movzbq	(%r11,%rdx), %rax
	movq	$3072, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$1357:
	movzbq	78(%r11,%rdx), %rax
	movq	$3088, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$1356:
	movzbq	156(%r11,%rdx), %rax
	movq	$3104, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$1355:
	movzbq	234(%r11,%rdx), %rax
	movq	$3120, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$1354:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$1352:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$1353
	movzbq	60(%r11), %rax
	movq	$3072, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$864, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1351:
	movzbq	138(%r11), %rax
	movq	$3088, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$864, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1350:
	movzbq	216(%r11), %rax
	movq	$3104, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$864, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1349:
	movzbq	294(%r11), %rax
	movq	$3120, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$864, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1348:
	movzbq	61(%r11), %rax
	movq	$3072, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$865, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1347:
	movzbq	139(%r11), %rax
	movq	$3088, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$865, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1346:
	movzbq	217(%r11), %rax
	movq	$3104, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$865, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1345:
	movzbq	295(%r11), %rax
	movq	$3120, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$865, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1344:
	movzbq	62(%r11), %rax
	movq	$3072, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$866, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1343:
	movzbq	140(%r11), %rax
	movq	$3088, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$866, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1342:
	movzbq	218(%r11), %rax
	movq	$3104, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$866, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1341:
	movzbq	296(%r11), %rax
	movq	$3120, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$866, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1340:
	movzbq	63(%r11), %rax
	movq	$3072, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$867, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1339:
	movzbq	141(%r11), %rax
	movq	$3088, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$867, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1338:
	movzbq	219(%r11), %rax
	movq	$3104, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$867, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1337:
	movzbq	297(%r11), %rax
	movq	$3120, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$867, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1336:
	movzbq	64(%r11), %rax
	movq	$3072, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$868, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1335:
	movzbq	142(%r11), %rax
	movq	$3088, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$868, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1334:
	movzbq	220(%r11), %rax
	movq	$3104, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$868, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1333:
	movzbq	298(%r11), %rax
	movq	$3120, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$868, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1332:
	movzbq	65(%r11), %rax
	movq	$3072, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$869, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1331:
	movzbq	143(%r11), %rax
	movq	$3088, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$869, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1330:
	movzbq	221(%r11), %rax
	movq	$3104, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$869, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1329:
	movzbq	299(%r11), %rax
	movq	$3120, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$869, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1328:
	movzbq	66(%r11), %rax
	movq	$3072, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$870, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1327:
	movzbq	144(%r11), %rax
	movq	$3088, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$870, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1326:
	movzbq	222(%r11), %rax
	movq	$3104, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$870, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1325:
	movzbq	300(%r11), %rax
	movq	$3120, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$870, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1324:
	movzbq	67(%r11), %rax
	movq	$3072, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$871, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1323:
	movzbq	145(%r11), %rax
	movq	$3088, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$871, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1322:
	movzbq	223(%r11), %rax
	movq	$3104, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$871, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1321:
	movzbq	301(%r11), %rax
	movq	$3120, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$871, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1320:
	movzbq	68(%r11), %rax
	movq	$3072, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$872, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1319:
	movzbq	146(%r11), %rax
	movq	$3088, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$872, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1318:
	movzbq	224(%r11), %rax
	movq	$3104, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$872, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1317:
	movzbq	302(%r11), %rax
	movq	$3120, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$872, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1316:
	movzbq	69(%r11), %rax
	movq	$3072, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$873, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1315:
	movzbq	147(%r11), %rax
	movq	$3088, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$873, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1314:
	movzbq	225(%r11), %rax
	movq	$3104, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$873, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1313:
	movzbq	303(%r11), %rax
	movq	$3120, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$873, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1312:
	movzbq	70(%r11), %rax
	movq	$3072, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$874, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1311:
	movzbq	148(%r11), %rax
	movq	$3088, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$874, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1310:
	movzbq	226(%r11), %rax
	movq	$3104, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$874, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1309:
	movzbq	304(%r11), %rax
	movq	$3120, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$874, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1308:
	movzbq	71(%r11), %rax
	movq	$3072, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$875, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1307:
	movzbq	149(%r11), %rax
	movq	$3088, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$875, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1306:
	movzbq	227(%r11), %rax
	movq	$3104, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$875, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1305:
	movzbq	305(%r11), %rax
	movq	$3120, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$875, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1304:
	movzbq	72(%r11), %rax
	movq	$3072, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$876, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1303:
	movzbq	150(%r11), %rax
	movq	$3088, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$876, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1302:
	movzbq	228(%r11), %rax
	movq	$3104, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$876, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1301:
	movzbq	306(%r11), %rax
	movq	$3120, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$876, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1300:
	movzbq	73(%r11), %rax
	movq	$3072, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$877, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1299:
	movzbq	151(%r11), %rax
	movq	$3088, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$877, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1298:
	movzbq	229(%r11), %rax
	movq	$3104, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$877, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1297:
	movzbq	307(%r11), %rax
	movq	$3120, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$877, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1296:
	movzbq	74(%r11), %rax
	movq	$3072, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$878, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1295:
	movzbq	152(%r11), %rax
	movq	$3088, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$878, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1294:
	movzbq	230(%r11), %rax
	movq	$3104, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$878, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1293:
	movzbq	308(%r11), %rax
	movq	$3120, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$878, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1292:
	movzbq	75(%r11), %rax
	movq	$3072, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$879, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1291:
	movzbq	153(%r11), %rax
	movq	$3088, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$879, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1290:
	movzbq	231(%r11), %rax
	movq	$3104, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$879, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1289:
	movzbq	309(%r11), %rax
	movq	$3120, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$879, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1288:
	movzbq	76(%r11), %rax
	movq	$3072, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$880, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1287:
	movzbq	154(%r11), %rax
	movq	$3088, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$880, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1286:
	movzbq	232(%r11), %rax
	movq	$3104, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$880, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1285:
	movzbq	310(%r11), %rax
	movq	$3120, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$880, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1284:
	movzbq	77(%r11), %rax
	movq	$3072, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$881, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1283:
	movzbq	155(%r11), %rax
	movq	$3088, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$881, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1282:
	movzbq	233(%r11), %rax
	movq	$3104, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$881, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1281:
	movzbq	311(%r11), %rax
	movq	$3120, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$881, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1280:
	movq	$49, %rdx
	jmp 	Lbitsliced_m_calculate_PS$1274
Lbitsliced_m_calculate_PS$1275:
	movzbq	(%r11,%rdx), %rax
	movq	$3136, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$1279:
	movzbq	78(%r11,%rdx), %rax
	movq	$3152, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$1278:
	movzbq	156(%r11,%rdx), %rax
	movq	$3168, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$1277:
	movzbq	234(%r11,%rdx), %rax
	movq	$3184, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$1276:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$1274:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$1275
	movzbq	60(%r11), %rax
	movq	$3136, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$882, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1273:
	movzbq	138(%r11), %rax
	movq	$3152, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$882, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1272:
	movzbq	216(%r11), %rax
	movq	$3168, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$882, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1271:
	movzbq	294(%r11), %rax
	movq	$3184, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$882, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1270:
	movzbq	61(%r11), %rax
	movq	$3136, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$883, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1269:
	movzbq	139(%r11), %rax
	movq	$3152, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$883, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1268:
	movzbq	217(%r11), %rax
	movq	$3168, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$883, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1267:
	movzbq	295(%r11), %rax
	movq	$3184, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$883, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1266:
	movzbq	62(%r11), %rax
	movq	$3136, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$884, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1265:
	movzbq	140(%r11), %rax
	movq	$3152, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$884, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1264:
	movzbq	218(%r11), %rax
	movq	$3168, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$884, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1263:
	movzbq	296(%r11), %rax
	movq	$3184, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$884, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1262:
	movzbq	63(%r11), %rax
	movq	$3136, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$885, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1261:
	movzbq	141(%r11), %rax
	movq	$3152, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$885, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1260:
	movzbq	219(%r11), %rax
	movq	$3168, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$885, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1259:
	movzbq	297(%r11), %rax
	movq	$3184, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$885, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1258:
	movzbq	64(%r11), %rax
	movq	$3136, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$886, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1257:
	movzbq	142(%r11), %rax
	movq	$3152, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$886, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1256:
	movzbq	220(%r11), %rax
	movq	$3168, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$886, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1255:
	movzbq	298(%r11), %rax
	movq	$3184, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$886, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1254:
	movzbq	65(%r11), %rax
	movq	$3136, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$887, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1253:
	movzbq	143(%r11), %rax
	movq	$3152, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$887, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1252:
	movzbq	221(%r11), %rax
	movq	$3168, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$887, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1251:
	movzbq	299(%r11), %rax
	movq	$3184, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$887, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1250:
	movzbq	66(%r11), %rax
	movq	$3136, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$888, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1249:
	movzbq	144(%r11), %rax
	movq	$3152, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$888, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1248:
	movzbq	222(%r11), %rax
	movq	$3168, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$888, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1247:
	movzbq	300(%r11), %rax
	movq	$3184, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$888, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1246:
	movzbq	67(%r11), %rax
	movq	$3136, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$889, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1245:
	movzbq	145(%r11), %rax
	movq	$3152, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$889, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1244:
	movzbq	223(%r11), %rax
	movq	$3168, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$889, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1243:
	movzbq	301(%r11), %rax
	movq	$3184, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$889, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1242:
	movzbq	68(%r11), %rax
	movq	$3136, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$890, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1241:
	movzbq	146(%r11), %rax
	movq	$3152, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$890, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1240:
	movzbq	224(%r11), %rax
	movq	$3168, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$890, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1239:
	movzbq	302(%r11), %rax
	movq	$3184, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$890, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1238:
	movzbq	69(%r11), %rax
	movq	$3136, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$891, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1237:
	movzbq	147(%r11), %rax
	movq	$3152, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$891, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1236:
	movzbq	225(%r11), %rax
	movq	$3168, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$891, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1235:
	movzbq	303(%r11), %rax
	movq	$3184, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$891, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1234:
	movzbq	70(%r11), %rax
	movq	$3136, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$892, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1233:
	movzbq	148(%r11), %rax
	movq	$3152, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$892, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1232:
	movzbq	226(%r11), %rax
	movq	$3168, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$892, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1231:
	movzbq	304(%r11), %rax
	movq	$3184, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$892, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1230:
	movzbq	71(%r11), %rax
	movq	$3136, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$893, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1229:
	movzbq	149(%r11), %rax
	movq	$3152, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$893, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1228:
	movzbq	227(%r11), %rax
	movq	$3168, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$893, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1227:
	movzbq	305(%r11), %rax
	movq	$3184, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$893, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1226:
	movzbq	72(%r11), %rax
	movq	$3136, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$894, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1225:
	movzbq	150(%r11), %rax
	movq	$3152, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$894, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1224:
	movzbq	228(%r11), %rax
	movq	$3168, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$894, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1223:
	movzbq	306(%r11), %rax
	movq	$3184, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$894, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1222:
	movzbq	73(%r11), %rax
	movq	$3136, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$895, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1221:
	movzbq	151(%r11), %rax
	movq	$3152, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$895, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1220:
	movzbq	229(%r11), %rax
	movq	$3168, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$895, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1219:
	movzbq	307(%r11), %rax
	movq	$3184, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$895, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1218:
	movzbq	74(%r11), %rax
	movq	$3136, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$896, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1217:
	movzbq	152(%r11), %rax
	movq	$3152, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$896, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1216:
	movzbq	230(%r11), %rax
	movq	$3168, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$896, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1215:
	movzbq	308(%r11), %rax
	movq	$3184, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$896, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1214:
	movzbq	75(%r11), %rax
	movq	$3136, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$897, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1213:
	movzbq	153(%r11), %rax
	movq	$3152, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$897, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1212:
	movzbq	231(%r11), %rax
	movq	$3168, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$897, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1211:
	movzbq	309(%r11), %rax
	movq	$3184, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$897, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1210:
	movzbq	76(%r11), %rax
	movq	$3136, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$898, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1209:
	movzbq	154(%r11), %rax
	movq	$3152, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$898, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1208:
	movzbq	232(%r11), %rax
	movq	$3168, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$898, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1207:
	movzbq	310(%r11), %rax
	movq	$3184, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$898, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1206:
	movzbq	77(%r11), %rax
	movq	$3136, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$899, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1205:
	movzbq	155(%r11), %rax
	movq	$3152, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$899, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1204:
	movzbq	233(%r11), %rax
	movq	$3168, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$899, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1203:
	movzbq	311(%r11), %rax
	movq	$3184, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$899, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1202:
	movq	$50, %rdx
	jmp 	Lbitsliced_m_calculate_PS$1196
Lbitsliced_m_calculate_PS$1197:
	movzbq	(%r11,%rdx), %rax
	movq	$3200, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$1201:
	movzbq	78(%r11,%rdx), %rax
	movq	$3216, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$1200:
	movzbq	156(%r11,%rdx), %rax
	movq	$3232, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$1199:
	movzbq	234(%r11,%rdx), %rax
	movq	$3248, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$1198:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$1196:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$1197
	movzbq	60(%r11), %rax
	movq	$3200, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$900, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1195:
	movzbq	138(%r11), %rax
	movq	$3216, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$900, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1194:
	movzbq	216(%r11), %rax
	movq	$3232, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$900, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1193:
	movzbq	294(%r11), %rax
	movq	$3248, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$900, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1192:
	movzbq	61(%r11), %rax
	movq	$3200, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$901, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1191:
	movzbq	139(%r11), %rax
	movq	$3216, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$901, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1190:
	movzbq	217(%r11), %rax
	movq	$3232, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$901, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1189:
	movzbq	295(%r11), %rax
	movq	$3248, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$901, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1188:
	movzbq	62(%r11), %rax
	movq	$3200, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$902, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1187:
	movzbq	140(%r11), %rax
	movq	$3216, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$902, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1186:
	movzbq	218(%r11), %rax
	movq	$3232, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$902, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1185:
	movzbq	296(%r11), %rax
	movq	$3248, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$902, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1184:
	movzbq	63(%r11), %rax
	movq	$3200, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$903, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1183:
	movzbq	141(%r11), %rax
	movq	$3216, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$903, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1182:
	movzbq	219(%r11), %rax
	movq	$3232, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$903, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1181:
	movzbq	297(%r11), %rax
	movq	$3248, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$903, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1180:
	movzbq	64(%r11), %rax
	movq	$3200, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$904, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1179:
	movzbq	142(%r11), %rax
	movq	$3216, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$904, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1178:
	movzbq	220(%r11), %rax
	movq	$3232, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$904, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1177:
	movzbq	298(%r11), %rax
	movq	$3248, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$904, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1176:
	movzbq	65(%r11), %rax
	movq	$3200, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$905, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1175:
	movzbq	143(%r11), %rax
	movq	$3216, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$905, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1174:
	movzbq	221(%r11), %rax
	movq	$3232, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$905, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1173:
	movzbq	299(%r11), %rax
	movq	$3248, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$905, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1172:
	movzbq	66(%r11), %rax
	movq	$3200, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$906, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1171:
	movzbq	144(%r11), %rax
	movq	$3216, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$906, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1170:
	movzbq	222(%r11), %rax
	movq	$3232, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$906, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1169:
	movzbq	300(%r11), %rax
	movq	$3248, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$906, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1168:
	movzbq	67(%r11), %rax
	movq	$3200, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$907, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1167:
	movzbq	145(%r11), %rax
	movq	$3216, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$907, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1166:
	movzbq	223(%r11), %rax
	movq	$3232, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$907, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1165:
	movzbq	301(%r11), %rax
	movq	$3248, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$907, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1164:
	movzbq	68(%r11), %rax
	movq	$3200, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$908, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1163:
	movzbq	146(%r11), %rax
	movq	$3216, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$908, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1162:
	movzbq	224(%r11), %rax
	movq	$3232, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$908, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1161:
	movzbq	302(%r11), %rax
	movq	$3248, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$908, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1160:
	movzbq	69(%r11), %rax
	movq	$3200, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$909, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1159:
	movzbq	147(%r11), %rax
	movq	$3216, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$909, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1158:
	movzbq	225(%r11), %rax
	movq	$3232, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$909, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1157:
	movzbq	303(%r11), %rax
	movq	$3248, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$909, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1156:
	movzbq	70(%r11), %rax
	movq	$3200, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$910, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1155:
	movzbq	148(%r11), %rax
	movq	$3216, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$910, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1154:
	movzbq	226(%r11), %rax
	movq	$3232, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$910, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1153:
	movzbq	304(%r11), %rax
	movq	$3248, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$910, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1152:
	movzbq	71(%r11), %rax
	movq	$3200, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$911, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1151:
	movzbq	149(%r11), %rax
	movq	$3216, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$911, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1150:
	movzbq	227(%r11), %rax
	movq	$3232, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$911, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1149:
	movzbq	305(%r11), %rax
	movq	$3248, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$911, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1148:
	movzbq	72(%r11), %rax
	movq	$3200, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$912, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1147:
	movzbq	150(%r11), %rax
	movq	$3216, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$912, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1146:
	movzbq	228(%r11), %rax
	movq	$3232, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$912, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1145:
	movzbq	306(%r11), %rax
	movq	$3248, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$912, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1144:
	movzbq	73(%r11), %rax
	movq	$3200, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$913, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1143:
	movzbq	151(%r11), %rax
	movq	$3216, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$913, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1142:
	movzbq	229(%r11), %rax
	movq	$3232, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$913, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1141:
	movzbq	307(%r11), %rax
	movq	$3248, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$913, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1140:
	movzbq	74(%r11), %rax
	movq	$3200, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$914, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1139:
	movzbq	152(%r11), %rax
	movq	$3216, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$914, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1138:
	movzbq	230(%r11), %rax
	movq	$3232, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$914, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1137:
	movzbq	308(%r11), %rax
	movq	$3248, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$914, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1136:
	movzbq	75(%r11), %rax
	movq	$3200, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$915, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1135:
	movzbq	153(%r11), %rax
	movq	$3216, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$915, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1134:
	movzbq	231(%r11), %rax
	movq	$3232, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$915, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1133:
	movzbq	309(%r11), %rax
	movq	$3248, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$915, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1132:
	movzbq	76(%r11), %rax
	movq	$3200, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$916, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1131:
	movzbq	154(%r11), %rax
	movq	$3216, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$916, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1130:
	movzbq	232(%r11), %rax
	movq	$3232, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$916, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1129:
	movzbq	310(%r11), %rax
	movq	$3248, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$916, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1128:
	movzbq	77(%r11), %rax
	movq	$3200, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$917, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1127:
	movzbq	155(%r11), %rax
	movq	$3216, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$917, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1126:
	movzbq	233(%r11), %rax
	movq	$3232, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$917, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1125:
	movzbq	311(%r11), %rax
	movq	$3248, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$917, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1124:
	movq	$51, %rdx
	jmp 	Lbitsliced_m_calculate_PS$1118
Lbitsliced_m_calculate_PS$1119:
	movzbq	(%r11,%rdx), %rax
	movq	$3264, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$1123:
	movzbq	78(%r11,%rdx), %rax
	movq	$3280, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$1122:
	movzbq	156(%r11,%rdx), %rax
	movq	$3296, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$1121:
	movzbq	234(%r11,%rdx), %rax
	movq	$3312, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$1120:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$1118:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$1119
	movzbq	60(%r11), %rax
	movq	$3264, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$918, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1117:
	movzbq	138(%r11), %rax
	movq	$3280, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$918, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1116:
	movzbq	216(%r11), %rax
	movq	$3296, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$918, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1115:
	movzbq	294(%r11), %rax
	movq	$3312, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$918, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1114:
	movzbq	61(%r11), %rax
	movq	$3264, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$919, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1113:
	movzbq	139(%r11), %rax
	movq	$3280, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$919, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1112:
	movzbq	217(%r11), %rax
	movq	$3296, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$919, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1111:
	movzbq	295(%r11), %rax
	movq	$3312, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$919, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1110:
	movzbq	62(%r11), %rax
	movq	$3264, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$920, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1109:
	movzbq	140(%r11), %rax
	movq	$3280, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$920, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1108:
	movzbq	218(%r11), %rax
	movq	$3296, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$920, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1107:
	movzbq	296(%r11), %rax
	movq	$3312, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$920, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1106:
	movzbq	63(%r11), %rax
	movq	$3264, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$921, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1105:
	movzbq	141(%r11), %rax
	movq	$3280, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$921, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1104:
	movzbq	219(%r11), %rax
	movq	$3296, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$921, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1103:
	movzbq	297(%r11), %rax
	movq	$3312, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$921, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1102:
	movzbq	64(%r11), %rax
	movq	$3264, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$922, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1101:
	movzbq	142(%r11), %rax
	movq	$3280, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$922, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1100:
	movzbq	220(%r11), %rax
	movq	$3296, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$922, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1099:
	movzbq	298(%r11), %rax
	movq	$3312, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$922, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1098:
	movzbq	65(%r11), %rax
	movq	$3264, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$923, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1097:
	movzbq	143(%r11), %rax
	movq	$3280, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$923, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1096:
	movzbq	221(%r11), %rax
	movq	$3296, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$923, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1095:
	movzbq	299(%r11), %rax
	movq	$3312, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$923, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1094:
	movzbq	66(%r11), %rax
	movq	$3264, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$924, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1093:
	movzbq	144(%r11), %rax
	movq	$3280, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$924, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1092:
	movzbq	222(%r11), %rax
	movq	$3296, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$924, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1091:
	movzbq	300(%r11), %rax
	movq	$3312, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$924, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1090:
	movzbq	67(%r11), %rax
	movq	$3264, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$925, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1089:
	movzbq	145(%r11), %rax
	movq	$3280, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$925, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1088:
	movzbq	223(%r11), %rax
	movq	$3296, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$925, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1087:
	movzbq	301(%r11), %rax
	movq	$3312, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$925, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1086:
	movzbq	68(%r11), %rax
	movq	$3264, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$926, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1085:
	movzbq	146(%r11), %rax
	movq	$3280, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$926, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1084:
	movzbq	224(%r11), %rax
	movq	$3296, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$926, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1083:
	movzbq	302(%r11), %rax
	movq	$3312, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$926, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1082:
	movzbq	69(%r11), %rax
	movq	$3264, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$927, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1081:
	movzbq	147(%r11), %rax
	movq	$3280, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$927, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1080:
	movzbq	225(%r11), %rax
	movq	$3296, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$927, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1079:
	movzbq	303(%r11), %rax
	movq	$3312, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$927, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1078:
	movzbq	70(%r11), %rax
	movq	$3264, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$928, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1077:
	movzbq	148(%r11), %rax
	movq	$3280, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$928, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1076:
	movzbq	226(%r11), %rax
	movq	$3296, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$928, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1075:
	movzbq	304(%r11), %rax
	movq	$3312, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$928, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1074:
	movzbq	71(%r11), %rax
	movq	$3264, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$929, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1073:
	movzbq	149(%r11), %rax
	movq	$3280, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$929, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1072:
	movzbq	227(%r11), %rax
	movq	$3296, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$929, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1071:
	movzbq	305(%r11), %rax
	movq	$3312, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$929, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1070:
	movzbq	72(%r11), %rax
	movq	$3264, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$930, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1069:
	movzbq	150(%r11), %rax
	movq	$3280, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$930, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1068:
	movzbq	228(%r11), %rax
	movq	$3296, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$930, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1067:
	movzbq	306(%r11), %rax
	movq	$3312, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$930, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1066:
	movzbq	73(%r11), %rax
	movq	$3264, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$931, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1065:
	movzbq	151(%r11), %rax
	movq	$3280, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$931, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1064:
	movzbq	229(%r11), %rax
	movq	$3296, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$931, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1063:
	movzbq	307(%r11), %rax
	movq	$3312, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$931, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1062:
	movzbq	74(%r11), %rax
	movq	$3264, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$932, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1061:
	movzbq	152(%r11), %rax
	movq	$3280, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$932, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1060:
	movzbq	230(%r11), %rax
	movq	$3296, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$932, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1059:
	movzbq	308(%r11), %rax
	movq	$3312, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$932, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1058:
	movzbq	75(%r11), %rax
	movq	$3264, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$933, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1057:
	movzbq	153(%r11), %rax
	movq	$3280, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$933, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1056:
	movzbq	231(%r11), %rax
	movq	$3296, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$933, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1055:
	movzbq	309(%r11), %rax
	movq	$3312, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$933, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1054:
	movzbq	76(%r11), %rax
	movq	$3264, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$934, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1053:
	movzbq	154(%r11), %rax
	movq	$3280, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$934, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1052:
	movzbq	232(%r11), %rax
	movq	$3296, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$934, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1051:
	movzbq	310(%r11), %rax
	movq	$3312, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$934, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1050:
	movzbq	77(%r11), %rax
	movq	$3264, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$935, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1049:
	movzbq	155(%r11), %rax
	movq	$3280, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$935, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1048:
	movzbq	233(%r11), %rax
	movq	$3296, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$935, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1047:
	movzbq	311(%r11), %rax
	movq	$3312, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$935, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1046:
	movq	$52, %rdx
	jmp 	Lbitsliced_m_calculate_PS$1040
Lbitsliced_m_calculate_PS$1041:
	movzbq	(%r11,%rdx), %rax
	movq	$3328, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$1045:
	movzbq	78(%r11,%rdx), %rax
	movq	$3344, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$1044:
	movzbq	156(%r11,%rdx), %rax
	movq	$3360, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$1043:
	movzbq	234(%r11,%rdx), %rax
	movq	$3376, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$1042:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$1040:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$1041
	movzbq	60(%r11), %rax
	movq	$3328, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$936, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1039:
	movzbq	138(%r11), %rax
	movq	$3344, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$936, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1038:
	movzbq	216(%r11), %rax
	movq	$3360, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$936, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1037:
	movzbq	294(%r11), %rax
	movq	$3376, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$936, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1036:
	movzbq	61(%r11), %rax
	movq	$3328, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$937, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1035:
	movzbq	139(%r11), %rax
	movq	$3344, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$937, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1034:
	movzbq	217(%r11), %rax
	movq	$3360, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$937, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1033:
	movzbq	295(%r11), %rax
	movq	$3376, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$937, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1032:
	movzbq	62(%r11), %rax
	movq	$3328, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$938, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1031:
	movzbq	140(%r11), %rax
	movq	$3344, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$938, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1030:
	movzbq	218(%r11), %rax
	movq	$3360, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$938, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1029:
	movzbq	296(%r11), %rax
	movq	$3376, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$938, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1028:
	movzbq	63(%r11), %rax
	movq	$3328, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$939, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1027:
	movzbq	141(%r11), %rax
	movq	$3344, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$939, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1026:
	movzbq	219(%r11), %rax
	movq	$3360, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$939, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1025:
	movzbq	297(%r11), %rax
	movq	$3376, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$939, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1024:
	movzbq	64(%r11), %rax
	movq	$3328, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$940, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1023:
	movzbq	142(%r11), %rax
	movq	$3344, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$940, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1022:
	movzbq	220(%r11), %rax
	movq	$3360, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$940, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1021:
	movzbq	298(%r11), %rax
	movq	$3376, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$940, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1020:
	movzbq	65(%r11), %rax
	movq	$3328, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$941, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1019:
	movzbq	143(%r11), %rax
	movq	$3344, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$941, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1018:
	movzbq	221(%r11), %rax
	movq	$3360, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$941, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1017:
	movzbq	299(%r11), %rax
	movq	$3376, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$941, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1016:
	movzbq	66(%r11), %rax
	movq	$3328, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$942, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1015:
	movzbq	144(%r11), %rax
	movq	$3344, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$942, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1014:
	movzbq	222(%r11), %rax
	movq	$3360, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$942, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1013:
	movzbq	300(%r11), %rax
	movq	$3376, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$942, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1012:
	movzbq	67(%r11), %rax
	movq	$3328, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$943, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1011:
	movzbq	145(%r11), %rax
	movq	$3344, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$943, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1010:
	movzbq	223(%r11), %rax
	movq	$3360, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$943, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1009:
	movzbq	301(%r11), %rax
	movq	$3376, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$943, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1008:
	movzbq	68(%r11), %rax
	movq	$3328, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$944, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1007:
	movzbq	146(%r11), %rax
	movq	$3344, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$944, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1006:
	movzbq	224(%r11), %rax
	movq	$3360, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$944, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1005:
	movzbq	302(%r11), %rax
	movq	$3376, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$944, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1004:
	movzbq	69(%r11), %rax
	movq	$3328, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$945, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1003:
	movzbq	147(%r11), %rax
	movq	$3344, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$945, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1002:
	movzbq	225(%r11), %rax
	movq	$3360, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$945, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1001:
	movzbq	303(%r11), %rax
	movq	$3376, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$945, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$1000:
	movzbq	70(%r11), %rax
	movq	$3328, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$946, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$999:
	movzbq	148(%r11), %rax
	movq	$3344, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$946, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$998:
	movzbq	226(%r11), %rax
	movq	$3360, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$946, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$997:
	movzbq	304(%r11), %rax
	movq	$3376, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$946, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$996:
	movzbq	71(%r11), %rax
	movq	$3328, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$947, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$995:
	movzbq	149(%r11), %rax
	movq	$3344, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$947, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$994:
	movzbq	227(%r11), %rax
	movq	$3360, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$947, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$993:
	movzbq	305(%r11), %rax
	movq	$3376, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$947, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$992:
	movzbq	72(%r11), %rax
	movq	$3328, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$948, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$991:
	movzbq	150(%r11), %rax
	movq	$3344, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$948, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$990:
	movzbq	228(%r11), %rax
	movq	$3360, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$948, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$989:
	movzbq	306(%r11), %rax
	movq	$3376, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$948, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$988:
	movzbq	73(%r11), %rax
	movq	$3328, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$949, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$987:
	movzbq	151(%r11), %rax
	movq	$3344, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$949, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$986:
	movzbq	229(%r11), %rax
	movq	$3360, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$949, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$985:
	movzbq	307(%r11), %rax
	movq	$3376, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$949, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$984:
	movzbq	74(%r11), %rax
	movq	$3328, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$950, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$983:
	movzbq	152(%r11), %rax
	movq	$3344, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$950, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$982:
	movzbq	230(%r11), %rax
	movq	$3360, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$950, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$981:
	movzbq	308(%r11), %rax
	movq	$3376, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$950, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$980:
	movzbq	75(%r11), %rax
	movq	$3328, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$951, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$979:
	movzbq	153(%r11), %rax
	movq	$3344, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$951, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$978:
	movzbq	231(%r11), %rax
	movq	$3360, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$951, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$977:
	movzbq	309(%r11), %rax
	movq	$3376, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$951, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$976:
	movzbq	76(%r11), %rax
	movq	$3328, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$952, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$975:
	movzbq	154(%r11), %rax
	movq	$3344, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$952, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$974:
	movzbq	232(%r11), %rax
	movq	$3360, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$952, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$973:
	movzbq	310(%r11), %rax
	movq	$3376, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$952, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$972:
	movzbq	77(%r11), %rax
	movq	$3328, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$953, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$971:
	movzbq	155(%r11), %rax
	movq	$3344, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$953, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$970:
	movzbq	233(%r11), %rax
	movq	$3360, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$953, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$969:
	movzbq	311(%r11), %rax
	movq	$3376, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$953, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$968:
	movq	$53, %rdx
	jmp 	Lbitsliced_m_calculate_PS$962
Lbitsliced_m_calculate_PS$963:
	movzbq	(%r11,%rdx), %rax
	movq	$3392, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$967:
	movzbq	78(%r11,%rdx), %rax
	movq	$3408, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$966:
	movzbq	156(%r11,%rdx), %rax
	movq	$3424, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$965:
	movzbq	234(%r11,%rdx), %rax
	movq	$3440, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$964:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$962:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$963
	movzbq	60(%r11), %rax
	movq	$3392, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$954, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$961:
	movzbq	138(%r11), %rax
	movq	$3408, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$954, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$960:
	movzbq	216(%r11), %rax
	movq	$3424, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$954, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$959:
	movzbq	294(%r11), %rax
	movq	$3440, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$954, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$958:
	movzbq	61(%r11), %rax
	movq	$3392, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$955, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$957:
	movzbq	139(%r11), %rax
	movq	$3408, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$955, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$956:
	movzbq	217(%r11), %rax
	movq	$3424, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$955, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$955:
	movzbq	295(%r11), %rax
	movq	$3440, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$955, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$954:
	movzbq	62(%r11), %rax
	movq	$3392, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$956, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$953:
	movzbq	140(%r11), %rax
	movq	$3408, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$956, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$952:
	movzbq	218(%r11), %rax
	movq	$3424, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$956, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$951:
	movzbq	296(%r11), %rax
	movq	$3440, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$956, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$950:
	movzbq	63(%r11), %rax
	movq	$3392, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$957, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$949:
	movzbq	141(%r11), %rax
	movq	$3408, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$957, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$948:
	movzbq	219(%r11), %rax
	movq	$3424, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$957, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$947:
	movzbq	297(%r11), %rax
	movq	$3440, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$957, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$946:
	movzbq	64(%r11), %rax
	movq	$3392, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$958, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$945:
	movzbq	142(%r11), %rax
	movq	$3408, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$958, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$944:
	movzbq	220(%r11), %rax
	movq	$3424, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$958, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$943:
	movzbq	298(%r11), %rax
	movq	$3440, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$958, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$942:
	movzbq	65(%r11), %rax
	movq	$3392, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$959, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$941:
	movzbq	143(%r11), %rax
	movq	$3408, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$959, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$940:
	movzbq	221(%r11), %rax
	movq	$3424, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$959, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$939:
	movzbq	299(%r11), %rax
	movq	$3440, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$959, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$938:
	movzbq	66(%r11), %rax
	movq	$3392, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$960, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$937:
	movzbq	144(%r11), %rax
	movq	$3408, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$960, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$936:
	movzbq	222(%r11), %rax
	movq	$3424, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$960, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$935:
	movzbq	300(%r11), %rax
	movq	$3440, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$960, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$934:
	movzbq	67(%r11), %rax
	movq	$3392, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$961, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$933:
	movzbq	145(%r11), %rax
	movq	$3408, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$961, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$932:
	movzbq	223(%r11), %rax
	movq	$3424, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$961, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$931:
	movzbq	301(%r11), %rax
	movq	$3440, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$961, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$930:
	movzbq	68(%r11), %rax
	movq	$3392, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$962, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$929:
	movzbq	146(%r11), %rax
	movq	$3408, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$962, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$928:
	movzbq	224(%r11), %rax
	movq	$3424, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$962, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$927:
	movzbq	302(%r11), %rax
	movq	$3440, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$962, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$926:
	movzbq	69(%r11), %rax
	movq	$3392, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$963, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$925:
	movzbq	147(%r11), %rax
	movq	$3408, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$963, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$924:
	movzbq	225(%r11), %rax
	movq	$3424, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$963, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$923:
	movzbq	303(%r11), %rax
	movq	$3440, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$963, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$922:
	movzbq	70(%r11), %rax
	movq	$3392, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$964, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$921:
	movzbq	148(%r11), %rax
	movq	$3408, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$964, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$920:
	movzbq	226(%r11), %rax
	movq	$3424, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$964, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$919:
	movzbq	304(%r11), %rax
	movq	$3440, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$964, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$918:
	movzbq	71(%r11), %rax
	movq	$3392, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$965, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$917:
	movzbq	149(%r11), %rax
	movq	$3408, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$965, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$916:
	movzbq	227(%r11), %rax
	movq	$3424, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$965, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$915:
	movzbq	305(%r11), %rax
	movq	$3440, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$965, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$914:
	movzbq	72(%r11), %rax
	movq	$3392, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$966, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$913:
	movzbq	150(%r11), %rax
	movq	$3408, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$966, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$912:
	movzbq	228(%r11), %rax
	movq	$3424, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$966, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$911:
	movzbq	306(%r11), %rax
	movq	$3440, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$966, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$910:
	movzbq	73(%r11), %rax
	movq	$3392, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$967, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$909:
	movzbq	151(%r11), %rax
	movq	$3408, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$967, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$908:
	movzbq	229(%r11), %rax
	movq	$3424, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$967, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$907:
	movzbq	307(%r11), %rax
	movq	$3440, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$967, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$906:
	movzbq	74(%r11), %rax
	movq	$3392, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$968, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$905:
	movzbq	152(%r11), %rax
	movq	$3408, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$968, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$904:
	movzbq	230(%r11), %rax
	movq	$3424, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$968, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$903:
	movzbq	308(%r11), %rax
	movq	$3440, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$968, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$902:
	movzbq	75(%r11), %rax
	movq	$3392, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$969, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$901:
	movzbq	153(%r11), %rax
	movq	$3408, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$969, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$900:
	movzbq	231(%r11), %rax
	movq	$3424, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$969, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$899:
	movzbq	309(%r11), %rax
	movq	$3440, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$969, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$898:
	movzbq	76(%r11), %rax
	movq	$3392, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$970, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$897:
	movzbq	154(%r11), %rax
	movq	$3408, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$970, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$896:
	movzbq	232(%r11), %rax
	movq	$3424, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$970, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$895:
	movzbq	310(%r11), %rax
	movq	$3440, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$970, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$894:
	movzbq	77(%r11), %rax
	movq	$3392, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$971, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$893:
	movzbq	155(%r11), %rax
	movq	$3408, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$971, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$892:
	movzbq	233(%r11), %rax
	movq	$3424, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$971, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$891:
	movzbq	311(%r11), %rax
	movq	$3440, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$971, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$890:
	movq	$54, %rdx
	jmp 	Lbitsliced_m_calculate_PS$884
Lbitsliced_m_calculate_PS$885:
	movzbq	(%r11,%rdx), %rax
	movq	$3456, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$889:
	movzbq	78(%r11,%rdx), %rax
	movq	$3472, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$888:
	movzbq	156(%r11,%rdx), %rax
	movq	$3488, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$887:
	movzbq	234(%r11,%rdx), %rax
	movq	$3504, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$886:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$884:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$885
	movzbq	60(%r11), %rax
	movq	$3456, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$972, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$883:
	movzbq	138(%r11), %rax
	movq	$3472, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$972, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$882:
	movzbq	216(%r11), %rax
	movq	$3488, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$972, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$881:
	movzbq	294(%r11), %rax
	movq	$3504, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$972, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$880:
	movzbq	61(%r11), %rax
	movq	$3456, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$973, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$879:
	movzbq	139(%r11), %rax
	movq	$3472, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$973, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$878:
	movzbq	217(%r11), %rax
	movq	$3488, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$973, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$877:
	movzbq	295(%r11), %rax
	movq	$3504, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$973, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$876:
	movzbq	62(%r11), %rax
	movq	$3456, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$974, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$875:
	movzbq	140(%r11), %rax
	movq	$3472, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$974, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$874:
	movzbq	218(%r11), %rax
	movq	$3488, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$974, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$873:
	movzbq	296(%r11), %rax
	movq	$3504, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$974, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$872:
	movzbq	63(%r11), %rax
	movq	$3456, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$975, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$871:
	movzbq	141(%r11), %rax
	movq	$3472, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$975, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$870:
	movzbq	219(%r11), %rax
	movq	$3488, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$975, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$869:
	movzbq	297(%r11), %rax
	movq	$3504, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$975, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$868:
	movzbq	64(%r11), %rax
	movq	$3456, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$976, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$867:
	movzbq	142(%r11), %rax
	movq	$3472, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$976, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$866:
	movzbq	220(%r11), %rax
	movq	$3488, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$976, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$865:
	movzbq	298(%r11), %rax
	movq	$3504, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$976, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$864:
	movzbq	65(%r11), %rax
	movq	$3456, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$977, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$863:
	movzbq	143(%r11), %rax
	movq	$3472, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$977, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$862:
	movzbq	221(%r11), %rax
	movq	$3488, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$977, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$861:
	movzbq	299(%r11), %rax
	movq	$3504, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$977, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$860:
	movzbq	66(%r11), %rax
	movq	$3456, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$978, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$859:
	movzbq	144(%r11), %rax
	movq	$3472, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$978, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$858:
	movzbq	222(%r11), %rax
	movq	$3488, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$978, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$857:
	movzbq	300(%r11), %rax
	movq	$3504, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$978, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$856:
	movzbq	67(%r11), %rax
	movq	$3456, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$979, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$855:
	movzbq	145(%r11), %rax
	movq	$3472, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$979, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$854:
	movzbq	223(%r11), %rax
	movq	$3488, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$979, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$853:
	movzbq	301(%r11), %rax
	movq	$3504, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$979, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$852:
	movzbq	68(%r11), %rax
	movq	$3456, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$980, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$851:
	movzbq	146(%r11), %rax
	movq	$3472, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$980, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$850:
	movzbq	224(%r11), %rax
	movq	$3488, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$980, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$849:
	movzbq	302(%r11), %rax
	movq	$3504, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$980, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$848:
	movzbq	69(%r11), %rax
	movq	$3456, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$981, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$847:
	movzbq	147(%r11), %rax
	movq	$3472, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$981, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$846:
	movzbq	225(%r11), %rax
	movq	$3488, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$981, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$845:
	movzbq	303(%r11), %rax
	movq	$3504, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$981, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$844:
	movzbq	70(%r11), %rax
	movq	$3456, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$982, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$843:
	movzbq	148(%r11), %rax
	movq	$3472, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$982, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$842:
	movzbq	226(%r11), %rax
	movq	$3488, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$982, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$841:
	movzbq	304(%r11), %rax
	movq	$3504, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$982, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$840:
	movzbq	71(%r11), %rax
	movq	$3456, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$983, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$839:
	movzbq	149(%r11), %rax
	movq	$3472, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$983, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$838:
	movzbq	227(%r11), %rax
	movq	$3488, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$983, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$837:
	movzbq	305(%r11), %rax
	movq	$3504, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$983, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$836:
	movzbq	72(%r11), %rax
	movq	$3456, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$984, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$835:
	movzbq	150(%r11), %rax
	movq	$3472, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$984, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$834:
	movzbq	228(%r11), %rax
	movq	$3488, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$984, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$833:
	movzbq	306(%r11), %rax
	movq	$3504, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$984, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$832:
	movzbq	73(%r11), %rax
	movq	$3456, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$985, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$831:
	movzbq	151(%r11), %rax
	movq	$3472, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$985, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$830:
	movzbq	229(%r11), %rax
	movq	$3488, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$985, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$829:
	movzbq	307(%r11), %rax
	movq	$3504, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$985, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$828:
	movzbq	74(%r11), %rax
	movq	$3456, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$986, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$827:
	movzbq	152(%r11), %rax
	movq	$3472, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$986, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$826:
	movzbq	230(%r11), %rax
	movq	$3488, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$986, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$825:
	movzbq	308(%r11), %rax
	movq	$3504, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$986, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$824:
	movzbq	75(%r11), %rax
	movq	$3456, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$987, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$823:
	movzbq	153(%r11), %rax
	movq	$3472, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$987, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$822:
	movzbq	231(%r11), %rax
	movq	$3488, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$987, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$821:
	movzbq	309(%r11), %rax
	movq	$3504, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$987, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$820:
	movzbq	76(%r11), %rax
	movq	$3456, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$988, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$819:
	movzbq	154(%r11), %rax
	movq	$3472, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$988, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$818:
	movzbq	232(%r11), %rax
	movq	$3488, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$988, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$817:
	movzbq	310(%r11), %rax
	movq	$3504, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$988, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$816:
	movzbq	77(%r11), %rax
	movq	$3456, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$989, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$815:
	movzbq	155(%r11), %rax
	movq	$3472, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$989, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$814:
	movzbq	233(%r11), %rax
	movq	$3488, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$989, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$813:
	movzbq	311(%r11), %rax
	movq	$3504, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$989, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$812:
	movq	$55, %rdx
	jmp 	Lbitsliced_m_calculate_PS$806
Lbitsliced_m_calculate_PS$807:
	movzbq	(%r11,%rdx), %rax
	movq	$3520, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$811:
	movzbq	78(%r11,%rdx), %rax
	movq	$3536, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$810:
	movzbq	156(%r11,%rdx), %rax
	movq	$3552, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$809:
	movzbq	234(%r11,%rdx), %rax
	movq	$3568, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$808:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$806:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$807
	movzbq	60(%r11), %rax
	movq	$3520, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$990, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$805:
	movzbq	138(%r11), %rax
	movq	$3536, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$990, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$804:
	movzbq	216(%r11), %rax
	movq	$3552, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$990, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$803:
	movzbq	294(%r11), %rax
	movq	$3568, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$990, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$802:
	movzbq	61(%r11), %rax
	movq	$3520, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$991, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$801:
	movzbq	139(%r11), %rax
	movq	$3536, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$991, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$800:
	movzbq	217(%r11), %rax
	movq	$3552, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$991, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$799:
	movzbq	295(%r11), %rax
	movq	$3568, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$991, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$798:
	movzbq	62(%r11), %rax
	movq	$3520, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$992, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$797:
	movzbq	140(%r11), %rax
	movq	$3536, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$992, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$796:
	movzbq	218(%r11), %rax
	movq	$3552, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$992, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$795:
	movzbq	296(%r11), %rax
	movq	$3568, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$992, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$794:
	movzbq	63(%r11), %rax
	movq	$3520, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$993, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$793:
	movzbq	141(%r11), %rax
	movq	$3536, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$993, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$792:
	movzbq	219(%r11), %rax
	movq	$3552, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$993, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$791:
	movzbq	297(%r11), %rax
	movq	$3568, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$993, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$790:
	movzbq	64(%r11), %rax
	movq	$3520, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$994, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$789:
	movzbq	142(%r11), %rax
	movq	$3536, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$994, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$788:
	movzbq	220(%r11), %rax
	movq	$3552, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$994, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$787:
	movzbq	298(%r11), %rax
	movq	$3568, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$994, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$786:
	movzbq	65(%r11), %rax
	movq	$3520, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$995, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$785:
	movzbq	143(%r11), %rax
	movq	$3536, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$995, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$784:
	movzbq	221(%r11), %rax
	movq	$3552, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$995, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$783:
	movzbq	299(%r11), %rax
	movq	$3568, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$995, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$782:
	movzbq	66(%r11), %rax
	movq	$3520, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$996, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$781:
	movzbq	144(%r11), %rax
	movq	$3536, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$996, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$780:
	movzbq	222(%r11), %rax
	movq	$3552, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$996, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$779:
	movzbq	300(%r11), %rax
	movq	$3568, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$996, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$778:
	movzbq	67(%r11), %rax
	movq	$3520, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$997, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$777:
	movzbq	145(%r11), %rax
	movq	$3536, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$997, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$776:
	movzbq	223(%r11), %rax
	movq	$3552, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$997, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$775:
	movzbq	301(%r11), %rax
	movq	$3568, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$997, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$774:
	movzbq	68(%r11), %rax
	movq	$3520, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$998, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$773:
	movzbq	146(%r11), %rax
	movq	$3536, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$998, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$772:
	movzbq	224(%r11), %rax
	movq	$3552, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$998, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$771:
	movzbq	302(%r11), %rax
	movq	$3568, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$998, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$770:
	movzbq	69(%r11), %rax
	movq	$3520, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$999, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$769:
	movzbq	147(%r11), %rax
	movq	$3536, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$999, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$768:
	movzbq	225(%r11), %rax
	movq	$3552, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$999, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$767:
	movzbq	303(%r11), %rax
	movq	$3568, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$999, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$766:
	movzbq	70(%r11), %rax
	movq	$3520, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1000, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$765:
	movzbq	148(%r11), %rax
	movq	$3536, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1000, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$764:
	movzbq	226(%r11), %rax
	movq	$3552, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1000, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$763:
	movzbq	304(%r11), %rax
	movq	$3568, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1000, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$762:
	movzbq	71(%r11), %rax
	movq	$3520, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1001, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$761:
	movzbq	149(%r11), %rax
	movq	$3536, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1001, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$760:
	movzbq	227(%r11), %rax
	movq	$3552, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1001, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$759:
	movzbq	305(%r11), %rax
	movq	$3568, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1001, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$758:
	movzbq	72(%r11), %rax
	movq	$3520, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1002, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$757:
	movzbq	150(%r11), %rax
	movq	$3536, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1002, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$756:
	movzbq	228(%r11), %rax
	movq	$3552, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1002, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$755:
	movzbq	306(%r11), %rax
	movq	$3568, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1002, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$754:
	movzbq	73(%r11), %rax
	movq	$3520, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1003, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$753:
	movzbq	151(%r11), %rax
	movq	$3536, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1003, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$752:
	movzbq	229(%r11), %rax
	movq	$3552, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1003, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$751:
	movzbq	307(%r11), %rax
	movq	$3568, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1003, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$750:
	movzbq	74(%r11), %rax
	movq	$3520, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1004, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$749:
	movzbq	152(%r11), %rax
	movq	$3536, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1004, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$748:
	movzbq	230(%r11), %rax
	movq	$3552, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1004, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$747:
	movzbq	308(%r11), %rax
	movq	$3568, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1004, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$746:
	movzbq	75(%r11), %rax
	movq	$3520, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1005, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$745:
	movzbq	153(%r11), %rax
	movq	$3536, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1005, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$744:
	movzbq	231(%r11), %rax
	movq	$3552, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1005, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$743:
	movzbq	309(%r11), %rax
	movq	$3568, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1005, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$742:
	movzbq	76(%r11), %rax
	movq	$3520, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1006, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$741:
	movzbq	154(%r11), %rax
	movq	$3536, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1006, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$740:
	movzbq	232(%r11), %rax
	movq	$3552, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1006, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$739:
	movzbq	310(%r11), %rax
	movq	$3568, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1006, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$738:
	movzbq	77(%r11), %rax
	movq	$3520, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1007, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$737:
	movzbq	155(%r11), %rax
	movq	$3536, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1007, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$736:
	movzbq	233(%r11), %rax
	movq	$3552, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1007, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$735:
	movzbq	311(%r11), %rax
	movq	$3568, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1007, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$734:
	movq	$56, %rdx
	jmp 	Lbitsliced_m_calculate_PS$728
Lbitsliced_m_calculate_PS$729:
	movzbq	(%r11,%rdx), %rax
	movq	$3584, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$733:
	movzbq	78(%r11,%rdx), %rax
	movq	$3600, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$732:
	movzbq	156(%r11,%rdx), %rax
	movq	$3616, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$731:
	movzbq	234(%r11,%rdx), %rax
	movq	$3632, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$730:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$728:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$729
	movzbq	60(%r11), %rax
	movq	$3584, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1008, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$727:
	movzbq	138(%r11), %rax
	movq	$3600, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1008, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$726:
	movzbq	216(%r11), %rax
	movq	$3616, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1008, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$725:
	movzbq	294(%r11), %rax
	movq	$3632, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1008, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$724:
	movzbq	61(%r11), %rax
	movq	$3584, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1009, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$723:
	movzbq	139(%r11), %rax
	movq	$3600, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1009, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$722:
	movzbq	217(%r11), %rax
	movq	$3616, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1009, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$721:
	movzbq	295(%r11), %rax
	movq	$3632, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1009, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$720:
	movzbq	62(%r11), %rax
	movq	$3584, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1010, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$719:
	movzbq	140(%r11), %rax
	movq	$3600, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1010, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$718:
	movzbq	218(%r11), %rax
	movq	$3616, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1010, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$717:
	movzbq	296(%r11), %rax
	movq	$3632, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1010, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$716:
	movzbq	63(%r11), %rax
	movq	$3584, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1011, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$715:
	movzbq	141(%r11), %rax
	movq	$3600, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1011, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$714:
	movzbq	219(%r11), %rax
	movq	$3616, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1011, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$713:
	movzbq	297(%r11), %rax
	movq	$3632, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1011, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$712:
	movzbq	64(%r11), %rax
	movq	$3584, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1012, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$711:
	movzbq	142(%r11), %rax
	movq	$3600, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1012, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$710:
	movzbq	220(%r11), %rax
	movq	$3616, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1012, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$709:
	movzbq	298(%r11), %rax
	movq	$3632, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1012, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$708:
	movzbq	65(%r11), %rax
	movq	$3584, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1013, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$707:
	movzbq	143(%r11), %rax
	movq	$3600, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1013, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$706:
	movzbq	221(%r11), %rax
	movq	$3616, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1013, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$705:
	movzbq	299(%r11), %rax
	movq	$3632, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1013, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$704:
	movzbq	66(%r11), %rax
	movq	$3584, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1014, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$703:
	movzbq	144(%r11), %rax
	movq	$3600, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1014, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$702:
	movzbq	222(%r11), %rax
	movq	$3616, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1014, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$701:
	movzbq	300(%r11), %rax
	movq	$3632, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1014, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$700:
	movzbq	67(%r11), %rax
	movq	$3584, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1015, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$699:
	movzbq	145(%r11), %rax
	movq	$3600, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1015, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$698:
	movzbq	223(%r11), %rax
	movq	$3616, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1015, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$697:
	movzbq	301(%r11), %rax
	movq	$3632, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1015, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$696:
	movzbq	68(%r11), %rax
	movq	$3584, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1016, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$695:
	movzbq	146(%r11), %rax
	movq	$3600, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1016, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$694:
	movzbq	224(%r11), %rax
	movq	$3616, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1016, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$693:
	movzbq	302(%r11), %rax
	movq	$3632, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1016, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$692:
	movzbq	69(%r11), %rax
	movq	$3584, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1017, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$691:
	movzbq	147(%r11), %rax
	movq	$3600, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1017, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$690:
	movzbq	225(%r11), %rax
	movq	$3616, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1017, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$689:
	movzbq	303(%r11), %rax
	movq	$3632, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1017, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$688:
	movzbq	70(%r11), %rax
	movq	$3584, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1018, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$687:
	movzbq	148(%r11), %rax
	movq	$3600, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1018, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$686:
	movzbq	226(%r11), %rax
	movq	$3616, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1018, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$685:
	movzbq	304(%r11), %rax
	movq	$3632, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1018, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$684:
	movzbq	71(%r11), %rax
	movq	$3584, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1019, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$683:
	movzbq	149(%r11), %rax
	movq	$3600, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1019, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$682:
	movzbq	227(%r11), %rax
	movq	$3616, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1019, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$681:
	movzbq	305(%r11), %rax
	movq	$3632, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1019, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$680:
	movzbq	72(%r11), %rax
	movq	$3584, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1020, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$679:
	movzbq	150(%r11), %rax
	movq	$3600, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1020, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$678:
	movzbq	228(%r11), %rax
	movq	$3616, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1020, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$677:
	movzbq	306(%r11), %rax
	movq	$3632, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1020, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$676:
	movzbq	73(%r11), %rax
	movq	$3584, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1021, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$675:
	movzbq	151(%r11), %rax
	movq	$3600, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1021, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$674:
	movzbq	229(%r11), %rax
	movq	$3616, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1021, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$673:
	movzbq	307(%r11), %rax
	movq	$3632, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1021, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$672:
	movzbq	74(%r11), %rax
	movq	$3584, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1022, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$671:
	movzbq	152(%r11), %rax
	movq	$3600, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1022, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$670:
	movzbq	230(%r11), %rax
	movq	$3616, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1022, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$669:
	movzbq	308(%r11), %rax
	movq	$3632, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1022, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$668:
	movzbq	75(%r11), %rax
	movq	$3584, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1023, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$667:
	movzbq	153(%r11), %rax
	movq	$3600, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1023, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$666:
	movzbq	231(%r11), %rax
	movq	$3616, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1023, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$665:
	movzbq	309(%r11), %rax
	movq	$3632, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1023, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$664:
	movzbq	76(%r11), %rax
	movq	$3584, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1024, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$663:
	movzbq	154(%r11), %rax
	movq	$3600, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1024, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$662:
	movzbq	232(%r11), %rax
	movq	$3616, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1024, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$661:
	movzbq	310(%r11), %rax
	movq	$3632, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1024, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$660:
	movzbq	77(%r11), %rax
	movq	$3584, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1025, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$659:
	movzbq	155(%r11), %rax
	movq	$3600, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1025, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$658:
	movzbq	233(%r11), %rax
	movq	$3616, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1025, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$657:
	movzbq	311(%r11), %rax
	movq	$3632, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1025, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$656:
	movq	$57, %rdx
	jmp 	Lbitsliced_m_calculate_PS$650
Lbitsliced_m_calculate_PS$651:
	movzbq	(%r11,%rdx), %rax
	movq	$3648, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$655:
	movzbq	78(%r11,%rdx), %rax
	movq	$3664, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$654:
	movzbq	156(%r11,%rdx), %rax
	movq	$3680, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$653:
	movzbq	234(%r11,%rdx), %rax
	movq	$3696, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$652:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$650:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$651
	movzbq	60(%r11), %rax
	movq	$3648, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1026, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$649:
	movzbq	138(%r11), %rax
	movq	$3664, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1026, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$648:
	movzbq	216(%r11), %rax
	movq	$3680, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1026, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$647:
	movzbq	294(%r11), %rax
	movq	$3696, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1026, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$646:
	movzbq	61(%r11), %rax
	movq	$3648, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1027, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$645:
	movzbq	139(%r11), %rax
	movq	$3664, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1027, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$644:
	movzbq	217(%r11), %rax
	movq	$3680, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1027, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$643:
	movzbq	295(%r11), %rax
	movq	$3696, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1027, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$642:
	movzbq	62(%r11), %rax
	movq	$3648, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1028, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$641:
	movzbq	140(%r11), %rax
	movq	$3664, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1028, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$640:
	movzbq	218(%r11), %rax
	movq	$3680, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1028, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$639:
	movzbq	296(%r11), %rax
	movq	$3696, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1028, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$638:
	movzbq	63(%r11), %rax
	movq	$3648, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1029, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$637:
	movzbq	141(%r11), %rax
	movq	$3664, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1029, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$636:
	movzbq	219(%r11), %rax
	movq	$3680, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1029, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$635:
	movzbq	297(%r11), %rax
	movq	$3696, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1029, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$634:
	movzbq	64(%r11), %rax
	movq	$3648, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1030, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$633:
	movzbq	142(%r11), %rax
	movq	$3664, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1030, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$632:
	movzbq	220(%r11), %rax
	movq	$3680, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1030, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$631:
	movzbq	298(%r11), %rax
	movq	$3696, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1030, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$630:
	movzbq	65(%r11), %rax
	movq	$3648, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1031, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$629:
	movzbq	143(%r11), %rax
	movq	$3664, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1031, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$628:
	movzbq	221(%r11), %rax
	movq	$3680, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1031, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$627:
	movzbq	299(%r11), %rax
	movq	$3696, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1031, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$626:
	movzbq	66(%r11), %rax
	movq	$3648, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1032, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$625:
	movzbq	144(%r11), %rax
	movq	$3664, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1032, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$624:
	movzbq	222(%r11), %rax
	movq	$3680, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1032, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$623:
	movzbq	300(%r11), %rax
	movq	$3696, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1032, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$622:
	movzbq	67(%r11), %rax
	movq	$3648, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1033, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$621:
	movzbq	145(%r11), %rax
	movq	$3664, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1033, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$620:
	movzbq	223(%r11), %rax
	movq	$3680, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1033, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$619:
	movzbq	301(%r11), %rax
	movq	$3696, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1033, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$618:
	movzbq	68(%r11), %rax
	movq	$3648, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1034, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$617:
	movzbq	146(%r11), %rax
	movq	$3664, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1034, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$616:
	movzbq	224(%r11), %rax
	movq	$3680, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1034, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$615:
	movzbq	302(%r11), %rax
	movq	$3696, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1034, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$614:
	movzbq	69(%r11), %rax
	movq	$3648, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1035, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$613:
	movzbq	147(%r11), %rax
	movq	$3664, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1035, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$612:
	movzbq	225(%r11), %rax
	movq	$3680, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1035, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$611:
	movzbq	303(%r11), %rax
	movq	$3696, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1035, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$610:
	movzbq	70(%r11), %rax
	movq	$3648, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1036, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$609:
	movzbq	148(%r11), %rax
	movq	$3664, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1036, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$608:
	movzbq	226(%r11), %rax
	movq	$3680, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1036, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$607:
	movzbq	304(%r11), %rax
	movq	$3696, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1036, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$606:
	movzbq	71(%r11), %rax
	movq	$3648, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1037, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$605:
	movzbq	149(%r11), %rax
	movq	$3664, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1037, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$604:
	movzbq	227(%r11), %rax
	movq	$3680, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1037, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$603:
	movzbq	305(%r11), %rax
	movq	$3696, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1037, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$602:
	movzbq	72(%r11), %rax
	movq	$3648, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1038, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$601:
	movzbq	150(%r11), %rax
	movq	$3664, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1038, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$600:
	movzbq	228(%r11), %rax
	movq	$3680, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1038, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$599:
	movzbq	306(%r11), %rax
	movq	$3696, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1038, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$598:
	movzbq	73(%r11), %rax
	movq	$3648, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1039, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$597:
	movzbq	151(%r11), %rax
	movq	$3664, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1039, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$596:
	movzbq	229(%r11), %rax
	movq	$3680, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1039, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$595:
	movzbq	307(%r11), %rax
	movq	$3696, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1039, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$594:
	movzbq	74(%r11), %rax
	movq	$3648, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1040, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$593:
	movzbq	152(%r11), %rax
	movq	$3664, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1040, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$592:
	movzbq	230(%r11), %rax
	movq	$3680, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1040, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$591:
	movzbq	308(%r11), %rax
	movq	$3696, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1040, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$590:
	movzbq	75(%r11), %rax
	movq	$3648, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1041, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$589:
	movzbq	153(%r11), %rax
	movq	$3664, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1041, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$588:
	movzbq	231(%r11), %rax
	movq	$3680, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1041, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$587:
	movzbq	309(%r11), %rax
	movq	$3696, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1041, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$586:
	movzbq	76(%r11), %rax
	movq	$3648, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1042, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$585:
	movzbq	154(%r11), %rax
	movq	$3664, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1042, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$584:
	movzbq	232(%r11), %rax
	movq	$3680, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1042, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$583:
	movzbq	310(%r11), %rax
	movq	$3696, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1042, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$582:
	movzbq	77(%r11), %rax
	movq	$3648, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1043, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$581:
	movzbq	155(%r11), %rax
	movq	$3664, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1043, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$580:
	movzbq	233(%r11), %rax
	movq	$3680, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1043, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$579:
	movzbq	311(%r11), %rax
	movq	$3696, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1043, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$578:
	movq	$58, %rdx
	jmp 	Lbitsliced_m_calculate_PS$572
Lbitsliced_m_calculate_PS$573:
	movzbq	(%r11,%rdx), %rax
	movq	$3712, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$577:
	movzbq	78(%r11,%rdx), %rax
	movq	$3728, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$576:
	movzbq	156(%r11,%rdx), %rax
	movq	$3744, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$575:
	movzbq	234(%r11,%rdx), %rax
	movq	$3760, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$574:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$572:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$573
	movzbq	60(%r11), %rax
	movq	$3712, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1044, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$571:
	movzbq	138(%r11), %rax
	movq	$3728, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1044, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$570:
	movzbq	216(%r11), %rax
	movq	$3744, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1044, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$569:
	movzbq	294(%r11), %rax
	movq	$3760, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1044, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$568:
	movzbq	61(%r11), %rax
	movq	$3712, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1045, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$567:
	movzbq	139(%r11), %rax
	movq	$3728, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1045, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$566:
	movzbq	217(%r11), %rax
	movq	$3744, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1045, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$565:
	movzbq	295(%r11), %rax
	movq	$3760, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1045, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$564:
	movzbq	62(%r11), %rax
	movq	$3712, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1046, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$563:
	movzbq	140(%r11), %rax
	movq	$3728, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1046, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$562:
	movzbq	218(%r11), %rax
	movq	$3744, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1046, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$561:
	movzbq	296(%r11), %rax
	movq	$3760, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1046, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$560:
	movzbq	63(%r11), %rax
	movq	$3712, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1047, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$559:
	movzbq	141(%r11), %rax
	movq	$3728, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1047, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$558:
	movzbq	219(%r11), %rax
	movq	$3744, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1047, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$557:
	movzbq	297(%r11), %rax
	movq	$3760, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1047, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$556:
	movzbq	64(%r11), %rax
	movq	$3712, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1048, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$555:
	movzbq	142(%r11), %rax
	movq	$3728, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1048, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$554:
	movzbq	220(%r11), %rax
	movq	$3744, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1048, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$553:
	movzbq	298(%r11), %rax
	movq	$3760, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1048, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$552:
	movzbq	65(%r11), %rax
	movq	$3712, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1049, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$551:
	movzbq	143(%r11), %rax
	movq	$3728, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1049, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$550:
	movzbq	221(%r11), %rax
	movq	$3744, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1049, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$549:
	movzbq	299(%r11), %rax
	movq	$3760, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1049, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$548:
	movzbq	66(%r11), %rax
	movq	$3712, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1050, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$547:
	movzbq	144(%r11), %rax
	movq	$3728, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1050, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$546:
	movzbq	222(%r11), %rax
	movq	$3744, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1050, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$545:
	movzbq	300(%r11), %rax
	movq	$3760, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1050, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$544:
	movzbq	67(%r11), %rax
	movq	$3712, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1051, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$543:
	movzbq	145(%r11), %rax
	movq	$3728, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1051, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$542:
	movzbq	223(%r11), %rax
	movq	$3744, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1051, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$541:
	movzbq	301(%r11), %rax
	movq	$3760, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1051, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$540:
	movzbq	68(%r11), %rax
	movq	$3712, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1052, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$539:
	movzbq	146(%r11), %rax
	movq	$3728, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1052, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$538:
	movzbq	224(%r11), %rax
	movq	$3744, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1052, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$537:
	movzbq	302(%r11), %rax
	movq	$3760, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1052, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$536:
	movzbq	69(%r11), %rax
	movq	$3712, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1053, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$535:
	movzbq	147(%r11), %rax
	movq	$3728, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1053, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$534:
	movzbq	225(%r11), %rax
	movq	$3744, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1053, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$533:
	movzbq	303(%r11), %rax
	movq	$3760, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1053, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$532:
	movzbq	70(%r11), %rax
	movq	$3712, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1054, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$531:
	movzbq	148(%r11), %rax
	movq	$3728, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1054, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$530:
	movzbq	226(%r11), %rax
	movq	$3744, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1054, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$529:
	movzbq	304(%r11), %rax
	movq	$3760, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1054, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$528:
	movzbq	71(%r11), %rax
	movq	$3712, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1055, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$527:
	movzbq	149(%r11), %rax
	movq	$3728, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1055, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$526:
	movzbq	227(%r11), %rax
	movq	$3744, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1055, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$525:
	movzbq	305(%r11), %rax
	movq	$3760, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1055, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$524:
	movzbq	72(%r11), %rax
	movq	$3712, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1056, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$523:
	movzbq	150(%r11), %rax
	movq	$3728, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1056, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$522:
	movzbq	228(%r11), %rax
	movq	$3744, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1056, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$521:
	movzbq	306(%r11), %rax
	movq	$3760, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1056, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$520:
	movzbq	73(%r11), %rax
	movq	$3712, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1057, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$519:
	movzbq	151(%r11), %rax
	movq	$3728, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1057, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$518:
	movzbq	229(%r11), %rax
	movq	$3744, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1057, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$517:
	movzbq	307(%r11), %rax
	movq	$3760, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1057, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$516:
	movzbq	74(%r11), %rax
	movq	$3712, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1058, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$515:
	movzbq	152(%r11), %rax
	movq	$3728, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1058, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$514:
	movzbq	230(%r11), %rax
	movq	$3744, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1058, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$513:
	movzbq	308(%r11), %rax
	movq	$3760, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1058, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$512:
	movzbq	75(%r11), %rax
	movq	$3712, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1059, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$511:
	movzbq	153(%r11), %rax
	movq	$3728, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1059, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$510:
	movzbq	231(%r11), %rax
	movq	$3744, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1059, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$509:
	movzbq	309(%r11), %rax
	movq	$3760, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1059, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$508:
	movzbq	76(%r11), %rax
	movq	$3712, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1060, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$507:
	movzbq	154(%r11), %rax
	movq	$3728, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1060, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$506:
	movzbq	232(%r11), %rax
	movq	$3744, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1060, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$505:
	movzbq	310(%r11), %rax
	movq	$3760, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1060, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$504:
	movzbq	77(%r11), %rax
	movq	$3712, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1061, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$503:
	movzbq	155(%r11), %rax
	movq	$3728, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1061, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$502:
	movzbq	233(%r11), %rax
	movq	$3744, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1061, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$501:
	movzbq	311(%r11), %rax
	movq	$3760, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1061, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$500:
	movq	$59, %rdx
	jmp 	Lbitsliced_m_calculate_PS$494
Lbitsliced_m_calculate_PS$495:
	movzbq	(%r11,%rdx), %rax
	movq	$3776, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$499:
	movzbq	78(%r11,%rdx), %rax
	movq	$3792, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$498:
	movzbq	156(%r11,%rdx), %rax
	movq	$3808, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$497:
	movzbq	234(%r11,%rdx), %rax
	movq	$3824, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	%r8, %rcx
	leaq	(,%rcx,8), %rsi
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice$1
Lbitsliced_m_calculate_PS$496:
	leaq	1(%r8), %r8
	leaq	1(%rdx), %rdx
Lbitsliced_m_calculate_PS$494:
	cmpq	$60, %rdx
	jb  	Lbitsliced_m_calculate_PS$495
	movzbq	60(%r11), %rax
	movq	$3776, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1062, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$493:
	movzbq	138(%r11), %rax
	movq	$3792, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1062, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$492:
	movzbq	216(%r11), %rax
	movq	$3808, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1062, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$491:
	movzbq	294(%r11), %rax
	movq	$3824, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1062, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$490:
	movzbq	61(%r11), %rax
	movq	$3776, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1063, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$489:
	movzbq	139(%r11), %rax
	movq	$3792, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1063, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$488:
	movzbq	217(%r11), %rax
	movq	$3808, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1063, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$487:
	movzbq	295(%r11), %rax
	movq	$3824, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1063, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$486:
	movzbq	62(%r11), %rax
	movq	$3776, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1064, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$485:
	movzbq	140(%r11), %rax
	movq	$3792, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1064, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$484:
	movzbq	218(%r11), %rax
	movq	$3808, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1064, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$483:
	movzbq	296(%r11), %rax
	movq	$3824, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1064, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$482:
	movzbq	63(%r11), %rax
	movq	$3776, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1065, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$481:
	movzbq	141(%r11), %rax
	movq	$3792, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1065, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$480:
	movzbq	219(%r11), %rax
	movq	$3808, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1065, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$479:
	movzbq	297(%r11), %rax
	movq	$3824, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1065, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$478:
	movzbq	64(%r11), %rax
	movq	$3776, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1066, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$477:
	movzbq	142(%r11), %rax
	movq	$3792, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1066, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$476:
	movzbq	220(%r11), %rax
	movq	$3808, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1066, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$475:
	movzbq	298(%r11), %rax
	movq	$3824, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1066, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$474:
	movzbq	65(%r11), %rax
	movq	$3776, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1067, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$473:
	movzbq	143(%r11), %rax
	movq	$3792, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1067, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$472:
	movzbq	221(%r11), %rax
	movq	$3808, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1067, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$471:
	movzbq	299(%r11), %rax
	movq	$3824, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1067, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$470:
	movzbq	66(%r11), %rax
	movq	$3776, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1068, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$469:
	movzbq	144(%r11), %rax
	movq	$3792, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1068, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$468:
	movzbq	222(%r11), %rax
	movq	$3808, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1068, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$467:
	movzbq	300(%r11), %rax
	movq	$3824, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1068, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$466:
	movzbq	67(%r11), %rax
	movq	$3776, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1069, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$465:
	movzbq	145(%r11), %rax
	movq	$3792, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1069, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$464:
	movzbq	223(%r11), %rax
	movq	$3808, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1069, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$463:
	movzbq	301(%r11), %rax
	movq	$3824, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1069, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$462:
	movzbq	68(%r11), %rax
	movq	$3776, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1070, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$461:
	movzbq	146(%r11), %rax
	movq	$3792, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1070, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$460:
	movzbq	224(%r11), %rax
	movq	$3808, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1070, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$459:
	movzbq	302(%r11), %rax
	movq	$3824, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1070, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$458:
	movzbq	69(%r11), %rax
	movq	$3776, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1071, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$457:
	movzbq	147(%r11), %rax
	movq	$3792, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1071, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$456:
	movzbq	225(%r11), %rax
	movq	$3808, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1071, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$455:
	movzbq	303(%r11), %rax
	movq	$3824, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1071, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$454:
	movzbq	70(%r11), %rax
	movq	$3776, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1072, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$453:
	movzbq	148(%r11), %rax
	movq	$3792, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1072, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$452:
	movzbq	226(%r11), %rax
	movq	$3808, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1072, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$451:
	movzbq	304(%r11), %rax
	movq	$3824, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1072, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$450:
	movzbq	71(%r11), %rax
	movq	$3776, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1073, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$449:
	movzbq	149(%r11), %rax
	movq	$3792, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1073, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$448:
	movzbq	227(%r11), %rax
	movq	$3808, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1073, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$447:
	movzbq	305(%r11), %rax
	movq	$3824, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1073, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$446:
	movzbq	72(%r11), %rax
	movq	$3776, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1074, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$445:
	movzbq	150(%r11), %rax
	movq	$3792, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1074, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$444:
	movzbq	228(%r11), %rax
	movq	$3808, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1074, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$443:
	movzbq	306(%r11), %rax
	movq	$3824, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1074, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$442:
	movzbq	73(%r11), %rax
	movq	$3776, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1075, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$441:
	movzbq	151(%r11), %rax
	movq	$3792, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1075, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$440:
	movzbq	229(%r11), %rax
	movq	$3808, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1075, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$439:
	movzbq	307(%r11), %rax
	movq	$3824, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1075, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$438:
	movzbq	74(%r11), %rax
	movq	$3776, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1076, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$437:
	movzbq	152(%r11), %rax
	movq	$3792, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1076, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$436:
	movzbq	230(%r11), %rax
	movq	$3808, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1076, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$435:
	movzbq	308(%r11), %rax
	movq	$3824, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1076, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$434:
	movzbq	75(%r11), %rax
	movq	$3776, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1077, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$433:
	movzbq	153(%r11), %rax
	movq	$3792, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1077, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$432:
	movzbq	231(%r11), %rax
	movq	$3808, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1077, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$431:
	movzbq	309(%r11), %rax
	movq	$3824, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1077, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$430:
	movzbq	76(%r11), %rax
	movq	$3776, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1078, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$429:
	movzbq	154(%r11), %rax
	movq	$3792, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1078, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$428:
	movzbq	232(%r11), %rax
	movq	$3808, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1078, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$427:
	movzbq	310(%r11), %rax
	movq	$3824, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1078, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$426:
	movzbq	77(%r11), %rax
	movq	$3776, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1079, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$425:
	movzbq	155(%r11), %rax
	movq	$3792, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1079, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$424:
	movzbq	233(%r11), %rax
	movq	$3808, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1079, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$423:
	movzbq	311(%r11), %rax
	movq	$3824, %rcx
	leaq	(%rcx,%rax), %rax
	leaq	(,%rax,8), %rax
	movq	$1079, %rcx
	leaq	(,%rcx,8), %rdx
	leaq	8(%rsp), %rcx
	call	Lbitsliced_m_vec_add_slice_p2$1
Lbitsliced_m_calculate_PS$422:
	movq	$0, %r8
	movq	$60, %rax
	jmp 	Lbitsliced_m_calculate_PS$416
Lbitsliced_m_calculate_PS$417:
	movzbq	(%r11,%rax), %rcx
	movq	$3840, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$421:
	movzbq	78(%r11,%rax), %rcx
	movq	$3856, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$420:
	movzbq	156(%r11,%rax), %rcx
	movq	$3872, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$419:
	movzbq	234(%r11,%rax), %rcx
	movq	$3888, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$418:
	leaq	1(%r8), %r8
	leaq	1(%rax), %rax
Lbitsliced_m_calculate_PS$416:
	cmpq	$78, %rax
	jb  	Lbitsliced_m_calculate_PS$417
	movq	$61, %rax
	jmp 	Lbitsliced_m_calculate_PS$410
Lbitsliced_m_calculate_PS$411:
	movzbq	(%r11,%rax), %rcx
	movq	$3904, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$415:
	movzbq	78(%r11,%rax), %rcx
	movq	$3920, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$414:
	movzbq	156(%r11,%rax), %rcx
	movq	$3936, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$413:
	movzbq	234(%r11,%rax), %rcx
	movq	$3952, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$412:
	leaq	1(%r8), %r8
	leaq	1(%rax), %rax
Lbitsliced_m_calculate_PS$410:
	cmpq	$78, %rax
	jb  	Lbitsliced_m_calculate_PS$411
	movq	$62, %rax
	jmp 	Lbitsliced_m_calculate_PS$404
Lbitsliced_m_calculate_PS$405:
	movzbq	(%r11,%rax), %rcx
	movq	$3968, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$409:
	movzbq	78(%r11,%rax), %rcx
	movq	$3984, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$408:
	movzbq	156(%r11,%rax), %rcx
	movq	$4000, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$407:
	movzbq	234(%r11,%rax), %rcx
	movq	$4016, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$406:
	leaq	1(%r8), %r8
	leaq	1(%rax), %rax
Lbitsliced_m_calculate_PS$404:
	cmpq	$78, %rax
	jb  	Lbitsliced_m_calculate_PS$405
	movq	$63, %rax
	jmp 	Lbitsliced_m_calculate_PS$398
Lbitsliced_m_calculate_PS$399:
	movzbq	(%r11,%rax), %rcx
	movq	$4032, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$403:
	movzbq	78(%r11,%rax), %rcx
	movq	$4048, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$402:
	movzbq	156(%r11,%rax), %rcx
	movq	$4064, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$401:
	movzbq	234(%r11,%rax), %rcx
	movq	$4080, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$400:
	leaq	1(%r8), %r8
	leaq	1(%rax), %rax
Lbitsliced_m_calculate_PS$398:
	cmpq	$78, %rax
	jb  	Lbitsliced_m_calculate_PS$399
	movq	$64, %rax
	jmp 	Lbitsliced_m_calculate_PS$392
Lbitsliced_m_calculate_PS$393:
	movzbq	(%r11,%rax), %rcx
	movq	$4096, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$397:
	movzbq	78(%r11,%rax), %rcx
	movq	$4112, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$396:
	movzbq	156(%r11,%rax), %rcx
	movq	$4128, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$395:
	movzbq	234(%r11,%rax), %rcx
	movq	$4144, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$394:
	leaq	1(%r8), %r8
	leaq	1(%rax), %rax
Lbitsliced_m_calculate_PS$392:
	cmpq	$78, %rax
	jb  	Lbitsliced_m_calculate_PS$393
	movq	$65, %rax
	jmp 	Lbitsliced_m_calculate_PS$386
Lbitsliced_m_calculate_PS$387:
	movzbq	(%r11,%rax), %rcx
	movq	$4160, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$391:
	movzbq	78(%r11,%rax), %rcx
	movq	$4176, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$390:
	movzbq	156(%r11,%rax), %rcx
	movq	$4192, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$389:
	movzbq	234(%r11,%rax), %rcx
	movq	$4208, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$388:
	leaq	1(%r8), %r8
	leaq	1(%rax), %rax
Lbitsliced_m_calculate_PS$386:
	cmpq	$78, %rax
	jb  	Lbitsliced_m_calculate_PS$387
	movq	$66, %rax
	jmp 	Lbitsliced_m_calculate_PS$380
Lbitsliced_m_calculate_PS$381:
	movzbq	(%r11,%rax), %rcx
	movq	$4224, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$385:
	movzbq	78(%r11,%rax), %rcx
	movq	$4240, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$384:
	movzbq	156(%r11,%rax), %rcx
	movq	$4256, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$383:
	movzbq	234(%r11,%rax), %rcx
	movq	$4272, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$382:
	leaq	1(%r8), %r8
	leaq	1(%rax), %rax
Lbitsliced_m_calculate_PS$380:
	cmpq	$78, %rax
	jb  	Lbitsliced_m_calculate_PS$381
	movq	$67, %rax
	jmp 	Lbitsliced_m_calculate_PS$374
Lbitsliced_m_calculate_PS$375:
	movzbq	(%r11,%rax), %rcx
	movq	$4288, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$379:
	movzbq	78(%r11,%rax), %rcx
	movq	$4304, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$378:
	movzbq	156(%r11,%rax), %rcx
	movq	$4320, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$377:
	movzbq	234(%r11,%rax), %rcx
	movq	$4336, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$376:
	leaq	1(%r8), %r8
	leaq	1(%rax), %rax
Lbitsliced_m_calculate_PS$374:
	cmpq	$78, %rax
	jb  	Lbitsliced_m_calculate_PS$375
	movq	$68, %rax
	jmp 	Lbitsliced_m_calculate_PS$368
Lbitsliced_m_calculate_PS$369:
	movzbq	(%r11,%rax), %rcx
	movq	$4352, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$373:
	movzbq	78(%r11,%rax), %rcx
	movq	$4368, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$372:
	movzbq	156(%r11,%rax), %rcx
	movq	$4384, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$371:
	movzbq	234(%r11,%rax), %rcx
	movq	$4400, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$370:
	leaq	1(%r8), %r8
	leaq	1(%rax), %rax
Lbitsliced_m_calculate_PS$368:
	cmpq	$78, %rax
	jb  	Lbitsliced_m_calculate_PS$369
	movq	$69, %rax
	jmp 	Lbitsliced_m_calculate_PS$362
Lbitsliced_m_calculate_PS$363:
	movzbq	(%r11,%rax), %rcx
	movq	$4416, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$367:
	movzbq	78(%r11,%rax), %rcx
	movq	$4432, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$366:
	movzbq	156(%r11,%rax), %rcx
	movq	$4448, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$365:
	movzbq	234(%r11,%rax), %rcx
	movq	$4464, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$364:
	leaq	1(%r8), %r8
	leaq	1(%rax), %rax
Lbitsliced_m_calculate_PS$362:
	cmpq	$78, %rax
	jb  	Lbitsliced_m_calculate_PS$363
	movq	$70, %rax
	jmp 	Lbitsliced_m_calculate_PS$356
Lbitsliced_m_calculate_PS$357:
	movzbq	(%r11,%rax), %rcx
	movq	$4480, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$361:
	movzbq	78(%r11,%rax), %rcx
	movq	$4496, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$360:
	movzbq	156(%r11,%rax), %rcx
	movq	$4512, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$359:
	movzbq	234(%r11,%rax), %rcx
	movq	$4528, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$358:
	leaq	1(%r8), %r8
	leaq	1(%rax), %rax
Lbitsliced_m_calculate_PS$356:
	cmpq	$78, %rax
	jb  	Lbitsliced_m_calculate_PS$357
	movq	$71, %rax
	jmp 	Lbitsliced_m_calculate_PS$350
Lbitsliced_m_calculate_PS$351:
	movzbq	(%r11,%rax), %rcx
	movq	$4544, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$355:
	movzbq	78(%r11,%rax), %rcx
	movq	$4560, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$354:
	movzbq	156(%r11,%rax), %rcx
	movq	$4576, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$353:
	movzbq	234(%r11,%rax), %rcx
	movq	$4592, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$352:
	leaq	1(%r8), %r8
	leaq	1(%rax), %rax
Lbitsliced_m_calculate_PS$350:
	cmpq	$78, %rax
	jb  	Lbitsliced_m_calculate_PS$351
	movq	$72, %rax
	jmp 	Lbitsliced_m_calculate_PS$344
Lbitsliced_m_calculate_PS$345:
	movzbq	(%r11,%rax), %rcx
	movq	$4608, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$349:
	movzbq	78(%r11,%rax), %rcx
	movq	$4624, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$348:
	movzbq	156(%r11,%rax), %rcx
	movq	$4640, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$347:
	movzbq	234(%r11,%rax), %rcx
	movq	$4656, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$346:
	leaq	1(%r8), %r8
	leaq	1(%rax), %rax
Lbitsliced_m_calculate_PS$344:
	cmpq	$78, %rax
	jb  	Lbitsliced_m_calculate_PS$345
	movq	$73, %rax
	jmp 	Lbitsliced_m_calculate_PS$338
Lbitsliced_m_calculate_PS$339:
	movzbq	(%r11,%rax), %rcx
	movq	$4672, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$343:
	movzbq	78(%r11,%rax), %rcx
	movq	$4688, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$342:
	movzbq	156(%r11,%rax), %rcx
	movq	$4704, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$341:
	movzbq	234(%r11,%rax), %rcx
	movq	$4720, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$340:
	leaq	1(%r8), %r8
	leaq	1(%rax), %rax
Lbitsliced_m_calculate_PS$338:
	cmpq	$78, %rax
	jb  	Lbitsliced_m_calculate_PS$339
	movq	$74, %rax
	jmp 	Lbitsliced_m_calculate_PS$332
Lbitsliced_m_calculate_PS$333:
	movzbq	(%r11,%rax), %rcx
	movq	$4736, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$337:
	movzbq	78(%r11,%rax), %rcx
	movq	$4752, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$336:
	movzbq	156(%r11,%rax), %rcx
	movq	$4768, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$335:
	movzbq	234(%r11,%rax), %rcx
	movq	$4784, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$334:
	leaq	1(%r8), %r8
	leaq	1(%rax), %rax
Lbitsliced_m_calculate_PS$332:
	cmpq	$78, %rax
	jb  	Lbitsliced_m_calculate_PS$333
	movq	$75, %rax
	jmp 	Lbitsliced_m_calculate_PS$326
Lbitsliced_m_calculate_PS$327:
	movzbq	(%r11,%rax), %rcx
	movq	$4800, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$331:
	movzbq	78(%r11,%rax), %rcx
	movq	$4816, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$330:
	movzbq	156(%r11,%rax), %rcx
	movq	$4832, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$329:
	movzbq	234(%r11,%rax), %rcx
	movq	$4848, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$328:
	leaq	1(%r8), %r8
	leaq	1(%rax), %rax
Lbitsliced_m_calculate_PS$326:
	cmpq	$78, %rax
	jb  	Lbitsliced_m_calculate_PS$327
	movq	$76, %rax
	jmp 	Lbitsliced_m_calculate_PS$320
Lbitsliced_m_calculate_PS$321:
	movzbq	(%r11,%rax), %rcx
	movq	$4864, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$325:
	movzbq	78(%r11,%rax), %rcx
	movq	$4880, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$324:
	movzbq	156(%r11,%rax), %rcx
	movq	$4896, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$323:
	movzbq	234(%r11,%rax), %rcx
	movq	$4912, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$322:
	leaq	1(%r8), %r8
	leaq	1(%rax), %rax
Lbitsliced_m_calculate_PS$320:
	cmpq	$78, %rax
	jb  	Lbitsliced_m_calculate_PS$321
	movq	$77, %rax
	jmp 	Lbitsliced_m_calculate_PS$314
Lbitsliced_m_calculate_PS$315:
	movzbq	(%r11,%rax), %rcx
	movq	$4928, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$319:
	movzbq	78(%r11,%rax), %rcx
	movq	$4944, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$318:
	movzbq	156(%r11,%rax), %rcx
	movq	$4960, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$317:
	movzbq	234(%r11,%rax), %rcx
	movq	$4976, %rdx
	leaq	(%rdx,%rcx), %rcx
	leaq	(,%rcx,8), %rcx
	movq	%r8, %rdx
	leaq	(,%rdx,8), %rdx
	leaq	8(%rsp), %rdi
	call	Lbitsliced_m_vec_add_slice_p3$1
Lbitsliced_m_calculate_PS$316:
	leaq	1(%r8), %r8
	leaq	1(%rax), %rax
Lbitsliced_m_calculate_PS$314:
	cmpq	$78, %rax
	jb  	Lbitsliced_m_calculate_PS$315
	leaq	8(%rsp), %rax
	movq	%rbp, %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$313:
	leaq	512(%rsp), %rsp
	leaq	520(%rsp), %rax
	leaq	32(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$312:
	leaq	512(%rsp), %rsp
	leaq	1032(%rsp), %rax
	leaq	64(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$311:
	leaq	512(%rsp), %rsp
	leaq	1544(%rsp), %rax
	leaq	96(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$310:
	leaq	512(%rsp), %rsp
	leaq	2056(%rsp), %rax
	leaq	128(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$309:
	leaq	512(%rsp), %rsp
	leaq	2568(%rsp), %rax
	leaq	160(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$308:
	leaq	512(%rsp), %rsp
	leaq	3080(%rsp), %rax
	leaq	192(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$307:
	leaq	512(%rsp), %rsp
	leaq	3592(%rsp), %rax
	leaq	224(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$306:
	leaq	512(%rsp), %rsp
	leaq	4104(%rsp), %rax
	leaq	256(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$305:
	leaq	512(%rsp), %rsp
	leaq	4616(%rsp), %rax
	leaq	288(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$304:
	leaq	512(%rsp), %rsp
	leaq	5128(%rsp), %rax
	leaq	320(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$303:
	leaq	512(%rsp), %rsp
	leaq	5640(%rsp), %rax
	leaq	352(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$302:
	leaq	512(%rsp), %rsp
	leaq	6152(%rsp), %rax
	leaq	384(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$301:
	leaq	512(%rsp), %rsp
	leaq	6664(%rsp), %rax
	leaq	416(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$300:
	leaq	512(%rsp), %rsp
	leaq	7176(%rsp), %rax
	leaq	448(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$299:
	leaq	512(%rsp), %rsp
	leaq	7688(%rsp), %rax
	leaq	480(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$298:
	leaq	512(%rsp), %rsp
	leaq	8200(%rsp), %rax
	leaq	512(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$297:
	leaq	512(%rsp), %rsp
	leaq	8712(%rsp), %rax
	leaq	544(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$296:
	leaq	512(%rsp), %rsp
	leaq	9224(%rsp), %rax
	leaq	576(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$295:
	leaq	512(%rsp), %rsp
	leaq	9736(%rsp), %rax
	leaq	608(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$294:
	leaq	512(%rsp), %rsp
	leaq	10248(%rsp), %rax
	leaq	640(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$293:
	leaq	512(%rsp), %rsp
	leaq	10760(%rsp), %rax
	leaq	672(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$292:
	leaq	512(%rsp), %rsp
	leaq	11272(%rsp), %rax
	leaq	704(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$291:
	leaq	512(%rsp), %rsp
	leaq	11784(%rsp), %rax
	leaq	736(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$290:
	leaq	512(%rsp), %rsp
	leaq	12296(%rsp), %rax
	leaq	768(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$289:
	leaq	512(%rsp), %rsp
	leaq	12808(%rsp), %rax
	leaq	800(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$288:
	leaq	512(%rsp), %rsp
	leaq	13320(%rsp), %rax
	leaq	832(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$287:
	leaq	512(%rsp), %rsp
	leaq	13832(%rsp), %rax
	leaq	864(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$286:
	leaq	512(%rsp), %rsp
	leaq	14344(%rsp), %rax
	leaq	896(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$285:
	leaq	512(%rsp), %rsp
	leaq	14856(%rsp), %rax
	leaq	928(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$284:
	leaq	512(%rsp), %rsp
	leaq	15368(%rsp), %rax
	leaq	960(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$283:
	leaq	512(%rsp), %rsp
	leaq	15880(%rsp), %rax
	leaq	992(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$282:
	leaq	512(%rsp), %rsp
	leaq	16392(%rsp), %rax
	leaq	1024(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$281:
	leaq	512(%rsp), %rsp
	leaq	16904(%rsp), %rax
	leaq	1056(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$280:
	leaq	512(%rsp), %rsp
	leaq	17416(%rsp), %rax
	leaq	1088(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$279:
	leaq	512(%rsp), %rsp
	leaq	17928(%rsp), %rax
	leaq	1120(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$278:
	leaq	512(%rsp), %rsp
	leaq	18440(%rsp), %rax
	leaq	1152(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$277:
	leaq	512(%rsp), %rsp
	leaq	18952(%rsp), %rax
	leaq	1184(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$276:
	leaq	512(%rsp), %rsp
	leaq	19464(%rsp), %rax
	leaq	1216(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$275:
	leaq	512(%rsp), %rsp
	leaq	19976(%rsp), %rax
	leaq	1248(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$274:
	leaq	512(%rsp), %rsp
	leaq	20488(%rsp), %rax
	leaq	1280(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$273:
	leaq	512(%rsp), %rsp
	leaq	21000(%rsp), %rax
	leaq	1312(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$272:
	leaq	512(%rsp), %rsp
	leaq	21512(%rsp), %rax
	leaq	1344(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$271:
	leaq	512(%rsp), %rsp
	leaq	22024(%rsp), %rax
	leaq	1376(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$270:
	leaq	512(%rsp), %rsp
	leaq	22536(%rsp), %rax
	leaq	1408(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$269:
	leaq	512(%rsp), %rsp
	leaq	23048(%rsp), %rax
	leaq	1440(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$268:
	leaq	512(%rsp), %rsp
	leaq	23560(%rsp), %rax
	leaq	1472(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$267:
	leaq	512(%rsp), %rsp
	leaq	24072(%rsp), %rax
	leaq	1504(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$266:
	leaq	512(%rsp), %rsp
	leaq	24584(%rsp), %rax
	leaq	1536(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$265:
	leaq	512(%rsp), %rsp
	leaq	25096(%rsp), %rax
	leaq	1568(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$264:
	leaq	512(%rsp), %rsp
	leaq	25608(%rsp), %rax
	leaq	1600(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$263:
	leaq	512(%rsp), %rsp
	leaq	26120(%rsp), %rax
	leaq	1632(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$262:
	leaq	512(%rsp), %rsp
	leaq	26632(%rsp), %rax
	leaq	1664(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$261:
	leaq	512(%rsp), %rsp
	leaq	27144(%rsp), %rax
	leaq	1696(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$260:
	leaq	512(%rsp), %rsp
	leaq	27656(%rsp), %rax
	leaq	1728(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$259:
	leaq	512(%rsp), %rsp
	leaq	28168(%rsp), %rax
	leaq	1760(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$258:
	leaq	512(%rsp), %rsp
	leaq	28680(%rsp), %rax
	leaq	1792(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$257:
	leaq	512(%rsp), %rsp
	leaq	29192(%rsp), %rax
	leaq	1824(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$256:
	leaq	512(%rsp), %rsp
	leaq	29704(%rsp), %rax
	leaq	1856(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$255:
	leaq	512(%rsp), %rsp
	leaq	30216(%rsp), %rax
	leaq	1888(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$254:
	leaq	512(%rsp), %rsp
	leaq	30728(%rsp), %rax
	leaq	1920(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$253:
	leaq	512(%rsp), %rsp
	leaq	31240(%rsp), %rax
	leaq	1952(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$252:
	leaq	512(%rsp), %rsp
	leaq	31752(%rsp), %rax
	leaq	1984(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$251:
	leaq	512(%rsp), %rsp
	leaq	32264(%rsp), %rax
	leaq	2016(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$250:
	leaq	512(%rsp), %rsp
	leaq	32776(%rsp), %rax
	leaq	2048(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$249:
	leaq	512(%rsp), %rsp
	leaq	33288(%rsp), %rax
	leaq	2080(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$248:
	leaq	512(%rsp), %rsp
	leaq	33800(%rsp), %rax
	leaq	2112(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$247:
	leaq	512(%rsp), %rsp
	leaq	34312(%rsp), %rax
	leaq	2144(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$246:
	leaq	512(%rsp), %rsp
	leaq	34824(%rsp), %rax
	leaq	2176(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$245:
	leaq	512(%rsp), %rsp
	leaq	35336(%rsp), %rax
	leaq	2208(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$244:
	leaq	512(%rsp), %rsp
	leaq	35848(%rsp), %rax
	leaq	2240(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$243:
	leaq	512(%rsp), %rsp
	leaq	36360(%rsp), %rax
	leaq	2272(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$242:
	leaq	512(%rsp), %rsp
	leaq	36872(%rsp), %rax
	leaq	2304(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$241:
	leaq	512(%rsp), %rsp
	leaq	37384(%rsp), %rax
	leaq	2336(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$240:
	leaq	512(%rsp), %rsp
	leaq	37896(%rsp), %rax
	leaq	2368(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$239:
	leaq	512(%rsp), %rsp
	leaq	38408(%rsp), %rax
	leaq	2400(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$238:
	leaq	512(%rsp), %rsp
	leaq	38920(%rsp), %rax
	leaq	2432(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$237:
	leaq	512(%rsp), %rsp
	leaq	39432(%rsp), %rax
	leaq	2464(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$236:
	leaq	512(%rsp), %rsp
	leaq	39944(%rsp), %rax
	leaq	2496(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$235:
	leaq	512(%rsp), %rsp
	leaq	40456(%rsp), %rax
	leaq	2528(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$234:
	leaq	512(%rsp), %rsp
	leaq	40968(%rsp), %rax
	leaq	2560(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$233:
	leaq	512(%rsp), %rsp
	leaq	41480(%rsp), %rax
	leaq	2592(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$232:
	leaq	512(%rsp), %rsp
	leaq	41992(%rsp), %rax
	leaq	2624(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$231:
	leaq	512(%rsp), %rsp
	leaq	42504(%rsp), %rax
	leaq	2656(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$230:
	leaq	512(%rsp), %rsp
	leaq	43016(%rsp), %rax
	leaq	2688(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$229:
	leaq	512(%rsp), %rsp
	leaq	43528(%rsp), %rax
	leaq	2720(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$228:
	leaq	512(%rsp), %rsp
	leaq	44040(%rsp), %rax
	leaq	2752(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$227:
	leaq	512(%rsp), %rsp
	leaq	44552(%rsp), %rax
	leaq	2784(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$226:
	leaq	512(%rsp), %rsp
	leaq	45064(%rsp), %rax
	leaq	2816(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$225:
	leaq	512(%rsp), %rsp
	leaq	45576(%rsp), %rax
	leaq	2848(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$224:
	leaq	512(%rsp), %rsp
	leaq	46088(%rsp), %rax
	leaq	2880(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$223:
	leaq	512(%rsp), %rsp
	leaq	46600(%rsp), %rax
	leaq	2912(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$222:
	leaq	512(%rsp), %rsp
	leaq	47112(%rsp), %rax
	leaq	2944(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$221:
	leaq	512(%rsp), %rsp
	leaq	47624(%rsp), %rax
	leaq	2976(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$220:
	leaq	512(%rsp), %rsp
	leaq	48136(%rsp), %rax
	leaq	3008(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$219:
	leaq	512(%rsp), %rsp
	leaq	48648(%rsp), %rax
	leaq	3040(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$218:
	leaq	512(%rsp), %rsp
	leaq	49160(%rsp), %rax
	leaq	3072(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$217:
	leaq	512(%rsp), %rsp
	leaq	49672(%rsp), %rax
	leaq	3104(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$216:
	leaq	512(%rsp), %rsp
	leaq	50184(%rsp), %rax
	leaq	3136(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$215:
	leaq	512(%rsp), %rsp
	leaq	50696(%rsp), %rax
	leaq	3168(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$214:
	leaq	512(%rsp), %rsp
	leaq	51208(%rsp), %rax
	leaq	3200(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$213:
	leaq	512(%rsp), %rsp
	leaq	51720(%rsp), %rax
	leaq	3232(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$212:
	leaq	512(%rsp), %rsp
	leaq	52232(%rsp), %rax
	leaq	3264(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$211:
	leaq	512(%rsp), %rsp
	leaq	52744(%rsp), %rax
	leaq	3296(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$210:
	leaq	512(%rsp), %rsp
	leaq	53256(%rsp), %rax
	leaq	3328(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$209:
	leaq	512(%rsp), %rsp
	leaq	53768(%rsp), %rax
	leaq	3360(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$208:
	leaq	512(%rsp), %rsp
	leaq	54280(%rsp), %rax
	leaq	3392(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$207:
	leaq	512(%rsp), %rsp
	leaq	54792(%rsp), %rax
	leaq	3424(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$206:
	leaq	512(%rsp), %rsp
	leaq	55304(%rsp), %rax
	leaq	3456(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$205:
	leaq	512(%rsp), %rsp
	leaq	55816(%rsp), %rax
	leaq	3488(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$204:
	leaq	512(%rsp), %rsp
	leaq	56328(%rsp), %rax
	leaq	3520(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$203:
	leaq	512(%rsp), %rsp
	leaq	56840(%rsp), %rax
	leaq	3552(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$202:
	leaq	512(%rsp), %rsp
	leaq	57352(%rsp), %rax
	leaq	3584(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$201:
	leaq	512(%rsp), %rsp
	leaq	57864(%rsp), %rax
	leaq	3616(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$200:
	leaq	512(%rsp), %rsp
	leaq	58376(%rsp), %rax
	leaq	3648(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$199:
	leaq	512(%rsp), %rsp
	leaq	58888(%rsp), %rax
	leaq	3680(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$198:
	leaq	512(%rsp), %rsp
	leaq	59400(%rsp), %rax
	leaq	3712(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$197:
	leaq	512(%rsp), %rsp
	leaq	59912(%rsp), %rax
	leaq	3744(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$196:
	leaq	512(%rsp), %rsp
	leaq	60424(%rsp), %rax
	leaq	3776(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$195:
	leaq	512(%rsp), %rsp
	leaq	60936(%rsp), %rax
	leaq	3808(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$194:
	leaq	512(%rsp), %rsp
	leaq	61448(%rsp), %rax
	leaq	3840(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$193:
	leaq	512(%rsp), %rsp
	leaq	61960(%rsp), %rax
	leaq	3872(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$192:
	leaq	512(%rsp), %rsp
	leaq	62472(%rsp), %rax
	leaq	3904(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$191:
	leaq	512(%rsp), %rsp
	leaq	62984(%rsp), %rax
	leaq	3936(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$190:
	leaq	512(%rsp), %rsp
	leaq	63496(%rsp), %rax
	leaq	3968(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$189:
	leaq	512(%rsp), %rsp
	leaq	64008(%rsp), %rax
	leaq	4000(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$188:
	leaq	512(%rsp), %rsp
	leaq	64520(%rsp), %rax
	leaq	4032(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$187:
	leaq	512(%rsp), %rsp
	leaq	65032(%rsp), %rax
	leaq	4064(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$186:
	leaq	512(%rsp), %rsp
	leaq	65544(%rsp), %rax
	leaq	4096(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$185:
	leaq	512(%rsp), %rsp
	leaq	66056(%rsp), %rax
	leaq	4128(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$184:
	leaq	512(%rsp), %rsp
	leaq	66568(%rsp), %rax
	leaq	4160(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$183:
	leaq	512(%rsp), %rsp
	leaq	67080(%rsp), %rax
	leaq	4192(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$182:
	leaq	512(%rsp), %rsp
	leaq	67592(%rsp), %rax
	leaq	4224(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$181:
	leaq	512(%rsp), %rsp
	leaq	68104(%rsp), %rax
	leaq	4256(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$180:
	leaq	512(%rsp), %rsp
	leaq	68616(%rsp), %rax
	leaq	4288(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$179:
	leaq	512(%rsp), %rsp
	leaq	69128(%rsp), %rax
	leaq	4320(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$178:
	leaq	512(%rsp), %rsp
	leaq	69640(%rsp), %rax
	leaq	4352(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$177:
	leaq	512(%rsp), %rsp
	leaq	70152(%rsp), %rax
	leaq	4384(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$176:
	leaq	512(%rsp), %rsp
	leaq	70664(%rsp), %rax
	leaq	4416(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$175:
	leaq	512(%rsp), %rsp
	leaq	71176(%rsp), %rax
	leaq	4448(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$174:
	leaq	512(%rsp), %rsp
	leaq	71688(%rsp), %rax
	leaq	4480(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$173:
	leaq	512(%rsp), %rsp
	leaq	72200(%rsp), %rax
	leaq	4512(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$172:
	leaq	512(%rsp), %rsp
	leaq	72712(%rsp), %rax
	leaq	4544(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$171:
	leaq	512(%rsp), %rsp
	leaq	73224(%rsp), %rax
	leaq	4576(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$170:
	leaq	512(%rsp), %rsp
	leaq	73736(%rsp), %rax
	leaq	4608(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$169:
	leaq	512(%rsp), %rsp
	leaq	74248(%rsp), %rax
	leaq	4640(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$168:
	leaq	512(%rsp), %rsp
	leaq	74760(%rsp), %rax
	leaq	4672(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$167:
	leaq	512(%rsp), %rsp
	leaq	75272(%rsp), %rax
	leaq	4704(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$166:
	leaq	512(%rsp), %rsp
	leaq	75784(%rsp), %rax
	leaq	4736(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$165:
	leaq	512(%rsp), %rsp
	leaq	76296(%rsp), %rax
	leaq	4768(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$164:
	leaq	512(%rsp), %rsp
	leaq	76808(%rsp), %rax
	leaq	4800(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$163:
	leaq	512(%rsp), %rsp
	leaq	77320(%rsp), %rax
	leaq	4832(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$162:
	leaq	512(%rsp), %rsp
	leaq	77832(%rsp), %rax
	leaq	4864(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$161:
	leaq	512(%rsp), %rsp
	leaq	78344(%rsp), %rax
	leaq	4896(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$160:
	leaq	512(%rsp), %rsp
	leaq	78856(%rsp), %rax
	leaq	4928(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$159:
	leaq	512(%rsp), %rsp
	leaq	79368(%rsp), %rax
	leaq	4960(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$158:
	leaq	512(%rsp), %rsp
	leaq	79880(%rsp), %rax
	leaq	4992(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$157:
	leaq	512(%rsp), %rsp
	leaq	80392(%rsp), %rax
	leaq	5024(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$156:
	leaq	512(%rsp), %rsp
	leaq	80904(%rsp), %rax
	leaq	5056(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$155:
	leaq	512(%rsp), %rsp
	leaq	81416(%rsp), %rax
	leaq	5088(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$154:
	leaq	512(%rsp), %rsp
	leaq	81928(%rsp), %rax
	leaq	5120(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$153:
	leaq	512(%rsp), %rsp
	leaq	82440(%rsp), %rax
	leaq	5152(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$152:
	leaq	512(%rsp), %rsp
	leaq	82952(%rsp), %rax
	leaq	5184(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$151:
	leaq	512(%rsp), %rsp
	leaq	83464(%rsp), %rax
	leaq	5216(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$150:
	leaq	512(%rsp), %rsp
	leaq	83976(%rsp), %rax
	leaq	5248(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$149:
	leaq	512(%rsp), %rsp
	leaq	84488(%rsp), %rax
	leaq	5280(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$148:
	leaq	512(%rsp), %rsp
	leaq	85000(%rsp), %rax
	leaq	5312(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$147:
	leaq	512(%rsp), %rsp
	leaq	85512(%rsp), %rax
	leaq	5344(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$146:
	leaq	512(%rsp), %rsp
	leaq	86024(%rsp), %rax
	leaq	5376(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$145:
	leaq	512(%rsp), %rsp
	leaq	86536(%rsp), %rax
	leaq	5408(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$144:
	leaq	512(%rsp), %rsp
	leaq	87048(%rsp), %rax
	leaq	5440(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$143:
	leaq	512(%rsp), %rsp
	leaq	87560(%rsp), %rax
	leaq	5472(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$142:
	leaq	512(%rsp), %rsp
	leaq	88072(%rsp), %rax
	leaq	5504(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$141:
	leaq	512(%rsp), %rsp
	leaq	88584(%rsp), %rax
	leaq	5536(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$140:
	leaq	512(%rsp), %rsp
	leaq	89096(%rsp), %rax
	leaq	5568(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$139:
	leaq	512(%rsp), %rsp
	leaq	89608(%rsp), %rax
	leaq	5600(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$138:
	leaq	512(%rsp), %rsp
	leaq	90120(%rsp), %rax
	leaq	5632(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$137:
	leaq	512(%rsp), %rsp
	leaq	90632(%rsp), %rax
	leaq	5664(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$136:
	leaq	512(%rsp), %rsp
	leaq	91144(%rsp), %rax
	leaq	5696(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$135:
	leaq	512(%rsp), %rsp
	leaq	91656(%rsp), %rax
	leaq	5728(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$134:
	leaq	512(%rsp), %rsp
	leaq	92168(%rsp), %rax
	leaq	5760(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$133:
	leaq	512(%rsp), %rsp
	leaq	92680(%rsp), %rax
	leaq	5792(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$132:
	leaq	512(%rsp), %rsp
	leaq	93192(%rsp), %rax
	leaq	5824(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$131:
	leaq	512(%rsp), %rsp
	leaq	93704(%rsp), %rax
	leaq	5856(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$130:
	leaq	512(%rsp), %rsp
	leaq	94216(%rsp), %rax
	leaq	5888(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$129:
	leaq	512(%rsp), %rsp
	leaq	94728(%rsp), %rax
	leaq	5920(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$128:
	leaq	512(%rsp), %rsp
	leaq	95240(%rsp), %rax
	leaq	5952(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$127:
	leaq	512(%rsp), %rsp
	leaq	95752(%rsp), %rax
	leaq	5984(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$126:
	leaq	512(%rsp), %rsp
	leaq	96264(%rsp), %rax
	leaq	6016(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$125:
	leaq	512(%rsp), %rsp
	leaq	96776(%rsp), %rax
	leaq	6048(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$124:
	leaq	512(%rsp), %rsp
	leaq	97288(%rsp), %rax
	leaq	6080(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$123:
	leaq	512(%rsp), %rsp
	leaq	97800(%rsp), %rax
	leaq	6112(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$122:
	leaq	512(%rsp), %rsp
	leaq	98312(%rsp), %rax
	leaq	6144(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$121:
	leaq	512(%rsp), %rsp
	leaq	98824(%rsp), %rax
	leaq	6176(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$120:
	leaq	512(%rsp), %rsp
	leaq	99336(%rsp), %rax
	leaq	6208(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$119:
	leaq	512(%rsp), %rsp
	leaq	99848(%rsp), %rax
	leaq	6240(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$118:
	leaq	512(%rsp), %rsp
	leaq	100360(%rsp), %rax
	leaq	6272(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$117:
	leaq	512(%rsp), %rsp
	leaq	100872(%rsp), %rax
	leaq	6304(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$116:
	leaq	512(%rsp), %rsp
	leaq	101384(%rsp), %rax
	leaq	6336(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$115:
	leaq	512(%rsp), %rsp
	leaq	101896(%rsp), %rax
	leaq	6368(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$114:
	leaq	512(%rsp), %rsp
	leaq	102408(%rsp), %rax
	leaq	6400(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$113:
	leaq	512(%rsp), %rsp
	leaq	102920(%rsp), %rax
	leaq	6432(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$112:
	leaq	512(%rsp), %rsp
	leaq	103432(%rsp), %rax
	leaq	6464(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$111:
	leaq	512(%rsp), %rsp
	leaq	103944(%rsp), %rax
	leaq	6496(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$110:
	leaq	512(%rsp), %rsp
	leaq	104456(%rsp), %rax
	leaq	6528(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$109:
	leaq	512(%rsp), %rsp
	leaq	104968(%rsp), %rax
	leaq	6560(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$108:
	leaq	512(%rsp), %rsp
	leaq	105480(%rsp), %rax
	leaq	6592(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$107:
	leaq	512(%rsp), %rsp
	leaq	105992(%rsp), %rax
	leaq	6624(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$106:
	leaq	512(%rsp), %rsp
	leaq	106504(%rsp), %rax
	leaq	6656(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$105:
	leaq	512(%rsp), %rsp
	leaq	107016(%rsp), %rax
	leaq	6688(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$104:
	leaq	512(%rsp), %rsp
	leaq	107528(%rsp), %rax
	leaq	6720(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$103:
	leaq	512(%rsp), %rsp
	leaq	108040(%rsp), %rax
	leaq	6752(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$102:
	leaq	512(%rsp), %rsp
	leaq	108552(%rsp), %rax
	leaq	6784(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$101:
	leaq	512(%rsp), %rsp
	leaq	109064(%rsp), %rax
	leaq	6816(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$100:
	leaq	512(%rsp), %rsp
	leaq	109576(%rsp), %rax
	leaq	6848(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$99:
	leaq	512(%rsp), %rsp
	leaq	110088(%rsp), %rax
	leaq	6880(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$98:
	leaq	512(%rsp), %rsp
	leaq	110600(%rsp), %rax
	leaq	6912(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$97:
	leaq	512(%rsp), %rsp
	leaq	111112(%rsp), %rax
	leaq	6944(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$96:
	leaq	512(%rsp), %rsp
	leaq	111624(%rsp), %rax
	leaq	6976(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$95:
	leaq	512(%rsp), %rsp
	leaq	112136(%rsp), %rax
	leaq	7008(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$94:
	leaq	512(%rsp), %rsp
	leaq	112648(%rsp), %rax
	leaq	7040(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$93:
	leaq	512(%rsp), %rsp
	leaq	113160(%rsp), %rax
	leaq	7072(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$92:
	leaq	512(%rsp), %rsp
	leaq	113672(%rsp), %rax
	leaq	7104(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$91:
	leaq	512(%rsp), %rsp
	leaq	114184(%rsp), %rax
	leaq	7136(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$90:
	leaq	512(%rsp), %rsp
	leaq	114696(%rsp), %rax
	leaq	7168(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$89:
	leaq	512(%rsp), %rsp
	leaq	115208(%rsp), %rax
	leaq	7200(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$88:
	leaq	512(%rsp), %rsp
	leaq	115720(%rsp), %rax
	leaq	7232(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$87:
	leaq	512(%rsp), %rsp
	leaq	116232(%rsp), %rax
	leaq	7264(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$86:
	leaq	512(%rsp), %rsp
	leaq	116744(%rsp), %rax
	leaq	7296(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$85:
	leaq	512(%rsp), %rsp
	leaq	117256(%rsp), %rax
	leaq	7328(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$84:
	leaq	512(%rsp), %rsp
	leaq	117768(%rsp), %rax
	leaq	7360(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$83:
	leaq	512(%rsp), %rsp
	leaq	118280(%rsp), %rax
	leaq	7392(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$82:
	leaq	512(%rsp), %rsp
	leaq	118792(%rsp), %rax
	leaq	7424(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$81:
	leaq	512(%rsp), %rsp
	leaq	119304(%rsp), %rax
	leaq	7456(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$80:
	leaq	512(%rsp), %rsp
	leaq	119816(%rsp), %rax
	leaq	7488(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$79:
	leaq	512(%rsp), %rsp
	leaq	120328(%rsp), %rax
	leaq	7520(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$78:
	leaq	512(%rsp), %rsp
	leaq	120840(%rsp), %rax
	leaq	7552(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$77:
	leaq	512(%rsp), %rsp
	leaq	121352(%rsp), %rax
	leaq	7584(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$76:
	leaq	512(%rsp), %rsp
	leaq	121864(%rsp), %rax
	leaq	7616(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$75:
	leaq	512(%rsp), %rsp
	leaq	122376(%rsp), %rax
	leaq	7648(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$74:
	leaq	512(%rsp), %rsp
	leaq	122888(%rsp), %rax
	leaq	7680(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$73:
	leaq	512(%rsp), %rsp
	leaq	123400(%rsp), %rax
	leaq	7712(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$72:
	leaq	512(%rsp), %rsp
	leaq	123912(%rsp), %rax
	leaq	7744(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$71:
	leaq	512(%rsp), %rsp
	leaq	124424(%rsp), %rax
	leaq	7776(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$70:
	leaq	512(%rsp), %rsp
	leaq	124936(%rsp), %rax
	leaq	7808(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$69:
	leaq	512(%rsp), %rsp
	leaq	125448(%rsp), %rax
	leaq	7840(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$68:
	leaq	512(%rsp), %rsp
	leaq	125960(%rsp), %rax
	leaq	7872(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$67:
	leaq	512(%rsp), %rsp
	leaq	126472(%rsp), %rax
	leaq	7904(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$66:
	leaq	512(%rsp), %rsp
	leaq	126984(%rsp), %rax
	leaq	7936(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$65:
	leaq	512(%rsp), %rsp
	leaq	127496(%rsp), %rax
	leaq	7968(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$64:
	leaq	512(%rsp), %rsp
	leaq	128008(%rsp), %rax
	leaq	8000(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$63:
	leaq	512(%rsp), %rsp
	leaq	128520(%rsp), %rax
	leaq	8032(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$62:
	leaq	512(%rsp), %rsp
	leaq	129032(%rsp), %rax
	leaq	8064(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$61:
	leaq	512(%rsp), %rsp
	leaq	129544(%rsp), %rax
	leaq	8096(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$60:
	leaq	512(%rsp), %rsp
	leaq	130056(%rsp), %rax
	leaq	8128(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$59:
	leaq	512(%rsp), %rsp
	leaq	130568(%rsp), %rax
	leaq	8160(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$58:
	leaq	512(%rsp), %rsp
	leaq	131080(%rsp), %rax
	leaq	8192(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$57:
	leaq	512(%rsp), %rsp
	leaq	131592(%rsp), %rax
	leaq	8224(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$56:
	leaq	512(%rsp), %rsp
	leaq	132104(%rsp), %rax
	leaq	8256(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$55:
	leaq	512(%rsp), %rsp
	leaq	132616(%rsp), %rax
	leaq	8288(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$54:
	leaq	512(%rsp), %rsp
	leaq	133128(%rsp), %rax
	leaq	8320(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$53:
	leaq	512(%rsp), %rsp
	leaq	133640(%rsp), %rax
	leaq	8352(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$52:
	leaq	512(%rsp), %rsp
	leaq	134152(%rsp), %rax
	leaq	8384(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$51:
	leaq	512(%rsp), %rsp
	leaq	134664(%rsp), %rax
	leaq	8416(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$50:
	leaq	512(%rsp), %rsp
	leaq	135176(%rsp), %rax
	leaq	8448(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$49:
	leaq	512(%rsp), %rsp
	leaq	135688(%rsp), %rax
	leaq	8480(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$48:
	leaq	512(%rsp), %rsp
	leaq	136200(%rsp), %rax
	leaq	8512(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$47:
	leaq	512(%rsp), %rsp
	leaq	136712(%rsp), %rax
	leaq	8544(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$46:
	leaq	512(%rsp), %rsp
	leaq	137224(%rsp), %rax
	leaq	8576(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$45:
	leaq	512(%rsp), %rsp
	leaq	137736(%rsp), %rax
	leaq	8608(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$44:
	leaq	512(%rsp), %rsp
	leaq	138248(%rsp), %rax
	leaq	8640(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$43:
	leaq	512(%rsp), %rsp
	leaq	138760(%rsp), %rax
	leaq	8672(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$42:
	leaq	512(%rsp), %rsp
	leaq	139272(%rsp), %rax
	leaq	8704(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$41:
	leaq	512(%rsp), %rsp
	leaq	139784(%rsp), %rax
	leaq	8736(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$40:
	leaq	512(%rsp), %rsp
	leaq	140296(%rsp), %rax
	leaq	8768(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$39:
	leaq	512(%rsp), %rsp
	leaq	140808(%rsp), %rax
	leaq	8800(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$38:
	leaq	512(%rsp), %rsp
	leaq	141320(%rsp), %rax
	leaq	8832(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$37:
	leaq	512(%rsp), %rsp
	leaq	141832(%rsp), %rax
	leaq	8864(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$36:
	leaq	512(%rsp), %rsp
	leaq	142344(%rsp), %rax
	leaq	8896(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$35:
	leaq	512(%rsp), %rsp
	leaq	142856(%rsp), %rax
	leaq	8928(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$34:
	leaq	512(%rsp), %rsp
	leaq	143368(%rsp), %rax
	leaq	8960(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$33:
	leaq	512(%rsp), %rsp
	leaq	143880(%rsp), %rax
	leaq	8992(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$32:
	leaq	512(%rsp), %rsp
	leaq	144392(%rsp), %rax
	leaq	9024(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$31:
	leaq	512(%rsp), %rsp
	leaq	144904(%rsp), %rax
	leaq	9056(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$30:
	leaq	512(%rsp), %rsp
	leaq	145416(%rsp), %rax
	leaq	9088(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$29:
	leaq	512(%rsp), %rsp
	leaq	145928(%rsp), %rax
	leaq	9120(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$28:
	leaq	512(%rsp), %rsp
	leaq	146440(%rsp), %rax
	leaq	9152(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$27:
	leaq	512(%rsp), %rsp
	leaq	146952(%rsp), %rax
	leaq	9184(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$26:
	leaq	512(%rsp), %rsp
	leaq	147464(%rsp), %rax
	leaq	9216(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$25:
	leaq	512(%rsp), %rsp
	leaq	147976(%rsp), %rax
	leaq	9248(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$24:
	leaq	512(%rsp), %rsp
	leaq	148488(%rsp), %rax
	leaq	9280(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$23:
	leaq	512(%rsp), %rsp
	leaq	149000(%rsp), %rax
	leaq	9312(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$22:
	leaq	512(%rsp), %rsp
	leaq	149512(%rsp), %rax
	leaq	9344(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$21:
	leaq	512(%rsp), %rsp
	leaq	150024(%rsp), %rax
	leaq	9376(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$20:
	leaq	512(%rsp), %rsp
	leaq	150536(%rsp), %rax
	leaq	9408(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$19:
	leaq	512(%rsp), %rsp
	leaq	151048(%rsp), %rax
	leaq	9440(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$18:
	leaq	512(%rsp), %rsp
	leaq	151560(%rsp), %rax
	leaq	9472(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$17:
	leaq	512(%rsp), %rsp
	leaq	152072(%rsp), %rax
	leaq	9504(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$16:
	leaq	512(%rsp), %rsp
	leaq	152584(%rsp), %rax
	leaq	9536(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$15:
	leaq	512(%rsp), %rsp
	leaq	153096(%rsp), %rax
	leaq	9568(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$14:
	leaq	512(%rsp), %rsp
	leaq	153608(%rsp), %rax
	leaq	9600(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$13:
	leaq	512(%rsp), %rsp
	leaq	154120(%rsp), %rax
	leaq	9632(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$12:
	leaq	512(%rsp), %rsp
	leaq	154632(%rsp), %rax
	leaq	9664(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$11:
	leaq	512(%rsp), %rsp
	leaq	155144(%rsp), %rax
	leaq	9696(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$10:
	leaq	512(%rsp), %rsp
	leaq	155656(%rsp), %rax
	leaq	9728(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$9:
	leaq	512(%rsp), %rsp
	leaq	156168(%rsp), %rax
	leaq	9760(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$8:
	leaq	512(%rsp), %rsp
	leaq	156680(%rsp), %rax
	leaq	9792(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$7:
	leaq	512(%rsp), %rsp
	leaq	157192(%rsp), %rax
	leaq	9824(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$6:
	leaq	512(%rsp), %rsp
	leaq	157704(%rsp), %rax
	leaq	9856(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$5:
	leaq	512(%rsp), %rsp
	leaq	158216(%rsp), %rax
	leaq	9888(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$4:
	leaq	512(%rsp), %rsp
	leaq	158728(%rsp), %rax
	leaq	9920(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$3:
	leaq	512(%rsp), %rsp
	leaq	159240(%rsp), %rax
	leaq	9952(%rbp), %rdx
	leaq	-512(%rsp), %rsp
	call	Lbitsliced_m_multiply_bins$1
Lbitsliced_m_calculate_PS$2:
	leaq	512(%rsp), %rsp
	ret
Lbitsliced_m_vec_add_slice_p3$1:
	movl	(%rbx,%rdx,4), %esi
	xorl	%esi, (%rdi,%rcx,4)
	leaq	1(%rdx), %rdx
	leaq	1(%rcx), %rcx
	movl	(%rbx,%rdx,4), %esi
	xorl	%esi, (%rdi,%rcx,4)
	leaq	1(%rdx), %rdx
	leaq	1(%rcx), %rcx
	movl	(%rbx,%rdx,4), %esi
	xorl	%esi, (%rdi,%rcx,4)
	leaq	1(%rdx), %rdx
	leaq	1(%rcx), %rcx
	movl	(%rbx,%rdx,4), %esi
	xorl	%esi, (%rdi,%rcx,4)
	leaq	1(%rdx), %rdx
	leaq	1(%rcx), %rcx
	movl	(%rbx,%rdx,4), %esi
	xorl	%esi, (%rdi,%rcx,4)
	leaq	1(%rdx), %rdx
	leaq	1(%rcx), %rcx
	movl	(%rbx,%rdx,4), %esi
	xorl	%esi, (%rdi,%rcx,4)
	leaq	1(%rdx), %rdx
	leaq	1(%rcx), %rcx
	movl	(%rbx,%rdx,4), %esi
	xorl	%esi, (%rdi,%rcx,4)
	leaq	1(%rdx), %rdx
	leaq	1(%rcx), %rcx
	movl	(%rbx,%rdx,4), %edx
	xorl	%edx, (%rdi,%rcx,4)
	ret
Lbitsliced_m_vec_add_slice_p2$1:
	movl	(%r10,%rdx,4), %esi
	xorl	%esi, (%rcx,%rax,4)
	leaq	1(%rdx), %rdx
	leaq	1(%rax), %rax
	movl	(%r10,%rdx,4), %esi
	xorl	%esi, (%rcx,%rax,4)
	leaq	1(%rdx), %rdx
	leaq	1(%rax), %rax
	movl	(%r10,%rdx,4), %esi
	xorl	%esi, (%rcx,%rax,4)
	leaq	1(%rdx), %rdx
	leaq	1(%rax), %rax
	movl	(%r10,%rdx,4), %esi
	xorl	%esi, (%rcx,%rax,4)
	leaq	1(%rdx), %rdx
	leaq	1(%rax), %rax
	movl	(%r10,%rdx,4), %esi
	xorl	%esi, (%rcx,%rax,4)
	leaq	1(%rdx), %rdx
	leaq	1(%rax), %rax
	movl	(%r10,%rdx,4), %esi
	xorl	%esi, (%rcx,%rax,4)
	leaq	1(%rdx), %rdx
	leaq	1(%rax), %rax
	movl	(%r10,%rdx,4), %esi
	xorl	%esi, (%rcx,%rax,4)
	leaq	1(%rdx), %rdx
	leaq	1(%rax), %rax
	movl	(%r10,%rdx,4), %edx
	xorl	%edx, (%rcx,%rax,4)
	ret
Lbitsliced_m_vec_add_slice$1:
	movl	(%r9,%rsi,4), %ecx
	xorl	%ecx, (%rdi,%rax,4)
	leaq	1(%rsi), %rsi
	leaq	1(%rax), %rax
	movl	(%r9,%rsi,4), %ecx
	xorl	%ecx, (%rdi,%rax,4)
	leaq	1(%rsi), %rsi
	leaq	1(%rax), %rax
	movl	(%r9,%rsi,4), %ecx
	xorl	%ecx, (%rdi,%rax,4)
	leaq	1(%rsi), %rsi
	leaq	1(%rax), %rax
	movl	(%r9,%rsi,4), %ecx
	xorl	%ecx, (%rdi,%rax,4)
	leaq	1(%rsi), %rsi
	leaq	1(%rax), %rax
	movl	(%r9,%rsi,4), %ecx
	xorl	%ecx, (%rdi,%rax,4)
	leaq	1(%rsi), %rsi
	leaq	1(%rax), %rax
	movl	(%r9,%rsi,4), %ecx
	xorl	%ecx, (%rdi,%rax,4)
	leaq	1(%rsi), %rsi
	leaq	1(%rax), %rax
	movl	(%r9,%rsi,4), %ecx
	xorl	%ecx, (%rdi,%rax,4)
	leaq	1(%rsi), %rcx
	leaq	1(%rax), %rax
	movl	(%r9,%rcx,4), %ecx
	xorl	%ecx, (%rdi,%rax,4)
	ret
Lbitsliced_m_multiply_bins$1:
	movq	$0, %rcx
	jmp 	Lbitsliced_m_multiply_bins$28
Lbitsliced_m_multiply_bins$29:
	movl	(%rax,%rcx,4), %esi
	movl	%esi, 8(%rsp,%rcx,4)
	leaq	1(%rcx), %rcx
Lbitsliced_m_multiply_bins$28:
	cmpq	$128, %rcx
	jb  	Lbitsliced_m_multiply_bins$29
	leaq	488(%rsp), %rax
	leaq	392(%rsp), %rcx
	call	Lbitsliced_m_vec_add$1
Lbitsliced_m_multiply_bins$27:
	leaq	488(%rsp), %rax
	leaq	104(%rsp), %rcx
	call	Lbitsliced_m_vec_add$1
Lbitsliced_m_multiply_bins$26:
	leaq	456(%rsp), %rax
	leaq	264(%rsp), %rcx
	call	Lbitsliced_m_vec_add$1
Lbitsliced_m_multiply_bins$25:
	leaq	456(%rsp), %rax
	leaq	200(%rsp), %rcx
	call	Lbitsliced_m_vec_add$1
Lbitsliced_m_multiply_bins$24:
	leaq	424(%rsp), %rax
	leaq	328(%rsp), %rcx
	call	Lbitsliced_m_vec_add$1
Lbitsliced_m_multiply_bins$23:
	leaq	424(%rsp), %rax
	leaq	232(%rsp), %rcx
	call	Lbitsliced_m_vec_add$1
Lbitsliced_m_multiply_bins$22:
	leaq	392(%rsp), %rax
	leaq	264(%rsp), %rcx
	call	Lbitsliced_m_vec_add$1
Lbitsliced_m_multiply_bins$21:
	leaq	392(%rsp), %rax
	leaq	136(%rsp), %rcx
	call	Lbitsliced_m_vec_add$1
Lbitsliced_m_multiply_bins$20:
	leaq	360(%rsp), %rax
	leaq	296(%rsp), %rcx
	call	Lbitsliced_m_vec_add$1
Lbitsliced_m_multiply_bins$19:
	leaq	360(%rsp), %rax
	leaq	72(%rsp), %rcx
	call	Lbitsliced_m_vec_add$1
Lbitsliced_m_multiply_bins$18:
	leaq	328(%rsp), %rax
	leaq	264(%rsp), %rcx
	call	Lbitsliced_m_vec_add$1
Lbitsliced_m_multiply_bins$17:
	leaq	328(%rsp), %rax
	leaq	72(%rsp), %rcx
	call	Lbitsliced_m_vec_add$1
Lbitsliced_m_multiply_bins$16:
	leaq	296(%rsp), %rax
	leaq	264(%rsp), %rcx
	call	Lbitsliced_m_vec_add$1
Lbitsliced_m_multiply_bins$15:
	leaq	296(%rsp), %rax
	leaq	40(%rsp), %rcx
	call	Lbitsliced_m_vec_add$1
Lbitsliced_m_multiply_bins$14:
	leaq	232(%rsp), %rax
	leaq	136(%rsp), %rcx
	call	Lbitsliced_m_vec_add$1
Lbitsliced_m_multiply_bins$13:
	leaq	232(%rsp), %rax
	leaq	104(%rsp), %rcx
	call	Lbitsliced_m_vec_add$1
Lbitsliced_m_multiply_bins$12:
	leaq	200(%rsp), %rax
	leaq	136(%rsp), %rcx
	call	Lbitsliced_m_vec_add$1
Lbitsliced_m_multiply_bins$11:
	leaq	200(%rsp), %rax
	leaq	72(%rsp), %rcx
	call	Lbitsliced_m_vec_add$1
Lbitsliced_m_multiply_bins$10:
	leaq	168(%rsp), %rax
	leaq	136(%rsp), %rcx
	call	Lbitsliced_m_vec_add$1
Lbitsliced_m_multiply_bins$9:
	leaq	168(%rsp), %rax
	leaq	40(%rsp), %rcx
	call	Lbitsliced_m_vec_add$1
Lbitsliced_m_multiply_bins$8:
	leaq	104(%rsp), %rax
	leaq	72(%rsp), %rcx
	call	Lbitsliced_m_vec_add$1
Lbitsliced_m_multiply_bins$7:
	leaq	104(%rsp), %rax
	leaq	40(%rsp), %rcx
	call	Lbitsliced_m_vec_add$1
Lbitsliced_m_multiply_bins$6:
	leaq	264(%rsp), %rdi
	leaq	136(%rsp), %r11
	call	Lbitsliced_m_vec_mul_add_x$1
Lbitsliced_m_multiply_bins$5:
	leaq	136(%rsp), %rdi
	leaq	72(%rsp), %r11
	call	Lbitsliced_m_vec_mul_add_x$1
Lbitsliced_m_multiply_bins$4:
	leaq	72(%rsp), %rdi
	leaq	40(%rsp), %r11
	call	Lbitsliced_m_vec_mul_add_x$1
Lbitsliced_m_multiply_bins$3:
	leaq	40(%rsp), %rax
	call	Lbitsliced_m_vec_copy$1
Lbitsliced_m_multiply_bins$2:
	ret
Lbitsliced_m_vec_mul_add_x$1:
	movq	%rdi, %rax
	leaq	8(%rdi), %rcx
	leaq	16(%rdi), %rsi
	leaq	24(%rdi), %rdi
	movq	%r11, %r8
	leaq	8(%r11), %r9
	leaq	16(%r11), %r10
	leaq	24(%r11), %r11
	movl	(%rax), %ebx
	xorl	(%rdi), %ebx
	movl	(%rdi), %r12d
	xorl	%r12d, (%r8)
	xorl	%ebx, (%r9)
	movl	(%rcx), %ebx
	xorl	%ebx, (%r10)
	movl	(%rsi), %ebx
	xorl	%ebx, (%r11)
	movl	4(%rax), %eax
	xorl	4(%rdi), %eax
	movl	4(%rdi), %edi
	xorl	%edi, 4(%r8)
	xorl	%eax, 4(%r9)
	movl	4(%rcx), %eax
	xorl	%eax, 4(%r10)
	movl	4(%rsi), %eax
	xorl	%eax, 4(%r11)
	ret
Ldecode_sig$1:
	movb	(%rax), %dl
	andb	$15, %dl
	movb	%dl, (%rcx)
	movb	(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 1(%rcx)
	movb	1(%rax), %dl
	andb	$15, %dl
	movb	%dl, 2(%rcx)
	movb	1(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 3(%rcx)
	movb	2(%rax), %dl
	andb	$15, %dl
	movb	%dl, 4(%rcx)
	movb	2(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 5(%rcx)
	movb	3(%rax), %dl
	andb	$15, %dl
	movb	%dl, 6(%rcx)
	movb	3(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 7(%rcx)
	movb	4(%rax), %dl
	andb	$15, %dl
	movb	%dl, 8(%rcx)
	movb	4(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 9(%rcx)
	movb	5(%rax), %dl
	andb	$15, %dl
	movb	%dl, 10(%rcx)
	movb	5(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 11(%rcx)
	movb	6(%rax), %dl
	andb	$15, %dl
	movb	%dl, 12(%rcx)
	movb	6(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 13(%rcx)
	movb	7(%rax), %dl
	andb	$15, %dl
	movb	%dl, 14(%rcx)
	movb	7(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 15(%rcx)
	movb	8(%rax), %dl
	andb	$15, %dl
	movb	%dl, 16(%rcx)
	movb	8(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 17(%rcx)
	movb	9(%rax), %dl
	andb	$15, %dl
	movb	%dl, 18(%rcx)
	movb	9(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 19(%rcx)
	movb	10(%rax), %dl
	andb	$15, %dl
	movb	%dl, 20(%rcx)
	movb	10(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 21(%rcx)
	movb	11(%rax), %dl
	andb	$15, %dl
	movb	%dl, 22(%rcx)
	movb	11(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 23(%rcx)
	movb	12(%rax), %dl
	andb	$15, %dl
	movb	%dl, 24(%rcx)
	movb	12(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 25(%rcx)
	movb	13(%rax), %dl
	andb	$15, %dl
	movb	%dl, 26(%rcx)
	movb	13(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 27(%rcx)
	movb	14(%rax), %dl
	andb	$15, %dl
	movb	%dl, 28(%rcx)
	movb	14(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 29(%rcx)
	movb	15(%rax), %dl
	andb	$15, %dl
	movb	%dl, 30(%rcx)
	movb	15(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 31(%rcx)
	movb	16(%rax), %dl
	andb	$15, %dl
	movb	%dl, 32(%rcx)
	movb	16(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 33(%rcx)
	movb	17(%rax), %dl
	andb	$15, %dl
	movb	%dl, 34(%rcx)
	movb	17(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 35(%rcx)
	movb	18(%rax), %dl
	andb	$15, %dl
	movb	%dl, 36(%rcx)
	movb	18(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 37(%rcx)
	movb	19(%rax), %dl
	andb	$15, %dl
	movb	%dl, 38(%rcx)
	movb	19(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 39(%rcx)
	movb	20(%rax), %dl
	andb	$15, %dl
	movb	%dl, 40(%rcx)
	movb	20(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 41(%rcx)
	movb	21(%rax), %dl
	andb	$15, %dl
	movb	%dl, 42(%rcx)
	movb	21(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 43(%rcx)
	movb	22(%rax), %dl
	andb	$15, %dl
	movb	%dl, 44(%rcx)
	movb	22(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 45(%rcx)
	movb	23(%rax), %dl
	andb	$15, %dl
	movb	%dl, 46(%rcx)
	movb	23(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 47(%rcx)
	movb	24(%rax), %dl
	andb	$15, %dl
	movb	%dl, 48(%rcx)
	movb	24(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 49(%rcx)
	movb	25(%rax), %dl
	andb	$15, %dl
	movb	%dl, 50(%rcx)
	movb	25(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 51(%rcx)
	movb	26(%rax), %dl
	andb	$15, %dl
	movb	%dl, 52(%rcx)
	movb	26(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 53(%rcx)
	movb	27(%rax), %dl
	andb	$15, %dl
	movb	%dl, 54(%rcx)
	movb	27(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 55(%rcx)
	movb	28(%rax), %dl
	andb	$15, %dl
	movb	%dl, 56(%rcx)
	movb	28(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 57(%rcx)
	movb	29(%rax), %dl
	andb	$15, %dl
	movb	%dl, 58(%rcx)
	movb	29(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 59(%rcx)
	movb	30(%rax), %dl
	andb	$15, %dl
	movb	%dl, 60(%rcx)
	movb	30(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 61(%rcx)
	movb	31(%rax), %dl
	andb	$15, %dl
	movb	%dl, 62(%rcx)
	movb	31(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 63(%rcx)
	movb	32(%rax), %dl
	andb	$15, %dl
	movb	%dl, 64(%rcx)
	movb	32(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 65(%rcx)
	movb	33(%rax), %dl
	andb	$15, %dl
	movb	%dl, 66(%rcx)
	movb	33(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 67(%rcx)
	movb	34(%rax), %dl
	andb	$15, %dl
	movb	%dl, 68(%rcx)
	movb	34(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 69(%rcx)
	movb	35(%rax), %dl
	andb	$15, %dl
	movb	%dl, 70(%rcx)
	movb	35(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 71(%rcx)
	movb	36(%rax), %dl
	andb	$15, %dl
	movb	%dl, 72(%rcx)
	movb	36(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 73(%rcx)
	movb	37(%rax), %dl
	andb	$15, %dl
	movb	%dl, 74(%rcx)
	movb	37(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 75(%rcx)
	movb	38(%rax), %dl
	andb	$15, %dl
	movb	%dl, 76(%rcx)
	movb	38(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 77(%rcx)
	movb	39(%rax), %dl
	andb	$15, %dl
	movb	%dl, 78(%rcx)
	movb	39(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 79(%rcx)
	movb	40(%rax), %dl
	andb	$15, %dl
	movb	%dl, 80(%rcx)
	movb	40(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 81(%rcx)
	movb	41(%rax), %dl
	andb	$15, %dl
	movb	%dl, 82(%rcx)
	movb	41(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 83(%rcx)
	movb	42(%rax), %dl
	andb	$15, %dl
	movb	%dl, 84(%rcx)
	movb	42(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 85(%rcx)
	movb	43(%rax), %dl
	andb	$15, %dl
	movb	%dl, 86(%rcx)
	movb	43(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 87(%rcx)
	movb	44(%rax), %dl
	andb	$15, %dl
	movb	%dl, 88(%rcx)
	movb	44(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 89(%rcx)
	movb	45(%rax), %dl
	andb	$15, %dl
	movb	%dl, 90(%rcx)
	movb	45(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 91(%rcx)
	movb	46(%rax), %dl
	andb	$15, %dl
	movb	%dl, 92(%rcx)
	movb	46(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 93(%rcx)
	movb	47(%rax), %dl
	andb	$15, %dl
	movb	%dl, 94(%rcx)
	movb	47(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 95(%rcx)
	movb	48(%rax), %dl
	andb	$15, %dl
	movb	%dl, 96(%rcx)
	movb	48(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 97(%rcx)
	movb	49(%rax), %dl
	andb	$15, %dl
	movb	%dl, 98(%rcx)
	movb	49(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 99(%rcx)
	movb	50(%rax), %dl
	andb	$15, %dl
	movb	%dl, 100(%rcx)
	movb	50(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 101(%rcx)
	movb	51(%rax), %dl
	andb	$15, %dl
	movb	%dl, 102(%rcx)
	movb	51(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 103(%rcx)
	movb	52(%rax), %dl
	andb	$15, %dl
	movb	%dl, 104(%rcx)
	movb	52(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 105(%rcx)
	movb	53(%rax), %dl
	andb	$15, %dl
	movb	%dl, 106(%rcx)
	movb	53(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 107(%rcx)
	movb	54(%rax), %dl
	andb	$15, %dl
	movb	%dl, 108(%rcx)
	movb	54(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 109(%rcx)
	movb	55(%rax), %dl
	andb	$15, %dl
	movb	%dl, 110(%rcx)
	movb	55(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 111(%rcx)
	movb	56(%rax), %dl
	andb	$15, %dl
	movb	%dl, 112(%rcx)
	movb	56(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 113(%rcx)
	movb	57(%rax), %dl
	andb	$15, %dl
	movb	%dl, 114(%rcx)
	movb	57(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 115(%rcx)
	movb	58(%rax), %dl
	andb	$15, %dl
	movb	%dl, 116(%rcx)
	movb	58(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 117(%rcx)
	movb	59(%rax), %dl
	andb	$15, %dl
	movb	%dl, 118(%rcx)
	movb	59(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 119(%rcx)
	movb	60(%rax), %dl
	andb	$15, %dl
	movb	%dl, 120(%rcx)
	movb	60(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 121(%rcx)
	movb	61(%rax), %dl
	andb	$15, %dl
	movb	%dl, 122(%rcx)
	movb	61(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 123(%rcx)
	movb	62(%rax), %dl
	andb	$15, %dl
	movb	%dl, 124(%rcx)
	movb	62(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 125(%rcx)
	movb	63(%rax), %dl
	andb	$15, %dl
	movb	%dl, 126(%rcx)
	movb	63(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 127(%rcx)
	movb	64(%rax), %dl
	andb	$15, %dl
	movb	%dl, 128(%rcx)
	movb	64(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 129(%rcx)
	movb	65(%rax), %dl
	andb	$15, %dl
	movb	%dl, 130(%rcx)
	movb	65(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 131(%rcx)
	movb	66(%rax), %dl
	andb	$15, %dl
	movb	%dl, 132(%rcx)
	movb	66(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 133(%rcx)
	movb	67(%rax), %dl
	andb	$15, %dl
	movb	%dl, 134(%rcx)
	movb	67(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 135(%rcx)
	movb	68(%rax), %dl
	andb	$15, %dl
	movb	%dl, 136(%rcx)
	movb	68(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 137(%rcx)
	movb	69(%rax), %dl
	andb	$15, %dl
	movb	%dl, 138(%rcx)
	movb	69(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 139(%rcx)
	movb	70(%rax), %dl
	andb	$15, %dl
	movb	%dl, 140(%rcx)
	movb	70(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 141(%rcx)
	movb	71(%rax), %dl
	andb	$15, %dl
	movb	%dl, 142(%rcx)
	movb	71(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 143(%rcx)
	movb	72(%rax), %dl
	andb	$15, %dl
	movb	%dl, 144(%rcx)
	movb	72(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 145(%rcx)
	movb	73(%rax), %dl
	andb	$15, %dl
	movb	%dl, 146(%rcx)
	movb	73(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 147(%rcx)
	movb	74(%rax), %dl
	andb	$15, %dl
	movb	%dl, 148(%rcx)
	movb	74(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 149(%rcx)
	movb	75(%rax), %dl
	andb	$15, %dl
	movb	%dl, 150(%rcx)
	movb	75(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 151(%rcx)
	movb	76(%rax), %dl
	andb	$15, %dl
	movb	%dl, 152(%rcx)
	movb	76(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 153(%rcx)
	movb	77(%rax), %dl
	andb	$15, %dl
	movb	%dl, 154(%rcx)
	movb	77(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 155(%rcx)
	movb	78(%rax), %dl
	andb	$15, %dl
	movb	%dl, 156(%rcx)
	movb	78(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 157(%rcx)
	movb	79(%rax), %dl
	andb	$15, %dl
	movb	%dl, 158(%rcx)
	movb	79(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 159(%rcx)
	movb	80(%rax), %dl
	andb	$15, %dl
	movb	%dl, 160(%rcx)
	movb	80(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 161(%rcx)
	movb	81(%rax), %dl
	andb	$15, %dl
	movb	%dl, 162(%rcx)
	movb	81(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 163(%rcx)
	movb	82(%rax), %dl
	andb	$15, %dl
	movb	%dl, 164(%rcx)
	movb	82(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 165(%rcx)
	movb	83(%rax), %dl
	andb	$15, %dl
	movb	%dl, 166(%rcx)
	movb	83(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 167(%rcx)
	movb	84(%rax), %dl
	andb	$15, %dl
	movb	%dl, 168(%rcx)
	movb	84(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 169(%rcx)
	movb	85(%rax), %dl
	andb	$15, %dl
	movb	%dl, 170(%rcx)
	movb	85(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 171(%rcx)
	movb	86(%rax), %dl
	andb	$15, %dl
	movb	%dl, 172(%rcx)
	movb	86(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 173(%rcx)
	movb	87(%rax), %dl
	andb	$15, %dl
	movb	%dl, 174(%rcx)
	movb	87(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 175(%rcx)
	movb	88(%rax), %dl
	andb	$15, %dl
	movb	%dl, 176(%rcx)
	movb	88(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 177(%rcx)
	movb	89(%rax), %dl
	andb	$15, %dl
	movb	%dl, 178(%rcx)
	movb	89(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 179(%rcx)
	movb	90(%rax), %dl
	andb	$15, %dl
	movb	%dl, 180(%rcx)
	movb	90(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 181(%rcx)
	movb	91(%rax), %dl
	andb	$15, %dl
	movb	%dl, 182(%rcx)
	movb	91(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 183(%rcx)
	movb	92(%rax), %dl
	andb	$15, %dl
	movb	%dl, 184(%rcx)
	movb	92(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 185(%rcx)
	movb	93(%rax), %dl
	andb	$15, %dl
	movb	%dl, 186(%rcx)
	movb	93(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 187(%rcx)
	movb	94(%rax), %dl
	andb	$15, %dl
	movb	%dl, 188(%rcx)
	movb	94(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 189(%rcx)
	movb	95(%rax), %dl
	andb	$15, %dl
	movb	%dl, 190(%rcx)
	movb	95(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 191(%rcx)
	movb	96(%rax), %dl
	andb	$15, %dl
	movb	%dl, 192(%rcx)
	movb	96(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 193(%rcx)
	movb	97(%rax), %dl
	andb	$15, %dl
	movb	%dl, 194(%rcx)
	movb	97(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 195(%rcx)
	movb	98(%rax), %dl
	andb	$15, %dl
	movb	%dl, 196(%rcx)
	movb	98(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 197(%rcx)
	movb	99(%rax), %dl
	andb	$15, %dl
	movb	%dl, 198(%rcx)
	movb	99(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 199(%rcx)
	movb	100(%rax), %dl
	andb	$15, %dl
	movb	%dl, 200(%rcx)
	movb	100(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 201(%rcx)
	movb	101(%rax), %dl
	andb	$15, %dl
	movb	%dl, 202(%rcx)
	movb	101(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 203(%rcx)
	movb	102(%rax), %dl
	andb	$15, %dl
	movb	%dl, 204(%rcx)
	movb	102(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 205(%rcx)
	movb	103(%rax), %dl
	andb	$15, %dl
	movb	%dl, 206(%rcx)
	movb	103(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 207(%rcx)
	movb	104(%rax), %dl
	andb	$15, %dl
	movb	%dl, 208(%rcx)
	movb	104(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 209(%rcx)
	movb	105(%rax), %dl
	andb	$15, %dl
	movb	%dl, 210(%rcx)
	movb	105(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 211(%rcx)
	movb	106(%rax), %dl
	andb	$15, %dl
	movb	%dl, 212(%rcx)
	movb	106(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 213(%rcx)
	movb	107(%rax), %dl
	andb	$15, %dl
	movb	%dl, 214(%rcx)
	movb	107(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 215(%rcx)
	movb	108(%rax), %dl
	andb	$15, %dl
	movb	%dl, 216(%rcx)
	movb	108(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 217(%rcx)
	movb	109(%rax), %dl
	andb	$15, %dl
	movb	%dl, 218(%rcx)
	movb	109(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 219(%rcx)
	movb	110(%rax), %dl
	andb	$15, %dl
	movb	%dl, 220(%rcx)
	movb	110(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 221(%rcx)
	movb	111(%rax), %dl
	andb	$15, %dl
	movb	%dl, 222(%rcx)
	movb	111(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 223(%rcx)
	movb	112(%rax), %dl
	andb	$15, %dl
	movb	%dl, 224(%rcx)
	movb	112(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 225(%rcx)
	movb	113(%rax), %dl
	andb	$15, %dl
	movb	%dl, 226(%rcx)
	movb	113(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 227(%rcx)
	movb	114(%rax), %dl
	andb	$15, %dl
	movb	%dl, 228(%rcx)
	movb	114(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 229(%rcx)
	movb	115(%rax), %dl
	andb	$15, %dl
	movb	%dl, 230(%rcx)
	movb	115(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 231(%rcx)
	movb	116(%rax), %dl
	andb	$15, %dl
	movb	%dl, 232(%rcx)
	movb	116(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 233(%rcx)
	movb	117(%rax), %dl
	andb	$15, %dl
	movb	%dl, 234(%rcx)
	movb	117(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 235(%rcx)
	movb	118(%rax), %dl
	andb	$15, %dl
	movb	%dl, 236(%rcx)
	movb	118(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 237(%rcx)
	movb	119(%rax), %dl
	andb	$15, %dl
	movb	%dl, 238(%rcx)
	movb	119(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 239(%rcx)
	movb	120(%rax), %dl
	andb	$15, %dl
	movb	%dl, 240(%rcx)
	movb	120(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 241(%rcx)
	movb	121(%rax), %dl
	andb	$15, %dl
	movb	%dl, 242(%rcx)
	movb	121(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 243(%rcx)
	movb	122(%rax), %dl
	andb	$15, %dl
	movb	%dl, 244(%rcx)
	movb	122(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 245(%rcx)
	movb	123(%rax), %dl
	andb	$15, %dl
	movb	%dl, 246(%rcx)
	movb	123(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 247(%rcx)
	movb	124(%rax), %dl
	andb	$15, %dl
	movb	%dl, 248(%rcx)
	movb	124(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 249(%rcx)
	movb	125(%rax), %dl
	andb	$15, %dl
	movb	%dl, 250(%rcx)
	movb	125(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 251(%rcx)
	movb	126(%rax), %dl
	andb	$15, %dl
	movb	%dl, 252(%rcx)
	movb	126(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 253(%rcx)
	movb	127(%rax), %dl
	andb	$15, %dl
	movb	%dl, 254(%rcx)
	movb	127(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 255(%rcx)
	movb	128(%rax), %dl
	andb	$15, %dl
	movb	%dl, 256(%rcx)
	movb	128(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 257(%rcx)
	movb	129(%rax), %dl
	andb	$15, %dl
	movb	%dl, 258(%rcx)
	movb	129(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 259(%rcx)
	movb	130(%rax), %dl
	andb	$15, %dl
	movb	%dl, 260(%rcx)
	movb	130(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 261(%rcx)
	movb	131(%rax), %dl
	andb	$15, %dl
	movb	%dl, 262(%rcx)
	movb	131(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 263(%rcx)
	movb	132(%rax), %dl
	andb	$15, %dl
	movb	%dl, 264(%rcx)
	movb	132(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 265(%rcx)
	movb	133(%rax), %dl
	andb	$15, %dl
	movb	%dl, 266(%rcx)
	movb	133(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 267(%rcx)
	movb	134(%rax), %dl
	andb	$15, %dl
	movb	%dl, 268(%rcx)
	movb	134(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 269(%rcx)
	movb	135(%rax), %dl
	andb	$15, %dl
	movb	%dl, 270(%rcx)
	movb	135(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 271(%rcx)
	movb	136(%rax), %dl
	andb	$15, %dl
	movb	%dl, 272(%rcx)
	movb	136(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 273(%rcx)
	movb	137(%rax), %dl
	andb	$15, %dl
	movb	%dl, 274(%rcx)
	movb	137(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 275(%rcx)
	movb	138(%rax), %dl
	andb	$15, %dl
	movb	%dl, 276(%rcx)
	movb	138(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 277(%rcx)
	movb	139(%rax), %dl
	andb	$15, %dl
	movb	%dl, 278(%rcx)
	movb	139(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 279(%rcx)
	movb	140(%rax), %dl
	andb	$15, %dl
	movb	%dl, 280(%rcx)
	movb	140(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 281(%rcx)
	movb	141(%rax), %dl
	andb	$15, %dl
	movb	%dl, 282(%rcx)
	movb	141(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 283(%rcx)
	movb	142(%rax), %dl
	andb	$15, %dl
	movb	%dl, 284(%rcx)
	movb	142(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 285(%rcx)
	movb	143(%rax), %dl
	andb	$15, %dl
	movb	%dl, 286(%rcx)
	movb	143(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 287(%rcx)
	movb	144(%rax), %dl
	andb	$15, %dl
	movb	%dl, 288(%rcx)
	movb	144(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 289(%rcx)
	movb	145(%rax), %dl
	andb	$15, %dl
	movb	%dl, 290(%rcx)
	movb	145(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 291(%rcx)
	movb	146(%rax), %dl
	andb	$15, %dl
	movb	%dl, 292(%rcx)
	movb	146(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 293(%rcx)
	movb	147(%rax), %dl
	andb	$15, %dl
	movb	%dl, 294(%rcx)
	movb	147(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 295(%rcx)
	movb	148(%rax), %dl
	andb	$15, %dl
	movb	%dl, 296(%rcx)
	movb	148(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 297(%rcx)
	movb	149(%rax), %dl
	andb	$15, %dl
	movb	%dl, 298(%rcx)
	movb	149(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 299(%rcx)
	movb	150(%rax), %dl
	andb	$15, %dl
	movb	%dl, 300(%rcx)
	movb	150(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 301(%rcx)
	movb	151(%rax), %dl
	andb	$15, %dl
	movb	%dl, 302(%rcx)
	movb	151(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 303(%rcx)
	movb	152(%rax), %dl
	andb	$15, %dl
	movb	%dl, 304(%rcx)
	movb	152(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 305(%rcx)
	movb	153(%rax), %dl
	andb	$15, %dl
	movb	%dl, 306(%rcx)
	movb	153(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 307(%rcx)
	movb	154(%rax), %dl
	andb	$15, %dl
	movb	%dl, 308(%rcx)
	movb	154(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 309(%rcx)
	movb	155(%rax), %dl
	andb	$15, %dl
	movb	%dl, 310(%rcx)
	movb	155(%rax), %al
	shrb	$4, %al
	movb	%al, 311(%rcx)
	ret
Ldecode_o_tenc$1:
	movb	(%rax), %dl
	andb	$15, %dl
	movb	%dl, (%rcx)
	movb	(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 1(%rcx)
	movb	1(%rax), %dl
	andb	$15, %dl
	movb	%dl, 2(%rcx)
	movb	1(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 3(%rcx)
	movb	2(%rax), %dl
	andb	$15, %dl
	movb	%dl, 4(%rcx)
	movb	2(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 5(%rcx)
	movb	3(%rax), %dl
	andb	$15, %dl
	movb	%dl, 6(%rcx)
	movb	3(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 7(%rcx)
	movb	4(%rax), %dl
	andb	$15, %dl
	movb	%dl, 8(%rcx)
	movb	4(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 9(%rcx)
	movb	5(%rax), %dl
	andb	$15, %dl
	movb	%dl, 10(%rcx)
	movb	5(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 11(%rcx)
	movb	6(%rax), %dl
	andb	$15, %dl
	movb	%dl, 12(%rcx)
	movb	6(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 13(%rcx)
	movb	7(%rax), %dl
	andb	$15, %dl
	movb	%dl, 14(%rcx)
	movb	7(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 15(%rcx)
	movb	8(%rax), %dl
	andb	$15, %dl
	movb	%dl, 16(%rcx)
	movb	8(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 17(%rcx)
	movb	9(%rax), %dl
	andb	$15, %dl
	movb	%dl, 18(%rcx)
	movb	9(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 19(%rcx)
	movb	10(%rax), %dl
	andb	$15, %dl
	movb	%dl, 20(%rcx)
	movb	10(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 21(%rcx)
	movb	11(%rax), %dl
	andb	$15, %dl
	movb	%dl, 22(%rcx)
	movb	11(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 23(%rcx)
	movb	12(%rax), %dl
	andb	$15, %dl
	movb	%dl, 24(%rcx)
	movb	12(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 25(%rcx)
	movb	13(%rax), %dl
	andb	$15, %dl
	movb	%dl, 26(%rcx)
	movb	13(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 27(%rcx)
	movb	14(%rax), %dl
	andb	$15, %dl
	movb	%dl, 28(%rcx)
	movb	14(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 29(%rcx)
	movb	15(%rax), %dl
	andb	$15, %dl
	movb	%dl, 30(%rcx)
	movb	15(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 31(%rcx)
	movb	16(%rax), %dl
	andb	$15, %dl
	movb	%dl, 32(%rcx)
	movb	16(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 33(%rcx)
	movb	17(%rax), %dl
	andb	$15, %dl
	movb	%dl, 34(%rcx)
	movb	17(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 35(%rcx)
	movb	18(%rax), %dl
	andb	$15, %dl
	movb	%dl, 36(%rcx)
	movb	18(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 37(%rcx)
	movb	19(%rax), %dl
	andb	$15, %dl
	movb	%dl, 38(%rcx)
	movb	19(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 39(%rcx)
	movb	20(%rax), %dl
	andb	$15, %dl
	movb	%dl, 40(%rcx)
	movb	20(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 41(%rcx)
	movb	21(%rax), %dl
	andb	$15, %dl
	movb	%dl, 42(%rcx)
	movb	21(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 43(%rcx)
	movb	22(%rax), %dl
	andb	$15, %dl
	movb	%dl, 44(%rcx)
	movb	22(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 45(%rcx)
	movb	23(%rax), %dl
	andb	$15, %dl
	movb	%dl, 46(%rcx)
	movb	23(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 47(%rcx)
	movb	24(%rax), %dl
	andb	$15, %dl
	movb	%dl, 48(%rcx)
	movb	24(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 49(%rcx)
	movb	25(%rax), %dl
	andb	$15, %dl
	movb	%dl, 50(%rcx)
	movb	25(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 51(%rcx)
	movb	26(%rax), %dl
	andb	$15, %dl
	movb	%dl, 52(%rcx)
	movb	26(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 53(%rcx)
	movb	27(%rax), %dl
	andb	$15, %dl
	movb	%dl, 54(%rcx)
	movb	27(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 55(%rcx)
	movb	28(%rax), %dl
	andb	$15, %dl
	movb	%dl, 56(%rcx)
	movb	28(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 57(%rcx)
	movb	29(%rax), %dl
	andb	$15, %dl
	movb	%dl, 58(%rcx)
	movb	29(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 59(%rcx)
	movb	30(%rax), %dl
	andb	$15, %dl
	movb	%dl, 60(%rcx)
	movb	30(%rax), %dl
	shrb	$4, %dl
	movb	%dl, 61(%rcx)
	movb	31(%rax), %dl
	andb	$15, %dl
	movb	%dl, 62(%rcx)
	movb	31(%rax), %al
	shrb	$4, %al
	movb	%al, 63(%rcx)
	ret
Lunbitslice_m_vec$1:
	movq	%rdi, %rcx
	leaq	8(%rdi), %rdx
	leaq	16(%rdi), %rsi
	leaq	24(%rdi), %rdi
	movl	(%rcx), %r8d
	shrl	$0, %r8d
	andl	$1, %r8d
	movl	(%rdx), %r9d
	shrl	$0, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	(%rsi), %r9d
	shrl	$0, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	(%rdi), %r9d
	shrl	$0, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, (%rax)
	movl	(%rcx), %r8d
	shrl	$1, %r8d
	andl	$1, %r8d
	movl	(%rdx), %r9d
	shrl	$1, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	(%rsi), %r9d
	shrl	$1, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	(%rdi), %r9d
	shrl	$1, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 1(%rax)
	movl	(%rcx), %r8d
	shrl	$2, %r8d
	andl	$1, %r8d
	movl	(%rdx), %r9d
	shrl	$2, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	(%rsi), %r9d
	shrl	$2, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	(%rdi), %r9d
	shrl	$2, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 2(%rax)
	movl	(%rcx), %r8d
	shrl	$3, %r8d
	andl	$1, %r8d
	movl	(%rdx), %r9d
	shrl	$3, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	(%rsi), %r9d
	shrl	$3, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	(%rdi), %r9d
	shrl	$3, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 3(%rax)
	movl	(%rcx), %r8d
	shrl	$4, %r8d
	andl	$1, %r8d
	movl	(%rdx), %r9d
	shrl	$4, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	(%rsi), %r9d
	shrl	$4, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	(%rdi), %r9d
	shrl	$4, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 4(%rax)
	movl	(%rcx), %r8d
	shrl	$5, %r8d
	andl	$1, %r8d
	movl	(%rdx), %r9d
	shrl	$5, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	(%rsi), %r9d
	shrl	$5, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	(%rdi), %r9d
	shrl	$5, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 5(%rax)
	movl	(%rcx), %r8d
	shrl	$6, %r8d
	andl	$1, %r8d
	movl	(%rdx), %r9d
	shrl	$6, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	(%rsi), %r9d
	shrl	$6, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	(%rdi), %r9d
	shrl	$6, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 6(%rax)
	movl	(%rcx), %r8d
	shrl	$7, %r8d
	andl	$1, %r8d
	movl	(%rdx), %r9d
	shrl	$7, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	(%rsi), %r9d
	shrl	$7, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	(%rdi), %r9d
	shrl	$7, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 7(%rax)
	movl	(%rcx), %r8d
	shrl	$8, %r8d
	andl	$1, %r8d
	movl	(%rdx), %r9d
	shrl	$8, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	(%rsi), %r9d
	shrl	$8, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	(%rdi), %r9d
	shrl	$8, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 8(%rax)
	movl	(%rcx), %r8d
	shrl	$9, %r8d
	andl	$1, %r8d
	movl	(%rdx), %r9d
	shrl	$9, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	(%rsi), %r9d
	shrl	$9, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	(%rdi), %r9d
	shrl	$9, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 9(%rax)
	movl	(%rcx), %r8d
	shrl	$10, %r8d
	andl	$1, %r8d
	movl	(%rdx), %r9d
	shrl	$10, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	(%rsi), %r9d
	shrl	$10, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	(%rdi), %r9d
	shrl	$10, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 10(%rax)
	movl	(%rcx), %r8d
	shrl	$11, %r8d
	andl	$1, %r8d
	movl	(%rdx), %r9d
	shrl	$11, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	(%rsi), %r9d
	shrl	$11, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	(%rdi), %r9d
	shrl	$11, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 11(%rax)
	movl	(%rcx), %r8d
	shrl	$12, %r8d
	andl	$1, %r8d
	movl	(%rdx), %r9d
	shrl	$12, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	(%rsi), %r9d
	shrl	$12, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	(%rdi), %r9d
	shrl	$12, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 12(%rax)
	movl	(%rcx), %r8d
	shrl	$13, %r8d
	andl	$1, %r8d
	movl	(%rdx), %r9d
	shrl	$13, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	(%rsi), %r9d
	shrl	$13, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	(%rdi), %r9d
	shrl	$13, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 13(%rax)
	movl	(%rcx), %r8d
	shrl	$14, %r8d
	andl	$1, %r8d
	movl	(%rdx), %r9d
	shrl	$14, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	(%rsi), %r9d
	shrl	$14, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	(%rdi), %r9d
	shrl	$14, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 14(%rax)
	movl	(%rcx), %r8d
	shrl	$15, %r8d
	andl	$1, %r8d
	movl	(%rdx), %r9d
	shrl	$15, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	(%rsi), %r9d
	shrl	$15, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	(%rdi), %r9d
	shrl	$15, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 15(%rax)
	movl	(%rcx), %r8d
	shrl	$16, %r8d
	andl	$1, %r8d
	movl	(%rdx), %r9d
	shrl	$16, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	(%rsi), %r9d
	shrl	$16, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	(%rdi), %r9d
	shrl	$16, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 16(%rax)
	movl	(%rcx), %r8d
	shrl	$17, %r8d
	andl	$1, %r8d
	movl	(%rdx), %r9d
	shrl	$17, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	(%rsi), %r9d
	shrl	$17, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	(%rdi), %r9d
	shrl	$17, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 17(%rax)
	movl	(%rcx), %r8d
	shrl	$18, %r8d
	andl	$1, %r8d
	movl	(%rdx), %r9d
	shrl	$18, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	(%rsi), %r9d
	shrl	$18, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	(%rdi), %r9d
	shrl	$18, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 18(%rax)
	movl	(%rcx), %r8d
	shrl	$19, %r8d
	andl	$1, %r8d
	movl	(%rdx), %r9d
	shrl	$19, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	(%rsi), %r9d
	shrl	$19, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	(%rdi), %r9d
	shrl	$19, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 19(%rax)
	movl	(%rcx), %r8d
	shrl	$20, %r8d
	andl	$1, %r8d
	movl	(%rdx), %r9d
	shrl	$20, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	(%rsi), %r9d
	shrl	$20, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	(%rdi), %r9d
	shrl	$20, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 20(%rax)
	movl	(%rcx), %r8d
	shrl	$21, %r8d
	andl	$1, %r8d
	movl	(%rdx), %r9d
	shrl	$21, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	(%rsi), %r9d
	shrl	$21, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	(%rdi), %r9d
	shrl	$21, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 21(%rax)
	movl	(%rcx), %r8d
	shrl	$22, %r8d
	andl	$1, %r8d
	movl	(%rdx), %r9d
	shrl	$22, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	(%rsi), %r9d
	shrl	$22, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	(%rdi), %r9d
	shrl	$22, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 22(%rax)
	movl	(%rcx), %r8d
	shrl	$23, %r8d
	andl	$1, %r8d
	movl	(%rdx), %r9d
	shrl	$23, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	(%rsi), %r9d
	shrl	$23, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	(%rdi), %r9d
	shrl	$23, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 23(%rax)
	movl	(%rcx), %r8d
	shrl	$24, %r8d
	andl	$1, %r8d
	movl	(%rdx), %r9d
	shrl	$24, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	(%rsi), %r9d
	shrl	$24, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	(%rdi), %r9d
	shrl	$24, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 24(%rax)
	movl	(%rcx), %r8d
	shrl	$25, %r8d
	andl	$1, %r8d
	movl	(%rdx), %r9d
	shrl	$25, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	(%rsi), %r9d
	shrl	$25, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	(%rdi), %r9d
	shrl	$25, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 25(%rax)
	movl	(%rcx), %r8d
	shrl	$26, %r8d
	andl	$1, %r8d
	movl	(%rdx), %r9d
	shrl	$26, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	(%rsi), %r9d
	shrl	$26, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	(%rdi), %r9d
	shrl	$26, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 26(%rax)
	movl	(%rcx), %r8d
	shrl	$27, %r8d
	andl	$1, %r8d
	movl	(%rdx), %r9d
	shrl	$27, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	(%rsi), %r9d
	shrl	$27, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	(%rdi), %r9d
	shrl	$27, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 27(%rax)
	movl	(%rcx), %r8d
	shrl	$28, %r8d
	andl	$1, %r8d
	movl	(%rdx), %r9d
	shrl	$28, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	(%rsi), %r9d
	shrl	$28, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	(%rdi), %r9d
	shrl	$28, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 28(%rax)
	movl	(%rcx), %r8d
	shrl	$29, %r8d
	andl	$1, %r8d
	movl	(%rdx), %r9d
	shrl	$29, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	(%rsi), %r9d
	shrl	$29, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	(%rdi), %r9d
	shrl	$29, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 29(%rax)
	movl	(%rcx), %r8d
	shrl	$30, %r8d
	andl	$1, %r8d
	movl	(%rdx), %r9d
	shrl	$30, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	(%rsi), %r9d
	shrl	$30, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	(%rdi), %r9d
	shrl	$30, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 30(%rax)
	movl	(%rcx), %r8d
	shrl	$31, %r8d
	andl	$1, %r8d
	movl	(%rdx), %r9d
	shrl	$31, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	(%rsi), %r9d
	shrl	$31, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	(%rdi), %r9d
	shrl	$31, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 31(%rax)
	movl	4(%rcx), %r8d
	shrl	$0, %r8d
	andl	$1, %r8d
	movl	4(%rdx), %r9d
	shrl	$0, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	4(%rsi), %r9d
	shrl	$0, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	4(%rdi), %r9d
	shrl	$0, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 32(%rax)
	movl	4(%rcx), %r8d
	shrl	$1, %r8d
	andl	$1, %r8d
	movl	4(%rdx), %r9d
	shrl	$1, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	4(%rsi), %r9d
	shrl	$1, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	4(%rdi), %r9d
	shrl	$1, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 33(%rax)
	movl	4(%rcx), %r8d
	shrl	$2, %r8d
	andl	$1, %r8d
	movl	4(%rdx), %r9d
	shrl	$2, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	4(%rsi), %r9d
	shrl	$2, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	4(%rdi), %r9d
	shrl	$2, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 34(%rax)
	movl	4(%rcx), %r8d
	shrl	$3, %r8d
	andl	$1, %r8d
	movl	4(%rdx), %r9d
	shrl	$3, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	4(%rsi), %r9d
	shrl	$3, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	4(%rdi), %r9d
	shrl	$3, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 35(%rax)
	movl	4(%rcx), %r8d
	shrl	$4, %r8d
	andl	$1, %r8d
	movl	4(%rdx), %r9d
	shrl	$4, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	4(%rsi), %r9d
	shrl	$4, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	4(%rdi), %r9d
	shrl	$4, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 36(%rax)
	movl	4(%rcx), %r8d
	shrl	$5, %r8d
	andl	$1, %r8d
	movl	4(%rdx), %r9d
	shrl	$5, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	4(%rsi), %r9d
	shrl	$5, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	4(%rdi), %r9d
	shrl	$5, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 37(%rax)
	movl	4(%rcx), %r8d
	shrl	$6, %r8d
	andl	$1, %r8d
	movl	4(%rdx), %r9d
	shrl	$6, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	4(%rsi), %r9d
	shrl	$6, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	4(%rdi), %r9d
	shrl	$6, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 38(%rax)
	movl	4(%rcx), %r8d
	shrl	$7, %r8d
	andl	$1, %r8d
	movl	4(%rdx), %r9d
	shrl	$7, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	4(%rsi), %r9d
	shrl	$7, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	4(%rdi), %r9d
	shrl	$7, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 39(%rax)
	movl	4(%rcx), %r8d
	shrl	$8, %r8d
	andl	$1, %r8d
	movl	4(%rdx), %r9d
	shrl	$8, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	4(%rsi), %r9d
	shrl	$8, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	4(%rdi), %r9d
	shrl	$8, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 40(%rax)
	movl	4(%rcx), %r8d
	shrl	$9, %r8d
	andl	$1, %r8d
	movl	4(%rdx), %r9d
	shrl	$9, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	4(%rsi), %r9d
	shrl	$9, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	4(%rdi), %r9d
	shrl	$9, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 41(%rax)
	movl	4(%rcx), %r8d
	shrl	$10, %r8d
	andl	$1, %r8d
	movl	4(%rdx), %r9d
	shrl	$10, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	4(%rsi), %r9d
	shrl	$10, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	4(%rdi), %r9d
	shrl	$10, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 42(%rax)
	movl	4(%rcx), %r8d
	shrl	$11, %r8d
	andl	$1, %r8d
	movl	4(%rdx), %r9d
	shrl	$11, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	4(%rsi), %r9d
	shrl	$11, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	4(%rdi), %r9d
	shrl	$11, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 43(%rax)
	movl	4(%rcx), %r8d
	shrl	$12, %r8d
	andl	$1, %r8d
	movl	4(%rdx), %r9d
	shrl	$12, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	4(%rsi), %r9d
	shrl	$12, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	4(%rdi), %r9d
	shrl	$12, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 44(%rax)
	movl	4(%rcx), %r8d
	shrl	$13, %r8d
	andl	$1, %r8d
	movl	4(%rdx), %r9d
	shrl	$13, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	4(%rsi), %r9d
	shrl	$13, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	4(%rdi), %r9d
	shrl	$13, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 45(%rax)
	movl	4(%rcx), %r8d
	shrl	$14, %r8d
	andl	$1, %r8d
	movl	4(%rdx), %r9d
	shrl	$14, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	4(%rsi), %r9d
	shrl	$14, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	4(%rdi), %r9d
	shrl	$14, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 46(%rax)
	movl	4(%rcx), %r8d
	shrl	$15, %r8d
	andl	$1, %r8d
	movl	4(%rdx), %r9d
	shrl	$15, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	4(%rsi), %r9d
	shrl	$15, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	4(%rdi), %r9d
	shrl	$15, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 47(%rax)
	movl	4(%rcx), %r8d
	shrl	$16, %r8d
	andl	$1, %r8d
	movl	4(%rdx), %r9d
	shrl	$16, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	4(%rsi), %r9d
	shrl	$16, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	4(%rdi), %r9d
	shrl	$16, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 48(%rax)
	movl	4(%rcx), %r8d
	shrl	$17, %r8d
	andl	$1, %r8d
	movl	4(%rdx), %r9d
	shrl	$17, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	4(%rsi), %r9d
	shrl	$17, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	4(%rdi), %r9d
	shrl	$17, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 49(%rax)
	movl	4(%rcx), %r8d
	shrl	$18, %r8d
	andl	$1, %r8d
	movl	4(%rdx), %r9d
	shrl	$18, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	4(%rsi), %r9d
	shrl	$18, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	4(%rdi), %r9d
	shrl	$18, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 50(%rax)
	movl	4(%rcx), %r8d
	shrl	$19, %r8d
	andl	$1, %r8d
	movl	4(%rdx), %r9d
	shrl	$19, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	4(%rsi), %r9d
	shrl	$19, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	4(%rdi), %r9d
	shrl	$19, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 51(%rax)
	movl	4(%rcx), %r8d
	shrl	$20, %r8d
	andl	$1, %r8d
	movl	4(%rdx), %r9d
	shrl	$20, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	4(%rsi), %r9d
	shrl	$20, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	4(%rdi), %r9d
	shrl	$20, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 52(%rax)
	movl	4(%rcx), %r8d
	shrl	$21, %r8d
	andl	$1, %r8d
	movl	4(%rdx), %r9d
	shrl	$21, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	4(%rsi), %r9d
	shrl	$21, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	4(%rdi), %r9d
	shrl	$21, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 53(%rax)
	movl	4(%rcx), %r8d
	shrl	$22, %r8d
	andl	$1, %r8d
	movl	4(%rdx), %r9d
	shrl	$22, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	4(%rsi), %r9d
	shrl	$22, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	4(%rdi), %r9d
	shrl	$22, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 54(%rax)
	movl	4(%rcx), %r8d
	shrl	$23, %r8d
	andl	$1, %r8d
	movl	4(%rdx), %r9d
	shrl	$23, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	4(%rsi), %r9d
	shrl	$23, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	4(%rdi), %r9d
	shrl	$23, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 55(%rax)
	movl	4(%rcx), %r8d
	shrl	$24, %r8d
	andl	$1, %r8d
	movl	4(%rdx), %r9d
	shrl	$24, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	4(%rsi), %r9d
	shrl	$24, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	4(%rdi), %r9d
	shrl	$24, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 56(%rax)
	movl	4(%rcx), %r8d
	shrl	$25, %r8d
	andl	$1, %r8d
	movl	4(%rdx), %r9d
	shrl	$25, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	4(%rsi), %r9d
	shrl	$25, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	4(%rdi), %r9d
	shrl	$25, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 57(%rax)
	movl	4(%rcx), %r8d
	shrl	$26, %r8d
	andl	$1, %r8d
	movl	4(%rdx), %r9d
	shrl	$26, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	4(%rsi), %r9d
	shrl	$26, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	4(%rdi), %r9d
	shrl	$26, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 58(%rax)
	movl	4(%rcx), %r8d
	shrl	$27, %r8d
	andl	$1, %r8d
	movl	4(%rdx), %r9d
	shrl	$27, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	4(%rsi), %r9d
	shrl	$27, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	4(%rdi), %r9d
	shrl	$27, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 59(%rax)
	movl	4(%rcx), %r8d
	shrl	$28, %r8d
	andl	$1, %r8d
	movl	4(%rdx), %r9d
	shrl	$28, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	4(%rsi), %r9d
	shrl	$28, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	4(%rdi), %r9d
	shrl	$28, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 60(%rax)
	movl	4(%rcx), %r8d
	shrl	$29, %r8d
	andl	$1, %r8d
	movl	4(%rdx), %r9d
	shrl	$29, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	4(%rsi), %r9d
	shrl	$29, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	4(%rdi), %r9d
	shrl	$29, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 61(%rax)
	movl	4(%rcx), %r8d
	shrl	$30, %r8d
	andl	$1, %r8d
	movl	4(%rdx), %r9d
	shrl	$30, %r9d
	andl	$1, %r9d
	shll	$1, %r9d
	xorl	%r9d, %r8d
	movl	4(%rsi), %r9d
	shrl	$30, %r9d
	andl	$1, %r9d
	shll	$2, %r9d
	xorl	%r9d, %r8d
	movl	4(%rdi), %r9d
	shrl	$30, %r9d
	andl	$1, %r9d
	shll	$3, %r9d
	xorl	%r9d, %r8d
	movb	%r8b, 62(%rax)
	movl	4(%rcx), %ecx
	shrl	$31, %ecx
	andl	$1, %ecx
	movl	4(%rdx), %edx
	shrl	$31, %edx
	andl	$1, %edx
	shll	$1, %edx
	xorl	%edx, %ecx
	movl	4(%rsi), %edx
	shrl	$31, %edx
	andl	$1, %edx
	shll	$2, %edx
	xorl	%edx, %ecx
	movl	4(%rdi), %edx
	shrl	$31, %edx
	andl	$1, %edx
	shll	$3, %edx
	xorl	%edx, %ecx
	movb	%cl, 63(%rax)
	ret
Lbitsliced_m_upper$1:
	movq	%rax, %rdx
	movq	%rcx, %rsi
	call	Lbitsliced_64_vec_copy$1
Lbitsliced_m_upper$17:
	leaq	32(%rax), %rdx
	leaq	32(%rcx), %rsi
	call	Lbitsliced_64_vec_copy$1
Lbitsliced_m_upper$16:
	leaq	128(%rax), %rdx
	leaq	32(%rcx), %rsi
	call	Lbitsliced_64_vec_add$1
Lbitsliced_m_upper$15:
	leaq	64(%rax), %rdx
	leaq	64(%rcx), %rsi
	call	Lbitsliced_64_vec_copy$1
Lbitsliced_m_upper$14:
	leaq	256(%rax), %rdx
	leaq	64(%rcx), %rsi
	call	Lbitsliced_64_vec_add$1
Lbitsliced_m_upper$13:
	leaq	96(%rax), %rdx
	leaq	96(%rcx), %rsi
	call	Lbitsliced_64_vec_copy$1
Lbitsliced_m_upper$12:
	leaq	384(%rax), %rdx
	leaq	96(%rcx), %rsi
	call	Lbitsliced_64_vec_add$1
Lbitsliced_m_upper$11:
	leaq	160(%rax), %rdx
	leaq	128(%rcx), %rsi
	call	Lbitsliced_64_vec_copy$1
Lbitsliced_m_upper$10:
	leaq	192(%rax), %rdx
	leaq	160(%rcx), %rsi
	call	Lbitsliced_64_vec_copy$1
Lbitsliced_m_upper$9:
	leaq	288(%rax), %rdx
	leaq	160(%rcx), %rsi
	call	Lbitsliced_64_vec_add$1
Lbitsliced_m_upper$8:
	leaq	224(%rax), %rdx
	leaq	192(%rcx), %rsi
	call	Lbitsliced_64_vec_copy$1
Lbitsliced_m_upper$7:
	leaq	416(%rax), %rdx
	leaq	192(%rcx), %rsi
	call	Lbitsliced_64_vec_add$1
Lbitsliced_m_upper$6:
	leaq	320(%rax), %rdx
	leaq	224(%rcx), %rsi
	call	Lbitsliced_64_vec_copy$1
Lbitsliced_m_upper$5:
	leaq	352(%rax), %rdx
	leaq	256(%rcx), %rsi
	call	Lbitsliced_64_vec_copy$1
Lbitsliced_m_upper$4:
	leaq	448(%rax), %rdx
	leaq	256(%rcx), %rsi
	call	Lbitsliced_64_vec_add$1
Lbitsliced_m_upper$3:
	leaq	480(%rax), %rdx
	leaq	288(%rcx), %rsi
	call	Lbitsliced_64_vec_copy$1
Lbitsliced_m_upper$2:
	ret
Lbitsliced_m_vec_add$1:
	movl	(%rax), %esi
	movl	(%rcx), %edi
	xorl	%edi, %esi
	movl	%esi, (%rcx)
	movl	4(%rax), %esi
	movl	4(%rcx), %edi
	xorl	%edi, %esi
	movl	%esi, 4(%rcx)
	movl	8(%rax), %esi
	movl	8(%rcx), %edi
	xorl	%edi, %esi
	movl	%esi, 8(%rcx)
	movl	12(%rax), %esi
	movl	12(%rcx), %edi
	xorl	%edi, %esi
	movl	%esi, 12(%rcx)
	movl	16(%rax), %esi
	movl	16(%rcx), %edi
	xorl	%edi, %esi
	movl	%esi, 16(%rcx)
	movl	20(%rax), %esi
	movl	20(%rcx), %edi
	xorl	%edi, %esi
	movl	%esi, 20(%rcx)
	movl	24(%rax), %esi
	movl	24(%rcx), %edi
	xorl	%edi, %esi
	movl	%esi, 24(%rcx)
	movl	28(%rax), %eax
	movl	28(%rcx), %esi
	xorl	%esi, %eax
	movl	%eax, 28(%rcx)
	ret
Lbitsliced_64_vec_add$1:
	movq	(%rdx), %rdi
	movq	(%rsi), %r8
	xorq	%r8, %rdi
	movq	%rdi, (%rsi)
	movq	8(%rdx), %rdi
	movq	8(%rsi), %r8
	xorq	%r8, %rdi
	movq	%rdi, 8(%rsi)
	movq	16(%rdx), %rdi
	movq	16(%rsi), %r8
	xorq	%r8, %rdi
	movq	%rdi, 16(%rsi)
	movq	24(%rdx), %rdx
	movq	24(%rsi), %rdi
	xorq	%rdi, %rdx
	movq	%rdx, 24(%rsi)
	ret
Lbitsliced_m_vec_copy$1:
	movl	(%rax), %ecx
	movl	%ecx, (%rdx)
	movl	4(%rax), %ecx
	movl	%ecx, 4(%rdx)
	movl	8(%rax), %ecx
	movl	%ecx, 8(%rdx)
	movl	12(%rax), %ecx
	movl	%ecx, 12(%rdx)
	movl	16(%rax), %ecx
	movl	%ecx, 16(%rdx)
	movl	20(%rax), %ecx
	movl	%ecx, 20(%rdx)
	movl	24(%rax), %ecx
	movl	%ecx, 24(%rdx)
	movl	28(%rax), %eax
	movl	%eax, 28(%rdx)
	ret
Lbitsliced_64_vec_copy$1:
	movq	(%rdx), %rdi
	movq	%rdi, (%rsi)
	movq	8(%rdx), %rdi
	movq	%rdi, 8(%rsi)
	movq	16(%rdx), %rdi
	movq	%rdi, 16(%rsi)
	movq	24(%rdx), %rdx
	movq	%rdx, 24(%rsi)
	ret
Lbitsliced_m_vec_mul_add_2$1:
	movq	%rax, %rdi
	leaq	8(%rax), %r11
	leaq	16(%rax), %r9
	leaq	24(%rax), %r8
	movq	%rsi, %r10
	leaq	8(%rsi), %rbx
	leaq	16(%rsi), %rbp
	leaq	24(%rsi), %rsi
	movl	%edx, 8(%rsp)
	andl	$1, 8(%rsp)
	negl	8(%rsp)
	movl	%edx, 12(%rsp)
	shrl	$1, 12(%rsp)
	andl	$1, 12(%rsp)
	negl	12(%rsp)
	movl	%edx, 16(%rsp)
	shrl	$2, 16(%rsp)
	andl	$1, 16(%rsp)
	negl	16(%rsp)
	movl	%edx, 20(%rsp)
	shrl	$3, 20(%rsp)
	andl	$1, 20(%rsp)
	negl	20(%rsp)
	movl	8(%rsp), %eax
	andl	(%rdi), %eax
	xorl	%eax, (%r10)
	movl	8(%rsp), %eax
	andl	(%r11), %eax
	xorl	%eax, (%rbx)
	movl	8(%rsp), %eax
	andl	(%r9), %eax
	xorl	%eax, (%rbp)
	movl	8(%rsp), %eax
	andl	(%r8), %eax
	xorl	%eax, (%rsi)
	movl	(%rdi), %eax
	xorl	(%r8), %eax
	movl	%eax, 24(%rsp)
	movl	12(%rsp), %eax
	andl	(%r8), %eax
	xorl	%eax, (%r10)
	movl	12(%rsp), %eax
	andl	24(%rsp), %eax
	xorl	%eax, (%rbx)
	movl	12(%rsp), %eax
	andl	(%r11), %eax
	xorl	%eax, (%rbp)
	movl	12(%rsp), %eax
	andl	(%r9), %eax
	xorl	%eax, (%rsi)
	movl	(%r8), %eax
	xorl	(%r9), %eax
	movl	%eax, 28(%rsp)
	movl	16(%rsp), %eax
	andl	(%r9), %eax
	xorl	%eax, (%r10)
	movl	16(%rsp), %eax
	andl	28(%rsp), %eax
	xorl	%eax, (%rbx)
	movl	16(%rsp), %eax
	andl	24(%rsp), %eax
	xorl	%eax, (%rbp)
	movl	16(%rsp), %eax
	andl	(%r11), %eax
	xorl	%eax, (%rsi)
	movl	(%r9), %eax
	xorl	(%r11), %eax
	movl	%eax, 32(%rsp)
	movl	20(%rsp), %eax
	andl	(%r11), %eax
	xorl	%eax, (%r10)
	movl	20(%rsp), %eax
	andl	32(%rsp), %eax
	xorl	%eax, (%rbx)
	movl	20(%rsp), %eax
	andl	28(%rsp), %eax
	xorl	%eax, (%rbp)
	movl	20(%rsp), %eax
	andl	24(%rsp), %eax
	xorl	%eax, (%rsi)
	movl	8(%rsp), %eax
	andl	4(%rdi), %eax
	xorl	%eax, 4(%r10)
	movl	8(%rsp), %eax
	andl	4(%r11), %eax
	xorl	%eax, 4(%rbx)
	movl	8(%rsp), %eax
	andl	4(%r9), %eax
	xorl	%eax, 4(%rbp)
	movl	8(%rsp), %eax
	andl	4(%r8), %eax
	xorl	%eax, 4(%rsi)
	movl	4(%rdi), %eax
	xorl	4(%r8), %eax
	movl	%eax, 8(%rsp)
	movl	12(%rsp), %eax
	andl	4(%r8), %eax
	xorl	%eax, 4(%r10)
	movl	12(%rsp), %eax
	andl	8(%rsp), %eax
	xorl	%eax, 4(%rbx)
	movl	12(%rsp), %eax
	andl	4(%r11), %eax
	xorl	%eax, 4(%rbp)
	movl	12(%rsp), %eax
	andl	4(%r9), %eax
	xorl	%eax, 4(%rsi)
	movl	4(%r8), %eax
	xorl	4(%r9), %eax
	movl	%eax, 12(%rsp)
	movl	16(%rsp), %eax
	andl	4(%r9), %eax
	xorl	%eax, 4(%r10)
	movl	16(%rsp), %eax
	andl	12(%rsp), %eax
	xorl	%eax, 4(%rbx)
	movl	16(%rsp), %eax
	andl	8(%rsp), %eax
	xorl	%eax, 4(%rbp)
	movl	16(%rsp), %eax
	andl	4(%r11), %eax
	xorl	%eax, 4(%rsi)
	movl	4(%r9), %eax
	xorl	4(%r11), %eax
	movl	%eax, 16(%rsp)
	movl	20(%rsp), %eax
	andl	4(%r11), %eax
	xorl	%eax, 4(%r10)
	movl	20(%rsp), %eax
	andl	16(%rsp), %eax
	xorl	%eax, 4(%rbx)
	movl	20(%rsp), %eax
	andl	12(%rsp), %eax
	xorl	%eax, 4(%rbp)
	movl	20(%rsp), %eax
	andl	8(%rsp), %eax
	xorl	%eax, 4(%rsi)
	ret
L_keccak1600_32_56$1:
	movq	%rax, 8(%rsp)
	movb	%dil, 248(%rsp)
	leaq	48(%rsp), %rax
	xorq	%rsi, %rsi
	movq	%rsi, (%rax)
	movq	%rsi, 8(%rax)
	movq	%rsi, 16(%rax)
	movq	%rsi, 24(%rax)
	movq	%rsi, 32(%rax)
	movq	%rsi, 40(%rax)
	movq	%rsi, 48(%rax)
	movq	%rsi, 56(%rax)
	movq	%rsi, 64(%rax)
	movq	%rsi, 72(%rax)
	movq	%rsi, 80(%rax)
	movq	%rsi, 88(%rax)
	movq	%rsi, 96(%rax)
	movq	%rsi, 104(%rax)
	movq	%rsi, 112(%rax)
	movq	%rsi, 120(%rax)
	movq	%rsi, 128(%rax)
	movq	%rsi, 136(%rax)
	movq	%rsi, 144(%rax)
	movq	%rsi, 152(%rax)
	movq	%rsi, 160(%rax)
	movq	%rsi, 168(%rax)
	movq	%rsi, 176(%rax)
	movq	%rsi, 184(%rax)
	movq	%rsi, 192(%rax)
	movq	$0, %rsi
	movq	$56, %rdi
	jmp 	L_keccak1600_32_56$16
L_keccak1600_32_56$17:
	subq	%rcx, %rdi
	movq	%rcx, %r8
	shrq	$3, %r8
	movq	$0, %r9
	jmp 	L_keccak1600_32_56$19
L_keccak1600_32_56$20:
	movq	(%rdx,%rsi,8), %r10
	xorq	%r10, (%rax,%r9,8)
	leaq	1(%r9), %r9
	leaq	1(%rsi), %rsi
L_keccak1600_32_56$19:
	cmpq	%r8, %r9
	jb  	L_keccak1600_32_56$20
	movq	%rdx, 16(%rsp)
	movq	%rdi, 24(%rsp)
	movq	%rsi, 32(%rsp)
	movq	%rcx, 40(%rsp)
	leaq	-224(%rsp), %rsp
	call	L_keccakf1600$1
L_keccak1600_32_56$18:
	leaq	224(%rsp), %rsp
	movq	16(%rsp), %rdx
	movq	24(%rsp), %rdi
	movq	32(%rsp), %rsi
	movq	40(%rsp), %rcx
L_keccak1600_32_56$16:
	cmpq	%rcx, %rdi
	jnb 	L_keccak1600_32_56$17
	movb	248(%rsp), %dil
	movq	%rsi, %r8
	shlq	$3, %r8
	movq	$56, %r9
	subq	%r8, %r9
	shrq	$3, %r9
	movq	$0, %r8
	jmp 	L_keccak1600_32_56$14
L_keccak1600_32_56$15:
	movq	(%rdx,%rsi,8), %r10
	xorq	%r10, (%rax,%r8,8)
	leaq	1(%r8), %r8
	leaq	1(%rsi), %rsi
L_keccak1600_32_56$14:
	cmpq	%r9, %r8
	jb  	L_keccak1600_32_56$15
	shlq	$3, %rsi
	shlq	$3, %r8
	movq	$56, %r9
	jmp 	L_keccak1600_32_56$12
L_keccak1600_32_56$13:
	movb	(%rdx,%rsi), %r10b
	xorb	%r10b, (%rax,%r8)
	leaq	1(%r8), %r8
	leaq	1(%rsi), %rsi
L_keccak1600_32_56$12:
	cmpq	%r9, %rsi
	jb  	L_keccak1600_32_56$13
	xorb	%dil, (%rax,%r8)
	movq	%rcx, %rdx
	leaq	-1(%rdx), %rdx
	xorb	$128, (%rax,%rdx)
	movq	8(%rsp), %rdx
	movq	$0, %rdi
	movq	$32, %rsi
	jmp 	L_keccak1600_32_56$7
L_keccak1600_32_56$8:
	subq	%rcx, %rsi
	movq	%rdx, 8(%rsp)
	movq	%rdi, 40(%rsp)
	movq	%rsi, 32(%rsp)
	movq	%rcx, 24(%rsp)
	leaq	-224(%rsp), %rsp
	call	L_keccakf1600$1
L_keccak1600_32_56$11:
	leaq	224(%rsp), %rsp
	movq	8(%rsp), %rdx
	movq	40(%rsp), %rdi
	movq	32(%rsp), %rsi
	movq	24(%rsp), %rcx
	movq	%rcx, %r8
	shrq	$3, %r8
	movq	$0, %r9
	jmp 	L_keccak1600_32_56$9
L_keccak1600_32_56$10:
	movq	(%rax,%r9,8), %r10
	movq	%r10, (%rdx,%rdi,8)
	leaq	1(%r9), %r9
	leaq	1(%rdi), %rdi
L_keccak1600_32_56$9:
	cmpq	%r8, %r9
	jb  	L_keccak1600_32_56$10
L_keccak1600_32_56$7:
	cmpq	%rcx, %rsi
	jnbe	L_keccak1600_32_56$8
	movq	%rdx, 24(%rsp)
	movq	%rdi, 32(%rsp)
	leaq	-224(%rsp), %rsp
	call	L_keccakf1600$1
L_keccak1600_32_56$6:
	leaq	224(%rsp), %rsp
	movq	24(%rsp), %rcx
	movq	32(%rsp), %rdx
	movq	%rdx, %rsi
	shlq	$3, %rsi
	movq	$32, %rdi
	subq	%rsi, %rdi
	shrq	$3, %rdi
	movq	$0, %rsi
	jmp 	L_keccak1600_32_56$4
L_keccak1600_32_56$5:
	movq	(%rax,%rsi,8), %r8
	movq	%r8, (%rcx,%rdx,8)
	leaq	1(%rsi), %rsi
	leaq	1(%rdx), %rdx
L_keccak1600_32_56$4:
	cmpq	%rdi, %rsi
	jb  	L_keccak1600_32_56$5
	shlq	$3, %rdx
	shlq	$3, %rsi
	movq	$32, %rdi
	jmp 	L_keccak1600_32_56$2
L_keccak1600_32_56$3:
	movb	(%rax,%rsi), %r8b
	movb	%r8b, (%rcx,%rdx)
	leaq	1(%rsi), %rsi
	leaq	1(%rdx), %rdx
L_keccak1600_32_56$2:
	cmpq	%rdi, %rdx
	jb  	L_keccak1600_32_56$3
	ret
L_keccak1600_32_x$1:
	movq	%rax, 8(%rsp)
	movb	%r8b, 240(%rsp)
	leaq	40(%rsp), %rax
	xorq	%r8, %r8
	movq	%r8, (%rax)
	movq	%r8, 8(%rax)
	movq	%r8, 16(%rax)
	movq	%r8, 24(%rax)
	movq	%r8, 32(%rax)
	movq	%r8, 40(%rax)
	movq	%r8, 48(%rax)
	movq	%r8, 56(%rax)
	movq	%r8, 64(%rax)
	movq	%r8, 72(%rax)
	movq	%r8, 80(%rax)
	movq	%r8, 88(%rax)
	movq	%r8, 96(%rax)
	movq	%r8, 104(%rax)
	movq	%r8, 112(%rax)
	movq	%r8, 120(%rax)
	movq	%r8, 128(%rax)
	movq	%r8, 136(%rax)
	movq	%r8, 144(%rax)
	movq	%r8, 152(%rax)
	movq	%r8, 160(%rax)
	movq	%r8, 168(%rax)
	movq	%r8, 176(%rax)
	movq	%r8, 184(%rax)
	movq	%r8, 192(%rax)
	jmp 	L_keccak1600_32_x$16
L_keccak1600_32_x$17:
	subq	%rsi, %rdx
	movq	%rsi, %r8
	shrq	$3, %r8
	movq	$0, %r9
	jmp 	L_keccak1600_32_x$19
L_keccak1600_32_x$20:
	movq	(%rdi,%r9,8), %r10
	xorq	%r10, (%rax,%r9,8)
	leaq	1(%r9), %r9
L_keccak1600_32_x$19:
	cmpq	%r8, %r9
	jb  	L_keccak1600_32_x$20
	leaq	(%rdi,%rsi), %rdi
	subq	%rsi, %rdx
	movq	%rdi, 16(%rsp)
	movq	%rdx, 24(%rsp)
	movq	%rsi, 32(%rsp)
	leaq	-224(%rsp), %rsp
	call	L_keccakf1600$1
L_keccak1600_32_x$18:
	leaq	224(%rsp), %rsp
	movq	16(%rsp), %rdi
	movq	24(%rsp), %rdx
	movq	32(%rsp), %rsi
L_keccak1600_32_x$16:
	cmpq	%rsi, %rdx
	jnb 	L_keccak1600_32_x$17
	movb	240(%rsp), %r8b
	movq	%rdx, %r9
	shrq	$3, %r9
	movq	$0, %r10
	jmp 	L_keccak1600_32_x$14
L_keccak1600_32_x$15:
	movq	(%rdi,%r10,8), %r11
	xorq	%r11, (%rax,%r10,8)
	leaq	1(%r10), %r10
L_keccak1600_32_x$14:
	cmpq	%r9, %r10
	jb  	L_keccak1600_32_x$15
	shlq	$3, %r10
	jmp 	L_keccak1600_32_x$12
L_keccak1600_32_x$13:
	movb	(%rdi,%r10), %r9b
	xorb	%r9b, (%rax,%r10)
	leaq	1(%r10), %r10
L_keccak1600_32_x$12:
	cmpq	%rdx, %r10
	jb  	L_keccak1600_32_x$13
	xorb	%r8b, (%rax,%r10)
	movq	%rsi, %rdx
	leaq	-1(%rdx), %rdx
	xorb	$128, (%rax,%rdx)
	movq	8(%rsp), %rdx
	movq	$0, %r8
	movq	$32, %rdi
	jmp 	L_keccak1600_32_x$7
L_keccak1600_32_x$8:
	subq	%rsi, %rdi
	movq	%rdx, 8(%rsp)
	movq	%r8, 32(%rsp)
	movq	%rdi, 24(%rsp)
	movq	%rsi, 16(%rsp)
	leaq	-224(%rsp), %rsp
	call	L_keccakf1600$1
L_keccak1600_32_x$11:
	leaq	224(%rsp), %rsp
	movq	8(%rsp), %rdx
	movq	32(%rsp), %r8
	movq	24(%rsp), %rdi
	movq	16(%rsp), %rsi
	movq	%rsi, %r9
	shrq	$3, %r9
	movq	$0, %r10
	jmp 	L_keccak1600_32_x$9
L_keccak1600_32_x$10:
	movq	(%rax,%r10,8), %r11
	movq	%r11, (%rdx,%r8,8)
	leaq	1(%r10), %r10
	leaq	1(%r8), %r8
L_keccak1600_32_x$9:
	cmpq	%r9, %r10
	jb  	L_keccak1600_32_x$10
L_keccak1600_32_x$7:
	cmpq	%rsi, %rdi
	jnbe	L_keccak1600_32_x$8
	movq	%rdx, 16(%rsp)
	movq	%r8, 24(%rsp)
	leaq	-224(%rsp), %rsp
	call	L_keccakf1600$1
L_keccak1600_32_x$6:
	leaq	224(%rsp), %rsp
	movq	16(%rsp), %rdx
	movq	24(%rsp), %rsi
	movq	%rsi, %rdi
	shlq	$3, %rdi
	movq	$32, %r8
	subq	%rdi, %r8
	shrq	$3, %r8
	movq	$0, %rdi
	jmp 	L_keccak1600_32_x$4
L_keccak1600_32_x$5:
	movq	(%rax,%rdi,8), %r9
	movq	%r9, (%rdx,%rsi,8)
	leaq	1(%rdi), %rdi
	leaq	1(%rsi), %rsi
L_keccak1600_32_x$4:
	cmpq	%r8, %rdi
	jb  	L_keccak1600_32_x$5
	shlq	$3, %rsi
	shlq	$3, %rdi
	movq	$32, %r8
	jmp 	L_keccak1600_32_x$2
L_keccak1600_32_x$3:
	movb	(%rax,%rdi), %r9b
	movb	%r9b, (%rdx,%rsi)
	leaq	1(%rdi), %rdi
	leaq	1(%rsi), %rsi
L_keccak1600_32_x$2:
	cmpq	%r8, %rsi
	jb  	L_keccak1600_32_x$3
	ret
L_keccakf1600$1:
	leaq	glob_data + 16(%rip), %rdx
	movq	%rdx, 8(%rsp)
	leaq	32(%rsp), %rdx
	movq	$0, %rsi
	jmp 	L_keccakf1600$2
L_keccakf1600$3:
	movq	%rsi, 16(%rsp)
	movq	8(%rsp), %rdi
	movq	(%rdi,%rsi,8), %rdi
	movq	%rdi, 24(%rsp)
	movq	(%rax), %r11
	movq	8(%rax), %r10
	movq	16(%rax), %rbx
	movq	24(%rax), %rbp
	movq	32(%rax), %r12
	xorq	40(%rax), %r11
	xorq	48(%rax), %r10
	xorq	56(%rax), %rbx
	xorq	64(%rax), %rbp
	xorq	72(%rax), %r12
	xorq	80(%rax), %r11
	xorq	88(%rax), %r10
	xorq	96(%rax), %rbx
	xorq	104(%rax), %rbp
	xorq	112(%rax), %r12
	xorq	120(%rax), %r11
	xorq	128(%rax), %r10
	xorq	136(%rax), %rbx
	xorq	144(%rax), %rbp
	xorq	152(%rax), %r12
	xorq	160(%rax), %r11
	xorq	168(%rax), %r10
	xorq	176(%rax), %rbx
	xorq	184(%rax), %rbp
	xorq	192(%rax), %r12
	movq	%r10, %rdi
	rolq	$1, %rdi
	xorq	%r12, %rdi
	movq	%rbx, %r8
	rolq	$1, %r8
	xorq	%r11, %r8
	movq	%rbp, %r9
	rolq	$1, %r9
	xorq	%r10, %r9
	movq	%r12, %r10
	rolq	$1, %r10
	xorq	%rbx, %r10
	rolq	$1, %r11
	xorq	%rbp, %r11
	movq	(%rax), %rbx
	xorq	%rdi, %rbx
	movq	48(%rax), %rbp
	xorq	%r8, %rbp
	rolq	$44, %rbp
	movq	96(%rax), %r12
	xorq	%r9, %r12
	rolq	$43, %r12
	movq	144(%rax), %r13
	xorq	%r10, %r13
	rolq	$21, %r13
	movq	192(%rax), %r14
	xorq	%r11, %r14
	rolq	$14, %r14
	andnq	%r12, %rbp, %r15
	xorq	%rbx, %r15
	xorq	24(%rsp), %r15
	movq	%r15, (%rdx)
	andnq	%r13, %r12, %r15
	xorq	%rbp, %r15
	movq	%r15, 8(%rdx)
	andnq	%r14, %r13, %r15
	xorq	%r12, %r15
	movq	%r15, 16(%rdx)
	andnq	%rbx, %r14, %r12
	xorq	%r13, %r12
	movq	%r12, 24(%rdx)
	andnq	%rbp, %rbx, %rbx
	xorq	%r14, %rbx
	movq	%rbx, 32(%rdx)
	movq	24(%rax), %rbx
	xorq	%r10, %rbx
	rolq	$28, %rbx
	movq	72(%rax), %rbp
	xorq	%r11, %rbp
	rolq	$20, %rbp
	movq	80(%rax), %r12
	xorq	%rdi, %r12
	rolq	$3, %r12
	movq	128(%rax), %r13
	xorq	%r8, %r13
	rolq	$45, %r13
	movq	176(%rax), %r14
	xorq	%r9, %r14
	rolq	$61, %r14
	andnq	%r12, %rbp, %r15
	xorq	%rbx, %r15
	movq	%r15, 40(%rdx)
	andnq	%r13, %r12, %r15
	xorq	%rbp, %r15
	movq	%r15, 48(%rdx)
	andnq	%r14, %r13, %r15
	xorq	%r12, %r15
	movq	%r15, 56(%rdx)
	andnq	%rbx, %r14, %r12
	xorq	%r13, %r12
	movq	%r12, 64(%rdx)
	andnq	%rbp, %rbx, %rbx
	xorq	%r14, %rbx
	movq	%rbx, 72(%rdx)
	movq	8(%rax), %rbx
	xorq	%r8, %rbx
	rolq	$1, %rbx
	movq	56(%rax), %rbp
	xorq	%r9, %rbp
	rolq	$6, %rbp
	movq	104(%rax), %r12
	xorq	%r10, %r12
	rolq	$25, %r12
	movq	152(%rax), %r13
	xorq	%r11, %r13
	rolq	$8, %r13
	movq	160(%rax), %r14
	xorq	%rdi, %r14
	rolq	$18, %r14
	andnq	%r12, %rbp, %r15
	xorq	%rbx, %r15
	movq	%r15, 80(%rdx)
	andnq	%r13, %r12, %r15
	xorq	%rbp, %r15
	movq	%r15, 88(%rdx)
	andnq	%r14, %r13, %r15
	xorq	%r12, %r15
	movq	%r15, 96(%rdx)
	andnq	%rbx, %r14, %r12
	xorq	%r13, %r12
	movq	%r12, 104(%rdx)
	andnq	%rbp, %rbx, %rbx
	xorq	%r14, %rbx
	movq	%rbx, 112(%rdx)
	movq	32(%rax), %rbx
	xorq	%r11, %rbx
	rolq	$27, %rbx
	movq	40(%rax), %rbp
	xorq	%rdi, %rbp
	rolq	$36, %rbp
	movq	88(%rax), %r12
	xorq	%r8, %r12
	rolq	$10, %r12
	movq	136(%rax), %r13
	xorq	%r9, %r13
	rolq	$15, %r13
	movq	184(%rax), %r14
	xorq	%r10, %r14
	rolq	$56, %r14
	andnq	%r12, %rbp, %r15
	xorq	%rbx, %r15
	movq	%r15, 120(%rdx)
	andnq	%r13, %r12, %r15
	xorq	%rbp, %r15
	movq	%r15, 128(%rdx)
	andnq	%r14, %r13, %r15
	xorq	%r12, %r15
	movq	%r15, 136(%rdx)
	andnq	%rbx, %r14, %r12
	xorq	%r13, %r12
	movq	%r12, 144(%rdx)
	andnq	%rbp, %rbx, %rbx
	xorq	%r14, %rbx
	movq	%rbx, 152(%rdx)
	movq	16(%rax), %rbx
	xorq	%r9, %rbx
	rolq	$62, %rbx
	movq	64(%rax), %r9
	xorq	%r10, %r9
	rolq	$55, %r9
	movq	112(%rax), %r10
	xorq	%r11, %r10
	rolq	$39, %r10
	movq	120(%rax), %r11
	xorq	%rdi, %r11
	rolq	$41, %r11
	movq	168(%rax), %rdi
	xorq	%r8, %rdi
	rolq	$2, %rdi
	andnq	%r10, %r9, %r8
	xorq	%rbx, %r8
	movq	%r8, 160(%rdx)
	andnq	%r11, %r10, %r8
	xorq	%r9, %r8
	movq	%r8, 168(%rdx)
	andnq	%rdi, %r11, %r8
	xorq	%r10, %r8
	movq	%r8, 176(%rdx)
	andnq	%rbx, %rdi, %r8
	xorq	%r11, %r8
	movq	%r8, 184(%rdx)
	andnq	%r9, %rbx, %r8
	xorq	%rdi, %r8
	movq	%r8, 192(%rdx)
	movq	8(%rsp), %rdi
	movq	8(%rdi,%rsi,8), %rsi
	movq	%rsi, 24(%rsp)
	movq	(%rdx), %r10
	movq	8(%rdx), %r9
	movq	16(%rdx), %r11
	movq	24(%rdx), %rbx
	movq	32(%rdx), %rbp
	xorq	40(%rdx), %r10
	xorq	48(%rdx), %r9
	xorq	56(%rdx), %r11
	xorq	64(%rdx), %rbx
	xorq	72(%rdx), %rbp
	xorq	80(%rdx), %r10
	xorq	88(%rdx), %r9
	xorq	96(%rdx), %r11
	xorq	104(%rdx), %rbx
	xorq	112(%rdx), %rbp
	xorq	120(%rdx), %r10
	xorq	128(%rdx), %r9
	xorq	136(%rdx), %r11
	xorq	144(%rdx), %rbx
	xorq	152(%rdx), %rbp
	xorq	160(%rdx), %r10
	xorq	168(%rdx), %r9
	xorq	176(%rdx), %r11
	xorq	184(%rdx), %rbx
	xorq	192(%rdx), %rbp
	movq	%r9, %rsi
	rolq	$1, %rsi
	xorq	%rbp, %rsi
	movq	%r11, %rdi
	rolq	$1, %rdi
	xorq	%r10, %rdi
	movq	%rbx, %r8
	rolq	$1, %r8
	xorq	%r9, %r8
	movq	%rbp, %r9
	rolq	$1, %r9
	xorq	%r11, %r9
	rolq	$1, %r10
	xorq	%rbx, %r10
	movq	(%rdx), %r11
	xorq	%rsi, %r11
	movq	48(%rdx), %rbx
	xorq	%rdi, %rbx
	rolq	$44, %rbx
	movq	96(%rdx), %rbp
	xorq	%r8, %rbp
	rolq	$43, %rbp
	movq	144(%rdx), %r12
	xorq	%r9, %r12
	rolq	$21, %r12
	movq	192(%rdx), %r13
	xorq	%r10, %r13
	rolq	$14, %r13
	andnq	%rbp, %rbx, %r14
	xorq	%r11, %r14
	xorq	24(%rsp), %r14
	movq	%r14, (%rax)
	andnq	%r12, %rbp, %r14
	xorq	%rbx, %r14
	movq	%r14, 8(%rax)
	andnq	%r13, %r12, %r14
	xorq	%rbp, %r14
	movq	%r14, 16(%rax)
	andnq	%r11, %r13, %rbp
	xorq	%r12, %rbp
	movq	%rbp, 24(%rax)
	andnq	%rbx, %r11, %r11
	xorq	%r13, %r11
	movq	%r11, 32(%rax)
	movq	24(%rdx), %r11
	xorq	%r9, %r11
	rolq	$28, %r11
	movq	72(%rdx), %rbx
	xorq	%r10, %rbx
	rolq	$20, %rbx
	movq	80(%rdx), %rbp
	xorq	%rsi, %rbp
	rolq	$3, %rbp
	movq	128(%rdx), %r12
	xorq	%rdi, %r12
	rolq	$45, %r12
	movq	176(%rdx), %r13
	xorq	%r8, %r13
	rolq	$61, %r13
	andnq	%rbp, %rbx, %r14
	xorq	%r11, %r14
	movq	%r14, 40(%rax)
	andnq	%r12, %rbp, %r14
	xorq	%rbx, %r14
	movq	%r14, 48(%rax)
	andnq	%r13, %r12, %r14
	xorq	%rbp, %r14
	movq	%r14, 56(%rax)
	andnq	%r11, %r13, %rbp
	xorq	%r12, %rbp
	movq	%rbp, 64(%rax)
	andnq	%rbx, %r11, %r11
	xorq	%r13, %r11
	movq	%r11, 72(%rax)
	movq	8(%rdx), %r11
	xorq	%rdi, %r11
	rolq	$1, %r11
	movq	56(%rdx), %rbx
	xorq	%r8, %rbx
	rolq	$6, %rbx
	movq	104(%rdx), %rbp
	xorq	%r9, %rbp
	rolq	$25, %rbp
	movq	152(%rdx), %r12
	xorq	%r10, %r12
	rolq	$8, %r12
	movq	160(%rdx), %r13
	xorq	%rsi, %r13
	rolq	$18, %r13
	andnq	%rbp, %rbx, %r14
	xorq	%r11, %r14
	movq	%r14, 80(%rax)
	andnq	%r12, %rbp, %r14
	xorq	%rbx, %r14
	movq	%r14, 88(%rax)
	andnq	%r13, %r12, %r14
	xorq	%rbp, %r14
	movq	%r14, 96(%rax)
	andnq	%r11, %r13, %rbp
	xorq	%r12, %rbp
	movq	%rbp, 104(%rax)
	andnq	%rbx, %r11, %r11
	xorq	%r13, %r11
	movq	%r11, 112(%rax)
	movq	32(%rdx), %r11
	xorq	%r10, %r11
	rolq	$27, %r11
	movq	40(%rdx), %rbx
	xorq	%rsi, %rbx
	rolq	$36, %rbx
	movq	88(%rdx), %rbp
	xorq	%rdi, %rbp
	rolq	$10, %rbp
	movq	136(%rdx), %r12
	xorq	%r8, %r12
	rolq	$15, %r12
	movq	184(%rdx), %r13
	xorq	%r9, %r13
	rolq	$56, %r13
	andnq	%rbp, %rbx, %r14
	xorq	%r11, %r14
	movq	%r14, 120(%rax)
	andnq	%r12, %rbp, %r14
	xorq	%rbx, %r14
	movq	%r14, 128(%rax)
	andnq	%r13, %r12, %r14
	xorq	%rbp, %r14
	movq	%r14, 136(%rax)
	andnq	%r11, %r13, %rbp
	xorq	%r12, %rbp
	movq	%rbp, 144(%rax)
	andnq	%rbx, %r11, %r11
	xorq	%r13, %r11
	movq	%r11, 152(%rax)
	movq	16(%rdx), %r11
	xorq	%r8, %r11
	rolq	$62, %r11
	movq	64(%rdx), %r8
	xorq	%r9, %r8
	rolq	$55, %r8
	movq	112(%rdx), %r9
	xorq	%r10, %r9
	rolq	$39, %r9
	movq	120(%rdx), %r10
	xorq	%rsi, %r10
	rolq	$41, %r10
	movq	168(%rdx), %rsi
	xorq	%rdi, %rsi
	rolq	$2, %rsi
	andnq	%r9, %r8, %rdi
	xorq	%r11, %rdi
	movq	%rdi, 160(%rax)
	andnq	%r10, %r9, %rdi
	xorq	%r8, %rdi
	movq	%rdi, 168(%rax)
	andnq	%rsi, %r10, %rdi
	xorq	%r9, %rdi
	movq	%rdi, 176(%rax)
	andnq	%r11, %rsi, %rdi
	xorq	%r10, %rdi
	movq	%rdi, 184(%rax)
	andnq	%r8, %r11, %rdi
	xorq	%rsi, %rdi
	movq	%rdi, 192(%rax)
	movq	16(%rsp), %rsi
	leaq	2(%rsi), %rsi
L_keccakf1600$2:
	cmpq	$23, %rsi
	jb  	L_keccakf1600$3
	ret
Laes128ctr$1:
	movq	$0, %rdx
	movq	$0, %rsi
	movq	(%rcx), %rdi
	movq	8(%rcx), %rcx
	movq	%rdi, %xmm0
	vpinsrq	$1, %rcx, %xmm0, %xmm1
	vmovdqu	%xmm1, %xmm0
	vpxor	%xmm2, %xmm2, %xmm2
	aeskeygenassist	$1, %xmm1, %xmm3
	vpshufd	$255, %xmm3, %xmm3
	vshufps	$16, %xmm1, %xmm2, %xmm2
	vpxor	%xmm2, %xmm1, %xmm1
	vshufps	$140, %xmm1, %xmm2, %xmm2
	vpxor	%xmm2, %xmm1, %xmm1
	vpxor	%xmm3, %xmm1, %xmm3
	vmovdqu	%xmm3, %xmm1
	aeskeygenassist	$2, %xmm3, %xmm4
	vpshufd	$255, %xmm4, %xmm4
	vshufps	$16, %xmm3, %xmm2, %xmm2
	vpxor	%xmm2, %xmm3, %xmm3
	vshufps	$140, %xmm3, %xmm2, %xmm5
	vpxor	%xmm5, %xmm3, %xmm2
	vpxor	%xmm4, %xmm2, %xmm3
	vmovdqu	%xmm3, %xmm2
	aeskeygenassist	$4, %xmm3, %xmm4
	vpshufd	$255, %xmm4, %xmm4
	vshufps	$16, %xmm3, %xmm5, %xmm5
	vpxor	%xmm5, %xmm3, %xmm3
	vshufps	$140, %xmm3, %xmm5, %xmm5
	vpxor	%xmm5, %xmm3, %xmm3
	vpxor	%xmm4, %xmm3, %xmm4
	vmovdqu	%xmm4, %xmm3
	aeskeygenassist	$8, %xmm4, %xmm6
	vpshufd	$255, %xmm6, %xmm6
	vshufps	$16, %xmm4, %xmm5, %xmm5
	vpxor	%xmm5, %xmm4, %xmm4
	vshufps	$140, %xmm4, %xmm5, %xmm5
	vpxor	%xmm5, %xmm4, %xmm4
	vpxor	%xmm6, %xmm4, %xmm6
	vmovdqu	%xmm6, %xmm4
	aeskeygenassist	$16, %xmm6, %xmm7
	vpshufd	$255, %xmm7, %xmm7
	vshufps	$16, %xmm6, %xmm5, %xmm5
	vpxor	%xmm5, %xmm6, %xmm6
	vshufps	$140, %xmm6, %xmm5, %xmm8
	vpxor	%xmm8, %xmm6, %xmm5
	vpxor	%xmm7, %xmm5, %xmm6
	vmovdqu	%xmm6, %xmm5
	aeskeygenassist	$32, %xmm6, %xmm7
	vpshufd	$255, %xmm7, %xmm7
	vshufps	$16, %xmm6, %xmm8, %xmm8
	vpxor	%xmm8, %xmm6, %xmm6
	vshufps	$140, %xmm6, %xmm8, %xmm8
	vpxor	%xmm8, %xmm6, %xmm6
	vpxor	%xmm7, %xmm6, %xmm7
	vmovdqu	%xmm7, %xmm6
	aeskeygenassist	$64, %xmm7, %xmm9
	vpshufd	$255, %xmm9, %xmm9
	vshufps	$16, %xmm7, %xmm8, %xmm8
	vpxor	%xmm8, %xmm7, %xmm7
	vshufps	$140, %xmm7, %xmm8, %xmm8
	vpxor	%xmm8, %xmm7, %xmm7
	vpxor	%xmm9, %xmm7, %xmm9
	vmovdqu	%xmm9, %xmm7
	aeskeygenassist	$128, %xmm9, %xmm10
	vpshufd	$255, %xmm10, %xmm10
	vshufps	$16, %xmm9, %xmm8, %xmm8
	vpxor	%xmm8, %xmm9, %xmm9
	vshufps	$140, %xmm9, %xmm8, %xmm11
	vpxor	%xmm11, %xmm9, %xmm8
	vpxor	%xmm10, %xmm8, %xmm9
	vmovdqu	%xmm9, %xmm8
	aeskeygenassist	$27, %xmm9, %xmm10
	vpshufd	$255, %xmm10, %xmm10
	vshufps	$16, %xmm9, %xmm11, %xmm11
	vpxor	%xmm11, %xmm9, %xmm12
	vshufps	$140, %xmm12, %xmm11, %xmm9
	vpxor	%xmm9, %xmm12, %xmm11
	vpxor	%xmm10, %xmm11, %xmm12
	vmovdqu	%xmm12, %xmm10
	aeskeygenassist	$54, %xmm12, %xmm11
	vpshufd	$255, %xmm11, %xmm11
	vshufps	$16, %xmm12, %xmm9, %xmm9
	vpxor	%xmm9, %xmm12, %xmm12
	vshufps	$140, %xmm12, %xmm9, %xmm9
	vpxor	%xmm9, %xmm12, %xmm9
	vpxor	%xmm11, %xmm9, %xmm9
	movq	$5820, %rcx
	movq	$0, %rdi
	jmp 	Laes128ctr$2
Laes128ctr$3:
	movq	%rdx, %xmm11
	vpinsrq	$1, %rsi, %xmm11, %xmm11
	vpshufb	glob_data + 0(%rip), %xmm11, %xmm11
	call	Laes_rounds$1
Laes128ctr$4:
	addq	$1, %rdx
	adcq	$0, %rsi
	vpextrq	$0, %xmm11, %r8
	movq	%r8, (%rax,%rdi,8)
	leaq	1(%rdi), %rdi
	vpextrq	$1, %xmm11, %r8
	movq	%r8, (%rax,%rdi,8)
	leaq	1(%rdi), %rdi
	leaq	-1(%rcx), %rcx
Laes128ctr$2:
	cmpq	$0, %rcx
	jnbe	Laes128ctr$3
	ret
Laes_rounds$1:
	vpxor	%xmm0, %xmm11, %xmm11
	aesenc	%xmm1, %xmm11
	aesenc	%xmm2, %xmm11
	aesenc	%xmm3, %xmm11
	aesenc	%xmm4, %xmm11
	aesenc	%xmm5, %xmm11
	aesenc	%xmm6, %xmm11
	aesenc	%xmm7, %xmm11
	aesenc	%xmm8, %xmm11
	aesenc	%xmm10, %xmm11
	aesenclast	%xmm9, %xmm11
	ret
	.data
	.p2align	5
_glob_data:
glob_data:
G$perm:
	.byte	15
	.byte	14
	.byte	13
	.byte	12
	.byte	11
	.byte	10
	.byte	9
	.byte	8
	.byte	7
	.byte	6
	.byte	5
	.byte	4
	.byte	3
	.byte	2
	.byte	1
	.byte	0
G$KECCAK1600_RC:
	.byte	1
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	-126
	.byte	-128
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	-118
	.byte	-128
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	-128
	.byte	0
	.byte	-128
	.byte	0
	.byte	-128
	.byte	0
	.byte	0
	.byte	0
	.byte	-128
	.byte	-117
	.byte	-128
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	1
	.byte	0
	.byte	0
	.byte	-128
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	-127
	.byte	-128
	.byte	0
	.byte	-128
	.byte	0
	.byte	0
	.byte	0
	.byte	-128
	.byte	9
	.byte	-128
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	-128
	.byte	-118
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	-120
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	9
	.byte	-128
	.byte	0
	.byte	-128
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	10
	.byte	0
	.byte	0
	.byte	-128
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	-117
	.byte	-128
	.byte	0
	.byte	-128
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	-117
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	-128
	.byte	-119
	.byte	-128
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	-128
	.byte	3
	.byte	-128
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	-128
	.byte	2
	.byte	-128
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	-128
	.byte	-128
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	-128
	.byte	10
	.byte	-128
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	10
	.byte	0
	.byte	0
	.byte	-128
	.byte	0
	.byte	0
	.byte	0
	.byte	-128
	.byte	-127
	.byte	-128
	.byte	0
	.byte	-128
	.byte	0
	.byte	0
	.byte	0
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	-128
	.byte	1
	.byte	0
	.byte	0
	.byte	-128
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	8
	.byte	-128
	.byte	0
	.byte	-128
	.byte	0
	.byte	0
	.byte	0
	.byte	-128
G$seed_pk_g:
	.byte	91
	.byte	97
	.byte	66
	.byte	30
	.byte	-36
	.byte	28
	.byte	-112
	.byte	-17
	.byte	-81
	.byte	96
	.byte	117
	.byte	86
	.byte	15
	.byte	2
	.byte	6
	.byte	23
G$f_tail:
	.byte	8
	.byte	0
	.byte	2
	.byte	8
	.byte	0
G$tabler:
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	1
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	9
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	14
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	13
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	11
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	7
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	6
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	15
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	2
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	12
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	5
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	10
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	4
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	3
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	8
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
	.byte	0
